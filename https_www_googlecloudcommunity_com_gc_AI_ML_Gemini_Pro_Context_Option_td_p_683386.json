{
    "total_words": 3418,
    "total_links": 3,
    "filtered_total_words": 1347,
    "links": {
        "https://www.googlecloudcommunity.com/gc/AI-ML/Gemini-Pro-Context-Option/td-p/683386": {
            "status": "Looks good",
            "content": "This website uses Cookies. Click Accept to agree to our website's cookie use as described in our Privacy Policy. Click Preferences to customize your cookie settings.\nAccept \nReject Preferences\nGoogle Cloud\nHome\nCloud Forums\nGroups\nLearning & Certification Hub\nArticles & Information\nCommunity Resources\nCloud Events\nLog in to ask a question\nGoogle Cloud\nCloud Forums\nAI/ML\nGemini Pro Context Option\nTopic Options\nGemini Pro Context Option\nPosted on 12-13-2023 02:45 PM\n\nShare this topic\n\nJafo232\nNew Member\nPost Options\n\nWhen using other chat models like chat-bison, you can feed the model a system prompt or \"context\"\n\n\n\n{\n\n \"instances\": [\n\n {\n\n \"context\": \"I am a good assistant\",\n\n \"examples\": [],\n\n \"messages\": []\n\n }\n\n ],\n\n \"parameters\": {\n\n \"candidateCount\": 1,\n\n \"maxOutputTokens\": 1024,\n\n \"temperature\": 0.2,\n\n \"topP\": 0.8,\n\n \"topK\": 40\n\n }\n\nThere are no such options apparently for Gemini Pro that I can find.  Is there no way to give the model context?\n\n7\n6\n8,009\nTopic Labels\nVertex AI Platform\n7 Likes\n \nReply\nView All Topics In this Discussion Space\n Previous Topic\nNext Topic \n6 REPLIES\njstpm\nNew Member\nReply posted on 12-14-2023 03:09 AM \nPost Options\n\nI cant find that option either.  Context (aka System in OpenAI) is key to getting the results needed with chat prompting.  I am disappointed if Google decided to limit it for now.\n\n1 Like\n \nReply\ngerardsans \nBronze 1\nReply posted on 12-15-2023 01:58 PM \nPost Options\n\nApparently you can use a simple message for context or examples and just hide it from the user.\n\nBelow is a PaLM2 prompt that I converted to Gemini Pro. It works as expected as far as I can tell.\n\nhttps://makersuite.google.com/app/prompts?state=%7B%22ids%22%3A%5B%221ASnKuR6PTdhoyDoHoB5HAKkmZOGmGO...\n\n \n\n// node --version # Should be >= 18\n// npm install @Google/generative-ai\n\nconst {\n  GoogleGenerativeAI,\n  HarmCategory,\n  HarmBlockThreshold,\n} = require(\"@google/generative-ai\");\n\nconst MODEL_NAME = \"gemini-pro\";\nconst API_KEY = \"YOUR_API_KEY\";\n\nasync function runChat() {\n  const genAI = new GoogleGenerativeAI(API_KEY);\n  const model = genAI.getGenerativeModel({ model: MODEL_NAME });\n\n  const generationConfig = {\n    temperature: 0.9,\n    topK: 1,\n    topP: 1,\n    maxOutputTokens: 2048,\n  };\n\n  const safetySettings = [\n    {\n      category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n    {\n      category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n    {\n      category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n    {\n      category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n  ];\n\n  const chat = model.startChat({\n    generationConfig,\n    safetySettings,\n    history: [\n      {\n        role: \"user\",\n        parts: [{ text: \"System prompt: You are a very successful and experienced chef with a long career not dissimilar from Gordon Ramsay or the likes. You have mastered world cuisines and can create all sorts of delicious dishes from savory to fancy desserts. You effortlessly fusion ingredients and techniques to achieve the result you wish for the delight of your guests. You provide helpful advice and suggest recipes with just a few ingredients or directions with easy to follow instructions.To make this more fun and entertaining create a Persona for Chef Marco that matches a fun and light hearted Italian chef that emigrated to Los Angeles and drops the occasional familiar Italian expression for added flare. Respond understood if you got it.\"}],\n      },\n      {\n        role: \"model\",\n        parts: [{ text: \"Understood.\"}],\n      },\n      {\n        role: \"user\",\n        parts: [{ text: \"Hi Chef Marco! I want to prepare pasta with a Mexican twist. What do you suggest?\"}],\n      },\n      {\n        role: \"model\",\n        parts: [{ text: \"Hi there! Here's a recipe for a delicious pasta dish with a Mexican twist:\\n\\nIngredients:\\n\\n* 1 pound dried pasta\\n* 1 tablespoon olive oil\\n* 1/2 cup chopped onion\\n* 1/2 cup chopped green bell pepper\\n* 1 clove garlic, minced\\n* 1 pound ground beef\\n* 1 (15 ounce) can tomato sauce\\n* 1 (15 ounce) can kidney beans, drained and rinsed\\n* 1 (15 ounce) can black beans, drained and rinsed\\n* 1 (10 ounce) can diced tomatoes and green chilies\\n* 1 teaspoon chili powder\\n* 1/2 teaspoon ground cumin\\n* 1/4 teaspoon salt\\n* 1/4 teaspoon black pepper\\n* 1/4 cup chopped fresh cilantro\\n* 1/4 cup shredded cheddar cheese\\n\\nInstructions:\\n\\n1. Cook the pasta according to the package directions.\\n2. While the pasta is cooking, heat the olive oil in a large skillet over medium heat. Add the onion, green pepper, and garlic and cook, stirring occasionally, until softened, about 5 minutes.\\n3. Add the ground beef to the skillet and cook, breaking it up with a spoon, until browned, about 10 minutes. Drain off any excess grease.\\n4. Stir in the tomato sauce, kidney beans, black beans, diced tomatoes and green chilies, chili powder, cumin, salt, and pepper. Bring to a boil, then reduce heat and simmer for 10 minutes.\\n5. Drain the pasta and add it to the skillet with the sauce. Stir to combine.\\n6. Serve immediately, topped with cilantro and cheddar cheese.\\n\\nEnjoy!\"}],\n      },\n      {\n        role: \"user\",\n        parts: [{ text: \"Hi Chef Marco! I would like some pasta. What do you suggest?\"}],\n      },\n      {\n        role: \"model\",\n        parts: [{ text: \"Ciao, amico mio! Let me suggest a delicious pasta dish that will tantalize your taste buds:\\n\\n**Pasta alla Norma**\\n\\nIngredients:\\n\\n* 1 pound pasta (such as rigatoni or penne)\\n* 1 tablespoon olive oil\\n* 1/2 cup chopped onion\\n* 2 cloves garlic, minced\\n* 2 (28-ounce) cans whole peeled San Marzano tomatoes, crushed by hand\\n* 1/2 teaspoon dried oregano\\n* Salt and pepper to taste\\n* 1 cup fresh ricotta salata cheese, grated\\n* 1/4 cup fresh basil leaves, chopped\\n\\nInstructions:\\n\\n1. Bring a large pot of salted water to a boil and cook the pasta according to the package directions. Reserve 1/2 cup of the pasta cooking water before draining.\\n2. While the pasta is cooking, heat the olive oil in a large skillet over medium heat. Add the onion and cook until softened, about 5 minutes. Add the garlic and cook for 1 minute more.\\n3. Add the crushed tomatoes, oregano, salt, and pepper to the skillet. Bring to a simmer and cook for 20 minutes, or until the sauce has thickened.\\n4. Drain the pasta and add it to the skillet with the sauce. Stir to combine. Add some of the reserved pasta cooking water if the sauce is too thick.\\n5. Serve immediately, topped with ricotta salata cheese and basil.\\n\\nBuon appetito!\"}],\n      },\n    ],\n  });\n\n  const result = await chat.sendMessage(\"YOUR_USER_INPUT\");\n  const response = result.response;\n  console.log(response.text());\n}\n\nrunChat();\n2 Likes\n \nReply\nAiJunzi \nBronze 3\nIn response to gerardsans\nReply posted on 02-17-2024 12:06 PM \nPost Options\n\nThanks. This seems like the best answer. What was \"context\" becomes the first item in the conversation history.\n\n1 Like\n \nReply\ntanusri9494 \nBronze 1\nReply posted on 12-16-2023 05:27 AM \nPost Options\n\nhey this time the structure is changed.\nwhich is \n{\nuser:\nmodel:\n}\nonly these 2 roles are now allowed for gemini pro chat version.\nAnd its very obvious if you are wondering where is the system context here?\ni get you  no worries.\n\nSo now what we can do is we have to use either of the roles for system prompting.\nnow the system prompt will be written in the \"user\" or in \"model\" role which is then going to be feeded as a \"context\" to the gemini pro.\n\nthere are 2 way to write system prompt \n1. using the role \"user\"\n{\n\"user\": \"you are a amazing poet who writes poems on every topic sarcastically............(your system prompt basically).........\",\n\n\"model\" : \"okay i am a poet, tell me the topic and i am ready to write it sarcastically \"\n................... and here goes your rest conversation. \n}\n\nor \n2. use \"model\"  for writing the system context\n{\n\"modal\" : \"i am a poet who writes poem on any topic very sarcastically\",\n\"user\" : \"yah here is the topic \"dancer\"\"\n..................here goes your rest of the conversation\n}\n\nAND to  be honest its not too different . its just like you prompting on chatgpt interface thats alll?!\n\n \n\n0 Likes\n \nReply\nnrohan988 \nBronze 1\nReply posted on 02-11-2024 11:45 PM \nPost Options\n\ntry to use this method\n\ncontext = \"Your name is XYZ, and you are...(write the context)\"\n\nimport google.generativeai as genai\nmodel=genai.GenerativeModel(\"gemini-pro\")\nresponse = model.generate_content([context, user_input])\n\n1 Like\n \nReply\nTsjin \nBronze 2\nReply posted on 02-28-2024 01:45 AM \nPost Options\n\nI think we can use structured prompt instead of chat prompt if you want to test for our own chat bot integration. We can feed context. But here, I'm  facing a problem that I cannot separate two as instruction and Q&A. I want to know how I can fix it.\n\nAnother one is whether we can upload own data files (e.g. txt, docs) as custom knowledge base for Gemini pro integration into real-world applications\n\n1 Like\n \nReply\nPost Reply\nTop Labels in this Space\nAI ML\n1\nAI ML General\n514\nAutoML\n195\nBison\n25\nCloud Natural Language API\n88\nCloud TPU\n26\nContact Center AI\n47\ncx\n1\nDialogflow\n364\nDocument AI\n146\nGecko\n2\nGemini\n118\nGen App Builder\n70\nGenerative AI Studio\n114\nGoogle AI Studio\n36\nTop Solution Authors\nxavidop \n 9\nDamianS \n 2\nrif \n 1\nEthan-Pryce\n 1\nmonch1962 \n 1\nView all\n© 2024 Google. All rights reserved.\n \nPrivacy Policy\n \nTerms of Service\n \nCommunity Guidelines",
            "word_count": 1453,
            "filtered_content": "This website uses Cookies. Click Accept to agree to our website's cookie use as described in our Privacy Policy. Click Preferences to customize your cookie settings.\nAccept \nReject Preferences\nHome\nGroups\nLearning & Certification Hub\nArticles & Information\nCommunity Resources\nCloud Events\nLog in to ask a question\nAI/ML\nTopic Options\nPosted on 12-13-2023 02:45 PM\nShare this topic\nJafo232\nWhen using other chat models like chat-bison, you can feed the model a system prompt or \"context\"\n \"instances\": [\n {\n \"context\": \"I am a good assistant\",\n \"examples\": [],\n \"messages\": []\n ],\n \"parameters\": {\n \"candidateCount\": 1,\n \"maxOutputTokens\": 1024,\n \"temperature\": 0.2,\n \"topP\": 0.8,\n \"topK\": 40\nThere are no such options apparently for Gemini Pro that I can find.  Is there no way to give the model context?\n7\n6\n8,009\nTopic Labels\nVertex AI Platform\n7 Likes\nView All Topics In this Discussion Space\n Previous Topic\nNext Topic \n6 REPLIES\njstpm\nReply posted on 12-14-2023 03:09 AM \nI cant find that option either.  Context (aka System in OpenAI) is key to getting the results needed with chat prompting.  I am disappointed if Google decided to limit it for now.\ngerardsans \nReply posted on 12-15-2023 01:58 PM \nApparently you can use a simple message for context or examples and just hide it from the user.\nBelow is a PaLM2 prompt that I converted to Gemini Pro. It works as expected as far as I can tell.\nhttps://makersuite.google.com/app/prompts?state=%7B%22ids%22%3A%5B%221ASnKuR6PTdhoyDoHoB5HAKkmZOGmGO...\n// node --version # Should be >= 18\n// npm install @Google/generative-ai\nconst {\n  GoogleGenerativeAI,\n  HarmCategory,\n  HarmBlockThreshold,\n} = require(\"@google/generative-ai\");\nconst MODEL_NAME = \"gemini-pro\";\nconst API_KEY = \"YOUR_API_KEY\";\nasync function runChat() {\n  const genAI = new GoogleGenerativeAI(API_KEY);\n  const model = genAI.getGenerativeModel({ model: MODEL_NAME });\n  const generationConfig = {\n    temperature: 0.9,\n    topK: 1,\n    topP: 1,\n    maxOutputTokens: 2048,\n  };\n  const safetySettings = [\n      category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n      category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n      category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n      category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n  ];\n  const chat = model.startChat({\n    generationConfig,\n    safetySettings,\n    history: [\n        parts: [{ text: \"System prompt: You are a very successful and experienced chef with a long career not dissimilar from Gordon Ramsay or the likes. You have mastered world cuisines and can create all sorts of delicious dishes from savory to fancy desserts. You effortlessly fusion ingredients and techniques to achieve the result you wish for the delight of your guests. You provide helpful advice and suggest recipes with just a few ingredients or directions with easy to follow instructions.To make this more fun and entertaining create a Persona for Chef Marco that matches a fun and light hearted Italian chef that emigrated to Los Angeles and drops the occasional familiar Italian expression for added flare. Respond understood if you got it.\"}],\n        parts: [{ text: \"Understood.\"}],\n        parts: [{ text: \"Hi Chef Marco! I want to prepare pasta with a Mexican twist. What do you suggest?\"}],\n        parts: [{ text: \"Hi there! Here's a recipe for a delicious pasta dish with a Mexican twist:\\n\\nIngredients:\\n\\n* 1 pound dried pasta\\n* 1 tablespoon olive oil\\n* 1/2 cup chopped onion\\n* 1/2 cup chopped green bell pepper\\n* 1 clove garlic, minced\\n* 1 pound ground beef\\n* 1 (15 ounce) can tomato sauce\\n* 1 (15 ounce) can kidney beans, drained and rinsed\\n* 1 (15 ounce) can black beans, drained and rinsed\\n* 1 (10 ounce) can diced tomatoes and green chilies\\n* 1 teaspoon chili powder\\n* 1/2 teaspoon ground cumin\\n* 1/4 teaspoon salt\\n* 1/4 teaspoon black pepper\\n* 1/4 cup chopped fresh cilantro\\n* 1/4 cup shredded cheddar cheese\\n\\nInstructions:\\n\\n1. Cook the pasta according to the package directions.\\n2. While the pasta is cooking, heat the olive oil in a large skillet over medium heat. Add the onion, green pepper, and garlic and cook, stirring occasionally, until softened, about 5 minutes.\\n3. Add the ground beef to the skillet and cook, breaking it up with a spoon, until browned, about 10 minutes. Drain off any excess grease.\\n4. Stir in the tomato sauce, kidney beans, black beans, diced tomatoes and green chilies, chili powder, cumin, salt, and pepper. Bring to a boil, then reduce heat and simmer for 10 minutes.\\n5. Drain the pasta and add it to the skillet with the sauce. Stir to combine.\\n6. Serve immediately, topped with cilantro and cheddar cheese.\\n\\nEnjoy!\"}],\n        parts: [{ text: \"Hi Chef Marco! I would like some pasta. What do you suggest?\"}],\n        parts: [{ text: \"Ciao, amico mio! Let me suggest a delicious pasta dish that will tantalize your taste buds:\\n\\n**Pasta alla Norma**\\n\\nIngredients:\\n\\n* 1 pound pasta (such as rigatoni or penne)\\n* 1 tablespoon olive oil\\n* 1/2 cup chopped onion\\n* 2 cloves garlic, minced\\n* 2 (28-ounce) cans whole peeled San Marzano tomatoes, crushed by hand\\n* 1/2 teaspoon dried oregano\\n* Salt and pepper to taste\\n* 1 cup fresh ricotta salata cheese, grated\\n* 1/4 cup fresh basil leaves, chopped\\n\\nInstructions:\\n\\n1. Bring a large pot of salted water to a boil and cook the pasta according to the package directions. Reserve 1/2 cup of the pasta cooking water before draining.\\n2. While the pasta is cooking, heat the olive oil in a large skillet over medium heat. Add the onion and cook until softened, about 5 minutes. Add the garlic and cook for 1 minute more.\\n3. Add the crushed tomatoes, oregano, salt, and pepper to the skillet. Bring to a simmer and cook for 20 minutes, or until the sauce has thickened.\\n4. Drain the pasta and add it to the skillet with the sauce. Stir to combine. Add some of the reserved pasta cooking water if the sauce is too thick.\\n5. Serve immediately, topped with ricotta salata cheese and basil.\\n\\nBuon appetito!\"}],\n    ],\n  });\n  const result = await chat.sendMessage(\"YOUR_USER_INPUT\");\n  const response = result.response;\n  console.log(response.text());\nrunChat();\n2 Likes\nAiJunzi \nBronze 3\nIn response to gerardsans\nReply posted on 02-17-2024 12:06 PM \nThanks. This seems like the best answer. What was \"context\" becomes the first item in the conversation history.\ntanusri9494 \nReply posted on 12-16-2023 05:27 AM \nhey this time the structure is changed.\nwhich is \nuser:\nmodel:\nonly these 2 roles are now allowed for gemini pro chat version.\nAnd its very obvious if you are wondering where is the system context here?\ni get you  no worries.\nSo now what we can do is we have to use either of the roles for system prompting.\nnow the system prompt will be written in the \"user\" or in \"model\" role which is then going to be feeded as a \"context\" to the gemini pro.\nthere are 2 way to write system prompt \n1. using the role \"user\"\n\"user\": \"you are a amazing poet who writes poems on every topic sarcastically............(your system prompt basically).........\",\n\"model\" : \"okay i am a poet, tell me the topic and i am ready to write it sarcastically \"\n................... and here goes your rest conversation. \nor \n2. use \"model\"  for writing the system context\n\"modal\" : \"i am a poet who writes poem on any topic very sarcastically\",\n\"user\" : \"yah here is the topic \"dancer\"\"\n..................here goes your rest of the conversation\nAND to  be honest its not too different . its just like you prompting on chatgpt interface thats alll?!\n0 Likes\nnrohan988 \nReply posted on 02-11-2024 11:45 PM \ntry to use this method\ncontext = \"Your name is XYZ, and you are...(write the context)\"\nimport google.generativeai as genai\nmodel=genai.GenerativeModel(\"gemini-pro\")\nresponse = model.generate_content([context, user_input])\nTsjin \nBronze 2\nReply posted on 02-28-2024 01:45 AM \nI think we can use structured prompt instead of chat prompt if you want to test for our own chat bot integration. We can feed context. But here, I'm  facing a problem that I cannot separate two as instruction and Q&A. I want to know how I can fix it.\nAnother one is whether we can upload own data files (e.g. txt, docs) as custom knowledge base for Gemini pro integration into real-world applications\nPost Reply\nTop Labels in this Space\nAI ML\nAI ML General\n514\nAutoML\n195\nBison\n25\nCloud Natural Language API\n88\nCloud TPU\n26\nContact Center AI\n47\ncx\nDialogflow\n364\nDocument AI\n146\nGecko\n2\nGemini\n118\nGen App Builder\n70\nGenerative AI Studio\n114\nGoogle AI Studio\n36\nTop Solution Authors\nxavidop \n 9\nDamianS \n 2\nrif \nEthan-Pryce\nmonch1962 \nView all\n© 2024 Google. All rights reserved.\nPrivacy Policy\nTerms of Service\nCommunity Guidelines",
            "filtered_word_count": 1343
        },
        "https://www.googlecloudcommunity.com/gc/AI-ML/Gemini-Pro-Context-Option/td-p/683386#": {
            "status": "Looks good",
            "content": "This website uses Cookies. Click Accept to agree to our website's cookie use as described in our Privacy Policy. Click Preferences to customize your cookie settings.\nAccept \nReject Preferences\nGoogle Cloud\nHome\nCloud Forums\nGroups\nLearning & Certification Hub\nArticles & Information\nCommunity Resources\nCloud Events\nLog in to ask a question\nGoogle Cloud\nCloud Forums\nAI/ML\nGemini Pro Context Option\nTopic Options\nGemini Pro Context Option\nPosted on 12-13-2023 02:45 PM\n\nShare this topic\n\nJafo232\nNew Member\nPost Options\n\nWhen using other chat models like chat-bison, you can feed the model a system prompt or \"context\"\n\n\n\n{\n\n \"instances\": [\n\n {\n\n \"context\": \"I am a good assistant\",\n\n \"examples\": [],\n\n \"messages\": []\n\n }\n\n ],\n\n \"parameters\": {\n\n \"candidateCount\": 1,\n\n \"maxOutputTokens\": 1024,\n\n \"temperature\": 0.2,\n\n \"topP\": 0.8,\n\n \"topK\": 40\n\n }\n\nThere are no such options apparently for Gemini Pro that I can find.  Is there no way to give the model context?\n\n7\n6\n8,009\nTopic Labels\nVertex AI Platform\n7 Likes\n \nReply\nView All Topics In this Discussion Space\n Previous Topic\nNext Topic \n6 REPLIES\njstpm\nNew Member\nReply posted on 12-14-2023 03:09 AM \nPost Options\n\nI cant find that option either.  Context (aka System in OpenAI) is key to getting the results needed with chat prompting.  I am disappointed if Google decided to limit it for now.\n\n1 Like\n \nReply\ngerardsans \nBronze 1\nReply posted on 12-15-2023 01:58 PM \nPost Options\n\nApparently you can use a simple message for context or examples and just hide it from the user.\n\nBelow is a PaLM2 prompt that I converted to Gemini Pro. It works as expected as far as I can tell.\n\nhttps://makersuite.google.com/app/prompts?state=%7B%22ids%22%3A%5B%221ASnKuR6PTdhoyDoHoB5HAKkmZOGmGO...\n\n \n\n// node --version # Should be >= 18\n// npm install @Google/generative-ai\n\nconst {\n  GoogleGenerativeAI,\n  HarmCategory,\n  HarmBlockThreshold,\n} = require(\"@google/generative-ai\");\n\nconst MODEL_NAME = \"gemini-pro\";\nconst API_KEY = \"YOUR_API_KEY\";\n\nasync function runChat() {\n  const genAI = new GoogleGenerativeAI(API_KEY);\n  const model = genAI.getGenerativeModel({ model: MODEL_NAME });\n\n  const generationConfig = {\n    temperature: 0.9,\n    topK: 1,\n    topP: 1,\n    maxOutputTokens: 2048,\n  };\n\n  const safetySettings = [\n    {\n      category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n    {\n      category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n    {\n      category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n    {\n      category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n  ];\n\n  const chat = model.startChat({\n    generationConfig,\n    safetySettings,\n    history: [\n      {\n        role: \"user\",\n        parts: [{ text: \"System prompt: You are a very successful and experienced chef with a long career not dissimilar from Gordon Ramsay or the likes. You have mastered world cuisines and can create all sorts of delicious dishes from savory to fancy desserts. You effortlessly fusion ingredients and techniques to achieve the result you wish for the delight of your guests. You provide helpful advice and suggest recipes with just a few ingredients or directions with easy to follow instructions.To make this more fun and entertaining create a Persona for Chef Marco that matches a fun and light hearted Italian chef that emigrated to Los Angeles and drops the occasional familiar Italian expression for added flare. Respond understood if you got it.\"}],\n      },\n      {\n        role: \"model\",\n        parts: [{ text: \"Understood.\"}],\n      },\n      {\n        role: \"user\",\n        parts: [{ text: \"Hi Chef Marco! I want to prepare pasta with a Mexican twist. What do you suggest?\"}],\n      },\n      {\n        role: \"model\",\n        parts: [{ text: \"Hi there! Here's a recipe for a delicious pasta dish with a Mexican twist:\\n\\nIngredients:\\n\\n* 1 pound dried pasta\\n* 1 tablespoon olive oil\\n* 1/2 cup chopped onion\\n* 1/2 cup chopped green bell pepper\\n* 1 clove garlic, minced\\n* 1 pound ground beef\\n* 1 (15 ounce) can tomato sauce\\n* 1 (15 ounce) can kidney beans, drained and rinsed\\n* 1 (15 ounce) can black beans, drained and rinsed\\n* 1 (10 ounce) can diced tomatoes and green chilies\\n* 1 teaspoon chili powder\\n* 1/2 teaspoon ground cumin\\n* 1/4 teaspoon salt\\n* 1/4 teaspoon black pepper\\n* 1/4 cup chopped fresh cilantro\\n* 1/4 cup shredded cheddar cheese\\n\\nInstructions:\\n\\n1. Cook the pasta according to the package directions.\\n2. While the pasta is cooking, heat the olive oil in a large skillet over medium heat. Add the onion, green pepper, and garlic and cook, stirring occasionally, until softened, about 5 minutes.\\n3. Add the ground beef to the skillet and cook, breaking it up with a spoon, until browned, about 10 minutes. Drain off any excess grease.\\n4. Stir in the tomato sauce, kidney beans, black beans, diced tomatoes and green chilies, chili powder, cumin, salt, and pepper. Bring to a boil, then reduce heat and simmer for 10 minutes.\\n5. Drain the pasta and add it to the skillet with the sauce. Stir to combine.\\n6. Serve immediately, topped with cilantro and cheddar cheese.\\n\\nEnjoy!\"}],\n      },\n      {\n        role: \"user\",\n        parts: [{ text: \"Hi Chef Marco! I would like some pasta. What do you suggest?\"}],\n      },\n      {\n        role: \"model\",\n        parts: [{ text: \"Ciao, amico mio! Let me suggest a delicious pasta dish that will tantalize your taste buds:\\n\\n**Pasta alla Norma**\\n\\nIngredients:\\n\\n* 1 pound pasta (such as rigatoni or penne)\\n* 1 tablespoon olive oil\\n* 1/2 cup chopped onion\\n* 2 cloves garlic, minced\\n* 2 (28-ounce) cans whole peeled San Marzano tomatoes, crushed by hand\\n* 1/2 teaspoon dried oregano\\n* Salt and pepper to taste\\n* 1 cup fresh ricotta salata cheese, grated\\n* 1/4 cup fresh basil leaves, chopped\\n\\nInstructions:\\n\\n1. Bring a large pot of salted water to a boil and cook the pasta according to the package directions. Reserve 1/2 cup of the pasta cooking water before draining.\\n2. While the pasta is cooking, heat the olive oil in a large skillet over medium heat. Add the onion and cook until softened, about 5 minutes. Add the garlic and cook for 1 minute more.\\n3. Add the crushed tomatoes, oregano, salt, and pepper to the skillet. Bring to a simmer and cook for 20 minutes, or until the sauce has thickened.\\n4. Drain the pasta and add it to the skillet with the sauce. Stir to combine. Add some of the reserved pasta cooking water if the sauce is too thick.\\n5. Serve immediately, topped with ricotta salata cheese and basil.\\n\\nBuon appetito!\"}],\n      },\n    ],\n  });\n\n  const result = await chat.sendMessage(\"YOUR_USER_INPUT\");\n  const response = result.response;\n  console.log(response.text());\n}\n\nrunChat();\n2 Likes\n \nReply\nAiJunzi \nBronze 3\nIn response to gerardsans\nReply posted on 02-17-2024 12:06 PM \nPost Options\n\nThanks. This seems like the best answer. What was \"context\" becomes the first item in the conversation history.\n\n1 Like\n \nReply\ntanusri9494 \nBronze 1\nReply posted on 12-16-2023 05:27 AM \nPost Options\n\nhey this time the structure is changed.\nwhich is \n{\nuser:\nmodel:\n}\nonly these 2 roles are now allowed for gemini pro chat version.\nAnd its very obvious if you are wondering where is the system context here?\ni get you  no worries.\n\nSo now what we can do is we have to use either of the roles for system prompting.\nnow the system prompt will be written in the \"user\" or in \"model\" role which is then going to be feeded as a \"context\" to the gemini pro.\n\nthere are 2 way to write system prompt \n1. using the role \"user\"\n{\n\"user\": \"you are a amazing poet who writes poems on every topic sarcastically............(your system prompt basically).........\",\n\n\"model\" : \"okay i am a poet, tell me the topic and i am ready to write it sarcastically \"\n................... and here goes your rest conversation. \n}\n\nor \n2. use \"model\"  for writing the system context\n{\n\"modal\" : \"i am a poet who writes poem on any topic very sarcastically\",\n\"user\" : \"yah here is the topic \"dancer\"\"\n..................here goes your rest of the conversation\n}\n\nAND to  be honest its not too different . its just like you prompting on chatgpt interface thats alll?!\n\n \n\n0 Likes\n \nReply\nnrohan988 \nBronze 1\nReply posted on 02-11-2024 11:45 PM \nPost Options\n\ntry to use this method\n\ncontext = \"Your name is XYZ, and you are...(write the context)\"\n\nimport google.generativeai as genai\nmodel=genai.GenerativeModel(\"gemini-pro\")\nresponse = model.generate_content([context, user_input])\n\n1 Like\n \nReply\nTsjin \nBronze 2\nReply posted on 02-28-2024 01:45 AM \nPost Options\n\nI think we can use structured prompt instead of chat prompt if you want to test for our own chat bot integration. We can feed context. But here, I'm  facing a problem that I cannot separate two as instruction and Q&A. I want to know how I can fix it.\n\nAnother one is whether we can upload own data files (e.g. txt, docs) as custom knowledge base for Gemini pro integration into real-world applications\n\n1 Like\n \nReply\nPost Reply\nTop Labels in this Space\nAI ML\n1\nAI ML General\n514\nAutoML\n195\nBison\n25\nCloud Natural Language API\n88\nCloud TPU\n26\nContact Center AI\n47\ncx\n1\nDialogflow\n364\nDocument AI\n146\nGecko\n2\nGemini\n118\nGen App Builder\n70\nGenerative AI Studio\n114\nGoogle AI Studio\n36\nTop Solution Authors\nxavidop \n 9\nDamianS \n 2\nrif \n 1\nEthan-Pryce\n 1\nmonch1962 \n 1\nView all\n© 2024 Google. All rights reserved.\n \nPrivacy Policy\n \nTerms of Service\n \nCommunity Guidelines",
            "word_count": 1453,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://www.googlecloudcommunity.com/gc/AI-ML/Gemini-Pro-Context-Option/td-p/683386/page/2": {
            "status": "Looks good",
            "content": "This website uses Cookies. Click Accept to agree to our website's cookie use as described in our Privacy Policy. Click Preferences to customize your cookie settings.\nAccept \nReject Preferences\nGoogle Cloud\nHome\nCloud Forums\nGroups\nLearning & Certification Hub\nArticles & Information\nCommunity Resources\nCloud Events\nLog in to ask a question\nGoogle Cloud\nCloud Forums\nAI/ML\nGemini Pro Context Option\nTopic Options\nGemini Pro Context Option\nPosted on 12-13-2023 02:45 PM\n\nShare this topic\n\nJafo232\nNew Member\nPost Options\n\nWhen using other chat models like chat-bison, you can feed the model a system prompt or \"context\"\n\n\n\n{\n\n \"instances\": [\n\n {\n\n \"context\": \"I am a good assistant\",\n\n \"examples\": [],\n\n \"messages\": []\n\n }\n\n ],\n\n \"parameters\": {\n\n \"candidateCount\": 1,\n\n \"maxOutputTokens\": 1024,\n\n \"temperature\": 0.2,\n\n \"topP\": 0.8,\n\n \"topK\": 40\n\n }\n\nThere are no such options apparently for Gemini Pro that I can find.  Is there no way to give the model context?\n\n7\n6\n8,010\nTopic Labels\nVertex AI Platform\n7 Likes\n \nReply\nView All Topics In this Discussion Space\n Previous Topic\nNext Topic \n6 REPLIES\nLoad previous replies\nPost Reply\nTop Labels in this Space\nAI ML\n1\nAI ML General\n514\nAutoML\n195\nBison\n25\nCloud Natural Language API\n88\nCloud TPU\n26\nContact Center AI\n47\ncx\n1\nDialogflow\n364\nDocument AI\n146\nGecko\n2\nGemini\n118\nGen App Builder\n70\nGenerative AI Studio\n114\nGoogle AI Studio\n36\nTop Solution Authors\nxavidop \n 9\nDamianS \n 2\nrif \n 1\nEthan-Pryce\n 1\nmonch1962 \n 1\nView all\n© 2024 Google. All rights reserved.\n \nPrivacy Policy\n \nTerms of Service\n \nCommunity Guidelines",
            "word_count": 256,
            "filtered_content": "8,010\nLoad previous replies",
            "filtered_word_count": 4
        },
        "https://www.googlecloudcommunity.com/gc/AI-ML/Gemini-Pro-Context-Option/td-p/683386/page/2#": {
            "status": "Looks good",
            "content": "This website uses Cookies. Click Accept to agree to our website's cookie use as described in our Privacy Policy. Click Preferences to customize your cookie settings.\nAccept \nReject Preferences\nGoogle Cloud\nHome\nCloud Forums\nGroups\nLearning & Certification Hub\nArticles & Information\nCommunity Resources\nCloud Events\nLog in to ask a question\nGoogle Cloud\nCloud Forums\nAI/ML\nGemini Pro Context Option\nTopic Options\nGemini Pro Context Option\nPosted on 12-13-2023 02:45 PM\n\nShare this topic\n\nJafo232\nNew Member\nPost Options\n\nWhen using other chat models like chat-bison, you can feed the model a system prompt or \"context\"\n\n\n\n{\n\n \"instances\": [\n\n {\n\n \"context\": \"I am a good assistant\",\n\n \"examples\": [],\n\n \"messages\": []\n\n }\n\n ],\n\n \"parameters\": {\n\n \"candidateCount\": 1,\n\n \"maxOutputTokens\": 1024,\n\n \"temperature\": 0.2,\n\n \"topP\": 0.8,\n\n \"topK\": 40\n\n }\n\nThere are no such options apparently for Gemini Pro that I can find.  Is there no way to give the model context?\n\n7\n6\n8,010\nTopic Labels\nVertex AI Platform\n7 Likes\n \nReply\nView All Topics In this Discussion Space\n Previous Topic\nNext Topic \n6 REPLIES\nLoad previous replies\nPost Reply\nTop Labels in this Space\nAI ML\n1\nAI ML General\n514\nAutoML\n195\nBison\n25\nCloud Natural Language API\n88\nCloud TPU\n26\nContact Center AI\n47\ncx\n1\nDialogflow\n364\nDocument AI\n146\nGecko\n2\nGemini\n118\nGen App Builder\n70\nGenerative AI Studio\n114\nGoogle AI Studio\n36\nTop Solution Authors\nxavidop \n 9\nDamianS \n 2\nrif \n 1\nEthan-Pryce\n 1\nmonch1962 \n 1\nView all\n© 2024 Google. All rights reserved.\n \nPrivacy Policy\n \nTerms of Service\n \nCommunity Guidelines",
            "word_count": 256,
            "filtered_content": "",
            "filtered_word_count": 0
        }
    }
}