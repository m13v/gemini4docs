{
    "total_words": 143670,
    "total_links": 1910,
    "filtered_total_words": 85461,
    "links": {
        "https://ai.google.dev/gemini-api/docs": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nCheck out the new Gemini API Cookbook and our community forum.\nGet started with the Gemini API \n\nGemini is a family of Google's most capable AI models. This site contains all the info you need to start building applications with the Gemini API.\n\nGemini 1.5 Pro is now available in Public Preview in Google AI Studio. Try it now.\n\nGoogle AI Studio \n\nThe fastest way to start using Gemini is with Google AI Studio, a web-based tool that lets you prototype, run prompts right in your browser, and get started with the Gemini API.\n\nLaunch Google AI Studio\nGoogle AI Studio quickstart\n\nTo get started, head to the Gemini API quickstart.\n\nTo learn how to use LLMs safely and responsibly, refer to the safety settings and safety guidance documentation.\n\nGet started with Python\nGet started with the REST API\nGet started on the Web\nGet started with Go\nGet started with Node\nGet started on Android\nGet started on iOS\nGet started with Dart (Flutter)\nBuild on Google Cloud\nFurther reading\nTo learn more about the models that power the Gemini API, refer to the models page.\nThe Gemini API and Google AI Studio are currently available in 180+ countries, check out the documentation to learn more.\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 358,
            "filtered_content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nCheck out the new Gemini API Cookbook and our community forum.\nGet started with the Gemini API \nGemini is a family of Google's most capable AI models. This site contains all the info you need to start building applications with the Gemini API.\nGemini 1.5 Pro is now available in Public Preview in Google AI Studio. Try it now.\nGoogle AI Studio \nThe fastest way to start using Gemini is with Google AI Studio, a web-based tool that lets you prototype, run prompts right in your browser, and get started with the Gemini API.\nLaunch Google AI Studio\nTo get started, head to the Gemini API quickstart.\nTo learn how to use LLMs safely and responsibly, refer to the safety settings and safety guidance documentation.\nGet started with Python\nGet started with the REST API\nGet started on the Web\nGet started with Go\nGet started with Node\nGet started on Android\nGet started on iOS\nGet started with Dart (Flutter)\nBuild on Google Cloud\nFurther reading\nTo learn more about the models that power the Gemini API, refer to the models page.\nThe Gemini API and Google AI Studio are currently available in 180+ countries, check out the documentation to learn more.\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\nLast updated 2024-04-23 UTC.\nTerms\nPrivacy",
            "filtered_word_count": 344
        },
        "https://ai.google.dev/gemini-api/docs#": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nCheck out the new Gemini API Cookbook and our community forum.\nGet started with the Gemini API \n\nGemini is a family of Google's most capable AI models. This site contains all the info you need to start building applications with the Gemini API.\n\nGemini 1.5 Pro is now available in Public Preview in Google AI Studio. Try it now.\n\nGoogle AI Studio \n\nThe fastest way to start using Gemini is with Google AI Studio, a web-based tool that lets you prototype, run prompts right in your browser, and get started with the Gemini API.\n\nLaunch Google AI Studio\nGoogle AI Studio quickstart\n\nTo get started, head to the Gemini API quickstart.\n\nTo learn how to use LLMs safely and responsibly, refer to the safety settings and safety guidance documentation.\n\nGet started with Python\nGet started with the REST API\nGet started on the Web\nGet started with Go\nGet started with Node\nGet started on Android\nGet started on iOS\nGet started with Dart (Flutter)\nBuild on Google Cloud\nFurther reading\nTo learn more about the models that power the Gemini API, refer to the models page.\nThe Gemini API and Google AI Studio are currently available in 180+ countries, check out the documentation to learn more.\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy\nThe new page has loaded.",
            "word_count": 363,
            "filtered_content": "The new page has loaded.",
            "filtered_word_count": 5
        },
        "https://ai.google.dev/gemini-api/docs?hl=de": {
            "status": "Looks good",
            "content": "Produkte\nBeispiele\nAnmelden\nDokumentation\nAPI-Referenz\nÜberblick\nJetzt starten\nAPI-Schlüssel anfordern\nGemini API – Kurzanleitung\nGoogle AI Studio – Kurzanleitung\nAnleitungen für den Einstieg\nModelle\nInformationen zu generativen Modellen\nGemini\nGemini API\nAPI-Übersicht\nAPI-Referenz\nAPI-Versionen\nVersionshinweise\nLeistungsspektrum\nModellabstimmung\nFunktionsaufruf\nEinbettungen\nSicherheit\nLeitfäden\nAufforderungen\nSystemanleitung\nSemantischer Abruf\nAuthentifizierung mit OAuth\nFirebase-Erweiterungen\nZu Cloud migrieren\nAnleitungen\nFunktionsaufruf\nEinbettungen\nAnwendungen\nProblembehebung\nTipps zur Fehlerbehebung\nÜber Workspace auf AI Studio zugreifen\nFehlerbehebung in AI Studio\nHöheres Kontingent beantragen\nCommunity\nDiskursforum\nPaLM API (alt)\nZu Gemini migrieren\nPaLM-Dokumentation\nRecht\nNutzungsbedingungen\n(Vorschau) Nutzungsbedingungen\nVerfügbare Regionen\nSehen Sie sich das neue Cookbook zur Gemini API und unser Community-Forum an.\n Diese Seite wurde von der Cloud Translation API übersetzt.\nErste Schritte mit der Gemini API \n\nGemini ist eine Familie der leistungsstärksten KI-Modelle von Google. Diese Website enthält alle Informationen, die Sie zum Erstellen von Anwendungen mit der Gemini API benötigen.\n\nGemini 1.5 Pro ist jetzt in der öffentlichen Vorschau in Google AI Studio verfügbar. Hier kannst du die Funktion ausprobieren.\n\nGoogle AI Studio \n\nAm schnellsten können Sie Gemini mit Google AI Studio einsteigen, einem webbasierten Tool, mit dem Sie Prototypen erstellen, Prompts direkt in Ihrem Browser ausführen und mit der Gemini API beginnen können.\n\nGoogle AI Studio starten\nGoogle AI Studio – Kurzanleitung\n\nRufen Sie die Kurzanleitung zur Gemini API auf.\n\nInformationen zur sicheren und verantwortungsvollen Verwendung von LLMs finden Sie in den Sicherheitseinstellungen und den Sicherheitsempfehlungen.\n\nErste Schritte mit Python\nErste Schritte mit der REST API\nErste Schritte im Web\nErste Schritte mit Go\nErste Schritte mit Node\nErste Schritte mit Android\nErste Schritte mit iOS\nErste Schritte mit Dart (Flutter)\nIn Google Cloud erstellen\nWeitere Informationen\nWeitere Informationen zu den Modellen, auf denen die Gemini API basiert, finden Sie auf der Seite Modelle.\nDie Gemini API und Google AI Studio sind derzeit in mehr als 180 Ländern verfügbar. Weitere Informationen finden Sie in der Dokumentation.\n\nSofern nicht anders angegeben, sind die Inhalte dieser Seite unter der Creative Commons Attribution 4.0 License und Codebeispiele unter der Apache 2.0 License lizenziert. Weitere Informationen finden Sie in den Websiterichtlinien von Google Developers. Java ist eine eingetragene Marke von Oracle und/oder seinen Partnern.\n\nZuletzt aktualisiert: 2024-04-23 (UTC).\n\nNutzungsbedingungen\nDatenschutz",
            "word_count": 358,
            "filtered_content": "Produkte\nBeispiele\nAnmelden\nDokumentation\nÜberblick\nJetzt starten\nAPI-Schlüssel anfordern\nGemini API – Kurzanleitung\nAnleitungen für den Einstieg\nModelle\nInformationen zu generativen Modellen\nAPI-Übersicht\nAPI-Versionen\nVersionshinweise\nLeistungsspektrum\nModellabstimmung\nSicherheit\nLeitfäden\nAufforderungen\nSystemanleitung\nSemantischer Abruf\nAuthentifizierung mit OAuth\nFirebase-Erweiterungen\nZu Cloud migrieren\nAnleitungen\nAnwendungen\nProblembehebung\nTipps zur Fehlerbehebung\nÜber Workspace auf AI Studio zugreifen\nFehlerbehebung in AI Studio\nHöheres Kontingent beantragen\nDiskursforum\nPaLM API (alt)\nZu Gemini migrieren\nPaLM-Dokumentation\nRecht\n(Vorschau) Nutzungsbedingungen\nVerfügbare Regionen\nSehen Sie sich das neue Cookbook zur Gemini API und unser Community-Forum an.\n Diese Seite wurde von der Cloud Translation API übersetzt.\nErste Schritte mit der Gemini API \nGemini ist eine Familie der leistungsstärksten KI-Modelle von Google. Diese Website enthält alle Informationen, die Sie zum Erstellen von Anwendungen mit der Gemini API benötigen.\nGemini 1.5 Pro ist jetzt in der öffentlichen Vorschau in Google AI Studio verfügbar. Hier kannst du die Funktion ausprobieren.\nAm schnellsten können Sie Gemini mit Google AI Studio einsteigen, einem webbasierten Tool, mit dem Sie Prototypen erstellen, Prompts direkt in Ihrem Browser ausführen und mit der Gemini API beginnen können.\nGoogle AI Studio starten\nRufen Sie die Kurzanleitung zur Gemini API auf.\nInformationen zur sicheren und verantwortungsvollen Verwendung von LLMs finden Sie in den Sicherheitseinstellungen und den Sicherheitsempfehlungen.\nErste Schritte mit Python\nErste Schritte mit der REST API\nErste Schritte im Web\nErste Schritte mit Go\nErste Schritte mit Node\nErste Schritte mit Android\nErste Schritte mit iOS\nErste Schritte mit Dart (Flutter)\nIn Google Cloud erstellen\nWeitere Informationen\nWeitere Informationen zu den Modellen, auf denen die Gemini API basiert, finden Sie auf der Seite Modelle.\nDie Gemini API und Google AI Studio sind derzeit in mehr als 180 Ländern verfügbar. Weitere Informationen finden Sie in der Dokumentation.\nSofern nicht anders angegeben, sind die Inhalte dieser Seite unter der Creative Commons Attribution 4.0 License und Codebeispiele unter der Apache 2.0 License lizenziert. Weitere Informationen finden Sie in den Websiterichtlinien von Google Developers. Java ist eine eingetragene Marke von Oracle und/oder seinen Partnern.\nZuletzt aktualisiert: 2024-04-23 (UTC).\nDatenschutz",
            "filtered_word_count": 333
        },
        "https://ai.google.dev/gemini-api/docs?hl=es-419": {
            "status": "Looks good",
            "content": "Productos\nEjemplos\nAcceder\nDocumentos\nReferencia de la API\nResumen\nComenzar\nObtén una clave de API\nGuía de inicio rápido de la API de Gemini\nGuía de inicio rápido de Google AI Studio\nInstructivos de introducción\nModelos\nAcerca de los modelos generativos\nGemini\nGemini API\nDescripción general de la API\nReferencia de la API\nVersiones de API\nNotas de la versión\nFunciones\nAjuste del modelo\nLlamada a función\nIncorporaciones\nSeguridad\nGuías\nMensajes\nInstrucciones del sistema\nRecuperación semántica\nAutenticación de OAuth\nExtensiones de Firebase\nMigra a Cloud\nInstructivos\nLlamada a función\nIncorporaciones\nAplicaciones\nSolución de problemas\nGuía de solución de problemas\nAccede a AI Studio con Workspace\nSolución de problemas de AI Studio\nCómo solicitar una cuota mayor\nComunidad\nForo del discurso\nAPI de PaLM (heredada)\nCómo migrar a Gemini\nDocumentos de PaLM\nLegal\nCondiciones del Servicio\n(vista previa) Condiciones del Servicio\nRegiones disponibles\nConsulta la nueva Guía de soluciones de la API de Gemini y nuestro foro de la comunidad.\n Se usó la API de Cloud Translation para traducir esta página.\nComienza a usar la API de Gemini \n\nGemini es una familia de modelos de IA más capaces de de Google. En este sitio, encontrarás toda la información que necesitas para comenzar a compilar aplicaciones con la API de Gemini.\n\nGemini 1.5 Pro ahora está disponible en versión preliminar pública en Google AI Studio. Pruébala ahora.\n\nGoogle AI Studio \n\nLa forma más rápida de comenzar a usar Gemini es con Google AI Studio, una herramienta basada en la Web que te permite crear prototipos, ejecutar instrucciones en el navegador y comenzar a usar la API de Gemini.\n\nIniciar Google AI Studio\nGuía de inicio rápido de Google AI Studio\n\nPara comenzar, ve a la guía de inicio rápido de la API de Gemini.\n\nPara aprender a usar los LLM de forma segura y responsable, consulta la documentación de la configuración de seguridad y la guía de seguridad.\n\nComienza a usar Python\nComienza a usar la API de REST\nComienza a usar la Web\nComienza a usar Go\nComienza a usar Node\nComienza en Android\nComienza en iOS\nCómo comenzar a usar Dart (Flutter)\nCompila en Google Cloud\nLecturas adicionales\nPara obtener más información sobre los modelos que potencian la API de Gemini, consulta la página de modelos.\nPor el momento, la API de Gemini y Google AI Studio están disponibles en más de 180 países. Consulta la documentación para obtener más información.\n\nSalvo que se indique lo contrario, el contenido de esta página está sujeto a la licencia Atribución 4.0 de Creative Commons, y los ejemplos de código están sujetos a la licencia Apache 2.0. Para obtener más información, consulta las políticas del sitio de Google Developers. Java es una marca registrada de Oracle o sus afiliados.\n\nÚltima actualización: 2024-04-23 (UTC)\n\nCondiciones\nPrivacidad",
            "word_count": 462,
            "filtered_content": "Productos\nEjemplos\nAcceder\nDocumentos\nResumen\nComenzar\nObtén una clave de API\nGuía de inicio rápido de la API de Gemini\nInstructivos de introducción\nModelos\nAcerca de los modelos generativos\nDescripción general de la API\nVersiones de API\nNotas de la versión\nFunciones\nAjuste del modelo\nSeguridad\nGuías\nMensajes\nInstrucciones del sistema\nRecuperación semántica\nAutenticación de OAuth\nExtensiones de Firebase\nMigra a Cloud\nInstructivos\nAplicaciones\nSolución de problemas\nGuía de solución de problemas\nAccede a AI Studio con Workspace\nSolución de problemas de AI Studio\nCómo solicitar una cuota mayor\nComunidad\nForo del discurso\nAPI de PaLM (heredada)\nCómo migrar a Gemini\nDocumentos de PaLM\nCondiciones del Servicio\n(vista previa) Condiciones del Servicio\nRegiones disponibles\nConsulta la nueva Guía de soluciones de la API de Gemini y nuestro foro de la comunidad.\n Se usó la API de Cloud Translation para traducir esta página.\nComienza a usar la API de Gemini \nGemini es una familia de modelos de IA más capaces de de Google. En este sitio, encontrarás toda la información que necesitas para comenzar a compilar aplicaciones con la API de Gemini.\nGemini 1.5 Pro ahora está disponible en versión preliminar pública en Google AI Studio. Pruébala ahora.\nLa forma más rápida de comenzar a usar Gemini es con Google AI Studio, una herramienta basada en la Web que te permite crear prototipos, ejecutar instrucciones en el navegador y comenzar a usar la API de Gemini.\nIniciar Google AI Studio\nPara comenzar, ve a la guía de inicio rápido de la API de Gemini.\nPara aprender a usar los LLM de forma segura y responsable, consulta la documentación de la configuración de seguridad y la guía de seguridad.\nComienza a usar Python\nComienza a usar la API de REST\nComienza a usar la Web\nComienza a usar Go\nComienza a usar Node\nComienza en Android\nComienza en iOS\nCómo comenzar a usar Dart (Flutter)\nCompila en Google Cloud\nLecturas adicionales\nPara obtener más información sobre los modelos que potencian la API de Gemini, consulta la página de modelos.\nPor el momento, la API de Gemini y Google AI Studio están disponibles en más de 180 países. Consulta la documentación para obtener más información.\nSalvo que se indique lo contrario, el contenido de esta página está sujeto a la licencia Atribución 4.0 de Creative Commons, y los ejemplos de código están sujetos a la licencia Apache 2.0. Para obtener más información, consulta las políticas del sitio de Google Developers. Java es una marca registrada de Oracle o sus afiliados.\nÚltima actualización: 2024-04-23 (UTC)\nCondiciones\nPrivacidad",
            "filtered_word_count": 423
        },
        "https://ai.google.dev/gemini-api/docs?hl=fr": {
            "status": "Looks good",
            "content": "Produits\nExemples\nConnexion\nDocumentation\nDocument de référence de l'API\nVue d'ensemble\nPremiers pas\nObtenir une clé d'API\nGuide de démarrage rapide de l'API Gemini\nGuide de démarrage rapide de Google AI Studio\nTutoriels de démarrage\nModèles\nÀ propos des modèles génératifs\nGemini\nGemini API\nPrésentation de l'API\nDocumentation de référence des API\nVersions d'API\nNotes de version\nCapacités\nRéglage du modèle\nAppel de fonction\nReprésentations vectorielles continues\nSécurité\nGuides\nInvites\nInstructions système\nRécupération sémantique\nAuthentification OAuth\nExtensions Firebase\nMigrer vers le cloud\nTutoriels\nAppel de fonction\nReprésentations vectorielles continues\nApplications\nDépannage\nGuide de dépannage\nAccéder à AI Studio à l'aide de Workspace\nRésoudre les problèmes liés à AI Studio\nDemander plus de quotas\nCommunauté\nForum de Discourse\nAPI PaLM (ancienne version)\nMigrer vers Gemini\nDocumentation sur PaLM\nJuridique\nConditions d'utilisation\n(Preview) Conditions d'utilisation\nRégions disponibles\nDécouvrez le livre de recettes avec l'API Gemini et notre forum de la communauté.\n Cette page a été traduite par l'API Cloud Translation.\nPremiers pas avec l'API Gemini \n\nGemini est une famille de modèles d'IA Google les plus performants. Ce site contient toutes les informations dont vous avez besoin pour commencer à créer des applications avec l'API Gemini.\n\nGemini 1.5 Pro est désormais disponible en version Preview publique dans Google AI Studio. Essayer\n\nGoogle AI Studio \n\nLe moyen le plus rapide d'utiliser Gemini est d'utiliser Google AI Studio, un outil Web qui vous permet de créer des prototypes, d'exécuter des requêtes directement dans votre navigateur et de faire vos premiers pas avec l'API Gemini.\n\nLancer Google AI Studio\nGuide de démarrage rapide de Google AI Studio\n\nPour commencer, accédez au guide de démarrage rapide de l'API Gemini.\n\nPour savoir comment utiliser les LLM de manière sécurisée et responsable, consultez la documentation sur les paramètres de sécurité et les conseils de sécurité.\n\nPremiers pas avec Python\nPremiers pas avec l'API REST\nPremiers pas sur le Web\nPremiers pas avec Go\nPremiers pas avec Node\nPremiers pas sur Android\nPremiers pas sur iOS\nPremiers pas avec Dart (Flutter)\nCréer sur Google Cloud\nComplément d'informations\nPour en savoir plus sur les modèles qui alimentent l'API Gemini, consultez la page Modèles.\nL'API Gemini et Google AI Studio sont actuellement disponibles dans plus de 180 pays. Consultez la documentation pour en savoir plus.\n\nSauf indication contraire, le contenu de cette page est régi par une licence Creative Commons Attribution 4.0, et les échantillons de code sont régis par une licence Apache 2.0. Pour en savoir plus, consultez les Règles du site Google Developers. Java est une marque déposée d'Oracle et/ou de ses sociétés affiliées.\n\nDernière mise à jour le 2024/04/23 (UTC).\n\nConditions d'utilisation\nRègles de confidentialité",
            "word_count": 436,
            "filtered_content": "Produits\nExemples\nConnexion\nDocumentation\nDocument de référence de l'API\nVue d'ensemble\nPremiers pas\nObtenir une clé d'API\nGuide de démarrage rapide de l'API Gemini\nTutoriels de démarrage\nModèles\nÀ propos des modèles génératifs\nPrésentation de l'API\nDocumentation de référence des API\nVersions d'API\nNotes de version\nCapacités\nRéglage du modèle\nSécurité\nInvites\nInstructions système\nRécupération sémantique\nAuthentification OAuth\nExtensions Firebase\nMigrer vers le cloud\nTutoriels\nDépannage\nGuide de dépannage\nAccéder à AI Studio à l'aide de Workspace\nRésoudre les problèmes liés à AI Studio\nDemander plus de quotas\nCommunauté\nForum de Discourse\nAPI PaLM (ancienne version)\nMigrer vers Gemini\nDocumentation sur PaLM\nJuridique\n(Preview) Conditions d'utilisation\nRégions disponibles\nDécouvrez le livre de recettes avec l'API Gemini et notre forum de la communauté.\n Cette page a été traduite par l'API Cloud Translation.\nPremiers pas avec l'API Gemini \nGemini est une famille de modèles d'IA Google les plus performants. Ce site contient toutes les informations dont vous avez besoin pour commencer à créer des applications avec l'API Gemini.\nGemini 1.5 Pro est désormais disponible en version Preview publique dans Google AI Studio. Essayer\nLe moyen le plus rapide d'utiliser Gemini est d'utiliser Google AI Studio, un outil Web qui vous permet de créer des prototypes, d'exécuter des requêtes directement dans votre navigateur et de faire vos premiers pas avec l'API Gemini.\nLancer Google AI Studio\nPour commencer, accédez au guide de démarrage rapide de l'API Gemini.\nPour savoir comment utiliser les LLM de manière sécurisée et responsable, consultez la documentation sur les paramètres de sécurité et les conseils de sécurité.\nPremiers pas avec Python\nPremiers pas avec l'API REST\nPremiers pas sur le Web\nPremiers pas avec Go\nPremiers pas avec Node\nPremiers pas sur Android\nPremiers pas sur iOS\nPremiers pas avec Dart (Flutter)\nCréer sur Google Cloud\nComplément d'informations\nPour en savoir plus sur les modèles qui alimentent l'API Gemini, consultez la page Modèles.\nL'API Gemini et Google AI Studio sont actuellement disponibles dans plus de 180 pays. Consultez la documentation pour en savoir plus.\nSauf indication contraire, le contenu de cette page est régi par une licence Creative Commons Attribution 4.0, et les échantillons de code sont régis par une licence Apache 2.0. Pour en savoir plus, consultez les Règles du site Google Developers. Java est une marque déposée d'Oracle et/ou de ses sociétés affiliées.\nDernière mise à jour le 2024/04/23 (UTC).\nRègles de confidentialité",
            "filtered_word_count": 396
        },
        "https://ai.google.dev/gemini-api/docs?hl=id": {
            "status": "Looks good",
            "content": "Produk\nContoh\nMasuk\nDokumen\nReferensi API\nRingkasan\nMulai\nMendapatkan kunci API\nPanduan memulai Gemini API\nPanduan memulai Google AI Studio\nTutorial memulai\nModel\nTentang model generatif\nGemini\nGemini API\nRingkasan API\nReferensi API\nVersi API\nCatatan rilis\nKemampuan\nPenyesuaian model\nPanggilan fungsi\nEmbedding\nKeamanan\nPanduan\nMeminta\nPetunjuk sistem\nPengambilan semantik\nAutentikasi OAuth\nEkstensi Firebase\nBermigrasi ke Cloud\nTutorial\nPanggilan fungsi\nEmbedding\nAplikasi\nPemecahan masalah\nPanduan pemecahan masalah\nMengakses AI Studio menggunakan Workspace\nMemecahkan masalah AI Studio\nMeminta lebih banyak kuota\nKomunitas\nForum wacana\nPaLM API (lama)\nBermigrasi ke Gemini\nDokumen PaLM\nHukum\nPersyaratan layanan\nPersyaratan layanan (Pratinjau)\nRegion yang tersedia\nLihat Cookbook Gemini API baru dan forum komunitas kami.\n Halaman ini diterjemahkan oleh Cloud Translation API.\nMulai menggunakan Gemini API \n\nGemini adalah kelompok model AI Google yang paling mumpuni. Situs ini berisi semua informasi yang Anda perlukan untuk mulai membangun aplikasi dengan Gemini API.\n\nGemini 1.5 Pro kini tersedia dalam Pratinjau Publik di Google AI Studio. Coba sekarang.\n\nGoogle AI Studio \n\nCara tercepat untuk mulai menggunakan Gemini adalah dengan Google AI Studio, yakni alat berbasis web yang memungkinkan Anda membuat prototipe, menjalankan perintah langsung di browser, dan mulai menggunakan Gemini API.\n\nLuncurkan Google AI Studio\nPanduan memulai Google AI Studio\n\nUntuk memulai, buka panduan memulai Gemini API.\n\nUntuk mempelajari cara menggunakan LLM dengan aman dan bertanggung jawab, lihat dokumentasi setelan keamanan dan panduan keamanan.\n\nMulai menggunakan Python\nMulai menggunakan REST API\nMemulai di Web\nMulai menggunakan Go\nMulai menggunakan Node\nMemulai di Android\nMemulai di iOS\nMulai menggunakan Dart (Flutter)\nMembangun aplikasi di Google Cloud\nBacaan lebih lanjut\nUntuk mempelajari lebih lanjut model yang mendukung Gemini API, lihat halaman model.\nGemini API dan Google AI Studio saat ini tersedia di lebih dari 180 negara. Lihat dokumentasinya untuk mempelajari lebih lanjut.\n\nKecuali dinyatakan lain, konten di halaman ini dilisensikan berdasarkan Lisensi Creative Commons Attribution 4.0, sedangkan contoh kode dilisensikan berdasarkan Lisensi Apache 2.0. Untuk mengetahui informasi selengkapnya, lihat Kebijakan Situs Google Developers. Java adalah merek dagang terdaftar dari Oracle dan/atau afiliasinya.\n\nTerakhir diperbarui pada 2024-04-23 UTC.\n\nPersyaratan\nPrivasi",
            "word_count": 337,
            "filtered_content": "Produk\nContoh\nMasuk\nDokumen\nRingkasan\nMulai\nMendapatkan kunci API\nPanduan memulai Gemini API\nTutorial memulai\nModel\nTentang model generatif\nRingkasan API\nVersi API\nCatatan rilis\nKemampuan\nPenyesuaian model\nKeamanan\nPanduan\nMeminta\nPetunjuk sistem\nPengambilan semantik\nAutentikasi OAuth\nEkstensi Firebase\nBermigrasi ke Cloud\nTutorial\nAplikasi\nPemecahan masalah\nPanduan pemecahan masalah\nMengakses AI Studio menggunakan Workspace\nMemecahkan masalah AI Studio\nMeminta lebih banyak kuota\nKomunitas\nForum wacana\nPaLM API (lama)\nBermigrasi ke Gemini\nDokumen PaLM\nHukum\nPersyaratan layanan\nPersyaratan layanan (Pratinjau)\nRegion yang tersedia\nLihat Cookbook Gemini API baru dan forum komunitas kami.\n Halaman ini diterjemahkan oleh Cloud Translation API.\nMulai menggunakan Gemini API \nGemini adalah kelompok model AI Google yang paling mumpuni. Situs ini berisi semua informasi yang Anda perlukan untuk mulai membangun aplikasi dengan Gemini API.\nGemini 1.5 Pro kini tersedia dalam Pratinjau Publik di Google AI Studio. Coba sekarang.\nCara tercepat untuk mulai menggunakan Gemini adalah dengan Google AI Studio, yakni alat berbasis web yang memungkinkan Anda membuat prototipe, menjalankan perintah langsung di browser, dan mulai menggunakan Gemini API.\nLuncurkan Google AI Studio\nUntuk memulai, buka panduan memulai Gemini API.\nUntuk mempelajari cara menggunakan LLM dengan aman dan bertanggung jawab, lihat dokumentasi setelan keamanan dan panduan keamanan.\nMulai menggunakan Python\nMulai menggunakan REST API\nMemulai di Web\nMulai menggunakan Go\nMulai menggunakan Node\nMemulai di Android\nMemulai di iOS\nMulai menggunakan Dart (Flutter)\nMembangun aplikasi di Google Cloud\nBacaan lebih lanjut\nUntuk mempelajari lebih lanjut model yang mendukung Gemini API, lihat halaman model.\nGemini API dan Google AI Studio saat ini tersedia di lebih dari 180 negara. Lihat dokumentasinya untuk mempelajari lebih lanjut.\nKecuali dinyatakan lain, konten di halaman ini dilisensikan berdasarkan Lisensi Creative Commons Attribution 4.0, sedangkan contoh kode dilisensikan berdasarkan Lisensi Apache 2.0. Untuk mengetahui informasi selengkapnya, lihat Kebijakan Situs Google Developers. Java adalah merek dagang terdaftar dari Oracle dan/atau afiliasinya.\nTerakhir diperbarui pada 2024-04-23 UTC.\nPersyaratan\nPrivasi",
            "filtered_word_count": 311
        },
        "https://ai.google.dev/gemini-api/docs?hl=it": {
            "status": "Looks good",
            "content": "Prodotti\nEsempi\nAccedi\nDocumenti\nRiferimento API\nPanoramica\nInizia\nOttieni una chiave API\nGuida rapida dell'API Gemini\nGuida rapida di Google AI Studio\nTutorial introduttivi\nModelli\nInformazioni sui modelli generativi\nGemini\nGemini API\nPanoramica dell'API\nRiferimento API\nVersioni API\nNote di rilascio\nFunzionalità\nOttimizzazione del modello\nChiamata di funzione\nIncorporamenti\nSicurezza\nGuide\nPrompt\nIstruzioni di sistema\nRecupero semantico\nAutenticazione OAuth\nEstensioni Firebase\nEsegui la migrazione a Cloud\nTutorial\nChiamata di funzione\nIncorporamenti\nApplicazioni\nRisoluzione dei problemi\nRisoluzione dei problemi\nAccedere ad AI Studio utilizzando Workspace\nRisoluzione dei problemi relativi ad AI Studio\nRichiedere una quota maggiore\ncommunity\nForum del discorso\nAPI PaLM (legacy)\nEsegui la migrazione a Gemini\nDocumenti PaLM\nLegale\nTermini di servizio\n(Anteprima) Termini di servizio\nAree geografiche disponibili\nDai un'occhiata al nuovo Cookbook dell'API Gemini e al nostro forum della community.\n Questa pagina è stata tradotta dall'API Cloud Translation.\nInizia a utilizzare l'API Gemini \n\nGemini è una famiglia dei modelli di IA più avanzati di Google. Questo sito contiene tutte le informazioni necessarie per iniziare a creare applicazioni con l'API Gemini.\n\nGemini 1.5 Pro è ora disponibile in Anteprima pubblica in Google AI Studio. Prova subito.\n\nGoogle AI Studio \n\nIl modo più rapido per iniziare a utilizzare Gemini è con Google AI Studio, uno strumento basato sul web che ti consente di prototipare, eseguire prompt direttamente nel browser e iniziare a utilizzare l'API Gemini.\n\nAvvia Google AI Studio\nGuida rapida di Google AI Studio\n\nPer iniziare, vai alla guida rapida dell'API Gemini.\n\nPer scoprire come utilizzare gli LLM in modo sicuro e responsabile, consulta la documentazione sulle impostazioni di sicurezza e sulle indicazioni di sicurezza.\n\nInizia a utilizzare Python\nInizia a utilizzare l'API REST\nIniziare a navigare sul web\nInizia a utilizzare Go\nInizia a utilizzare Node\nInizia su Android\nInizia su iOS\nInizia a utilizzare Dart (Flutter)\nCrea su Google Cloud\nPer approfondire\nPer saperne di più sui modelli alla base dell'API Gemini, consulta la pagina relativa ai modelli.\nL'API Gemini e Google AI Studio sono attualmente disponibili in oltre 180 paesi. Consulta la documentazione per saperne di più.\n\nSalvo quando diversamente specificato, i contenuti di questa pagina sono concessi in base alla licenza Creative Commons Attribution 4.0, mentre gli esempi di codice sono concessi in base alla licenza Apache 2.0. Per ulteriori dettagli, consulta le norme del sito di Google Developers. Java è un marchio registrato di Oracle e/o delle sue consociate.\n\nUltimo aggiornamento 2024-04-23 UTC.\n\nTermini\nPrivacy",
            "word_count": 402,
            "filtered_content": "Prodotti\nEsempi\nAccedi\nDocumenti\nPanoramica\nInizia\nOttieni una chiave API\nGuida rapida dell'API Gemini\nTutorial introduttivi\nModelli\nInformazioni sui modelli generativi\nPanoramica dell'API\nVersioni API\nNote di rilascio\nFunzionalità\nOttimizzazione del modello\nSicurezza\nGuide\nPrompt\nIstruzioni di sistema\nRecupero semantico\nAutenticazione OAuth\nEstensioni Firebase\nEsegui la migrazione a Cloud\nApplicazioni\nAccedere ad AI Studio utilizzando Workspace\nRisoluzione dei problemi relativi ad AI Studio\nRichiedere una quota maggiore\ncommunity\nForum del discorso\nAPI PaLM (legacy)\nEsegui la migrazione a Gemini\nDocumenti PaLM\nLegale\nTermini di servizio\n(Anteprima) Termini di servizio\nAree geografiche disponibili\nDai un'occhiata al nuovo Cookbook dell'API Gemini e al nostro forum della community.\n Questa pagina è stata tradotta dall'API Cloud Translation.\nInizia a utilizzare l'API Gemini \nGemini è una famiglia dei modelli di IA più avanzati di Google. Questo sito contiene tutte le informazioni necessarie per iniziare a creare applicazioni con l'API Gemini.\nGemini 1.5 Pro è ora disponibile in Anteprima pubblica in Google AI Studio. Prova subito.\nIl modo più rapido per iniziare a utilizzare Gemini è con Google AI Studio, uno strumento basato sul web che ti consente di prototipare, eseguire prompt direttamente nel browser e iniziare a utilizzare l'API Gemini.\nAvvia Google AI Studio\nPer iniziare, vai alla guida rapida dell'API Gemini.\nPer scoprire come utilizzare gli LLM in modo sicuro e responsabile, consulta la documentazione sulle impostazioni di sicurezza e sulle indicazioni di sicurezza.\nInizia a utilizzare Python\nInizia a utilizzare l'API REST\nIniziare a navigare sul web\nInizia a utilizzare Go\nInizia a utilizzare Node\nInizia su Android\nInizia su iOS\nInizia a utilizzare Dart (Flutter)\nCrea su Google Cloud\nPer approfondire\nPer saperne di più sui modelli alla base dell'API Gemini, consulta la pagina relativa ai modelli.\nL'API Gemini e Google AI Studio sono attualmente disponibili in oltre 180 paesi. Consulta la documentazione per saperne di più.\nSalvo quando diversamente specificato, i contenuti di questa pagina sono concessi in base alla licenza Creative Commons Attribution 4.0, mentre gli esempi di codice sono concessi in base alla licenza Apache 2.0. Per ulteriori dettagli, consulta le norme del sito di Google Developers. Java è un marchio registrato di Oracle e/o delle sue consociate.\nUltimo aggiornamento 2024-04-23 UTC.\nTermini",
            "filtered_word_count": 364
        },
        "https://ai.google.dev/gemini-api/docs?hl=pl": {
            "status": "Looks good",
            "content": "Produkty\nPrzykłady\nZaloguj się\nDokumenty\nDokumentacja API\nPrzegląd\nRozpocznij\nUzyskiwanie klucza interfejsu API\nKrótkie wprowadzenie do interfejsu Gemini API\nKrótkie wprowadzenie do Google AI Studio\nSamouczki na początek\nModele\nInformacje o modelach generatywnych\nGemini\nGemini API\nPrzegląd interfejsów API\nDokumentacja API\nWersje interfejsu API\nInformacje o wersjach\nMożliwości\nDostrajanie modeli\nWywoływanie funkcji\nOsadzone elementy\nBezpieczeństwo\nPrzewodniki\nPrompt\nInstrukcje systemowe\nPobieranie semantyczne\nUwierzytelnianie OAuth\nRozszerzenia Firebase\nMigracja do Cloud\nSamouczki\nWywoływanie funkcji\nOsadzone elementy\nAplikacje\nRozwiązywanie problemów\nPrzewodnik rozwiązywania problemów\nDostęp do AI Studio za pomocą Workspace\nRozwiązywanie problemów z AI Studio\nZgłaszanie prośby o dodatkowy limit\nSpołeczność\nForum dyskusyjne\nPaLM API (starsza wersja)\nMigracja do Gemini\nDokumentacja PaLM\nLegal\nWarunki korzystania z usługi\n(Wersja testowa) Warunki korzystania z usługi\nRegiony, w których działa ta usługa\nZapoznaj się z nową książką kucharską na temat interfejsu Gemini API i poznaj nasze forum społeczności.\n Ta strona została przetłumaczona przez Cloud Translation API.\nPierwsze kroki z interfejsem Gemini API \n\nGemini to rodzina najbardziej wydajnych modeli AI Google. Ta witryna zawiera wszystkie informacje potrzebne do rozpoczęcia tworzenia aplikacji za pomocą interfejsu Gemini API.\n\nGemini 1.5 Pro jest teraz dostępny w publicznej wersji przedpremierowej w Google AI Studio. Wypróbuj teraz\n\nGoogle AI Studio \n\nNajszybszym sposobem na rozpoczęcie korzystania z Gemini jest Google AI Studio, narzędzie internetowe, które umożliwia tworzenie prototypów, uruchamianie promptów bezpośrednio w przeglądarce i rozpoczęcie korzystania z interfejsu Gemini API.\n\nUruchom Google AI Studio\nKrótkie wprowadzenie do Google AI Studio\n\nNa początek zapoznaj się z krótkim wprowadzeniem do interfejsu API Gemini.\n\nAby dowiedzieć się, jak bezpiecznie i odpowiedzialnie korzystać z LLM, zapoznaj się z ustawieniami bezpieczeństwa i dokumentacją dotyczącą wskazówek dotyczących bezpieczeństwa.\n\nPierwsze kroki z Pythonem\nPierwsze kroki z interfejsem API typu REST\nPierwsze kroki w internecie\nPierwsze kroki w Go\nWprowadzenie do węzła\nPierwsze kroki na Androidzie\nWypróbuj na iOS\nWprowadzenie do gry Dart (Flutter)\nWykorzystaj Google Cloud\nWięcej informacji\nWięcej informacji o modelach, które obsługują interfejs Gemini API, znajdziesz na stronie z modelami.\nInterfejs Gemini API i Google AI Studio są obecnie dostępne w ponad 180 krajach. Więcej informacji znajdziesz w dokumentacji.\n\nO ile nie stwierdzono inaczej, treść tej strony jest objęta licencją Creative Commons – uznanie autorstwa 4.0, a fragmenty kodu są dostępne na licencji Apache 2.0. Szczegółowe informacje na ten temat zawierają zasady dotyczące witryny Google Developers. Java jest zastrzeżonym znakiem towarowym firmy Oracle i jej podmiotów stowarzyszonych.\n\nOstatnia aktualizacja: 2024-04-23 UTC.\n\nWarunki\nPrywatność",
            "word_count": 394,
            "filtered_content": "Produkty\nPrzykłady\nZaloguj się\nDokumenty\nPrzegląd\nRozpocznij\nUzyskiwanie klucza interfejsu API\nKrótkie wprowadzenie do interfejsu Gemini API\nSamouczki na początek\nModele\nInformacje o modelach generatywnych\nPrzegląd interfejsów API\nWersje interfejsu API\nInformacje o wersjach\nMożliwości\nDostrajanie modeli\nBezpieczeństwo\nPrzewodniki\nInstrukcje systemowe\nPobieranie semantyczne\nUwierzytelnianie OAuth\nRozszerzenia Firebase\nMigracja do Cloud\nSamouczki\nAplikacje\nRozwiązywanie problemów\nPrzewodnik rozwiązywania problemów\nDostęp do AI Studio za pomocą Workspace\nRozwiązywanie problemów z AI Studio\nZgłaszanie prośby o dodatkowy limit\nSpołeczność\nForum dyskusyjne\nPaLM API (starsza wersja)\nMigracja do Gemini\nDokumentacja PaLM\nWarunki korzystania z usługi\n(Wersja testowa) Warunki korzystania z usługi\nRegiony, w których działa ta usługa\nZapoznaj się z nową książką kucharską na temat interfejsu Gemini API i poznaj nasze forum społeczności.\n Ta strona została przetłumaczona przez Cloud Translation API.\nPierwsze kroki z interfejsem Gemini API \nGemini to rodzina najbardziej wydajnych modeli AI Google. Ta witryna zawiera wszystkie informacje potrzebne do rozpoczęcia tworzenia aplikacji za pomocą interfejsu Gemini API.\nGemini 1.5 Pro jest teraz dostępny w publicznej wersji przedpremierowej w Google AI Studio. Wypróbuj teraz\nNajszybszym sposobem na rozpoczęcie korzystania z Gemini jest Google AI Studio, narzędzie internetowe, które umożliwia tworzenie prototypów, uruchamianie promptów bezpośrednio w przeglądarce i rozpoczęcie korzystania z interfejsu Gemini API.\nUruchom Google AI Studio\nNa początek zapoznaj się z krótkim wprowadzeniem do interfejsu API Gemini.\nAby dowiedzieć się, jak bezpiecznie i odpowiedzialnie korzystać z LLM, zapoznaj się z ustawieniami bezpieczeństwa i dokumentacją dotyczącą wskazówek dotyczących bezpieczeństwa.\nPierwsze kroki z Pythonem\nPierwsze kroki z interfejsem API typu REST\nPierwsze kroki w internecie\nPierwsze kroki w Go\nWprowadzenie do węzła\nPierwsze kroki na Androidzie\nWypróbuj na iOS\nWprowadzenie do gry Dart (Flutter)\nWykorzystaj Google Cloud\nWięcej informacji\nWięcej informacji o modelach, które obsługują interfejs Gemini API, znajdziesz na stronie z modelami.\nInterfejs Gemini API i Google AI Studio są obecnie dostępne w ponad 180 krajach. Więcej informacji znajdziesz w dokumentacji.\nO ile nie stwierdzono inaczej, treść tej strony jest objęta licencją Creative Commons – uznanie autorstwa 4.0, a fragmenty kodu są dostępne na licencji Apache 2.0. Szczegółowe informacje na ten temat zawierają zasady dotyczące witryny Google Developers. Java jest zastrzeżonym znakiem towarowym firmy Oracle i jej podmiotów stowarzyszonych.\nOstatnia aktualizacja: 2024-04-23 UTC.\nWarunki\nPrywatność",
            "filtered_word_count": 362
        },
        "https://ai.google.dev/gemini-api/docs?hl=pt-br": {
            "status": "Looks good",
            "content": "Produtos\nExemplos\nFazer login\nDocs\nReferência da API\nVisão geral\nComeçar\nObter uma chave de API\nGuia de início rápido da API Gemini\nGuia de início rápido do Google AI Studio\nTutoriais com os primeiros passos\nModelos\nSobre modelos generativos\nGemini\nGemini API\nVisão geral da API\nReferência da API\nVersões da API\nNotas da versão\nRecursos\nAjuste do modelo\nChamadas de funções\nEmbeddings\nSegurança\nGuias\nSolicitações de prompt\nInstruções do sistema\nRecuperação semântica\nAutenticação OAuth\nExtensões do Firebase\nMigrar para o Cloud\nTutoriais\nChamadas de funções\nEmbeddings\nAplicativos\nSolução de problemas\nGuia de solução de problemas\nAcessar o AI Studio usando o Workspace\nComo solucionar problemas no AI Studio\nSolicitar mais cotas\nComunidade\nFórum do Discourse\nAPI PaLM (legada)\nMigrar para o Gêmeos\nDocumentos do PaLM\nJurídico\nTermos de Serviço\n(Prévia) Termos de Serviço\nRegiões disponíveis\nConfira o Cookbook da nova API Gemini e nosso fórum da comunidade.\n Esta página foi traduzida pela API Cloud Translation.\nComeçar a usar a API Gemini \n\nO Gemini é uma família de modelos de IA mais qualificados do Google. Este site contém todas as informações que você precisa para começar a criar aplicativos com a API Gemini.\n\nO Gemini 1.5 Pro já está disponível em Acesso antecipado no Google AI Studio. Faça um teste agora.\n\nGoogle AI Studio \n\nA maneira mais rápida de começar a usar o Gemini é com o Google AI Studio, uma ferramenta baseada na Web que permite criar protótipos, executar comandos diretamente no navegador e começar a usar a API Gemini.\n\nInicie o Google AI Studio\nGuia de início rápido do Google AI Studio\n\nPara começar, acesse o guia de início rápido da API Genmini.\n\nPara aprender a usar LLMs com segurança e responsabilidade, consulte a documentação sobre configurações de segurança e orientações de segurança.\n\nIntrodução ao Python\nPrimeiros passos com a API REST\nComeçar na Web\nComeçar a usar Go\nComeçar a usar o Node\nPrimeiros passos no Android\nPrimeiros passos no iOS\nComeçar a usar o Dart (Flutter)\nCrie no Google Cloud\nLeia mais\nPara saber mais sobre os modelos usados na API Gemini, consulte a página Modelos.\nAtualmente, a API Gemini e o Google AI Studio estão disponíveis em mais de 180 países. Confira a documentação para saber mais.\n\nExceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.\n\nÚltima atualização 2024-04-23 UTC.\n\nTermos de Serviço\nPrivacidade",
            "word_count": 438,
            "filtered_content": "Produtos\nExemplos\nFazer login\nVisão geral\nComeçar\nObter uma chave de API\nGuia de início rápido da API Gemini\nTutoriais com os primeiros passos\nSobre modelos generativos\nVisão geral da API\nVersões da API\nNotas da versão\nRecursos\nAjuste do modelo\nSegurança\nGuias\nSolicitações de prompt\nInstruções do sistema\nRecuperação semântica\nAutenticação OAuth\nExtensões do Firebase\nMigrar para o Cloud\nTutoriais\nAplicativos\nSolução de problemas\nGuia de solução de problemas\nAcessar o AI Studio usando o Workspace\nComo solucionar problemas no AI Studio\nSolicitar mais cotas\nComunidade\nFórum do Discourse\nAPI PaLM (legada)\nMigrar para o Gêmeos\nDocumentos do PaLM\nJurídico\n(Prévia) Termos de Serviço\nRegiões disponíveis\nConfira o Cookbook da nova API Gemini e nosso fórum da comunidade.\n Esta página foi traduzida pela API Cloud Translation.\nComeçar a usar a API Gemini \nO Gemini é uma família de modelos de IA mais qualificados do Google. Este site contém todas as informações que você precisa para começar a criar aplicativos com a API Gemini.\nO Gemini 1.5 Pro já está disponível em Acesso antecipado no Google AI Studio. Faça um teste agora.\nA maneira mais rápida de começar a usar o Gemini é com o Google AI Studio, uma ferramenta baseada na Web que permite criar protótipos, executar comandos diretamente no navegador e começar a usar a API Gemini.\nInicie o Google AI Studio\nPara começar, acesse o guia de início rápido da API Genmini.\nPara aprender a usar LLMs com segurança e responsabilidade, consulte a documentação sobre configurações de segurança e orientações de segurança.\nIntrodução ao Python\nPrimeiros passos com a API REST\nComeçar na Web\nComeçar a usar Go\nComeçar a usar o Node\nPrimeiros passos no Android\nPrimeiros passos no iOS\nComeçar a usar o Dart (Flutter)\nCrie no Google Cloud\nLeia mais\nPara saber mais sobre os modelos usados na API Gemini, consulte a página Modelos.\nAtualmente, a API Gemini e o Google AI Studio estão disponíveis em mais de 180 países. Confira a documentação para saber mais.\nExceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.\nÚltima atualização 2024-04-23 UTC.\nPrivacidade",
            "filtered_word_count": 394
        },
        "https://ai.google.dev/gemini-api/docs?hl=vi": {
            "status": "Looks good",
            "content": "Sản phẩm\nVí dụ\nĐăng nhập\nTài liệu\nTài liệu tham khảo API\nTổng quan\nBắt đầu\nNhận khoá API\nBắt đầu nhanh API Gemini\nHướng dẫn nhanh về Google AI Studio\nHướng dẫn bắt đầu sử dụng\nMô hình\nGiới thiệu về các mô hình tạo sinh\nGemini\nGemini API\nTổng quan về API\nTài liệu tham khảo API\nPhiên bản API\nGhi chú phát hành\nChức năng\nĐiều chỉnh mô hình\nGọi hàm\nNhúng\nAn toàn\nHướng dẫn\nNhắc nhở\nHướng dẫn hệ thống\nTruy xuất ngữ nghĩa\nXác thực OAuth\nTiện ích Firebase\nDi chuyển sang nền tảng đám mây\nHướng dẫn\nGọi hàm\nNhúng\nỨng dụng\nKhắc phục sự cố\nHướng dẫn khắc phục sự cố\nTruy cập vào AI Studio bằng Workspace\nKhắc phục sự cố với AI Studio\nYêu cầu tăng hạn mức\nCộng đồng\nDiễn đàn Discourse\nAPI PaLM (cũ)\nDi chuyển sang Gemini\nTài liệu PaLM\nPháp lý\nĐiều khoản dịch vụ\n(Bản xem trước) Điều khoản dịch vụ\nKhu vực khả dụng\nHãy khám phá Cookbook API mới và diễn đàn cộng đồng của chúng tôi.\n Trang này được dịch bởi Cloud Translation API.\nLàm quen với API Gemini \n\nGemini là một dòng mô hình AI có hiệu suất cao nhất của Google. Trang web này chứa tất cả thông tin bạn cần để bắt đầu xây dựng ứng dụng bằng API Gemini.\n\nGemini 1.5 Pro hiện đã có Bản dùng trước công khai trong Google AI Studio. Thử ngay.\n\nGoogle AI Studio \n\nCách nhanh nhất để bắt đầu sử dụng Gemini là sử dụng Google AI Studio, một công cụ dựa trên nền tảng web, cho phép bạn tạo nguyên mẫu, chạy câu lệnh ngay trong trình duyệt và bắt đầu sử dụng API Gemini.\n\nMở Google AI Studio\nHướng dẫn nhanh về Google AI Studio\n\nĐể bắt đầu, hãy chuyển đến phần hướng dẫn bắt đầu nhanh về API Gemini.\n\nĐể tìm hiểu cách sử dụng các LLM một cách an toàn và có trách nhiệm, hãy tham khảo chế độ cài đặt an toàn và hướng dẫn về an toàn.\n\nLàm quen với Python\nLàm quen với API REST\nBắt đầu trên web\nLàm quen với Go\nLàm quen với Nút\nBắt đầu trên Android\nBắt đầu trên iOS\nBắt đầu với Dart (Flutter)\nXây dựng trên Google Cloud\nTài liệu đọc thêm\nĐể tìm hiểu thêm về các mô hình hỗ trợ API Gemini, hãy tham khảo trang mô hình.\nAPI Gemini và Google AI Studio hiện có tại hơn 180 quốc gia, hãy xem tài liệu để tìm hiểu thêm.\n\nTrừ khi có lưu ý khác, nội dung của trang này được cấp phép theo Giấy phép ghi nhận tác giả 4.0 của Creative Commons và các mẫu mã lập trình được cấp phép theo Giấy phép Apache 2.0. Để biết thông tin chi tiết, vui lòng tham khảo Chính sách trang web của Google Developers. Java là nhãn hiệu đã đăng ký của Oracle và/hoặc các đơn vị liên kết với Oracle.\n\nCập nhật lần gần đây nhất: 2024-04-23 UTC.\n\nĐiều khoản\nQuyền riêng tư",
            "word_count": 520,
            "filtered_content": "Sản phẩm\nVí dụ\nĐăng nhập\nTài liệu\nTổng quan\nBắt đầu\nNhận khoá API\nBắt đầu nhanh API Gemini\nHướng dẫn bắt đầu sử dụng\nMô hình\nGiới thiệu về các mô hình tạo sinh\nTổng quan về API\nPhiên bản API\nGhi chú phát hành\nChức năng\nĐiều chỉnh mô hình\nAn toàn\nNhắc nhở\nHướng dẫn hệ thống\nTruy xuất ngữ nghĩa\nXác thực OAuth\nTiện ích Firebase\nDi chuyển sang nền tảng đám mây\nỨng dụng\nKhắc phục sự cố\nHướng dẫn khắc phục sự cố\nTruy cập vào AI Studio bằng Workspace\nKhắc phục sự cố với AI Studio\nYêu cầu tăng hạn mức\nCộng đồng\nDiễn đàn Discourse\nAPI PaLM (cũ)\nDi chuyển sang Gemini\nTài liệu PaLM\nPháp lý\nĐiều khoản dịch vụ\n(Bản xem trước) Điều khoản dịch vụ\nKhu vực khả dụng\nHãy khám phá Cookbook API mới và diễn đàn cộng đồng của chúng tôi.\n Trang này được dịch bởi Cloud Translation API.\nLàm quen với API Gemini \nGemini là một dòng mô hình AI có hiệu suất cao nhất của Google. Trang web này chứa tất cả thông tin bạn cần để bắt đầu xây dựng ứng dụng bằng API Gemini.\nGemini 1.5 Pro hiện đã có Bản dùng trước công khai trong Google AI Studio. Thử ngay.\nCách nhanh nhất để bắt đầu sử dụng Gemini là sử dụng Google AI Studio, một công cụ dựa trên nền tảng web, cho phép bạn tạo nguyên mẫu, chạy câu lệnh ngay trong trình duyệt và bắt đầu sử dụng API Gemini.\nMở Google AI Studio\nĐể bắt đầu, hãy chuyển đến phần hướng dẫn bắt đầu nhanh về API Gemini.\nĐể tìm hiểu cách sử dụng các LLM một cách an toàn và có trách nhiệm, hãy tham khảo chế độ cài đặt an toàn và hướng dẫn về an toàn.\nLàm quen với Python\nLàm quen với API REST\nBắt đầu trên web\nLàm quen với Go\nLàm quen với Nút\nBắt đầu trên Android\nBắt đầu trên iOS\nBắt đầu với Dart (Flutter)\nXây dựng trên Google Cloud\nTài liệu đọc thêm\nĐể tìm hiểu thêm về các mô hình hỗ trợ API Gemini, hãy tham khảo trang mô hình.\nAPI Gemini và Google AI Studio hiện có tại hơn 180 quốc gia, hãy xem tài liệu để tìm hiểu thêm.\nTrừ khi có lưu ý khác, nội dung của trang này được cấp phép theo Giấy phép ghi nhận tác giả 4.0 của Creative Commons và các mẫu mã lập trình được cấp phép theo Giấy phép Apache 2.0. Để biết thông tin chi tiết, vui lòng tham khảo Chính sách trang web của Google Developers. Java là nhãn hiệu đã đăng ký của Oracle và/hoặc các đơn vị liên kết với Oracle.\nCập nhật lần gần đây nhất: 2024-04-23 UTC.\nĐiều khoản\nQuyền riêng tư",
            "filtered_word_count": 480
        },
        "https://ai.google.dev/gemini-api/docs?hl=tr": {
            "status": "Looks good",
            "content": "Ürünler\nÖrnekler\nOturum aç\nDokümanlar\nAPI Referansı\nGenel bakış\nBaşlama\nAPI anahtarı alma\nGemini API hızlı başlangıç kılavuzu\nGoogle AI Studio hızlı başlangıç kılavuzu\nBaşlangıç eğiticileri\nModeller\nÜretken modeller hakkında\nGemini\nGemini API\nAPI'ye genel bakış\nAPI referansı\nAPI sürümleri\nSürüm notları\nÖzellikler\nModel ince ayarı\nİşlev çağrısı\nYerleştirmeler\nGüvenlik\nRehberler\nİstemde bulunma\nSistem talimatları\nAnlamsal alma\nOAuth kimlik doğrulaması\nFirebase uzantıları\nCloud'a taşı\nEğitimler\nİşlev çağrısı\nYerleştirmeler\nUygulamalar\nSorun giderme\nSorun giderme kılavuzu\nWorkspace'i kullanarak AI Studio'ya erişme\nAI Studio ile ilgili sorunları giderme\nDaha fazla kota isteme\nTopluluk\nTartışma forumu\nPaLM API (eski)\nGemini'a taşıyın\nPaLM belgeleri\nHukuk\nHizmet şartları\n(Önizleme) Hizmet şartları\nKullanılabildiği bölgeler\nYeni Gemini API Cookbook'una ve topluluk forumumuza göz atın.\n Bu sayfa, Cloud Translation API ile çevrilmiştir.\nGemini API'yi kullanmaya başlama \n\nGemini, Google'ın en yetenekli yapay zeka modellerinden oluşan bir ailedir. Gemini API ile uygulama derlemeye başlamak için ihtiyacınız olan tüm bilgileri bu sitede bulabilirsiniz.\n\nGemini 1.5 Pro, artık Google AI Studio'daki Genel Önizleme sürümünde kullanılabilir. Hemen deneyin.\n\nGoogle AI Studio \n\nGemini'ı kullanmaya başlamanın en hızlı yolu, prototip oluşturmanıza, doğrudan tarayıcınızda istemleri çalıştırmanıza ve Gemini API'yi kullanmaya başlamanıza olanak tanıyan web tabanlı Google AI Studio aracından yararlanmaktır.\n\nGoogle AI Studio'yu başlat\nGoogle AI Studio hızlı başlangıç kılavuzu\n\nBaşlamak için Gemini API hızlı başlangıç kılavuzu sayfasına gidin.\n\nLLM'lerin güvenli ve sorumlu bir şekilde nasıl kullanılacağını öğrenmek için güvenlik ayarları ve güvenlik kılavuzu belgelerini inceleyin.\n\nPython'u kullanmaya başlayın\nREST API'yi kullanmaya başlama\nWeb'i kullanmaya başlayın\nGo'yu kullanmaya başlama\nDüğüm kullanmaya başlayın\nAndroid'i kullanmaya başlama\niOS kullanmaya başlayın\nDart'ı (Flutter) kullanmaya başlama\nGoogle Cloud'da geliştirin\nDaha fazla bilgi\nGemini API'yi destekleyen modeller hakkında daha fazla bilgi edinmek için modeller sayfasına bakın.\nGemini API ve Google AI Studio şu anda 180'den fazla ülkede kullanılabilir. Daha fazla bilgi için belgelere göz atın.\n\nAksi belirtilmediği sürece bu sayfanın içeriği Creative Commons Atıf 4.0 Lisansı altında ve kod örnekleri Apache 2.0 Lisansı altında lisanslanmıştır. Ayrıntılı bilgi için Google Developers Site Politikaları'na göz atın. Java, Oracle ve/veya satış ortaklarının tescilli ticari markasıdır.\n\nSon güncelleme tarihi: 2024-04-23 UTC.\n\nŞartlar\nGizlilik",
            "word_count": 337,
            "filtered_content": "Ürünler\nÖrnekler\nOturum aç\nDokümanlar\nAPI Referansı\nGenel bakış\nBaşlama\nAPI anahtarı alma\nGemini API hızlı başlangıç kılavuzu\nBaşlangıç eğiticileri\nModeller\nÜretken modeller hakkında\nAPI'ye genel bakış\nAPI referansı\nAPI sürümleri\nSürüm notları\nÖzellikler\nModel ince ayarı\nGüvenlik\nRehberler\nİstemde bulunma\nSistem talimatları\nAnlamsal alma\nOAuth kimlik doğrulaması\nFirebase uzantıları\nCloud'a taşı\nEğitimler\nUygulamalar\nSorun giderme\nSorun giderme kılavuzu\nWorkspace'i kullanarak AI Studio'ya erişme\nAI Studio ile ilgili sorunları giderme\nDaha fazla kota isteme\nTopluluk\nTartışma forumu\nPaLM API (eski)\nGemini'a taşıyın\nPaLM belgeleri\nHukuk\nHizmet şartları\n(Önizleme) Hizmet şartları\nKullanılabildiği bölgeler\nYeni Gemini API Cookbook'una ve topluluk forumumuza göz atın.\n Bu sayfa, Cloud Translation API ile çevrilmiştir.\nGemini API'yi kullanmaya başlama \nGemini, Google'ın en yetenekli yapay zeka modellerinden oluşan bir ailedir. Gemini API ile uygulama derlemeye başlamak için ihtiyacınız olan tüm bilgileri bu sitede bulabilirsiniz.\nGemini 1.5 Pro, artık Google AI Studio'daki Genel Önizleme sürümünde kullanılabilir. Hemen deneyin.\nGemini'ı kullanmaya başlamanın en hızlı yolu, prototip oluşturmanıza, doğrudan tarayıcınızda istemleri çalıştırmanıza ve Gemini API'yi kullanmaya başlamanıza olanak tanıyan web tabanlı Google AI Studio aracından yararlanmaktır.\nGoogle AI Studio'yu başlat\nBaşlamak için Gemini API hızlı başlangıç kılavuzu sayfasına gidin.\nLLM'lerin güvenli ve sorumlu bir şekilde nasıl kullanılacağını öğrenmek için güvenlik ayarları ve güvenlik kılavuzu belgelerini inceleyin.\nPython'u kullanmaya başlayın\nREST API'yi kullanmaya başlama\nWeb'i kullanmaya başlayın\nGo'yu kullanmaya başlama\nDüğüm kullanmaya başlayın\nAndroid'i kullanmaya başlama\niOS kullanmaya başlayın\nDart'ı (Flutter) kullanmaya başlama\nGoogle Cloud'da geliştirin\nDaha fazla bilgi\nGemini API'yi destekleyen modeller hakkında daha fazla bilgi edinmek için modeller sayfasına bakın.\nGemini API ve Google AI Studio şu anda 180'den fazla ülkede kullanılabilir. Daha fazla bilgi için belgelere göz atın.\nAksi belirtilmediği sürece bu sayfanın içeriği Creative Commons Atıf 4.0 Lisansı altında ve kod örnekleri Apache 2.0 Lisansı altında lisanslanmıştır. Ayrıntılı bilgi için Google Developers Site Politikaları'na göz atın. Java, Oracle ve/veya satış ortaklarının tescilli ticari markasıdır.\nSon güncelleme tarihi: 2024-04-23 UTC.\nŞartlar\nGizlilik",
            "filtered_word_count": 313
        },
        "https://ai.google.dev/gemini-api/docs?hl=ru": {
            "status": "Looks good",
            "content": "Продукты\nПримеры\nВойти\nДокументы\nДокументация по API\nОбзор\nНачало работы\nПолучить ключ API\nКраткое руководство по API Gemini\nКраткое руководство по Google AI Studio\nУчебники по началу работы\nМодели\nО генеративных моделях\nGemini\nGemini API\nОбзор API\nСправочник по API\nВерсии API\nПримечания к выпускам\nВозможности, Возможности\nТюнинг модели\nВызов функции\nВложения\nБезопасность\nПутеводители\nПодсказка\nСистемные инструкции\nСемантический поиск\nOAuth-аутентификация\nРасширения Firebase\nМиграция в облако\nРуководства\nВызов функции\nВложения\nПриложения\nУстранение неполадок\nРуководство по устранению неполадок\nДоступ к AI Studio с помощью Workspace\nУстранение неполадок AI Studio\nКак увеличить квоту\nСообщество\nДискурс-форум\nPaLM API (устаревший)\nПерейти на Близнецы\nДокументы ПалМ\nЮридический\nУсловия использования\n(Предварительная версия) Условия использования\nДоступные регионы\nОзнакомьтесь с новой кулинарной книгой Gemini API и форумом нашего сообщества .\n Эта страница переведена с помощью Cloud Translation API.\nНачните работу с API Gemini \n\nGemini — это семейство самых эффективных моделей искусственного интеллекта от Google. Этот сайт содержит всю информацию, необходимую для начала создания приложений с помощью Gemini API.\n\nGemini 1.5 Pro теперь доступен в общедоступной предварительной версии в Google AI Studio. Попробуй это сейчас .\n\nGoogle AI Studio \n\nСамый быстрый способ начать использовать Gemini — использовать Google AI Studio , веб-инструмент, который позволяет создавать прототипы, запускать подсказки прямо в браузере и начинать работу с Gemini API.\n\nЗапустите Google AI Studio.\nКраткое руководство по Google AI Studio\n\nЧтобы начать, перейдите к краткому руководству Gemini API .\n\nЧтобы узнать, как безопасно и ответственно использовать LLM, обратитесь к настройкам безопасности и документации по безопасности .\n\nНачать работу с Python\nНачало работы с REST API\nНачало работы в Интернете\nНачните работу с Go\nНачало работы с Node\nНачать работу на Android\nНачать работу на iOS\nНачните работу с Dart (Flutter)\nИспользуйте Google Cloud\nдальнейшее чтение\nЧтобы узнать больше о моделях, на которых работает Gemini API, посетите страницу моделей .\nGemini API и Google AI Studio в настоящее время доступны более чем в 180 странах. Чтобы узнать больше, ознакомьтесь с документацией.\n\nЕсли не указано иное, контент на этой странице предоставляется по лицензии Creative Commons \"С указанием авторства 4.0\", а примеры кода – по лицензии Apache 2.0. Подробнее об этом написано в правилах сайта. Java – это зарегистрированный товарный знак корпорации Oracle и ее аффилированных лиц.\n\nПоследнее обновление: 2024-04-23 UTC.\n\nУсловия использования\nКонфиденциальность",
            "word_count": 368,
            "filtered_content": "Продукты\nПримеры\nВойти\nДокументы\nДокументация по API\nОбзор\nНачало работы\nПолучить ключ API\nКраткое руководство по API Gemini\nУчебники по началу работы\nМодели\nО генеративных моделях\nОбзор API\nСправочник по API\nВерсии API\nПримечания к выпускам\nВозможности, Возможности\nТюнинг модели\nБезопасность\nПутеводители\nПодсказка\nСистемные инструкции\nСемантический поиск\nOAuth-аутентификация\nРасширения Firebase\nМиграция в облако\nРуководства\nПриложения\nУстранение неполадок\nРуководство по устранению неполадок\nДоступ к AI Studio с помощью Workspace\nУстранение неполадок AI Studio\nКак увеличить квоту\nСообщество\nДискурс-форум\nPaLM API (устаревший)\nПерейти на Близнецы\nДокументы ПалМ\nЮридический\n(Предварительная версия) Условия использования\nДоступные регионы\nОзнакомьтесь с новой кулинарной книгой Gemini API и форумом нашего сообщества .\n Эта страница переведена с помощью Cloud Translation API.\nНачните работу с API Gemini \nGemini — это семейство самых эффективных моделей искусственного интеллекта от Google. Этот сайт содержит всю информацию, необходимую для начала создания приложений с помощью Gemini API.\nGemini 1.5 Pro теперь доступен в общедоступной предварительной версии в Google AI Studio. Попробуй это сейчас .\nСамый быстрый способ начать использовать Gemini — использовать Google AI Studio , веб-инструмент, который позволяет создавать прототипы, запускать подсказки прямо в браузере и начинать работу с Gemini API.\nЗапустите Google AI Studio.\nЧтобы начать, перейдите к краткому руководству Gemini API .\nЧтобы узнать, как безопасно и ответственно использовать LLM, обратитесь к настройкам безопасности и документации по безопасности .\nНачать работу с Python\nНачало работы с REST API\nНачало работы в Интернете\nНачните работу с Go\nНачало работы с Node\nНачать работу на Android\nНачать работу на iOS\nНачните работу с Dart (Flutter)\nИспользуйте Google Cloud\nдальнейшее чтение\nЧтобы узнать больше о моделях, на которых работает Gemini API, посетите страницу моделей .\nGemini API и Google AI Studio в настоящее время доступны более чем в 180 странах. Чтобы узнать больше, ознакомьтесь с документацией.\nЕсли не указано иное, контент на этой странице предоставляется по лицензии Creative Commons \"С указанием авторства 4.0\", а примеры кода – по лицензии Apache 2.0. Подробнее об этом написано в правилах сайта. Java – это зарегистрированный товарный знак корпорации Oracle и ее аффилированных лиц.\nПоследнее обновление: 2024-04-23 UTC.\nКонфиденциальность",
            "filtered_word_count": 340
        },
        "https://ai.google.dev/gemini-api/docs?hl=he": {
            "status": "Looks good",
            "content": "מוצרים\nדוגמאות\nהיכנס\nמסמכים\nהפניית API\nסקירה כללית\nשנתחיל?\nקבלת מפתח API\nהמדריך למתחילים של Gemini API\nהמדריך למתחילים של Google AI Studio\nמדריכים לתחילת העבודה\nדגמים\nמידע על מודלים גנרטיביים\nGemini\nGemini API\nסקירה כללית בנושא API\nהפניית API\nגרסאות API\nהערות מוצר\nיכולות\nכוונון של מודל\nהפעלת פונקציה\nהטמעות\nסייפטי\nמדריכים\nהנחיות\nהוראות המערכת\nאחזור סמנטי\nאימות OAuth\nתוספי Firebase\nהעברה לענן\nמדריכים\nהפעלת פונקציה\nהטמעות\nאפליקציות\nפתרון בעיות\nמדריך לפתרון בעיות\nגישה ל-AI Studio באמצעות Workspace\nפתרון בעיות ב-AI Studio\nבקשה למכסה נוספת\nקהילה\nפורום דיונים\nPaLM API (קודם)\nמעבר ל-Gemini\nמסמכי PaLM\nמשפטי\nתנאים והגבלות\n(תצוגה מקדימה) תנאים והגבלות\nאזורים זמינים\nכדאי לעיין בספר הבישול החדש של Gemini API ובפורום הקהילה שלנו.\n דף זה תורגם על ידי Cloud Translation API.\nתחילת השימוש ב-Gemini API \n\nGemini הם משפחה של דגמי ה-AI המתקדמים ביותר של Google. אתר זה מכיל את כל המידע הדרוש כדי להתחיל לפתח אפליקציות באמצעות Gemini API.\n\nGemini 1.5 Pro זמין עכשיו בתוכנית Public Preview ב-Google AI Studio. כדאי לנסות עכשיו.\n\nGoogle AI Studio \n\nהדרך המהירה ביותר להתחיל להשתמש ב-Gemini היא באמצעות Google AI Studio, כלי מבוסס-אינטרנט שמאפשר ליצור אב-טיפוס, להריץ הנחיות ישירות בדפדפן ולהתחיל להשתמש ב-Gemini API.\n\nהפעלת Google AI Studio\nהמדריך למתחילים של Google AI Studio\n\nכדי להתחיל, כדאי להיכנס אל המדריך למתחילים של Gemini API.\n\nכדי להבין איך להשתמש ב-LLM בצורה בטוחה ואחראית, אפשר לעיין בהגדרות הבטיחות ובהנחיות הבטיחות.\n\nתחילת העבודה עם Python\nתחילת השימוש ב-API ל-REST\nתחילת העבודה באינטרנט\nתחילת העבודה עם Go\nתחילת העבודה עם Node\nתחילת העבודה ב-Android\nתחילת העבודה ב-iOS\nתחילת העבודה עם Dut (Flutter)\nפיתוח ב-Google Cloud\nקריאה נוספת\nמידע נוסף על המודלים שמפעילים את Gemini API זמין בדף מודלים.\nGemini API ו-Google AI Studio זמינים כרגע ביותר מ-180 מדינות. אפשר לקרוא מידע נוסף במסמכי התיעוד.\n\nאלא אם צוין אחרת, התוכן של דף זה הוא ברישיון Creative Commons Attribution 4.0 ודוגמאות הקוד הן ברישיון Apache 2.0. לפרטים, ניתן לעיין במדיניות האתר Google Developers‏.‏ Java הוא סימן מסחרי רשום של חברת Oracle ו/או של השותפים העצמאיים שלה.\n\nעדכון אחרון: 2024-04-23 (שעון UTC).\n\nתנאים\nפרטיות",
            "word_count": 336,
            "filtered_content": "מוצרים\nדוגמאות\nהיכנס\nמסמכים\nסקירה כללית\nשנתחיל?\nקבלת מפתח API\nהמדריך למתחילים של Gemini API\nמדריכים לתחילת העבודה\nדגמים\nמידע על מודלים גנרטיביים\nסקירה כללית בנושא API\nגרסאות API\nהערות מוצר\nיכולות\nכוונון של מודל\nסייפטי\nהנחיות\nהוראות המערכת\nאחזור סמנטי\nאימות OAuth\nתוספי Firebase\nהעברה לענן\nאפליקציות\nפתרון בעיות\nמדריך לפתרון בעיות\nגישה ל-AI Studio באמצעות Workspace\nפתרון בעיות ב-AI Studio\nבקשה למכסה נוספת\nקהילה\nפורום דיונים\nPaLM API (קודם)\nמעבר ל-Gemini\nמסמכי PaLM\nמשפטי\nתנאים והגבלות\n(תצוגה מקדימה) תנאים והגבלות\nאזורים זמינים\nכדאי לעיין בספר הבישול החדש של Gemini API ובפורום הקהילה שלנו.\n דף זה תורגם על ידי Cloud Translation API.\nתחילת השימוש ב-Gemini API \nGemini הם משפחה של דגמי ה-AI המתקדמים ביותר של Google. אתר זה מכיל את כל המידע הדרוש כדי להתחיל לפתח אפליקציות באמצעות Gemini API.\nGemini 1.5 Pro זמין עכשיו בתוכנית Public Preview ב-Google AI Studio. כדאי לנסות עכשיו.\nהדרך המהירה ביותר להתחיל להשתמש ב-Gemini היא באמצעות Google AI Studio, כלי מבוסס-אינטרנט שמאפשר ליצור אב-טיפוס, להריץ הנחיות ישירות בדפדפן ולהתחיל להשתמש ב-Gemini API.\nהפעלת Google AI Studio\nכדי להתחיל, כדאי להיכנס אל המדריך למתחילים של Gemini API.\nכדי להבין איך להשתמש ב-LLM בצורה בטוחה ואחראית, אפשר לעיין בהגדרות הבטיחות ובהנחיות הבטיחות.\nתחילת העבודה עם Python\nתחילת השימוש ב-API ל-REST\nתחילת העבודה באינטרנט\nתחילת העבודה עם Go\nתחילת העבודה עם Node\nתחילת העבודה ב-Android\nתחילת העבודה ב-iOS\nתחילת העבודה עם Dut (Flutter)\nפיתוח ב-Google Cloud\nקריאה נוספת\nמידע נוסף על המודלים שמפעילים את Gemini API זמין בדף מודלים.\nGemini API ו-Google AI Studio זמינים כרגע ביותר מ-180 מדינות. אפשר לקרוא מידע נוסף במסמכי התיעוד.\nאלא אם צוין אחרת, התוכן של דף זה הוא ברישיון Creative Commons Attribution 4.0 ודוגמאות הקוד הן ברישיון Apache 2.0. לפרטים, ניתן לעיין במדיניות האתר Google Developers‏.‏ Java הוא סימן מסחרי רשום של חברת Oracle ו/או של השותפים העצמאיים שלה.\nעדכון אחרון: 2024-04-23 (שעון UTC).\nתנאים\nפרטיות",
            "filtered_word_count": 306
        },
        "https://ai.google.dev/gemini-api/docs?hl=ar": {
            "status": "Looks good",
            "content": "المنتجات\nأمثلة\nتسجيل الدخول\nالمستندات\nمرجع واجهة برمجة تطبيقات\nنظرة عامة\nالبدء\nالحصول على مفتاح واجهة برمجة التطبيقات\nالبدء السريع لواجهة برمجة تطبيقات Gemini\nدليل البدء السريع لاستخدام Google AI Studio\nالبرامج التعليمية للبدء\nالنماذج\nلمحة عن النماذج التوليدية\nGemini\nGemini API\nنظرة عامة على واجهة برمجة التطبيقات\nمرجع واجهة برمجة التطبيقات\nإصدارات واجهة برمجة التطبيقات\nملاحظات الإصدار\nالإمكانيات\nضبط النموذج\nاستدعاء الدوالّ\nعمليات التضمين\nدفاع\nالأدلة\nجارٍ الطلب\nتعليمات النظام\nالاسترجاع الدلالي\nمصادقة OAuth\nإضافات Firebase\nنقل البيانات إلى السحابة الإلكترونية\nالبرامج التعليمية\nاستدعاء الدوالّ\nعمليات التضمين\nالتطبيقات\nتحديد المشاكل وحلّها\nدليل تحديد المشاكل وحلّها\nالوصول إلى AI Studio باستخدام Workspace\nتحديد المشاكل في AI Studio وحلّها\nطلب المزيد من الحصص\nفعالية مجتمعية\nمنتدى الحوار\nPaLM API (الإصدار القديم)\nالانتقال إلى حساب Gemini\nمستندات PaLM\nشؤون قانونية\nبنود الخدمة\n(معاينة) بنود الخدمة\nالمناطق المتاحة\nاطّلِع على دليل Gemini API الجديد والمنتدى الخاص بنا.\n تمت ترجمة هذه الصفحة بواسطة Cloud Translation API‏.\nبدء استخدام Gemini API \n\nGemini هي مجموعة من طُرز الذكاء الاصطناعي الأكثر تطوّرًا من Google. يحتوي هذا الموقع الإلكتروني على جميع المعلومات التي تحتاج إليها لبدء إنشاء التطبيقات باستخدام Gemini API.\n\nيتوفر Gemini 1.5 Pro الآن في برنامج \"الميزات التجريبية المتاحة للجميع\" في \"استوديو Google AI Studio\". التجربة الآن\n\nGoogle AI Studio \n\nإنّ أسرع طريقة لبدء استخدام Gemini هي من خلال استوديو Google AI Studio، وهي أداة مستندة إلى الويب تتيح لك إنشاء نماذج أولية وتشغيل الطلبات مباشرةً من متصفحك وبدء استخدام Gemini API.\n\nفتح Google AI Studio\nدليل البدء السريع لاستخدام Google AI Studio\n\nللبدء، انتقِل إلى البدء السريع لواجهة برمجة تطبيقات Gemini API.\n\nللتعرّف على كيفية استخدام النماذج اللغوية الكبيرة بأمان ومسؤولية، يمكنك الاطّلاع على مستندات إعدادات الأمان وإرشادات السلامة.\n\nبدء استخدام بايثون\nبدء استخدام REST API\nالبدء على الويب\nبدء استخدام Go\nبدء استخدام Node\nالبدء على Android\nالبدء على نظام التشغيل iOS\nبدء استخدام Dart (Flutter)\nإنشاء التطبيقات باستخدام Google Cloud\nمحتوى إضافي للقراءة\nللاطّلاع على مزيد من المعلومات حول التصاميم التي تستند إليها واجهة Gemini API، يمكنك مراجعة صفحة النماذج.\nتتوفر واجهة Gemini API وGoogle AI Studio حاليًا في أكثر من 180 بلدًا، ويمكنك الاطّلاع على المستندات للحصول على مزيد من المعلومات.\n\nإنّ محتوى هذه الصفحة مرخّص بموجب ترخيص Creative Commons Attribution 4.0‏ ما لم يُنصّ على خلاف ذلك، ونماذج الرموز مرخّصة بموجب ترخيص Apache 2.0‏. للاطّلاع على التفاصيل، يُرجى مراجعة سياسات موقع Google Developers‏. إنّ Java هي علامة تجارية مسجَّلة لشركة Oracle و/أو شركائها التابعين.\n\nتاريخ التعديل الأخير: 2024-04-23 (حسب التوقيت العالمي المتفَّق عليه)\n\nالبنود\nالخصوصية",
            "word_count": 404,
            "filtered_content": "المنتجات\nأمثلة\nتسجيل الدخول\nالمستندات\nمرجع واجهة برمجة تطبيقات\nنظرة عامة\nالبدء\nالحصول على مفتاح واجهة برمجة التطبيقات\nالبدء السريع لواجهة برمجة تطبيقات Gemini\nالبرامج التعليمية للبدء\nالنماذج\nلمحة عن النماذج التوليدية\nنظرة عامة على واجهة برمجة التطبيقات\nمرجع واجهة برمجة التطبيقات\nإصدارات واجهة برمجة التطبيقات\nملاحظات الإصدار\nالإمكانيات\nضبط النموذج\nدفاع\nالأدلة\nجارٍ الطلب\nتعليمات النظام\nالاسترجاع الدلالي\nمصادقة OAuth\nإضافات Firebase\nنقل البيانات إلى السحابة الإلكترونية\nالبرامج التعليمية\nالتطبيقات\nتحديد المشاكل وحلّها\nدليل تحديد المشاكل وحلّها\nالوصول إلى AI Studio باستخدام Workspace\nتحديد المشاكل في AI Studio وحلّها\nطلب المزيد من الحصص\nفعالية مجتمعية\nمنتدى الحوار\nPaLM API (الإصدار القديم)\nالانتقال إلى حساب Gemini\nمستندات PaLM\nشؤون قانونية\nبنود الخدمة\n(معاينة) بنود الخدمة\nالمناطق المتاحة\nاطّلِع على دليل Gemini API الجديد والمنتدى الخاص بنا.\n تمت ترجمة هذه الصفحة بواسطة Cloud Translation API‏.\nبدء استخدام Gemini API \nGemini هي مجموعة من طُرز الذكاء الاصطناعي الأكثر تطوّرًا من Google. يحتوي هذا الموقع الإلكتروني على جميع المعلومات التي تحتاج إليها لبدء إنشاء التطبيقات باستخدام Gemini API.\nيتوفر Gemini 1.5 Pro الآن في برنامج \"الميزات التجريبية المتاحة للجميع\" في \"استوديو Google AI Studio\". التجربة الآن\nإنّ أسرع طريقة لبدء استخدام Gemini هي من خلال استوديو Google AI Studio، وهي أداة مستندة إلى الويب تتيح لك إنشاء نماذج أولية وتشغيل الطلبات مباشرةً من متصفحك وبدء استخدام Gemini API.\nفتح Google AI Studio\nللبدء، انتقِل إلى البدء السريع لواجهة برمجة تطبيقات Gemini API.\nللتعرّف على كيفية استخدام النماذج اللغوية الكبيرة بأمان ومسؤولية، يمكنك الاطّلاع على مستندات إعدادات الأمان وإرشادات السلامة.\nبدء استخدام بايثون\nبدء استخدام REST API\nالبدء على الويب\nبدء استخدام Go\nبدء استخدام Node\nالبدء على Android\nالبدء على نظام التشغيل iOS\nبدء استخدام Dart (Flutter)\nإنشاء التطبيقات باستخدام Google Cloud\nمحتوى إضافي للقراءة\nللاطّلاع على مزيد من المعلومات حول التصاميم التي تستند إليها واجهة Gemini API، يمكنك مراجعة صفحة النماذج.\nتتوفر واجهة Gemini API وGoogle AI Studio حاليًا في أكثر من 180 بلدًا، ويمكنك الاطّلاع على المستندات للحصول على مزيد من المعلومات.\nإنّ محتوى هذه الصفحة مرخّص بموجب ترخيص Creative Commons Attribution 4.0‏ ما لم يُنصّ على خلاف ذلك، ونماذج الرموز مرخّصة بموجب ترخيص Apache 2.0‏. للاطّلاع على التفاصيل، يُرجى مراجعة سياسات موقع Google Developers‏. إنّ Java هي علامة تجارية مسجَّلة لشركة Oracle و/أو شركائها التابعين.\nتاريخ التعديل الأخير: 2024-04-23 (حسب التوقيت العالمي المتفَّق عليه)\nالبنود\nالخصوصية",
            "filtered_word_count": 376
        },
        "https://ai.google.dev/gemini-api/docs?hl=fa": {
            "status": "Looks good",
            "content": "محصولات\nمثال ها\nورود به برنامه\nاسناد\nمرجع API\nبررسی اجمالی\nشروع کنید\nیک کلید API دریافت کنید\nGemini API شروع سریع\nشروع سریع استودیوی هوش مصنوعی گوگل\nآموزش های شروع\nمدل ها\nدرباره مدل های مولد\nGemini\nGemini API\nنمای کلی API\nمرجع API\nنسخه های API\nیادداشت های انتشار\nقابلیت ها، قابلیت ها\nتیونینگ مدل\nفراخوانی تابع\nجاسازی ها\nایمنی\nراهنماها\nتحریک کردن\nدستورالعمل های سیستم\nبازیابی معنایی\nاحراز هویت OAuth\nافزونه های Firebase\nمهاجرت به ابر\nآموزش ها\nفراخوانی تابع\nجاسازی ها\nبرنامه های کاربردی\nعیب یابی\nراهنمای عیب یابی\nبا استفاده از Workspace به AI Studio دسترسی پیدا کنید\nعیب یابی AI Studio\nدرخواست سهمیه بیشتر\nانجمن\nانجمن گفتمان\nPalm API (میراث)\nبه جمینی مهاجرت کنید\nاسناد PalM\nمجاز\nشرایط استفاده از خدمات\n(پیش نمایش) شرایط خدمات\nمناطق در دسترس\nکتاب آشپزی جدید Gemini API و انجمن انجمن ما را بررسی کنید.\n این صفحه به‌وسیله ‏Cloud Translation API‏ ترجمه شده است.\nبا Gemini API شروع کنید \n\nجمینی خانواده ای از توانمندترین مدل های هوش مصنوعی گوگل است. این سایت حاوی تمام اطلاعاتی است که برای شروع ساختن اپلیکیشن با Gemini API نیاز دارید.\n\nGemini 1.5 Pro اکنون در پیش نمایش عمومی در Google AI Studio در دسترس است. الآن امتحانش کن .\n\nGoogle AI Studio \n\nسریع‌ترین راه برای شروع استفاده از Gemini، استفاده از Google AI Studio است، ابزاری مبتنی بر وب که به شما امکان می‌دهد نمونه‌سازی اولیه کنید، درخواست‌ها را مستقیماً در مرورگر خود اجرا کنید و با Gemini API شروع کنید.\n\nGoogle AI Studio را راه اندازی کنید\nشروع سریع استودیوی هوش مصنوعی گوگل\n\nبرای شروع، به Gemini API Quickstart بروید.\n\nبرای یادگیری نحوه استفاده ایمن و مسئولانه از LLM، به تنظیمات ایمنی و مستندات راهنمای ایمنی مراجعه کنید.\n\nبا پایتون شروع کنید\nبا REST API شروع کنید\nدر وب شروع کنید\nبا Go شروع کنید\nبا Node شروع کنید\nدر اندروید شروع کنید\nدر iOS شروع کنید\nبا دارت (فلاتر) شروع کنید\nساخت بر روی Google Cloud\nبیشتر خواندن\nبرای کسب اطلاعات بیشتر در مورد مدل هایی که API Gemini را تامین می کنند، به صفحه مدل ها مراجعه کنید.\nGemini API و Google AI Studio در حال حاضر در بیش از 180 کشور در دسترس هستند، برای کسب اطلاعات بیشتر، مستندات را بررسی کنید.\n\nجز در مواردی که غیر از این ذکر شده باشد،‌محتوای این صفحه تحت مجوز Creative Commons Attribution 4.0 License است. نمونه کدها نیز دارای مجوز Apache 2.0 License است. برای اطلاع از جزئیات، به خطمشی‌های سایت Google Developers‏ مراجعه کنید. جاوا علامت تجاری ثبت‌شده Oracle و/یا شرکت‌های وابسته به آن است.\n\nتاریخ آخرین به‌روزرسانی 2024-04-23 به‌وقت ساعت هماهنگ جهانی.\n\nشرایط\nحریم خصوصی",
            "word_count": 435,
            "filtered_content": "محصولات\nمثال ها\nورود به برنامه\nاسناد\nبررسی اجمالی\nشروع کنید\nیک کلید API دریافت کنید\nGemini API شروع سریع\nآموزش های شروع\nمدل ها\nدرباره مدل های مولد\nنمای کلی API\nنسخه های API\nیادداشت های انتشار\nقابلیت ها، قابلیت ها\nتیونینگ مدل\nایمنی\nراهنماها\nتحریک کردن\nدستورالعمل های سیستم\nبازیابی معنایی\nاحراز هویت OAuth\nافزونه های Firebase\nمهاجرت به ابر\nآموزش ها\nبرنامه های کاربردی\nعیب یابی\nراهنمای عیب یابی\nبا استفاده از Workspace به AI Studio دسترسی پیدا کنید\nعیب یابی AI Studio\nدرخواست سهمیه بیشتر\nانجمن\nانجمن گفتمان\nPalm API (میراث)\nبه جمینی مهاجرت کنید\nاسناد PalM\nمجاز\nشرایط استفاده از خدمات\n(پیش نمایش) شرایط خدمات\nمناطق در دسترس\nکتاب آشپزی جدید Gemini API و انجمن انجمن ما را بررسی کنید.\n این صفحه به‌وسیله ‏Cloud Translation API‏ ترجمه شده است.\nبا Gemini API شروع کنید \nجمینی خانواده ای از توانمندترین مدل های هوش مصنوعی گوگل است. این سایت حاوی تمام اطلاعاتی است که برای شروع ساختن اپلیکیشن با Gemini API نیاز دارید.\nGemini 1.5 Pro اکنون در پیش نمایش عمومی در Google AI Studio در دسترس است. الآن امتحانش کن .\nسریع‌ترین راه برای شروع استفاده از Gemini، استفاده از Google AI Studio است، ابزاری مبتنی بر وب که به شما امکان می‌دهد نمونه‌سازی اولیه کنید، درخواست‌ها را مستقیماً در مرورگر خود اجرا کنید و با Gemini API شروع کنید.\nGoogle AI Studio را راه اندازی کنید\nبرای شروع، به Gemini API Quickstart بروید.\nبرای یادگیری نحوه استفاده ایمن و مسئولانه از LLM، به تنظیمات ایمنی و مستندات راهنمای ایمنی مراجعه کنید.\nبا پایتون شروع کنید\nبا REST API شروع کنید\nدر وب شروع کنید\nبا Go شروع کنید\nبا Node شروع کنید\nدر اندروید شروع کنید\nدر iOS شروع کنید\nبا دارت (فلاتر) شروع کنید\nساخت بر روی Google Cloud\nبیشتر خواندن\nبرای کسب اطلاعات بیشتر در مورد مدل هایی که API Gemini را تامین می کنند، به صفحه مدل ها مراجعه کنید.\nGemini API و Google AI Studio در حال حاضر در بیش از 180 کشور در دسترس هستند، برای کسب اطلاعات بیشتر، مستندات را بررسی کنید.\nجز در مواردی که غیر از این ذکر شده باشد،‌محتوای این صفحه تحت مجوز Creative Commons Attribution 4.0 License است. نمونه کدها نیز دارای مجوز Apache 2.0 License است. برای اطلاع از جزئیات، به خطمشی‌های سایت Google Developers‏ مراجعه کنید. جاوا علامت تجاری ثبت‌شده Oracle و/یا شرکت‌های وابسته به آن است.\nتاریخ آخرین به‌روزرسانی 2024-04-23 به‌وقت ساعت هماهنگ جهانی.\nشرایط\nحریم خصوصی",
            "filtered_word_count": 405
        },
        "https://ai.google.dev/gemini-api/docs?hl=hi": {
            "status": "Looks good",
            "content": "प्रॉडक्ट\nउदाहरण\nप्रवेश करें\nDocs\nएपीआई का संदर्भ\nखास जानकारी\nशुरू करें\nएपीआई पासकोड पाएं\nGemini API क्विकस्टार्ट\nGoogle AI Studio क्विकस्टार्ट\nट्यूटोरियल शुरू करना\nमॉडल\nजनरेटिव मॉडल के बारे में जानकारी\nGemini\nGemini API\nएपीआई के बारे में खास जानकारी\nएपीआई का संदर्भ\nएपीआई वर्शन\nप्रॉडक्ट की जानकारी\nमिलने वाली अनुमतियां\nमॉडल ट्यूनिंग\nफ़ंक्शन कॉल करने की सुविधा\nएम्बेड करना\nसुरक्षा\nगाइड\nप्रॉम्प्ट करना\nसिस्टम से जुड़े निर्देश\nसिमैंटिक रिकवरी\nOAuth प्रमाणीकरण\nFirebase एक्सटेंशन\nCloud पर माइग्रेट करें\nट्यूटोरियल\nफ़ंक्शन कॉल करने की सुविधा\nएम्बेड करना\nऐप्लिकेशन\nसमस्या का हल\nसमस्या हल करने के लिए गाइड\nWorkspace की मदद से एआई स्टूडियो को ऐक्सेस करना\nAI Studio से जुड़ी समस्याएं हल करना\nअनुरोध भेजने की सीमा बढ़ाने का अनुरोध करना\nकम्यूनिटी\nबातचीत के लिए फ़ोरम\nPaLM API (लेगसी)\nGemini में माइग्रेट करें\nPaLM के दस्तावेज़\nकानूनी\nसेवा की शर्तें\n(झलक) सेवा की शर्तें\nउपलब्ध क्षेत्र\nनया Gemini API कुकबुक और हमारा कम्यूनिटी फ़ोरम देखें.\n इस पेज का अनुवाद Cloud Translation API से किया गया है.\nGemini API का इस्तेमाल शुरू करना \n\nGemini, Google के सबसे ज़्यादा कारगर एआई मॉडल का फ़ैमिली ग्रुप है. इस साइट में वह सारी जानकारी मौजूद है जो Gemini API की मदद से ऐप्लिकेशन बनाने के लिए ज़रूरी है.\n\nGoogle AI Studio में, Gemini 1.5 Pro अब Public Preview में उपलब्ध है. इसे अभी आज़माएं.\n\nGoogle AI Studio \n\nGemini का इस्तेमाल तेज़ी से शुरू करने के लिए, Google AI Studio का इस्तेमाल करें. यह वेब पर आधारित टूल है. इसकी मदद से प्रोटोटाइप बनाया जा सकता है, सीधे अपने ब्राउज़र में प्रॉम्प्ट चलाए जा सकते हैं, और Gemini API का इस्तेमाल किया जा सकता है.\n\nGoogle AI Studio लॉन्च करें\nGoogle AI Studio क्विकस्टार्ट\n\nशुरू करने के लिए, Gemini API क्विकस्टार्ट पर जाएं.\n\nएलएलएम का सुरक्षित और ज़िम्मेदारी के साथ इस्तेमाल करने के बारे में जानने के लिए, सुरक्षा सेटिंग और सुरक्षा से जुड़े दिशा-निर्देश वाले दस्तावेज़ देखें.\n\nPython का इस्तेमाल शुरू करना\nREST API का इस्तेमाल शुरू करना\nवेब पर इस्तेमाल शुरू करना\nGo के साथ शुरू करें\nNode का इस्तेमाल शुरू करें\nAndroid पर इस्तेमाल शुरू करना\niOS पर इस्तेमाल करना शुरू करें\nDart (Flutter) के साथ शुरू करना\nGoogle Cloud पर बनाएं\nइसके बारे में और पढ़ें\nGemini API को बेहतर बनाने वाले मॉडल के बारे में ज़्यादा जानने के लिए, मॉडल पेज देखें.\nफ़िलहाल, Gemini API और Google AI Studio 180 से ज़्यादा देशों में उपलब्ध हैं. ज़्यादा जानने के लिए दस्तावेज़ देखें.\n\nजब तक कुछ अलग से न बताया जाए, तब तक इस पेज की सामग्री को Creative Commons Attribution 4.0 License के तहत और कोड के नमूनों को Apache 2.0 License के तहत लाइसेंस मिला है. ज़्यादा जानकारी के लिए, Google Developers साइट नीतियां देखें. Oracle और/या इससे जुड़ी हुई कंपनियों का, Java एक रजिस्टर किया हुआ ट्रेडमार्क है.\n\nआखिरी बार 2024-04-23 (UTC) को अपडेट किया गया.\n\nशर्तें\nनिजता",
            "word_count": 470,
            "filtered_content": "प्रॉडक्ट\nउदाहरण\nप्रवेश करें\nखास जानकारी\nशुरू करें\nएपीआई पासकोड पाएं\nGemini API क्विकस्टार्ट\nट्यूटोरियल शुरू करना\nमॉडल\nजनरेटिव मॉडल के बारे में जानकारी\nएपीआई के बारे में खास जानकारी\nएपीआई वर्शन\nप्रॉडक्ट की जानकारी\nमिलने वाली अनुमतियां\nमॉडल ट्यूनिंग\nसुरक्षा\nगाइड\nप्रॉम्प्ट करना\nसिस्टम से जुड़े निर्देश\nसिमैंटिक रिकवरी\nOAuth प्रमाणीकरण\nFirebase एक्सटेंशन\nCloud पर माइग्रेट करें\nट्यूटोरियल\nऐप्लिकेशन\nसमस्या का हल\nसमस्या हल करने के लिए गाइड\nWorkspace की मदद से एआई स्टूडियो को ऐक्सेस करना\nAI Studio से जुड़ी समस्याएं हल करना\nअनुरोध भेजने की सीमा बढ़ाने का अनुरोध करना\nकम्यूनिटी\nबातचीत के लिए फ़ोरम\nPaLM API (लेगसी)\nGemini में माइग्रेट करें\nPaLM के दस्तावेज़\nकानूनी\nसेवा की शर्तें\n(झलक) सेवा की शर्तें\nउपलब्ध क्षेत्र\nनया Gemini API कुकबुक और हमारा कम्यूनिटी फ़ोरम देखें.\n इस पेज का अनुवाद Cloud Translation API से किया गया है.\nGemini API का इस्तेमाल शुरू करना \nGemini, Google के सबसे ज़्यादा कारगर एआई मॉडल का फ़ैमिली ग्रुप है. इस साइट में वह सारी जानकारी मौजूद है जो Gemini API की मदद से ऐप्लिकेशन बनाने के लिए ज़रूरी है.\nGoogle AI Studio में, Gemini 1.5 Pro अब Public Preview में उपलब्ध है. इसे अभी आज़माएं.\nGemini का इस्तेमाल तेज़ी से शुरू करने के लिए, Google AI Studio का इस्तेमाल करें. यह वेब पर आधारित टूल है. इसकी मदद से प्रोटोटाइप बनाया जा सकता है, सीधे अपने ब्राउज़र में प्रॉम्प्ट चलाए जा सकते हैं, और Gemini API का इस्तेमाल किया जा सकता है.\nGoogle AI Studio लॉन्च करें\nशुरू करने के लिए, Gemini API क्विकस्टार्ट पर जाएं.\nएलएलएम का सुरक्षित और ज़िम्मेदारी के साथ इस्तेमाल करने के बारे में जानने के लिए, सुरक्षा सेटिंग और सुरक्षा से जुड़े दिशा-निर्देश वाले दस्तावेज़ देखें.\nPython का इस्तेमाल शुरू करना\nREST API का इस्तेमाल शुरू करना\nवेब पर इस्तेमाल शुरू करना\nGo के साथ शुरू करें\nNode का इस्तेमाल शुरू करें\nAndroid पर इस्तेमाल शुरू करना\niOS पर इस्तेमाल करना शुरू करें\nDart (Flutter) के साथ शुरू करना\nGoogle Cloud पर बनाएं\nइसके बारे में और पढ़ें\nGemini API को बेहतर बनाने वाले मॉडल के बारे में ज़्यादा जानने के लिए, मॉडल पेज देखें.\nफ़िलहाल, Gemini API और Google AI Studio 180 से ज़्यादा देशों में उपलब्ध हैं. ज़्यादा जानने के लिए दस्तावेज़ देखें.\nजब तक कुछ अलग से न बताया जाए, तब तक इस पेज की सामग्री को Creative Commons Attribution 4.0 License के तहत और कोड के नमूनों को Apache 2.0 License के तहत लाइसेंस मिला है. ज़्यादा जानकारी के लिए, Google Developers साइट नीतियां देखें. Oracle और/या इससे जुड़ी हुई कंपनियों का, Java एक रजिस्टर किया हुआ ट्रेडमार्क है.\nआखिरी बार 2024-04-23 (UTC) को अपडेट किया गया.\nशर्तें\nनिजता",
            "filtered_word_count": 435
        },
        "https://ai.google.dev/gemini-api/docs?hl=bn": {
            "status": "Looks good",
            "content": "পণ্য\nউদাহরণ\nসাইন-ইন করুন\nডক্স\nAPI রেফারেন্স\nওভারভিউ\nএবার শুরু করা যাক\nএকটি API কী পান\nজেমিনি API কুইকস্টার্ট\nগুগল এআই স্টুডিও দ্রুত শুরু\nটিউটোরিয়াল শুরু করা হচ্ছে\nমডেল\nজেনারেটিভ মডেল সম্পর্কে\nGemini\nGemini API\nAPI ওভারভিউ\nAPI রেফারেন্স\nAPI সংস্করণ\nঅব্যাহতি পত্র\nক্ষমতা, ক্ষমতা\nমডেল টিউনিং\nফাংশন কলিং\nএমবেডিং\nনিরাপত্তা\nগাইড\nপ্রম্পটিং\nসিস্টেম নির্দেশাবলী\nশব্দার্থিক পুনরুদ্ধার\nOAuth প্রমাণীকরণ\nফায়ারবেস এক্সটেনশন\nক্লাউডে মাইগ্রেট করুন\nটিউটোরিয়াল\nফাংশন কলিং\nএমবেডিং\nঅ্যাপ্লিকেশন\nসমস্যা সমাধান\nসমস্যা সমাধানের গাইড\nওয়ার্কস্পেস ব্যবহার করে এআই স্টুডিও অ্যাক্সেস করুন\nএআই স্টুডিওর সমস্যা সমাধান করা হচ্ছে\nআরো কোটা অনুরোধ\nসম্প্রদায়\nডিসকোর্স ফোরাম\nPaLM API (উত্তরাধিকার)\nমিথুন রাশিতে চলে যান\nPaLM ডক্স\nআইনি\nসেবা পাবার শর্ত\n(প্রিভিউ) পরিষেবার শর্তাবলী\nউপলব্ধ অঞ্চল\nনতুন জেমিনি API কুকবুক এবং আমাদের কমিউনিটি ফোরাম দেখুন।\n এই পৃষ্ঠাটি Cloud Translation API অনুবাদ করেছে।\nGemini API দিয়ে শুরু করুন \n\nGemini হল Google এর সবচেয়ে সক্ষম AI মডেলের একটি পরিবার। জেমিনি এপিআই-এর সাহায্যে অ্যাপ্লিকেশান তৈরি করা শুরু করার জন্য আপনার প্রয়োজনীয় সমস্ত তথ্য এই সাইটে রয়েছে৷\n\nGemini 1.5 Pro এখন Google AI স্টুডিওতে পাবলিক প্রিভিউতে পাওয়া যাচ্ছে। এটা এখন চেষ্টা কর .\n\nGoogle AI Studio \n\nGemini ব্যবহার শুরু করার দ্রুততম উপায় হল Google AI Studio , একটি ওয়েব-ভিত্তিক টুল যা আপনাকে প্রোটোটাইপ করতে দেয়, সরাসরি আপনার ব্রাউজারে প্রম্পট চালাতে এবং Gemini API দিয়ে শুরু করতে দেয়।\n\nগুগল এআই স্টুডিও চালু করুন\nগুগল এআই স্টুডিও দ্রুত শুরু\n\nশুরু করতে, Gemini API quickstart- এ যান।\n\nকীভাবে নিরাপদে এবং দায়িত্বের সাথে LLM ব্যবহার করবেন তা শিখতে, নিরাপত্তা সেটিংস এবং নিরাপত্তা নির্দেশিকা ডকুমেন্টেশন পড়ুন।\n\nপাইথন দিয়ে শুরু করুন\nREST API দিয়ে শুরু করুন\nওয়েবে শুরু করুন\nGo দিয়ে শুরু করুন\nনোড দিয়ে শুরু করুন\nAndroid এ শুরু করুন\niOS এ শুরু করুন\nডার্ট দিয়ে শুরু করুন (ফ্লাটার)\nGoogle ক্লাউডে তৈরি করুন\nআরও পড়া\nজেমিনি APIকে শক্তি দেয় এমন মডেলগুলি সম্পর্কে আরও জানতে, মডেল পৃষ্ঠাটি পড়ুন৷\nGemini API এবং Google AI স্টুডিও বর্তমানে 180+ দেশে উপলব্ধ, আরও জানতে ডকুমেন্টেশন দেখুন।\n\nঅন্য কিছু উল্লেখ না করা থাকলে, এই পৃষ্ঠার কন্টেন্ট Creative Commons Attribution 4.0 License-এর অধীনে এবং কোডের নমুনাগুলি Apache 2.0 License-এর অধীনে লাইসেন্স প্রাপ্ত। আরও জানতে, Google Developers সাইট নীতি দেখুন। Java হল Oracle এবং/অথবা তার অ্যাফিলিয়েট সংস্থার রেজিস্টার্ড ট্রেডমার্ক।\n\n2024-04-23 UTC-তে শেষবার আপডেট করা হয়েছে।\n\nশর্তাবলী\nগোপনীয়তা",
            "word_count": 355,
            "filtered_content": "পণ্য\nউদাহরণ\nসাইন-ইন করুন\nডক্স\nওভারভিউ\nএবার শুরু করা যাক\nএকটি API কী পান\nজেমিনি API কুইকস্টার্ট\nটিউটোরিয়াল শুরু করা হচ্ছে\nমডেল\nজেনারেটিভ মডেল সম্পর্কে\nAPI ওভারভিউ\nAPI সংস্করণ\nঅব্যাহতি পত্র\nক্ষমতা, ক্ষমতা\nমডেল টিউনিং\nনিরাপত্তা\nগাইড\nপ্রম্পটিং\nসিস্টেম নির্দেশাবলী\nশব্দার্থিক পুনরুদ্ধার\nOAuth প্রমাণীকরণ\nফায়ারবেস এক্সটেনশন\nক্লাউডে মাইগ্রেট করুন\nটিউটোরিয়াল\nঅ্যাপ্লিকেশন\nসমস্যা সমাধান\nসমস্যা সমাধানের গাইড\nওয়ার্কস্পেস ব্যবহার করে এআই স্টুডিও অ্যাক্সেস করুন\nএআই স্টুডিওর সমস্যা সমাধান করা হচ্ছে\nআরো কোটা অনুরোধ\nসম্প্রদায়\nডিসকোর্স ফোরাম\nPaLM API (উত্তরাধিকার)\nমিথুন রাশিতে চলে যান\nPaLM ডক্স\nআইনি\nসেবা পাবার শর্ত\n(প্রিভিউ) পরিষেবার শর্তাবলী\nউপলব্ধ অঞ্চল\nনতুন জেমিনি API কুকবুক এবং আমাদের কমিউনিটি ফোরাম দেখুন।\n এই পৃষ্ঠাটি Cloud Translation API অনুবাদ করেছে।\nGemini API দিয়ে শুরু করুন \nGemini হল Google এর সবচেয়ে সক্ষম AI মডেলের একটি পরিবার। জেমিনি এপিআই-এর সাহায্যে অ্যাপ্লিকেশান তৈরি করা শুরু করার জন্য আপনার প্রয়োজনীয় সমস্ত তথ্য এই সাইটে রয়েছে৷\nGemini 1.5 Pro এখন Google AI স্টুডিওতে পাবলিক প্রিভিউতে পাওয়া যাচ্ছে। এটা এখন চেষ্টা কর .\nGemini ব্যবহার শুরু করার দ্রুততম উপায় হল Google AI Studio , একটি ওয়েব-ভিত্তিক টুল যা আপনাকে প্রোটোটাইপ করতে দেয়, সরাসরি আপনার ব্রাউজারে প্রম্পট চালাতে এবং Gemini API দিয়ে শুরু করতে দেয়।\nগুগল এআই স্টুডিও চালু করুন\nশুরু করতে, Gemini API quickstart- এ যান।\nকীভাবে নিরাপদে এবং দায়িত্বের সাথে LLM ব্যবহার করবেন তা শিখতে, নিরাপত্তা সেটিংস এবং নিরাপত্তা নির্দেশিকা ডকুমেন্টেশন পড়ুন।\nপাইথন দিয়ে শুরু করুন\nREST API দিয়ে শুরু করুন\nওয়েবে শুরু করুন\nGo দিয়ে শুরু করুন\nনোড দিয়ে শুরু করুন\nAndroid এ শুরু করুন\niOS এ শুরু করুন\nডার্ট দিয়ে শুরু করুন (ফ্লাটার)\nGoogle ক্লাউডে তৈরি করুন\nআরও পড়া\nজেমিনি APIকে শক্তি দেয় এমন মডেলগুলি সম্পর্কে আরও জানতে, মডেল পৃষ্ঠাটি পড়ুন৷\nGemini API এবং Google AI স্টুডিও বর্তমানে 180+ দেশে উপলব্ধ, আরও জানতে ডকুমেন্টেশন দেখুন।\nঅন্য কিছু উল্লেখ না করা থাকলে, এই পৃষ্ঠার কন্টেন্ট Creative Commons Attribution 4.0 License-এর অধীনে এবং কোডের নমুনাগুলি Apache 2.0 License-এর অধীনে লাইসেন্স প্রাপ্ত। আরও জানতে, Google Developers সাইট নীতি দেখুন। Java হল Oracle এবং/অথবা তার অ্যাফিলিয়েট সংস্থার রেজিস্টার্ড ট্রেডমার্ক।\n2024-04-23 UTC-তে শেষবার আপডেট করা হয়েছে।\nশর্তাবলী\nগোপনীয়তা",
            "filtered_word_count": 329
        },
        "https://ai.google.dev/gemini-api/docs?hl=th": {
            "status": "Looks good",
            "content": "ผลิตภัณฑ์\nตัวอย่าง\nลงชื่อเข้าใช้\nเอกสาร\nเอกสารอ้างอิง API\nภาพรวม\nเริ่มต้น\nรับคีย์ API\nการเริ่มต้นใช้งาน Gemini API อย่างรวดเร็ว\nคู่มือเริ่มใช้งาน Google AI Studio อย่างรวดเร็ว\nบทแนะนําสําหรับเริ่มต้นใช้งาน\nรูปแบบ\nเกี่ยวกับโมเดล Generative\nGemini\nGemini API\nภาพรวม API\nเอกสารอ้างอิง API\nเวอร์ชัน API\nบันทึกประจำรุ่น\nความสามารถ\nการปรับแต่งโมเดล\nการเรียกใช้ฟังก์ชัน\nการฝัง\nความปลอดภัย\nคำแนะนำ\nข้อความแจ้ง\nวิธีการสำหรับระบบ\nการดึงข้อมูลความหมาย\nการตรวจสอบสิทธิ์ OAuth\nส่วนขยาย Firebase\nย้ายข้อมูลไปยังระบบคลาวด์\nบทแนะนำ\nการเรียกใช้ฟังก์ชัน\nการฝัง\nแอปพลิเคชัน\nการแก้ปัญหา\nคู่มือการแก้ปัญหา\nเข้าถึง AI Studio โดยใช้ Workspace\nการแก้ปัญหาเกี่ยวกับ AI Studio\nขอเพิ่มโควต้า\nชุมชน\nฟอรัมสนทนา\nPaLM API (เดิม)\nย้ายข้อมูลไปยัง Gemini\nเอกสาร PaLM\nกฎหมาย\nข้อกำหนดในการให้บริการ\n(ตัวอย่าง) ข้อกำหนดในการให้บริการ\nภูมิภาคที่สามารถใช้บริการได้\nดูตำราอาหาร Gemini API และฟอรัมชุมชนของเรา\n หน้านี้ได้รับการแปลโดย Cloud Translation API\nเริ่มต้นใช้งาน Gemini API \n\nGemini เป็นกลุ่มโมเดล AI ที่มีความสามารถมากที่สุดของ Google เว็บไซต์นี้มีข้อมูลทั้งหมดที่จำเป็นต่อการสร้างแอปพลิเคชันด้วย Gemini API\n\nGemini 1.5 Pro พร้อมให้ใช้งานในเวอร์ชันตัวอย่างแบบสาธารณะใน Google AI Studio แล้ว ลองใช้เลย\n\nGoogle AI Studio \n\nวิธีที่เร็วที่สุดในการเริ่มใช้ Gemini คือ Google AI Studio ซึ่งเป็นเครื่องมือบนเว็บที่ช่วยให้คุณสร้างต้นแบบ เรียกใช้พรอมต์ในเบราว์เซอร์ได้โดยตรง และเริ่มต้นใช้งาน Gemini API\n\nเปิด Google AI Studio\nคู่มือเริ่มใช้งาน Google AI Studio อย่างรวดเร็ว\n\nหากต้องการเริ่มต้นใช้งาน ให้ไปที่การเริ่มต้นอย่างรวดเร็วสำหรับ Gemini API\n\nหากต้องการดูวิธีใช้ LLM อย่างปลอดภัยและมีความรับผิดชอบ โปรดอ่านเอกสารการตั้งค่าความปลอดภัยและคำแนะนำด้านความปลอดภัย\n\nเริ่มต้นใช้งาน Python\nเริ่มต้นใช้งาน REST API\nเริ่มต้นใช้งานบนเว็บ\nเริ่มต้นใช้งาน Go\nเริ่มต้นใช้งานโหนด\nเริ่มต้นใช้งานบน Android\nเริ่มต้นใช้งานบน iOS\nเริ่มต้นใช้งาน Dart (Flutter)\nสร้างบน Google Cloud\nอ่านเพิ่มเติม\nดูข้อมูลเพิ่มเติมเกี่ยวกับโมเดลที่ขับเคลื่อน Gemini API ได้ที่หน้ารุ่น\nขณะนี้ Gemini API และ Google AI Studio มีให้บริการในกว่า 180 ประเทศ โปรดอ่านเอกสารประกอบเพื่อดูข้อมูลเพิ่มเติม\n\nเนื้อหาของหน้าเว็บนี้ได้รับอนุญาตภายใต้ใบอนุญาตที่ต้องระบุที่มาของครีเอทีฟคอมมอนส์ 4.0 และตัวอย่างโค้ดได้รับอนุญาตภายใต้ใบอนุญาต Apache 2.0 เว้นแต่จะระบุไว้เป็นอย่างอื่น โปรดดูรายละเอียดที่นโยบายเว็บไซต์ Google Developers Java เป็นเครื่องหมายการค้าจดทะเบียนของ Oracle และ/หรือบริษัทในเครือ\n\nอัปเดตล่าสุด 2024-04-23 UTC\n\nข้อกำหนด\nความเป็นส่วนตัว",
            "word_count": 188,
            "filtered_content": "ผลิตภัณฑ์\nตัวอย่าง\nลงชื่อเข้าใช้\nเอกสาร\nภาพรวม\nเริ่มต้น\nรับคีย์ API\nการเริ่มต้นใช้งาน Gemini API อย่างรวดเร็ว\nบทแนะนําสําหรับเริ่มต้นใช้งาน\nรูปแบบ\nเกี่ยวกับโมเดล Generative\nภาพรวม API\nเวอร์ชัน API\nบันทึกประจำรุ่น\nความสามารถ\nการปรับแต่งโมเดล\nความปลอดภัย\nคำแนะนำ\nข้อความแจ้ง\nวิธีการสำหรับระบบ\nการดึงข้อมูลความหมาย\nการตรวจสอบสิทธิ์ OAuth\nส่วนขยาย Firebase\nย้ายข้อมูลไปยังระบบคลาวด์\nบทแนะนำ\nแอปพลิเคชัน\nการแก้ปัญหา\nคู่มือการแก้ปัญหา\nเข้าถึง AI Studio โดยใช้ Workspace\nการแก้ปัญหาเกี่ยวกับ AI Studio\nขอเพิ่มโควต้า\nชุมชน\nฟอรัมสนทนา\nPaLM API (เดิม)\nย้ายข้อมูลไปยัง Gemini\nเอกสาร PaLM\nกฎหมาย\nข้อกำหนดในการให้บริการ\n(ตัวอย่าง) ข้อกำหนดในการให้บริการ\nภูมิภาคที่สามารถใช้บริการได้\nดูตำราอาหาร Gemini API และฟอรัมชุมชนของเรา\n หน้านี้ได้รับการแปลโดย Cloud Translation API\nเริ่มต้นใช้งาน Gemini API \nGemini เป็นกลุ่มโมเดล AI ที่มีความสามารถมากที่สุดของ Google เว็บไซต์นี้มีข้อมูลทั้งหมดที่จำเป็นต่อการสร้างแอปพลิเคชันด้วย Gemini API\nGemini 1.5 Pro พร้อมให้ใช้งานในเวอร์ชันตัวอย่างแบบสาธารณะใน Google AI Studio แล้ว ลองใช้เลย\nวิธีที่เร็วที่สุดในการเริ่มใช้ Gemini คือ Google AI Studio ซึ่งเป็นเครื่องมือบนเว็บที่ช่วยให้คุณสร้างต้นแบบ เรียกใช้พรอมต์ในเบราว์เซอร์ได้โดยตรง และเริ่มต้นใช้งาน Gemini API\nเปิด Google AI Studio\nหากต้องการเริ่มต้นใช้งาน ให้ไปที่การเริ่มต้นอย่างรวดเร็วสำหรับ Gemini API\nหากต้องการดูวิธีใช้ LLM อย่างปลอดภัยและมีความรับผิดชอบ โปรดอ่านเอกสารการตั้งค่าความปลอดภัยและคำแนะนำด้านความปลอดภัย\nเริ่มต้นใช้งาน Python\nเริ่มต้นใช้งาน REST API\nเริ่มต้นใช้งานบนเว็บ\nเริ่มต้นใช้งาน Go\nเริ่มต้นใช้งานโหนด\nเริ่มต้นใช้งานบน Android\nเริ่มต้นใช้งานบน iOS\nเริ่มต้นใช้งาน Dart (Flutter)\nสร้างบน Google Cloud\nอ่านเพิ่มเติม\nดูข้อมูลเพิ่มเติมเกี่ยวกับโมเดลที่ขับเคลื่อน Gemini API ได้ที่หน้ารุ่น\nขณะนี้ Gemini API และ Google AI Studio มีให้บริการในกว่า 180 ประเทศ โปรดอ่านเอกสารประกอบเพื่อดูข้อมูลเพิ่มเติม\nเนื้อหาของหน้าเว็บนี้ได้รับอนุญาตภายใต้ใบอนุญาตที่ต้องระบุที่มาของครีเอทีฟคอมมอนส์ 4.0 และตัวอย่างโค้ดได้รับอนุญาตภายใต้ใบอนุญาต Apache 2.0 เว้นแต่จะระบุไว้เป็นอย่างอื่น โปรดดูรายละเอียดที่นโยบายเว็บไซต์ Google Developers Java เป็นเครื่องหมายการค้าจดทะเบียนของ Oracle และ/หรือบริษัทในเครือ\nอัปเดตล่าสุด 2024-04-23 UTC\nข้อกำหนด\nความเป็นส่วนตัว",
            "filtered_word_count": 164
        },
        "https://ai.google.dev/gemini-api/docs?hl=zh-cn": {
            "status": "Looks good",
            "content": "产品\n示例\n登录\n文档\nAPI 参考文档\n概览\n开始使用\n获取 API 密钥\nGemini API 快速入门\nGoogle AI Studio 快速入门\n入门教程\n模型\n生成模型简介\nGemini\nGemini API\nAPI 概览\nAPI 参考\nAPI 版本\n版本说明\n功能\n模型调整\n函数调用\nEmbeddings\n安全\n指南\n提示\n系统说明\n语义检索\nOAuth 身份验证\nFirebase Extensions\n迁移到云端\n教程\n函数调用\nEmbeddings\n应用\n问题排查\n问题排查指南\n使用 Workspace 访问 AI Studio\n排查 AI Studio 问题\n申请增加配额\n社区\n对话论坛\nPaLM API（旧版）\n迁移到 Gemini\nPaLM 文档\n法律\n服务条款\n（预览版）服务条款\n可用区域\n查看全新 Gemini API 实战宝典和我们的社区论坛。\n 此页面由 Cloud Translation API 翻译。\nGemini API 使用入门 \n\nGemini 是 Google 功能最强大的 AI 模型系列。此网站包含您开始使用 Gemini API 构建应用所需的全部信息。\n\nGemini 1.5 Pro 现已在 Google AI Studio 中提供公开预览版。立即试用。\n\nGoogle AI Studio \n\n最快速开始使用 Gemini 的方法是 Google AI Studio，这是一款基于网络的工具，可让您直接在浏览器中设计原型、运行提示并开始使用 Gemini API。\n\n启动 Google AI Studio\nGoogle AI Studio 快速入门\n\n要开始使用，请转到 Gemini API 快速入门。\n\n如需了解如何安全、负责任地使用 LLM，请参阅安全设置和安全指南文档。\n\nPython 使用入门\n开始使用 REST API\n开始网页版\nGo 使用入门\nNode 使用入门\n适用于 Android 的使用入门\n适用于 iOS 的使用入门\nDart 使用入门 (Flutter)\n在 Google Cloud 上构建\n深入阅读\n如需详细了解为 Gemini API 提供支持的模型，请参阅模型页面。\nGemini API 和 Google AI Studio 目前可在 180 多个国家/地区使用，请查看相关文档了解详情。\n\n如未另行说明，那么本页面中的内容已根据知识共享署名 4.0 许可获得了许可，并且代码示例已根据 Apache 2.0 许可获得了许可。有关详情，请参阅 Google 开发者网站政策。Java 是 Oracle 和/或其关联公司的注册商标。\n\n最后更新时间 (UTC)：2024-04-23。\n\n条款\n隐私权政策",
            "word_count": 179,
            "filtered_content": "产品\n示例\n登录\n文档\nAPI 参考文档\n概览\n开始使用\n获取 API 密钥\nGemini API 快速入门\n入门教程\n模型\n生成模型简介\nAPI 概览\nAPI 参考\nAPI 版本\n版本说明\n功能\n模型调整\n安全\n指南\n提示\n系统说明\n语义检索\nOAuth 身份验证\nFirebase Extensions\n迁移到云端\n教程\n应用\n问题排查\n问题排查指南\n使用 Workspace 访问 AI Studio\n排查 AI Studio 问题\n申请增加配额\n社区\n对话论坛\nPaLM API（旧版）\n迁移到 Gemini\nPaLM 文档\n法律\n服务条款\n（预览版）服务条款\n可用区域\n查看全新 Gemini API 实战宝典和我们的社区论坛。\n 此页面由 Cloud Translation API 翻译。\nGemini API 使用入门 \nGemini 是 Google 功能最强大的 AI 模型系列。此网站包含您开始使用 Gemini API 构建应用所需的全部信息。\nGemini 1.5 Pro 现已在 Google AI Studio 中提供公开预览版。立即试用。\n最快速开始使用 Gemini 的方法是 Google AI Studio，这是一款基于网络的工具，可让您直接在浏览器中设计原型、运行提示并开始使用 Gemini API。\n启动 Google AI Studio\n要开始使用，请转到 Gemini API 快速入门。\n如需了解如何安全、负责任地使用 LLM，请参阅安全设置和安全指南文档。\nPython 使用入门\n开始使用 REST API\n开始网页版\nGo 使用入门\nNode 使用入门\n适用于 Android 的使用入门\n适用于 iOS 的使用入门\nDart 使用入门 (Flutter)\n在 Google Cloud 上构建\n深入阅读\n如需详细了解为 Gemini API 提供支持的模型，请参阅模型页面。\nGemini API 和 Google AI Studio 目前可在 180 多个国家/地区使用，请查看相关文档了解详情。\n如未另行说明，那么本页面中的内容已根据知识共享署名 4.0 许可获得了许可，并且代码示例已根据 Apache 2.0 许可获得了许可。有关详情，请参阅 Google 开发者网站政策。Java 是 Oracle 和/或其关联公司的注册商标。\n最后更新时间 (UTC)：2024-04-23。\n条款\n隐私权政策",
            "filtered_word_count": 161
        },
        "https://ai.google.dev/gemini-api/docs?hl=zh-tw": {
            "status": "Looks good",
            "content": "產品\n範例\n登入\n文件\nAPI 參考資料\n總覽\n開始轉接\n取得 API 金鑰\nGemini API 快速入門導覽課程\nGoogle AI Studio 快速入門導覽課程\n入門教學課程\n模型\n關於生成式模型\nGemini\nGemini API\nAPI 總覽\nAPI 參考資料\nAPI 版本\n版本資訊\n功能\n模型調整\n函式呼叫\n嵌入\n安全分\n指南\n提示\n系統操作說明\n語意擷取\nOAuth 驗證\nFirebase 擴充功能\n遷移至 Cloud\n教學課程\n函式呼叫\n嵌入\n應用程式\n疑難排解\n疑難排解指南\n使用 Workspace 存取 AI Studio\nAI Studio 疑難排解\n要求提高配額\n社群\n討論論壇\nPaLM API (舊版)\n遷移至 Gemini\nPaLM 文件\nLegal\n服務條款\n(預先發布版) 服務條款\n可用地區\n有興趣看看全新的 Gemini API 教戰手冊和我們的社群論壇。\n 本頁面由 Cloud Translation API 翻譯而成。\n開始使用 Gemini API \n\nGemini 是 Google 功能最強大的 AI 模型系列，這個網站提供了開始使用 Gemini API 建構應用程式所需的一切資訊。\n\nGoogle AI Studio 的公開測試版現已支援 Gemini 1.5 Pro。立即試用。\n\nGoogle AI Studio \n\n如要開始使用 Gemini，最快的方法是透過 Google AI Studio 這項網頁式工具。這項工具可讓您設計原型、直接在瀏覽器中執行提示，並開始使用 Gemini API。\n\n啟動 Google AI Studio\nGoogle AI Studio 快速入門導覽課程\n\n如要開始使用，請前往 Gemini API 快速入門導覽課程。\n\n如要瞭解如何以負責任的方式使用 LLM，請參閱安全性設定和安全指南說明文件。\n\n開始使用 Python\n開始使用 REST API\n開始使用網頁版\n開始使用 Go\n開始使用節點\n開始使用 Android\n開始使用 iOS 裝置\n開始使用 Dart (Flutter)\n在 Google Cloud 中建構\n其他資訊\n如要進一步瞭解採用 Gemini API 的模型，請參閱模型頁面。\nGemini API 和 Google AI Studio 目前已在 180 多個國家/地區提供服務，詳情請參閱說明文件。\n\n除非另有註明，否則本頁面中的內容是採用創用 CC 姓名標示 4.0 授權，程式碼範例則為阿帕契 2.0 授權。詳情請參閱《Google Developers 網站政策》。Java 是 Oracle 和/或其關聯企業的註冊商標。\n\n上次更新時間：2024-04-23 (世界標準時間)。\n\n條款\n隱私權",
            "word_count": 179,
            "filtered_content": "產品\n範例\n登入\n文件\n總覽\n開始轉接\n取得 API 金鑰\nGemini API 快速入門導覽課程\n入門教學課程\n關於生成式模型\nAPI 總覽\n版本資訊\n模型調整\n安全分\n系統操作說明\n語意擷取\nOAuth 驗證\nFirebase 擴充功能\n遷移至 Cloud\n教學課程\n應用程式\n疑難排解\n疑難排解指南\n使用 Workspace 存取 AI Studio\nAI Studio 疑難排解\n要求提高配額\n社群\n討論論壇\nPaLM API (舊版)\n遷移至 Gemini\nPaLM 文件\n服務條款\n(預先發布版) 服務條款\n可用地區\n有興趣看看全新的 Gemini API 教戰手冊和我們的社群論壇。\n 本頁面由 Cloud Translation API 翻譯而成。\n開始使用 Gemini API \nGemini 是 Google 功能最強大的 AI 模型系列，這個網站提供了開始使用 Gemini API 建構應用程式所需的一切資訊。\nGoogle AI Studio 的公開測試版現已支援 Gemini 1.5 Pro。立即試用。\n如要開始使用 Gemini，最快的方法是透過 Google AI Studio 這項網頁式工具。這項工具可讓您設計原型、直接在瀏覽器中執行提示，並開始使用 Gemini API。\n啟動 Google AI Studio\n如要開始使用，請前往 Gemini API 快速入門導覽課程。\n如要瞭解如何以負責任的方式使用 LLM，請參閱安全性設定和安全指南說明文件。\n開始使用 Python\n開始使用 REST API\n開始使用網頁版\n開始使用 Go\n開始使用節點\n開始使用 Android\n開始使用 iOS 裝置\n開始使用 Dart (Flutter)\n在 Google Cloud 中建構\n其他資訊\n如要進一步瞭解採用 Gemini API 的模型，請參閱模型頁面。\nGemini API 和 Google AI Studio 目前已在 180 多個國家/地區提供服務，詳情請參閱說明文件。\n除非另有註明，否則本頁面中的內容是採用創用 CC 姓名標示 4.0 授權，程式碼範例則為阿帕契 2.0 授權。詳情請參閱《Google Developers 網站政策》。Java 是 Oracle 和/或其關聯企業的註冊商標。\n上次更新時間：2024-04-23 (世界標準時間)。\n條款\n隱私權",
            "filtered_word_count": 150
        },
        "https://ai.google.dev/gemini-api/docs?hl=ja": {
            "status": "Looks good",
            "content": "プロダクト\n例\nログイン\nドキュメント\nAPI リファレンス\n概要\n使ってみる\nAPI キーを取得する\nGemini API クイックスタート\nGoogle AI Studio のクイックスタート\nスタートガイドのチュートリアル\nモデル\n生成モデルについて\nGemini\nGemini API\nAPI の概要\nAPI リファレンス\nAPI バージョン\nリリースノート\n機能\nモデルのチューニング\n関数呼び出し\nEmbeddings\n安全性\nガイド\nプロンプト\nシステムの説明\nセマンティック取得\nOAuth 認証\nFirebase Extensions\nクラウドに移行する\nチュートリアル\n関数呼び出し\nEmbeddings\nアプリケーション\nトラブルシューティング\nトラブルシューティング ガイド\nWorkspace を使用して AI Studio にアクセスする\nAI Studio のトラブルシューティング\n割り当ての増加をリクエストする\nコミュニティ\n対話フォーラム\nPaLM API（レガシー）\ngen に移行する\nPaLM ドキュメント\n法務\n利用規約\n（プレビュー）利用規約\n利用可能なリージョン\n新しい Gemini API クックブックとコミュニティ フォーラムをご覧ください。\n このページは Cloud Translation API によって翻訳されました。\nGemini API のスタートガイド \n\nGemini は、Google の最も高性能な AI モデルのファミリーです。このサイトには、Gemini API を使用してアプリケーションを構築するために必要な情報がすべて記載されています。\n\nGemini 1.5 Pro が Google AI Studio の公開プレビュー版で利用可能になりました。こちらから今すぐお試しください。\n\nGoogle AI Studio \n\nGemini の使用を開始する際は、ウェブベースのツールである Google AI Studio を使用することが最速です。これを使用すると、プロトタイプを作成し、ブラウザでプロンプトを実行し、Gemini API を開始できます。\n\nGoogle AI Studio を起動する\nGoogle AI Studio のクイックスタート\n\n開始するには、Gemini API クイックスタートをご覧ください。\n\n安全かつ責任を持って LLM を使用する方法については、安全性設定と安全性に関するガイダンスのドキュメントをご覧ください。\n\nPython のスタートガイド\nREST API を使ってみる\nウェブで使ってみる\nGo スタート ガイド\nNode を使ってみる\nAndroid で使ってみる\niOS で使ってみる\nDart（Flutter）を使ってみる\nGoogle Cloud 上に構築\n関連情報\nGemini API で使用されているモデルの詳細については、モデルのページをご覧ください。\nGemini API と Google AI Studio は現在、180 か国以上で利用できます。詳しくは、ドキュメントをご覧ください。\n\n特に記載のない限り、このページのコンテンツはクリエイティブ・コモンズの表示 4.0 ライセンスにより使用許諾されます。コードサンプルは Apache 2.0 ライセンスにより使用許諾されます。詳しくは、Google Developers サイトのポリシーをご覧ください。Java は Oracle および関連会社の登録商標です。\n\n最終更新日 2024-04-23 UTC。\n\n利用規約\nプライバシー",
            "word_count": 172,
            "filtered_content": "プロダクト\n例\nログイン\nドキュメント\n概要\n使ってみる\nAPI キーを取得する\nGemini API クイックスタート\nスタートガイドのチュートリアル\nモデル\n生成モデルについて\nAPI の概要\nAPI バージョン\nリリースノート\n機能\nモデルのチューニング\n安全性\nガイド\nプロンプト\nシステムの説明\nセマンティック取得\nOAuth 認証\nクラウドに移行する\nチュートリアル\nアプリケーション\nトラブルシューティング\nトラブルシューティング ガイド\nWorkspace を使用して AI Studio にアクセスする\nAI Studio のトラブルシューティング\n割り当ての増加をリクエストする\nコミュニティ\n対話フォーラム\nPaLM API（レガシー）\ngen に移行する\nPaLM ドキュメント\n法務\n（プレビュー）利用規約\n利用可能なリージョン\n新しい Gemini API クックブックとコミュニティ フォーラムをご覧ください。\n このページは Cloud Translation API によって翻訳されました。\nGemini API のスタートガイド \nGemini は、Google の最も高性能な AI モデルのファミリーです。このサイトには、Gemini API を使用してアプリケーションを構築するために必要な情報がすべて記載されています。\nGemini 1.5 Pro が Google AI Studio の公開プレビュー版で利用可能になりました。こちらから今すぐお試しください。\nGemini の使用を開始する際は、ウェブベースのツールである Google AI Studio を使用することが最速です。これを使用すると、プロトタイプを作成し、ブラウザでプロンプトを実行し、Gemini API を開始できます。\nGoogle AI Studio を起動する\n開始するには、Gemini API クイックスタートをご覧ください。\n安全かつ責任を持って LLM を使用する方法については、安全性設定と安全性に関するガイダンスのドキュメントをご覧ください。\nPython のスタートガイド\nREST API を使ってみる\nウェブで使ってみる\nGo スタート ガイド\nNode を使ってみる\nAndroid で使ってみる\niOS で使ってみる\nDart（Flutter）を使ってみる\nGoogle Cloud 上に構築\n関連情報\nGemini API で使用されているモデルの詳細については、モデルのページをご覧ください。\nGemini API と Google AI Studio は現在、180 か国以上で利用できます。詳しくは、ドキュメントをご覧ください。\n特に記載のない限り、このページのコンテンツはクリエイティブ・コモンズの表示 4.0 ライセンスにより使用許諾されます。コードサンプルは Apache 2.0 ライセンスにより使用許諾されます。詳しくは、Google Developers サイトのポリシーをご覧ください。Java は Oracle および関連会社の登録商標です。\n最終更新日 2024-04-23 UTC。\nプライバシー",
            "filtered_word_count": 146
        },
        "https://ai.google.dev/gemini-api/docs?hl=ko": {
            "status": "Looks good",
            "content": "제품\n예\n로그인\nDocs\nAPI 참조\n개요\n시작하기\nAPI 키 가져오기\nGemini API 빠른 시작\nGoogle AI 스튜디오 빠른 시작\n시작 가이드\n모델\n생성 모델 정보\nGemini\nGemini API\nAPI 개요\nAPI 참조 문서\nAPI 버전\n출시 노트\n기능\n모델 조정\n함수 호출\n임베딩\n안전\n가이드\n메시지 표시\n시스템 안내\n시맨틱 검색\nOAuth 인증\nFirebase Extensions\n클라우드로 마이그레이션\n튜토리얼\n함수 호출\n임베딩\n애플리케이션\n문제해결\n문제 해결 가이드\nWorkspace를 사용하여 AI Studio에 액세스\nAI Studio 문제 해결\n할당량 추가 요청\n커뮤니티\n담화 포럼\nPaLM API (기존)\nGemini로 이전\nPaLM 문서\n법률\n서비스 약관\n(미리보기) 서비스 약관\n사용 가능한 리전\n새로운 Gemini API 설명서와 커뮤니티 포럼을 확인하세요.\n 이 페이지는 Cloud Translation API를 통해 번역되었습니다.\nGemini API 시작하기 \n\nGemini는 Google에서 가장 성능이 뛰어난 AI 모델 제품군입니다. 이 사이트에는 Gemini API로 애플리케이션 빌드를 시작하는 데 필요한 모든 정보가 포함되어 있습니다.\n\n이제 Gemini 1.5 Pro가 Google AI 스튜디오의 공개 미리보기로 제공됩니다. 지금 사용해보기\n\nGoogle AI Studio \n\nGemini를 사용하는 가장 빠른 방법은 웹 기반 도구인 Google AI 스튜디오를 사용하는 것입니다. 이 도구를 사용하면 프로토타입을 제작하고 브라우저에서 바로 프롬프트를 실행하고 Gemini API를 시작할 수 있습니다.\n\nGoogle AI 스튜디오 실행\nGoogle AI 스튜디오 빠른 시작\n\n시작하려면 Gemini API 빠른 시작으로 이동하세요.\n\nLLM을 안전하고 책임감 있게 사용하는 방법을 알아보려면 안전 설정 및 안전 안내 문서를 참조하세요.\n\nPython 시작하기\nREST API 시작하기\n웹에서 시작하기\nGo 시작하기\nNode 시작하기\nAndroid에서 시작하기\niOS에서 시작하기\nDart (Flutter) 시작하기\nGoogle Cloud에서 빌드\n추가 자료\nGemini API를 구동하는 모델에 대해 자세히 알아보려면 모델 페이지를 참조하세요.\nGemini API 및 Google AI 스튜디오는 현재 180개 이상의 국가에서 사용할 수 있습니다. 자세한 내용은 문서를 확인하세요.\n\n달리 명시되지 않는 한 이 페이지의 콘텐츠에는 Creative Commons Attribution 4.0 라이선스에 따라 라이선스가 부여되며, 코드 샘플에는 Apache 2.0 라이선스에 따라 라이선스가 부여됩니다. 자세한 내용은 Google Developers 사이트 정책을 참조하세요. 자바는 Oracle 및/또는 Oracle 계열사의 등록 상표입니다.\n\n최종 업데이트: 2024-04-23(UTC)\n\n약관\n개인정보처리방침",
            "word_count": 299,
            "filtered_content": "제품\n예\n로그인\nAPI 참조\n개요\n시작하기\nAPI 키 가져오기\nGemini API 빠른 시작\n시작 가이드\n모델\n생성 모델 정보\nAPI 개요\nAPI 참조 문서\nAPI 버전\n출시 노트\n기능\n모델 조정\n안전\n가이드\n메시지 표시\n시스템 안내\n시맨틱 검색\nOAuth 인증\n클라우드로 마이그레이션\n튜토리얼\n애플리케이션\n문제해결\n문제 해결 가이드\nWorkspace를 사용하여 AI Studio에 액세스\nAI Studio 문제 해결\n할당량 추가 요청\n커뮤니티\n담화 포럼\nPaLM API (기존)\nGemini로 이전\nPaLM 문서\n법률\n서비스 약관\n(미리보기) 서비스 약관\n사용 가능한 리전\n새로운 Gemini API 설명서와 커뮤니티 포럼을 확인하세요.\n 이 페이지는 Cloud Translation API를 통해 번역되었습니다.\nGemini API 시작하기 \nGemini는 Google에서 가장 성능이 뛰어난 AI 모델 제품군입니다. 이 사이트에는 Gemini API로 애플리케이션 빌드를 시작하는 데 필요한 모든 정보가 포함되어 있습니다.\n이제 Gemini 1.5 Pro가 Google AI 스튜디오의 공개 미리보기로 제공됩니다. 지금 사용해보기\nGemini를 사용하는 가장 빠른 방법은 웹 기반 도구인 Google AI 스튜디오를 사용하는 것입니다. 이 도구를 사용하면 프로토타입을 제작하고 브라우저에서 바로 프롬프트를 실행하고 Gemini API를 시작할 수 있습니다.\nGoogle AI 스튜디오 실행\n시작하려면 Gemini API 빠른 시작으로 이동하세요.\nLLM을 안전하고 책임감 있게 사용하는 방법을 알아보려면 안전 설정 및 안전 안내 문서를 참조하세요.\nPython 시작하기\nREST API 시작하기\n웹에서 시작하기\nGo 시작하기\nNode 시작하기\nAndroid에서 시작하기\niOS에서 시작하기\nDart (Flutter) 시작하기\nGoogle Cloud에서 빌드\n추가 자료\nGemini API를 구동하는 모델에 대해 자세히 알아보려면 모델 페이지를 참조하세요.\nGemini API 및 Google AI 스튜디오는 현재 180개 이상의 국가에서 사용할 수 있습니다. 자세한 내용은 문서를 확인하세요.\n달리 명시되지 않는 한 이 페이지의 콘텐츠에는 Creative Commons Attribution 4.0 라이선스에 따라 라이선스가 부여되며, 코드 샘플에는 Apache 2.0 라이선스에 따라 라이선스가 부여됩니다. 자세한 내용은 Google Developers 사이트 정책을 참조하세요. 자바는 Oracle 및/또는 Oracle 계열사의 등록 상표입니다.\n최종 업데이트: 2024-04-23(UTC)\n약관\n개인정보처리방침",
            "filtered_word_count": 274
        },
        "https://ai.google.dev/gemini-api/docs/api-key": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nVerify your API key with a curl command\nKeep your API key secure\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet an API key \nbookmark_border\n\nTo use the Gemini API, you need an API key. You can create a key with one click in Google AI Studio.\n\nGet an API key\n\nImportant: Remember to use your API keys securely. Review Keep your API key secure and then check out the API quickstarts to learn language-specific best practices for securing your API key.\nVerify your API key with a curl command\n\nYou can use a curl command to verify your setup. You can pass the API key either in the URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOr in the x-goog-api-key header:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nKeep your API key secure\n\nIt's important to keep your Gemini API key secure. Here are a few things to keep in mind when using your Gemini API key:\n\nThe Google AI Gemini API uses API keys for authorization. If others get access to your Gemini API key, they can make calls using your project's quota, which could result in lost quota or additional billing charges (if billing is enabled). API keys also guard access to tuned models and files.\n\nWhen you click Get API key in Google AI Studio, you choose whether to provision a Gemini API key in a new or existing Google Cloud project. The API keys list in Google AI Studio shows all the API keys that AI Studio has provisioned for use with the Google AI Gemini API (along with all their associated Google Cloud projects).\n\nHowever, any API keys within the Google Cloud project can potentially be used to call the Google AI Gemini API. You can view and manage all your project's API keys in the APIs & Services > Credentials panel in the Google Cloud console.\n\nAdding API key restrictions can help limit the surface area usable through each API key. By default, the Gemini API key generated by Google AI Studio can only be used with the Google AI Gemini API (officially called the \"Generative Language API\" or generativelanguage.googleapis.com).\n\nIf there are any API keys within your Google Cloud project that lack API restrictions or any API keys that have allowlisted the Generative Language API, then those keys can be used with the Google AI Gemini API. It's best practice to restrict each API key to only the APIs that you call using that key.\nNote that even with API key restrictions, if a malicious actor obtains your API key, they can use it to make calls using your project's quota for all the APIs allowlisted for that API key.\n\nYou're responsible for keeping your Gemini API key secure.\n\nDo NOT check Gemini API keys into source control.\nClient-side applications (Android, Swift, web, and Dart/Flutter) risk exposing API keys, so we do not recommend using the Google AI client SDKs in production apps to call the Google AI Gemini API directly from your mobile and web apps. Check out the SDK quickstarts to learn language-specific best practices for securing your API key.\n\nFor some general best practices, you can also review this support article.\n\nNext steps\nCheck out the API quickstarts to learn best practices for securing your API key and using it.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 754,
            "filtered_content": "On this page\nGoogle AI for Developers\nGet an API key \nbookmark_border\nTo use the Gemini API, you need an API key. You can create a key with one click in Google AI Studio.\nImportant: Remember to use your API keys securely. Review Keep your API key secure and then check out the API quickstarts to learn language-specific best practices for securing your API key.\nYou can use a curl command to verify your setup. You can pass the API key either in the URL:\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\nOr in the x-goog-api-key header:\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\nIt's important to keep your Gemini API key secure. Here are a few things to keep in mind when using your Gemini API key:\nThe Google AI Gemini API uses API keys for authorization. If others get access to your Gemini API key, they can make calls using your project's quota, which could result in lost quota or additional billing charges (if billing is enabled). API keys also guard access to tuned models and files.\nWhen you click Get API key in Google AI Studio, you choose whether to provision a Gemini API key in a new or existing Google Cloud project. The API keys list in Google AI Studio shows all the API keys that AI Studio has provisioned for use with the Google AI Gemini API (along with all their associated Google Cloud projects).\nHowever, any API keys within the Google Cloud project can potentially be used to call the Google AI Gemini API. You can view and manage all your project's API keys in the APIs & Services > Credentials panel in the Google Cloud console.\nAdding API key restrictions can help limit the surface area usable through each API key. By default, the Gemini API key generated by Google AI Studio can only be used with the Google AI Gemini API (officially called the \"Generative Language API\" or generativelanguage.googleapis.com).\nIf there are any API keys within your Google Cloud project that lack API restrictions or any API keys that have allowlisted the Generative Language API, then those keys can be used with the Google AI Gemini API. It's best practice to restrict each API key to only the APIs that you call using that key.\nNote that even with API key restrictions, if a malicious actor obtains your API key, they can use it to make calls using your project's quota for all the APIs allowlisted for that API key.\nYou're responsible for keeping your Gemini API key secure.\nDo NOT check Gemini API keys into source control.\nClient-side applications (Android, Swift, web, and Dart/Flutter) risk exposing API keys, so we do not recommend using the Google AI client SDKs in production apps to call the Google AI Gemini API directly from your mobile and web apps. Check out the SDK quickstarts to learn language-specific best practices for securing your API key.\nFor some general best practices, you can also review this support article.\nCheck out the API quickstarts to learn best practices for securing your API key and using it.",
            "filtered_word_count": 511
        },
        "https://ai.google.dev/gemini-api/docs/quickstart": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 501,
            "filtered_content": "Gemini API quickstart \nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\nRun in Google Colab\n\t\nView notebook on GitHub\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\nPython 3.9+\nAn installation of jupyter to run the notebook.\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\nThen configure your key.\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\nAssign your API key to an environment variable:\nexport API_KEY=<YOUR_API_KEY>\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\npip install -q -U google-generativeai\nBefore you can make any API calls, you need to import and initialize the generative model.\nimport google.generativeai as genai\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\nAndroid (on-device)\nYou can also use curl commands to try out the Gemini API:\nREST API\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\nLast updated 2024-04-26 UTC.",
            "filtered_word_count": 238
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrompts and model tuning\nFreeform prompt example: Learn more about a building\nStep 1 - Create a prompt with text and images\nStep 2 - Add a replaceable variable to the prompt\nStep 3 - Experiment with model parameters\nStep 4 - Next steps\nStructured prompt example: Build a product copy generator\nStep 1 - Create a structured prompt\nStep 2 - Add examples\nStep 3 - Test your prompt\nStep 4 - Next steps\nChat prompt example: Build a custom chat application\nStep 1 - Create a chat prompt\nStep 2 - Teach your bot to chat better\nStep 3 - Experiment with model parameters\nStep 4 - Next steps\nFurther reading\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGoogle AI Studio quickstart \nbookmark_border\n\nGoogle AI Studio is a browser-based IDE for prototyping with generative models. Google AI Studio lets you quickly try out models and experiment with different prompts. When you've built something you're happy with, you can export it to code in your preferred programming language, powered by the Gemini API.\n\nPrompts and model tuning\n\nGoogle AI Studio provides several interfaces for prompts that are designed for different use cases:\n\nFreeform prompts - These prompts offer an open-ended prompting experience for generating content and responses to instructions. You can use both images and text data for your prompts. Learn more\n\nStructured prompts - This prompting technique lets you guide model output by providing a set of example requests and replies. Use this approach when you need more control over the structure of model output. Learn more\n\nChat prompts - Use chat prompts to build conversational experiences. This prompting technique allows for multiple input and response turns to generate output. Learn more\n\nGoogle AI Studio also lets you to change the behavior of a model, using a technique called tuning:\n\nTuned model - Use this advanced technique to improve a model's responses for a specific task by providing more examples. Learn more\nFreeform prompt example: Learn more about a building\n\nGemini's multimodal abilities let you prompt the model with a combination of imagery and text. For example, you can use this feature to learn more about a building shown in an image.\n\nStep 1 - Create a prompt with text and images\n\nTo create a multimodal prompt:\n\nNavigate to Google AI Studio.\nIn the left panel, select Create new > Freeform prompt.\nIn the right column Model field, select a model that supports images, such as the Gemini Pro Vision model.\n\nIn the prompt text area, enter the following text:\n\nlook at the following picture and tell me who is the architect\n\n\nFrom the Insert bar above the prompt area, select Image, and choose one of the sample images of a building.\n\nAt the bottom of the app window, select Run to generate a reply for this request.\n\nStep 2 - Add a replaceable variable to the prompt\n\nIn step 1, you prompted the model with a fixed string of text and an image. But sometimes, you want to be able to dynamically change parts of a prompt. For example, if you're building an interactive application, you may want to modify your prompt with different user inputs. For this, you can parameterize your prompts using variables.\n\nTo add variables to your prompts:\n\nSelect the word or phrase you want to replace in your prompt. In this case, select the text: who is the architect.\nFrom the Insert: header above the prompt, select {{ }} Test input.\nIn the Test your prompt table below the prompt, add an additional value for your prompt by selecting Add test example and entering an additional prompt value. Feel free to add several new input values.\nAt the bottom of the app window, select Run to generate a reply for each of the varying requests.\nStep 3 - Experiment with model parameters\n\nAs you're prototyping your prompt, you can also play around with model run settings on the right side of the application. These are key settings to know about:\n\nModel - Select what model you want to respond to your prompts. For more information about the available models and capabilities, see Models.\nTemperature - Control how much randomness is allowed in the model's responses. Raising this value allows the model to produce more unexpected and creative responses.\nMax outputs - Increase the number of responses the model returns for each request. This option can be helpful for quickly testing prompts by generating multiple responses for a single prompt.\nSafety settings - Adjust safety settings for managing model responses. For more details about these controls, see the Safety settings.\nStep 4 - Next steps\n\nNow that you've prototyped a generative AI application, you can save your work or generate code to use this prompt in your own development environment.\n\nTo save the prompt you created:\n\nIn the top right corner of the Google AI Studio app, select Save.\nConnect the app to your Google Drive account, if you have not already done so.\nIn the Save Prompt dialog, enter a Prompt name, an optional Description, and then select Save.\n\nTo export the prompt you created as code:\n\nIn the top right corner of the Google AI Studio app, select Get code.\nSelect a programming language tab.\nSelect Copy to copy the code to your clipboard.\nNote: You need an API key to run the prompt code outside of Google AI Studio, so make sure to create a key and include it with your prompt code.\nCaution: Treat your API key like a password and protect it appropriately. Don't embed your key in publicly published code.\nStructured prompt example: Build a product copy generator\n\nSo far, you've seen how you can prompt your model with an instruction (look at the following picture and tell me who is the architect). Sometimes, however, you can get better results by prompting the model with a combination of instructions and examples. Structured prompts in Google AI Studio help you do just that–combine instructions with examples to show the model the kind of output you want, rather than just telling it what to do. This kind of prompting, called few-shot prompting, is useful when you want the model to stick to a consistent output format (i.e. structured json) or when it's difficult to describe in words what you want the model to do (i.e. write in a particular style). In this section, you'll see how to create structured prompts in Google AI Studio.\n\nNote: You can try this example out directly in Google AI Studio from the examples gallery.\nStep 1 - Create a structured prompt\n\nIn this example, you'll create a structured prompt that generates advertising copy for products. To start, you’ll define the structure for the prompt by creating two columns: a Product input column and a Product copy output column.\n\nTo create the structured prompt:\n\nIn the top left of the Google AI Studio web app, select Create new > Structured prompt.\n\nBelow the Insert: header, add the instructions for the structured prompt:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nAdd a descriptive header for the INPUT by replacing the default input: text description with Product:.\n\nAdd a descriptive header for the OUTPUT by replacing the default output: text description with Product copy:.\n\nTip: Add colons to the end of column names to make it easier for the model to parse the structure.\nStep 2 - Add examples\n\nNow that you've named your columns, provide some example rows. These rows should contain example inputs (product names for this example) and example outputs (corresponding product descriptions). By providing the model a couple of example product descriptions, you can guide it to replicate a similar style when generating its own outputs. You can enter examples manually or import from a file using the import data menu.\n\nTo manually enter examples:\n\nIn the top examples data table, select the field below the Product: header and type a product description.\n\nSelect the field below the Product copy: header and type marketing copy for this product.\n\nHere's an example of input and output values for this prompt:\n\nProduct:\tProduct copy:\nOld-school sneaker\tLet's lace up! These kicks bring an iconic look and a one of a kind color palette, while supporting you in style and function like no other shoe before.\nSupersoft hoodie\tStay cozy and stylish in our new unisex hoodie! Made from 100% cotton, this hoodie is soft and comfortable to wear all day long. The semi-brushed inside will keep you warm on even the coldest days.\n\nTip: If you're having writers block or don't have example product copy examples on hand, you can use the Freeform prompt to have the text model generate some for you.\n\nTo import examples from a file:\n\nIn the top, right corner of examples table, select Actions > Import examples.\n\nIn the dialog, select a CSV or Google Sheets file in your Google Drive, or upload from your computer.\n\nIn the import examples dialog, choose which columns to import and which to leave out. The dialog also lets you specify which data column imports to which table column in your structured prompt.\n\nStep 3 - Test your prompt\n\nOnce you have the examples that show the model what you want, test your prompt with new input in the Test your prompt table at the bottom. As with the text prompt type, you can adjust model parameters to test if they help produce better results for your use case.\n\nReview how examples are sent to the model\n\nUnder the hood, Google AI Studio constructs a prompt by combining the instructions with the examples you provide. As you add more examples, these get added to the text sent to the model. Depending on how long your examples are, you may start hitting the model's token limit. All generative AI models have a token limit, which is the maximum length of the text they can accept as input.\n\nTo see the complete content of your prompt:\n\nSelect the Text preview at the bottom of the Google AI Studio web app.\nNote: The model token limit is displayed at the bottom of the preview pane.\nStep 4 - Next steps\n\nOnce you're happy with your prompt, you can Save it or export it to code by clicking the Get Code button.\n\nYou can also export the individual few-shot examples to a CSV file or Google Sheet. Choose the Export examples option under the Action menu to export your examples.\n\nChat prompt example: Build a custom chat application\n\nIf you've used a general-purpose chatbot like Gemini , you've experienced first-hand how powerful generative AI models can be for open-ended dialog. While these general-purpose chatbots are useful, often they need to be tailored for particular use cases. For example, maybe you want to build a customer service chatbot that only supports conversations that talk about a company's product. You might want to build a chatbot that speaks with a particular tone or style: a bot that cracks lots of jokes, rhymes like a poet, or uses lots of emojis in its answers.\n\nThis example shows you how to use Google AI Studio to build a friendly chatbot that communicates as if it is an alien living on one of Jupiter's moons, Europa.\n\nStep 1 - Create a chat prompt\n\nIn the last section, you designed a structured prompt using a combination of input and output examples. Similarly, to build a chatbot, you need to provide examples of interactions between a user and the chatbot to guide the model to provide the responses you're looking for.\n\nTo create a chat prompt:\n\nIn the top left of the Google AI Studio web app, select Create new > Chat prompt.\n\nIn the Write your prompt examples column of the prompt interface, you can start providing examples of interactions. You can also provide additional context in the first example such as:\n\nUser: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModel: none Ok\n\nIn the User and the Model fields provide an example of what interactions between a user and your chatbot might look like:\n\nUser: none Hi!\n\nModel: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nAfter you've filled out an example, start testing your application by chatting with the model on the right pane of the chat prompt interface.\n\nTo test the chatbot behavior:\n\nIn the Test your prompt panel, select the input field at the bottom.\n\nType in a question or observation that a user might make, for example:\n\nUser: none What's the weather like?\n\nSelect the diamond button to the right of the input field to get a response from the chatbot, which may be something like the following:\n\nModel: none The weather on Europa is very cold and icy. ...\n\nStep 2 - Teach your bot to chat better\n\nBy providing a single statement and response example, you were able to build a basic Europa alien chatbot. However, a single example is usually not enough to ensure consistency and quality in the model's responses. Without further input, the model's response to a question about the weather tends to be very long, and sounds like it comes out of a textbook rather than from a friendly alien.\n\nCustomize the tone of your chatbot by using the model response and editing it to match the desired tone and style of your alien chatbot.\n\nTo add and edit examples for the chatbot definition:\n\nIn the Test your prompt panel, hold the cursor over the left side of the User heading, and select the Add to examples button.\n\nIn the Write your prompt examples column, edit the copied input and response to match the intended style and tone of your chatbot.\n\nYou can use this approach to add additional examples. Ask more questions, edit the answers, and improve the quality of your chatbot. Continue to add examples and test how they modify the behavior of your chatbot. Typically, more examples correspond to higher quality chatbot responses.\n\nUnder the hood, Google AI Studio constructs a prompt by combining:\n\nDialog examples\nConversation history\n\ninto a single block of text that's sent to the model. To see what the complete prompt looks like, click Preview at the bottom of the screen to bring up the preview pane.\n\nNote that, because every message between the model and user is included in the prompt (this is the “conversational history”), conversational prompts can grow quite long as a conversation goes on. Eventually, you may hit the model's token limit, the maximum length of the text the model can accept. You can see the complete conversation and token count in the Preview tab.\n\nStep 3 - Experiment with model parameters\n\nYou can also try adjusting the model parameters to see if they produce more appropriate results for your use case.\n\nStep 4 - Next steps\n\nSimilar to the other prompt types, once you have your prompt prototyped to your satisfaction, you can use the Get Code button to start coding or save your prompt to work on later and share with others.\n\nFurther reading\nIf you're ready to move on to code, see the API quickstarts.\nTo learn how to craft better prompts, check out the Prompt design guidelines.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-22 UTC.\n\nTerms\nPrivacy",
            "word_count": 2744,
            "filtered_content": "Google AI Studio quickstart \nGoogle AI Studio is a browser-based IDE for prototyping with generative models. Google AI Studio lets you quickly try out models and experiment with different prompts. When you've built something you're happy with, you can export it to code in your preferred programming language, powered by the Gemini API.\nGoogle AI Studio provides several interfaces for prompts that are designed for different use cases:\nFreeform prompts - These prompts offer an open-ended prompting experience for generating content and responses to instructions. You can use both images and text data for your prompts. Learn more\nStructured prompts - This prompting technique lets you guide model output by providing a set of example requests and replies. Use this approach when you need more control over the structure of model output. Learn more\nChat prompts - Use chat prompts to build conversational experiences. This prompting technique allows for multiple input and response turns to generate output. Learn more\nGoogle AI Studio also lets you to change the behavior of a model, using a technique called tuning:\nTuned model - Use this advanced technique to improve a model's responses for a specific task by providing more examples. Learn more\nGemini's multimodal abilities let you prompt the model with a combination of imagery and text. For example, you can use this feature to learn more about a building shown in an image.\nTo create a multimodal prompt:\nNavigate to Google AI Studio.\nIn the left panel, select Create new > Freeform prompt.\nIn the right column Model field, select a model that supports images, such as the Gemini Pro Vision model.\nIn the prompt text area, enter the following text:\nlook at the following picture and tell me who is the architect\nFrom the Insert bar above the prompt area, select Image, and choose one of the sample images of a building.\nAt the bottom of the app window, select Run to generate a reply for this request.\nIn step 1, you prompted the model with a fixed string of text and an image. But sometimes, you want to be able to dynamically change parts of a prompt. For example, if you're building an interactive application, you may want to modify your prompt with different user inputs. For this, you can parameterize your prompts using variables.\nTo add variables to your prompts:\nSelect the word or phrase you want to replace in your prompt. In this case, select the text: who is the architect.\nFrom the Insert: header above the prompt, select {{ }} Test input.\nIn the Test your prompt table below the prompt, add an additional value for your prompt by selecting Add test example and entering an additional prompt value. Feel free to add several new input values.\nAt the bottom of the app window, select Run to generate a reply for each of the varying requests.\nAs you're prototyping your prompt, you can also play around with model run settings on the right side of the application. These are key settings to know about:\nModel - Select what model you want to respond to your prompts. For more information about the available models and capabilities, see Models.\nTemperature - Control how much randomness is allowed in the model's responses. Raising this value allows the model to produce more unexpected and creative responses.\nMax outputs - Increase the number of responses the model returns for each request. This option can be helpful for quickly testing prompts by generating multiple responses for a single prompt.\nSafety settings - Adjust safety settings for managing model responses. For more details about these controls, see the Safety settings.\nNow that you've prototyped a generative AI application, you can save your work or generate code to use this prompt in your own development environment.\nTo save the prompt you created:\nIn the top right corner of the Google AI Studio app, select Save.\nConnect the app to your Google Drive account, if you have not already done so.\nIn the Save Prompt dialog, enter a Prompt name, an optional Description, and then select Save.\nTo export the prompt you created as code:\nIn the top right corner of the Google AI Studio app, select Get code.\nSelect a programming language tab.\nSelect Copy to copy the code to your clipboard.\nNote: You need an API key to run the prompt code outside of Google AI Studio, so make sure to create a key and include it with your prompt code.\nCaution: Treat your API key like a password and protect it appropriately. Don't embed your key in publicly published code.\nSo far, you've seen how you can prompt your model with an instruction (look at the following picture and tell me who is the architect). Sometimes, however, you can get better results by prompting the model with a combination of instructions and examples. Structured prompts in Google AI Studio help you do just that–combine instructions with examples to show the model the kind of output you want, rather than just telling it what to do. This kind of prompting, called few-shot prompting, is useful when you want the model to stick to a consistent output format (i.e. structured json) or when it's difficult to describe in words what you want the model to do (i.e. write in a particular style). In this section, you'll see how to create structured prompts in Google AI Studio.\nNote: You can try this example out directly in Google AI Studio from the examples gallery.\nIn this example, you'll create a structured prompt that generates advertising copy for products. To start, you’ll define the structure for the prompt by creating two columns: a Product input column and a Product copy output column.\nTo create the structured prompt:\nIn the top left of the Google AI Studio web app, select Create new > Structured prompt.\nBelow the Insert: header, add the instructions for the structured prompt:\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\nAdd a descriptive header for the INPUT by replacing the default input: text description with Product:.\nAdd a descriptive header for the OUTPUT by replacing the default output: text description with Product copy:.\nTip: Add colons to the end of column names to make it easier for the model to parse the structure.\nNow that you've named your columns, provide some example rows. These rows should contain example inputs (product names for this example) and example outputs (corresponding product descriptions). By providing the model a couple of example product descriptions, you can guide it to replicate a similar style when generating its own outputs. You can enter examples manually or import from a file using the import data menu.\nTo manually enter examples:\nIn the top examples data table, select the field below the Product: header and type a product description.\nSelect the field below the Product copy: header and type marketing copy for this product.\nHere's an example of input and output values for this prompt:\nProduct:\tProduct copy:\nOld-school sneaker\tLet's lace up! These kicks bring an iconic look and a one of a kind color palette, while supporting you in style and function like no other shoe before.\nSupersoft hoodie\tStay cozy and stylish in our new unisex hoodie! Made from 100% cotton, this hoodie is soft and comfortable to wear all day long. The semi-brushed inside will keep you warm on even the coldest days.\nTip: If you're having writers block or don't have example product copy examples on hand, you can use the Freeform prompt to have the text model generate some for you.\nTo import examples from a file:\nIn the top, right corner of examples table, select Actions > Import examples.\nIn the dialog, select a CSV or Google Sheets file in your Google Drive, or upload from your computer.\nIn the import examples dialog, choose which columns to import and which to leave out. The dialog also lets you specify which data column imports to which table column in your structured prompt.\nOnce you have the examples that show the model what you want, test your prompt with new input in the Test your prompt table at the bottom. As with the text prompt type, you can adjust model parameters to test if they help produce better results for your use case.\nReview how examples are sent to the model\nUnder the hood, Google AI Studio constructs a prompt by combining the instructions with the examples you provide. As you add more examples, these get added to the text sent to the model. Depending on how long your examples are, you may start hitting the model's token limit. All generative AI models have a token limit, which is the maximum length of the text they can accept as input.\nTo see the complete content of your prompt:\nSelect the Text preview at the bottom of the Google AI Studio web app.\nNote: The model token limit is displayed at the bottom of the preview pane.\nOnce you're happy with your prompt, you can Save it or export it to code by clicking the Get Code button.\nYou can also export the individual few-shot examples to a CSV file or Google Sheet. Choose the Export examples option under the Action menu to export your examples.\nIf you've used a general-purpose chatbot like Gemini , you've experienced first-hand how powerful generative AI models can be for open-ended dialog. While these general-purpose chatbots are useful, often they need to be tailored for particular use cases. For example, maybe you want to build a customer service chatbot that only supports conversations that talk about a company's product. You might want to build a chatbot that speaks with a particular tone or style: a bot that cracks lots of jokes, rhymes like a poet, or uses lots of emojis in its answers.\nThis example shows you how to use Google AI Studio to build a friendly chatbot that communicates as if it is an alien living on one of Jupiter's moons, Europa.\nIn the last section, you designed a structured prompt using a combination of input and output examples. Similarly, to build a chatbot, you need to provide examples of interactions between a user and the chatbot to guide the model to provide the responses you're looking for.\nTo create a chat prompt:\nIn the top left of the Google AI Studio web app, select Create new > Chat prompt.\nIn the Write your prompt examples column of the prompt interface, you can start providing examples of interactions. You can also provide additional context in the first example such as:\nUser: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nModel: none Ok\nIn the User and the Model fields provide an example of what interactions between a user and your chatbot might look like:\nUser: none Hi!\nModel: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\nAfter you've filled out an example, start testing your application by chatting with the model on the right pane of the chat prompt interface.\nTo test the chatbot behavior:\nIn the Test your prompt panel, select the input field at the bottom.\nType in a question or observation that a user might make, for example:\nUser: none What's the weather like?\nSelect the diamond button to the right of the input field to get a response from the chatbot, which may be something like the following:\nModel: none The weather on Europa is very cold and icy. ...\nBy providing a single statement and response example, you were able to build a basic Europa alien chatbot. However, a single example is usually not enough to ensure consistency and quality in the model's responses. Without further input, the model's response to a question about the weather tends to be very long, and sounds like it comes out of a textbook rather than from a friendly alien.\nCustomize the tone of your chatbot by using the model response and editing it to match the desired tone and style of your alien chatbot.\nTo add and edit examples for the chatbot definition:\nIn the Test your prompt panel, hold the cursor over the left side of the User heading, and select the Add to examples button.\nIn the Write your prompt examples column, edit the copied input and response to match the intended style and tone of your chatbot.\nYou can use this approach to add additional examples. Ask more questions, edit the answers, and improve the quality of your chatbot. Continue to add examples and test how they modify the behavior of your chatbot. Typically, more examples correspond to higher quality chatbot responses.\nUnder the hood, Google AI Studio constructs a prompt by combining:\nDialog examples\nConversation history\ninto a single block of text that's sent to the model. To see what the complete prompt looks like, click Preview at the bottom of the screen to bring up the preview pane.\nNote that, because every message between the model and user is included in the prompt (this is the “conversational history”), conversational prompts can grow quite long as a conversation goes on. Eventually, you may hit the model's token limit, the maximum length of the text the model can accept. You can see the complete conversation and token count in the Preview tab.\nYou can also try adjusting the model parameters to see if they produce more appropriate results for your use case.\nSimilar to the other prompt types, once you have your prompt prototyped to your satisfaction, you can use the Get Code button to start coding or save your prompt to work on later and share with others.\nIf you're ready to move on to code, see the API quickstarts.\nTo learn how to craft better prompts, check out the Prompt design guidelines.\nLast updated 2024-04-22 UTC.",
            "filtered_word_count": 2341
        },
        "https://ai.google.dev/gemini-api/docs/get-started": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API tutorials \nbookmark_border\n\nThe Gemini API gives you access to the latest generative AI models from Google. The Gemini tutorials will help you get started with Gemini using a programming language of your choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nIf you're ready to start programming, but you're not sure which language to use, try the Python tutorial. It's available as a Colab notebook, so you can run code from the browser with minimal setup.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 310,
            "filtered_content": "Downloads\nGemini API tutorials \nThe Gemini API gives you access to the latest generative AI models from Google. The Gemini tutorials will help you get started with Gemini using a programming language of your choice.\nIf you're ready to start programming, but you're not sure which language to use, try the Python tutorial. It's available as a Colab notebook, so you can run code from the browser with minimal setup.\nLast updated 2024-04-18 UTC.",
            "filtered_word_count": 74
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSetup\nInstall the Python SDK\nImport packages\nSetup your API key\nList models\nGenerate text from text inputs\nGenerate text from image and text inputs\nChat conversations\nCount tokens\nUse embeddings\nAdvanced use cases\nSafety settings\nEncode messages\nMulti-turn conversations\nGeneration configuration\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with the Gemini API: Python \nbookmark_border\n\nRun in Google Colab\n\t\nView source on GitHub\n\nThis quickstart demonstrates how to use the Python SDK for the Gemini API, which gives you access to Google's Gemini large language models. In this quickstart, you will learn how to:\n\nSet up your development environment and API access to use Gemini.\nGenerate text responses from text inputs.\nGenerate text responses from multimodal inputs (text and images).\nUse Gemini for multi-turn conversations (chat).\nUse embeddings for large language models.\nPrerequisites\n\nYou can run this quickstart in Google Colab, which runs this notebook directly in the browser and does not require additional environment configuration.\n\nAlternatively, to complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSetup\nInstall the Python SDK\n\nThe Python SDK for the Gemini API, is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nImport packages\n\nImport the necessary packages.\n\nimport pathlib\nimport textwrap\n\nimport google.generativeai as genai\n\nfrom IPython.display import display\nfrom IPython.display import Markdown\n\n\ndef to_markdown(text):\n  text = text.replace('•', '  *')\n  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n\n# Used to securely store your API key\nfrom google.colab import userdata\n\nSetup your API key\n\nBefore you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n\nGet an API key\n\nIn Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name GOOGLE_API_KEY.\n\nOnce you have the API key, pass it to the SDK. You can do this in two ways:\n\nPut the key in the GOOGLE_API_KEY environment variable (the SDK will automatically pick it up from there).\nPass the key to genai.configure(api_key=...)\n# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\ngenai.configure(api_key=GOOGLE_API_KEY)\n\nList models\n\nNow you're ready to call the Gemini API. Use list_models to see the available Gemini models:\n\ngemini-pro: optimized for text-only prompts.\ngemini-pro-vision: optimized for text-and-images prompts.\nfor m in genai.list_models():\n  if 'generateContent' in m.supported_generation_methods:\n    print(m.name)\n\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. There are options for requesting rate limit increases. The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\n\nThe genai package also supports the PaLM family of models, but only the Gemini models support the generic, multimodal capabilities of the generateContent method.\n\nGenerate text from text inputs\n\nFor text-only prompts, use the gemini-pro model:\n\nmodel = genai.GenerativeModel('gemini-pro')\n\n\nThe generate_content method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\n\nIn the simplest case, you can pass a prompt string to the GenerativeModel.generate_content method:\n\n%%time\nresponse = model.generate_content(\"What is the meaning of life?\")\n\nCPU times: user 110 ms, sys: 12.3 ms, total: 123 ms\nWall time: 8.25 s\n\n\nIn simple cases, the response.text accessor is all you need. To display formatted Markdown text, use the to_markdown function:\n\nto_markdown(response.text)\n\n\nThe query of life's purpose has perplexed people across centuries, cultures, and continents. While there is no universally recognized response, many ideas have been put forth, and the response is frequently dependent on individual ideas, beliefs, and life experiences.\n\nHappiness and Well-being: Many individuals believe that the goal of life is to attain personal happiness and well-being. This might entail locating pursuits that provide joy, establishing significant connections, caring for one's physical and mental health, and pursuing personal goals and interests.\n\nMeaningful Contribution: Some believe that the purpose of life is to make a meaningful contribution to the world. This might entail pursuing a profession that benefits others, engaging in volunteer or charitable activities, generating art or literature, or inventing.\n\nSelf-realization and Personal Growth: The pursuit of self-realization and personal development is another common goal in life. This might entail learning new skills, pushing one's boundaries, confronting personal obstacles, and evolving as a person.\n\nEthical and Moral Behavior: Some believe that the goal of life is to act ethically and morally. This might entail adhering to one's moral principles, doing the right thing even when it is difficult, and attempting to make the world a better place.\n\nSpiritual Fulfillment: For some, the purpose of life is connected to spiritual or religious beliefs. This might entail seeking a connection with a higher power, practicing religious rituals, or following spiritual teachings.\n\nExperiencing Life to the Fullest: Some individuals believe that the goal of life is to experience all that it has to offer. This might entail traveling, trying new things, taking risks, and embracing new encounters.\n\nLegacy and Impact: Others believe that the purpose of life is to leave a lasting legacy and impact on the world. This might entail accomplishing something noteworthy, being remembered for one's contributions, or inspiring and motivating others.\n\nFinding Balance and Harmony: For some, the purpose of life is to find balance and harmony in all aspects of their lives. This might entail juggling personal, professional, and social obligations, seeking inner peace and contentment, and living a life that is in accordance with one's values and beliefs.\n\nUltimately, the meaning of life is a personal journey, and different individuals may discover their own unique purpose through their experiences, reflections, and interactions with the world around them.\n\nIf the API failed to return a result, use GenerateContentResponse.prompt_feedback to see if it was blocked due to safety concerns regarding the prompt.\n\nresponse.prompt_feedback\n\nsafety_ratings {\n  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HATE_SPEECH\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HARASSMENT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_DANGEROUS_CONTENT\n  probability: NEGLIGIBLE\n}\n\n\nGemini can generate multiple possible responses for a single prompt. These possible responses are called candidates, and you can review them to select the most suitable one as the response.\n\nView the response candidates with GenerateContentResponse.candidates:\n\nresponse.candidates\n\n[content {\n  parts {\n    text: \"The query of life\\'s purpose has perplexed people across centuries, cultures, and continents. While there is no universally recognized response, many ideas have been put forth, and the response is frequently dependent on individual ideas, beliefs, and life experiences.\\n\\n1. **Happiness and Well-being:** Many individuals believe that the goal of life is to attain personal happiness and well-being. This might entail locating pursuits that provide joy, establishing significant connections, caring for one\\'s physical and mental health, and pursuing personal goals and interests.\\n\\n2. **Meaningful Contribution:** Some believe that the purpose of life is to make a meaningful contribution to the world. This might entail pursuing a profession that benefits others, engaging in volunteer or charitable activities, generating art or literature, or inventing.\\n\\n3. **Self-realization and Personal Growth:** The pursuit of self-realization and personal development is another common goal in life. This might entail learning new skills, pushing one\\'s boundaries, confronting personal obstacles, and evolving as a person.\\n\\n4. **Ethical and Moral Behavior:** Some believe that the goal of life is to act ethically and morally. This might entail adhering to one\\'s moral principles, doing the right thing even when it is difficult, and attempting to make the world a better place.\\n\\n5. **Spiritual Fulfillment:** For some, the purpose of life is connected to spiritual or religious beliefs. This might entail seeking a connection with a higher power, practicing religious rituals, or following spiritual teachings.\\n\\n6. **Experiencing Life to the Fullest:** Some individuals believe that the goal of life is to experience all that it has to offer. This might entail traveling, trying new things, taking risks, and embracing new encounters.\\n\\n7. **Legacy and Impact:** Others believe that the purpose of life is to leave a lasting legacy and impact on the world. This might entail accomplishing something noteworthy, being remembered for one\\'s contributions, or inspiring and motivating others.\\n\\n8. **Finding Balance and Harmony:** For some, the purpose of life is to find balance and harmony in all aspects of their lives. This might entail juggling personal, professional, and social obligations, seeking inner peace and contentment, and living a life that is in accordance with one\\'s values and beliefs.\\n\\nUltimately, the meaning of life is a personal journey, and different individuals may discover their own unique purpose through their experiences, reflections, and interactions with the world around them.\"\n  }\n  role: \"model\"\n}\nfinish_reason: STOP\nindex: 0\nsafety_ratings {\n  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HATE_SPEECH\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HARASSMENT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_DANGEROUS_CONTENT\n  probability: NEGLIGIBLE\n}\n]\n\n\nBy default, the model returns a response after completing the entire generation process. You can also stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated.\n\nTo stream responses, use GenerativeModel.generate_content(..., stream=True).\n\n%%time\nresponse = model.generate_content(\"What is the meaning of life?\", stream=True)\n\nCPU times: user 102 ms, sys: 25.1 ms, total: 128 ms\nWall time: 7.94 s\n\nfor chunk in response:\n  print(chunk.text)\n  print(\"_\"*80)\n\nThe query of life's purpose has perplexed people across centuries, cultures, and\n________________________________________________________________________________\n continents. While there is no universally recognized response, many ideas have been put forth, and the response is frequently dependent on individual ideas, beliefs, and life experiences\n________________________________________________________________________________\n.\n\n1. **Happiness and Well-being:** Many individuals believe that the goal of life is to attain personal happiness and well-being. This might entail locating pursuits that provide joy, establishing significant connections, caring for one's physical and mental health, and pursuing personal goals and aspirations.\n\n2. **Meaning\n________________________________________________________________________________\nful Contribution:** Some believe that the purpose of life is to make a meaningful contribution to the world. This might entail pursuing a profession that benefits others, engaging in volunteer or charitable activities, generating art or literature, or inventing.\n\n3. **Self-realization and Personal Growth:** The pursuit of self-realization and personal development is another common goal in life. This might entail learning new skills, exploring one's interests and abilities, overcoming obstacles, and becoming the best version of oneself.\n\n4. **Connection and Relationships:** For many individuals, the purpose of life is found in their relationships with others. This might entail building\n________________________________________________________________________________\n strong bonds with family and friends, fostering a sense of community, and contributing to the well-being of those around them.\n\n5. **Spiritual Fulfillment:** For those with religious or spiritual beliefs, the purpose of life may be centered on seeking spiritual fulfillment or enlightenment. This might entail following religious teachings, engaging in spiritual practices, or seeking a deeper understanding of the divine.\n\n6. **Experiencing the Journey:** Some believe that the purpose of life is simply to experience the journey itself, with all its joys and sorrows. This perspective emphasizes embracing the present moment, appreciating life's experiences, and finding meaning in the act of living itself.\n\n7. **Legacy and Impact:** For others, the goal of life is to leave a lasting legacy or impact on the world. This might entail making a significant contribution to a particular field, leaving a positive mark on future generations, or creating something that will be remembered and cherished long after one's lifetime.\n\nUltimately, the meaning of life is a personal and subjective question, and there is no single, universally accepted answer. It is about discovering what brings you fulfillment, purpose, and meaning in your own life, and living in accordance with those values.\n________________________________________________________________________________\n\n\nWhen streaming, some response attributes are not available until you've iterated through all the response chunks. This is demonstrated below:\n\nresponse = model.generate_content(\"What is the meaning of life?\", stream=True)\n\n\nThe prompt_feedback attribute works:\n\nresponse.prompt_feedback\n\nsafety_ratings {\n  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HATE_SPEECH\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HARASSMENT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_DANGEROUS_CONTENT\n  probability: NEGLIGIBLE\n}\n\n\nBut attributes like text do not:\n\ntry:\n  response.text\nexcept Exception as e:\n  print(f'{type(e).__name__}: {e}')\n\nIncompleteIterationError: Please let the response complete iteration before accessing the final accumulated\nattributes (or call `response.resolve()`)\n\nGenerate text from image and text inputs\n\nGemini provides a multimodal model (gemini-pro-vision) that accepts both text and images and inputs. The GenerativeModel.generate_content API is designed to handle multimodal prompts and returns a text output.\n\nLet's include an image:\n\ncurl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw\n\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100  405k  100  405k    0     0  6982k      0 --:--:-- --:--:-- --:--:-- 7106k\n\nimport PIL.Image\n\nimg = PIL.Image.open('image.jpg')\nimg\n\n\nUse the gemini-pro-vision model and pass the image to the model with generate_content.\n\nmodel = genai.GenerativeModel('gemini-pro-vision')\n\nresponse = model.generate_content(img)\n\nto_markdown(response.text)\n\n\nChicken Teriyaki Meal Prep Bowls with brown rice, roasted broccoli and bell peppers.\n\nTo provide both text and images in a prompt, pass a list containing the strings and images:\n\nresponse = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\nresponse.resolve()\n\nto_markdown(response.text)\n\n\nMeal prepping is a great way to save time and money, and it can also help you to eat healthier. This meal is a great example of a healthy and delicious meal that can be easily prepped ahead of time.\n\nThis meal features brown rice, roasted vegetables, and chicken teriyaki. The brown rice is a whole grain that is high in fiber and nutrients. The roasted vegetables are a great way to get your daily dose of vitamins and minerals. And the chicken teriyaki is a lean protein source that is also packed with flavor.\n\nThis meal is easy to prepare ahead of time. Simply cook the brown rice, roast the vegetables, and cook the chicken teriyaki. Then, divide the meal into individual containers and store them in the refrigerator. When you're ready to eat, simply grab a container and heat it up.\n\nThis meal is a great option for busy people who are looking for a healthy and delicious way to eat. It's also a great meal for those who are trying to lose weight or maintain a healthy weight.\n\nIf you're looking for a healthy and delicious meal that can be easily prepped ahead of time, this meal is a great option. Give it a try today!\n\nChat conversations\n\nGemini enables you to have freeform conversations across multiple turns. The ChatSession class simplifies the process by managing the state of the conversation, so unlike with generate_content, you do not have to store the conversation history as a list.\n\nInitialize the chat:\n\nmodel = genai.GenerativeModel('gemini-pro')\nchat = model.start_chat(history=[])\nchat\n\n<google.generativeai.generative_models.ChatSession at 0x7b7b68250100>\n\nNote: The vision model gemini-pro-vision is not optimized for multi-turn chat.\n\nThe ChatSession.send_message method returns the same GenerateContentResponse type as GenerativeModel.generate_content. It also appends your message and the response to the chat history:\n\nresponse = chat.send_message(\"In one sentence, explain how a computer works to a young child.\")\nto_markdown(response.text)\n\n\nA computer is like a very smart machine that can understand and follow our instructions, help us with our work, and even play games with us!\n\nchat.history\n\n[parts {\n   text: \"In one sentence, explain how a computer works to a young child.\"\n }\n role: \"user\",\n parts {\n   text: \"A computer is like a very smart machine that can understand and follow our instructions, help us with our work, and even play games with us!\"\n }\n role: \"model\"]\n\n\nYou can keep sending messages to continue the conversation. Use the stream=True argument to stream the chat:\n\nresponse = chat.send_message(\"Okay, how about a more detailed explanation to a high schooler?\", stream=True)\n\nfor chunk in response:\n  print(chunk.text)\n  print(\"_\"*80)\n\nA computer works by following instructions, called a program, which tells it what to\n________________________________________________________________________________\n do. These instructions are written in a special language that the computer can understand, and they are stored in the computer's memory. The computer's processor\n________________________________________________________________________________\n, or CPU, reads the instructions from memory and carries them out, performing calculations and making decisions based on the program's logic. The results of these calculations and decisions are then displayed on the computer's screen or stored in memory for later use.\n\nTo give you a simple analogy, imagine a computer as a\n________________________________________________________________________________\n chef following a recipe. The recipe is like the program, and the chef's actions are like the instructions the computer follows. The chef reads the recipe (the program) and performs actions like gathering ingredients (fetching data from memory), mixing them together (performing calculations), and cooking them (processing data). The final dish (the output) is then presented on a plate (the computer screen).\n\nIn summary, a computer works by executing a series of instructions, stored in its memory, to perform calculations, make decisions, and display or store the results.\n________________________________________________________________________________\n\n\nglm.Content objects contain a list of glm.Part objects that each contain either a text (string) or inline_data (glm.Blob), where a blob contains binary data and a mime_type. The chat history is available as a list of glm.Content objects in ChatSession.history:\n\nfor message in chat.history:\n  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n\n\nuser: In one sentence, explain how a computer works to a young child.\n\nmodel: A computer is like a very smart machine that can understand and follow our instructions, help us with our work, and even play games with us!\n\nuser: Okay, how about a more detailed explanation to a high schooler?\n\nmodel: A computer works by following instructions, called a program, which tells it what to do. These instructions are written in a special language that the computer can understand, and they are stored in the computer's memory. The computer's processor, or CPU, reads the instructions from memory and carries them out, performing calculations and making decisions based on the program's logic. The results of these calculations and decisions are then displayed on the computer's screen or stored in memory for later use.\n\nTo give you a simple analogy, imagine a computer as a chef following a recipe. The recipe is like the program, and the chef's actions are like the instructions the computer follows. The chef reads the recipe (the program) and performs actions like gathering ingredients (fetching data from memory), mixing them together (performing calculations), and cooking them (processing data). The final dish (the output) is then presented on a plate (the computer screen).\n\nIn summary, a computer works by executing a series of instructions, stored in its memory, to perform calculations, make decisions, and display or store the results.\n\nCount tokens\n\nLarge language models have a context window, and the context length is often measured in terms of the number of tokens. With the Gemini API, you can determine the number of tokens per any glm.Content object. In the simplest case, you can pass a query string to the GenerativeModel.count_tokens method as follows:\n\nmodel.count_tokens(\"What is the meaning of life?\")\n\ntotal_tokens: 7\n\n\nSimilarly, you can check token_count for your ChatSession:\n\nmodel.count_tokens(chat.history)\n\ntotal_tokens: 501\n\nUse embeddings\n\nEmbedding is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity. For more on how and why you should use embeddings, refer to the Embeddings guide.\n\nUse the embed_content method to generate embeddings. The method handles embedding for the following tasks (task_type):\n\nTask Type\tDescription\nRETRIEVAL_QUERY\tSpecifies the given text is a query in a search/retrieval setting.\nRETRIEVAL_DOCUMENT\tSpecifies the given text is a document in a search/retrieval setting. Using this task type requires a title.\nSEMANTIC_SIMILARITY\tSpecifies the given text will be used for Semantic Textual Similarity (STS).\nCLASSIFICATION\tSpecifies that the embeddings will be used for classification.\nCLUSTERING\tSpecifies that the embeddings will be used for clustering.\n\nThe following generates an embedding for a single string for document retrieval:\n\nresult = genai.embed_content(\n    model=\"models/embedding-001\",\n    content=\"What is the meaning of life?\",\n    task_type=\"retrieval_document\",\n    title=\"Embedding of single string\")\n\n# 1 input > 1 vector output\nprint(str(result['embedding'])[:50], '... TRIMMED]')\n\n[-0.003216741, -0.013358698, -0.017649598, -0.0091 ... TRIMMED]\n\nNote: The retrieval_document task type is the only task that accepts a title.\n\nTo handle batches of strings, pass a list of strings in content:\n\nresult = genai.embed_content(\n    model=\"models/embedding-001\",\n    content=[\n      'What is the meaning of life?',\n      'How much wood would a woodchuck chuck?',\n      'How does the brain work?'],\n    task_type=\"retrieval_document\",\n    title=\"Embedding of list of strings\")\n\n# A list of inputs > A list of vectors output\nfor v in result['embedding']:\n  print(str(v)[:50], '... TRIMMED ...')\n\n[0.0040260437, 0.004124458, -0.014209415, -0.00183 ... TRIMMED ...\n[-0.004049845, -0.0075574904, -0.0073463684, -0.03 ... TRIMMED ...\n[0.025310587, -0.0080734305, -0.029902633, 0.01160 ... TRIMMED ...\n\n\nWhile the genai.embed_content function accepts simple strings or lists of strings, it is actually built around the glm.Content type (like GenerativeModel.generate_content). glm.Content objects are the primary units of conversation in the API.\n\nWhile the glm.Content object is multimodal, the embed_content method only supports text embeddings. This design gives the API the possibility to expand to multimodal embeddings.\n\nresponse.candidates[0].content\n\nparts {\n  text: \"A computer works by following instructions, called a program, which tells it what to do. These instructions are written in a special language that the computer can understand, and they are stored in the computer\\'s memory. The computer\\'s processor, or CPU, reads the instructions from memory and carries them out, performing calculations and making decisions based on the program\\'s logic. The results of these calculations and decisions are then displayed on the computer\\'s screen or stored in memory for later use.\\n\\nTo give you a simple analogy, imagine a computer as a chef following a recipe. The recipe is like the program, and the chef\\'s actions are like the instructions the computer follows. The chef reads the recipe (the program) and performs actions like gathering ingredients (fetching data from memory), mixing them together (performing calculations), and cooking them (processing data). The final dish (the output) is then presented on a plate (the computer screen).\\n\\nIn summary, a computer works by executing a series of instructions, stored in its memory, to perform calculations, make decisions, and display or store the results.\"\n}\nrole: \"model\"\n\nresult = genai.embed_content(\n    model = 'models/embedding-001',\n    content = response.candidates[0].content)\n\n# 1 input > 1 vector output\nprint(str(result['embedding'])[:50], '... TRIMMED ...')\n\n[-0.013921871, -0.03504407, -0.0051786783, 0.03113 ... TRIMMED ...\n\n\nSimilarly, the chat history contains a list of glm.Content objects, which you can pass directly to the embed_content function:\n\nchat.history\n\n[parts {\n   text: \"In one sentence, explain how a computer works to a young child.\"\n }\n role: \"user\",\n parts {\n   text: \"A computer is like a very smart machine that can understand and follow our instructions, help us with our work, and even play games with us!\"\n }\n role: \"model\",\n parts {\n   text: \"Okay, how about a more detailed explanation to a high schooler?\"\n }\n role: \"user\",\n parts {\n   text: \"A computer works by following instructions, called a program, which tells it what to do. These instructions are written in a special language that the computer can understand, and they are stored in the computer\\'s memory. The computer\\'s processor, or CPU, reads the instructions from memory and carries them out, performing calculations and making decisions based on the program\\'s logic. The results of these calculations and decisions are then displayed on the computer\\'s screen or stored in memory for later use.\\n\\nTo give you a simple analogy, imagine a computer as a chef following a recipe. The recipe is like the program, and the chef\\'s actions are like the instructions the computer follows. The chef reads the recipe (the program) and performs actions like gathering ingredients (fetching data from memory), mixing them together (performing calculations), and cooking them (processing data). The final dish (the output) is then presented on a plate (the computer screen).\\n\\nIn summary, a computer works by executing a series of instructions, stored in its memory, to perform calculations, make decisions, and display or store the results.\"\n }\n role: \"model\"]\n\nresult = genai.embed_content(\n    model = 'models/embedding-001',\n    content = chat.history)\n\n# 1 input > 1 vector output\nfor i,v in enumerate(result['embedding']):\n  print(str(v)[:50], '... TRIMMED...')\n\n[-0.014632266, -0.042202696, -0.015757175, 0.01548 ... TRIMMED...\n[-0.010979066, -0.024494737, 0.0092659835, 0.00803 ... TRIMMED...\n[-0.010055617, -0.07208932, -0.00011750793, -0.023 ... TRIMMED...\n[-0.013921871, -0.03504407, -0.0051786783, 0.03113 ... TRIMMED...\n\nAdvanced use cases\n\nThe following sections discuss advanced use cases and lower-level details of the Python SDK for the Gemini API.\n\nSafety settings\n\nThe safety_settings argument lets you configure what the model blocks and allows in both prompts and responses. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\n\nEnter a questionable prompt and run the model with the default safety settings, and it will not return any candidates:\n\nresponse = model.generate_content('[Questionable prompt here]')\nresponse.candidates\n\n[content {\n  parts {\n    text: \"I\\'m sorry, but this prompt involves a sensitive topic and I\\'m not allowed to generate responses that are potentially harmful or inappropriate.\"\n  }\n  role: \"model\"\n}\nfinish_reason: STOP\nindex: 0\nsafety_ratings {\n  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HATE_SPEECH\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HARASSMENT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_DANGEROUS_CONTENT\n  probability: NEGLIGIBLE\n}\n]\n\n\nThe prompt_feedback will tell you which safety filter blocked the prompt:\n\nresponse.prompt_feedback\n\nsafety_ratings {\n  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HATE_SPEECH\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_HARASSMENT\n  probability: NEGLIGIBLE\n}\nsafety_ratings {\n  category: HARM_CATEGORY_DANGEROUS_CONTENT\n  probability: NEGLIGIBLE\n}\n\n\nNow provide the same prompt to the model with newly configured safety settings, and you may get a response.\n\nresponse = model.generate_content('[Questionable prompt here]',\n                                  safety_settings={'HARASSMENT':'block_none'})\nresponse.text\n\n\nAlso note that each candidate has its own safety_ratings, in case the prompt passes but the individual responses fail the safety checks.\n\nEncode messages\n\nThe previous sections relied on the SDK to make it easy for you to send prompts to the API. This section offers a fully-typed equivalent to the previous example, so you can better understand the lower-level details regarding how the SDK encodes messages.\n\nUnderlying the Python SDK is the google.ai.generativelanguage client library:\n\nimport google.ai.generativelanguage as glm\n\n\nThe SDK attempts to convert your message to a glm.Content object, which contains a list of glm.Part objects that each contain either:\n\na text (string)\ninline_data (glm.Blob), where a blob contains binary data and a mime_type.\n\nYou can also pass any of these classes as an equivalent dictionary.\n\nNote: The only accepted mime types are some image types, image/*.\n\nSo, the fully-typed equivalent to the previous example is:\n\nmodel = genai.GenerativeModel('gemini-pro-vision')\nresponse = model.generate_content(\n    glm.Content(\n        parts = [\n            glm.Part(text=\"Write a short, engaging blog post based on this picture.\"),\n            glm.Part(\n                inline_data=glm.Blob(\n                    mime_type='image/jpeg',\n                    data=pathlib.Path('image.jpg').read_bytes()\n                )\n            ),\n        ],\n    ),\n    stream=True)\n\nresponse.resolve()\n\nto_markdown(response.text[:100] + \"... [TRIMMED] ...\")\n\n\nMeal prepping is a great way to save time and money, and it can also help you to eat healthier. By ... [TRIMMED] ...\n\nMulti-turn conversations\n\nWhile the genai.ChatSession class shown earlier can handle many use cases, it does make some assumptions. If your use case doesn't fit into this chat implementation it's good to remember that genai.ChatSession is just a wrapper around GenerativeModel.generate_content. In addition to single requests, it can handle multi-turn conversations.\n\nThe individual messages are glm.Content objects or compatible dictionaries, as seen in previous sections. As a dictionary, the message requires role and parts keys. The role in a conversation can either be the user, which provides the prompts, or model, which provides the responses.\n\nPass a list of glm.Content objects and it will be treated as multi-turn chat:\n\nmodel = genai.GenerativeModel('gemini-pro')\n\nmessages = [\n    {'role':'user',\n     'parts': [\"Briefly explain how a computer works to a young child.\"]}\n]\nresponse = model.generate_content(messages)\n\nto_markdown(response.text)\n\n\nImagine a computer as a really smart friend who can help you with many things. Just like you have a brain to think and learn, a computer has a brain too, called a processor. It's like the boss of the computer, telling it what to do.\n\nInside the computer, there's a special place called memory, which is like a big storage box. It remembers all the things you tell it to do, like opening games or playing videos.\n\nWhen you press buttons on the keyboard or click things on the screen with the mouse, you're sending messages to the computer. These messages travel through special wires, called cables, to the processor.\n\nThe processor reads the messages and tells the computer what to do. It can open programs, show you pictures, or even play music for you.\n\nAll the things you see on the screen are created by the graphics card, which is like a magic artist inside the computer. It takes the processor's instructions and turns them into colorful pictures and videos.\n\nTo save your favorite games, videos, or pictures, the computer uses a special storage space called a hard drive. It's like a giant library where the computer can keep all your precious things safe.\n\nAnd when you want to connect to the internet to play games with friends or watch funny videos, the computer uses something called a network card to send and receive messages through the internet cables or Wi-Fi signals.\n\nSo, just like your brain helps you learn and play, the computer's processor, memory, graphics card, hard drive, and network card all work together to make your computer a super-smart friend that can help you do amazing things!\n\nTo continue the conversation, add the response and another message.\n\nNote: For multi-turn conversations, you need to send the whole conversation history with each request. The API is stateless.\nmessages.append({'role':'model',\n                 'parts':[response.text]})\n\nmessages.append({'role':'user',\n                 'parts':[\"Okay, how about a more detailed explanation to a high school student?\"]})\n\nresponse = model.generate_content(messages)\n\nto_markdown(response.text)\n\n\nAt its core, a computer is a machine that can be programmed to carry out a set of instructions. It consists of several essential components that work together to process, store, and display information:\n\n1. Processor (CPU): - The brain of the computer. - Executes instructions and performs calculations. - Speed measured in gigahertz (GHz). - More GHz generally means faster processing.\n\n2. Memory (RAM): - Temporary storage for data being processed. - Holds instructions and data while the program is running. - Measured in gigabytes (GB). - More GB of RAM allows for more programs to run simultaneously.\n\n3. Storage (HDD/SSD): - Permanent storage for data. - Stores operating system, programs, and user files. - Measured in gigabytes (GB) or terabytes (TB). - Hard disk drives (HDDs) are traditional, slower, and cheaper. - Solid-state drives (SSDs) are newer, faster, and more expensive.\n\n4. Graphics Card (GPU): - Processes and displays images. - Essential for gaming, video editing, and other graphics-intensive tasks. - Measured in video RAM (VRAM) and clock speed.\n\n5. Motherboard: - Connects all the components. - Provides power and communication pathways.\n\n6. Input/Output (I/O) Devices: - Allow the user to interact with the computer. - Examples: keyboard, mouse, monitor, printer.\n\n7. Operating System (OS): - Software that manages the computer's resources. - Provides a user interface and basic functionality. - Examples: Windows, macOS, Linux.\n\nWhen you run a program on your computer, the following happens:\n\nThe program instructions are loaded from storage into memory.\nThe processor reads the instructions from memory and executes them one by one.\nIf the instruction involves calculations, the processor performs them using its arithmetic logic unit (ALU).\nIf the instruction involves data, the processor reads or writes to memory.\nThe results of the calculations or data manipulation are stored in memory.\nIf the program needs to display something on the screen, it sends the necessary data to the graphics card.\nThe graphics card processes the data and sends it to the monitor, which displays it.\n\nThis process continues until the program has completed its task or the user terminates it.\n\nGeneration configuration\n\nThe generation_config argument allows you to modify the generation parameters. Every prompt you send to the model includes parameter values that control how the model generates responses.\n\nmodel = genai.GenerativeModel('gemini-pro')\nresponse = model.generate_content(\n    'Tell me a story about a magic backpack.',\n    generation_config=genai.types.GenerationConfig(\n        # Only one candidate for now.\n        candidate_count=1,\n        stop_sequences=['x'],\n        max_output_tokens=20,\n        temperature=1.0)\n)\n\ntext = response.text\n\nif response.candidates[0].finish_reason.name == \"MAX_TOKENS\":\n    text += '...'\n\nto_markdown(text)\n\n\nOnce upon a time, in a small town nestled amidst lush green hills, lived a young girl named...\n\nWhat's next\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for prompt writing.\nGemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available Gemini models.\nGemini offers options for requesting rate limit increases. The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 5659,
            "filtered_content": "Get started with the Gemini API: Python \nView source on GitHub\nThis quickstart demonstrates how to use the Python SDK for the Gemini API, which gives you access to Google's Gemini large language models. In this quickstart, you will learn how to:\nSet up your development environment and API access to use Gemini.\nGenerate text responses from text inputs.\nGenerate text responses from multimodal inputs (text and images).\nUse Gemini for multi-turn conversations (chat).\nUse embeddings for large language models.\nYou can run this quickstart in Google Colab, which runs this notebook directly in the browser and does not require additional environment configuration.\nAlternatively, to complete this quickstart locally, ensure that your development environment meets the following requirements:\nThe Python SDK for the Gemini API, is contained in the google-generativeai package. Install the dependency using pip:\nImport the necessary packages.\nimport pathlib\nimport textwrap\nfrom IPython.display import display\nfrom IPython.display import Markdown\ndef to_markdown(text):\n  text = text.replace('•', '  *')\n  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n# Used to securely store your API key\nfrom google.colab import userdata\nBefore you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\nIn Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name GOOGLE_API_KEY.\nOnce you have the API key, pass it to the SDK. You can do this in two ways:\nPut the key in the GOOGLE_API_KEY environment variable (the SDK will automatically pick it up from there).\nPass the key to genai.configure(api_key=...)\n# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\ngenai.configure(api_key=GOOGLE_API_KEY)\nNow you're ready to call the Gemini API. Use list_models to see the available Gemini models:\ngemini-pro: optimized for text-only prompts.\ngemini-pro-vision: optimized for text-and-images prompts.\nfor m in genai.list_models():\n  if 'generateContent' in m.supported_generation_methods:\n    print(m.name)\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. There are options for requesting rate limit increases. The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\nThe genai package also supports the PaLM family of models, but only the Gemini models support the generic, multimodal capabilities of the generateContent method.\nFor text-only prompts, use the gemini-pro model:\nThe generate_content method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\nIn the simplest case, you can pass a prompt string to the GenerativeModel.generate_content method:\nresponse = model.generate_content(\"What is the meaning of life?\")\nCPU times: user 110 ms, sys: 12.3 ms, total: 123 ms\nWall time: 8.25 s\nIn simple cases, the response.text accessor is all you need. To display formatted Markdown text, use the to_markdown function:\nThe query of life's purpose has perplexed people across centuries, cultures, and continents. While there is no universally recognized response, many ideas have been put forth, and the response is frequently dependent on individual ideas, beliefs, and life experiences.\nHappiness and Well-being: Many individuals believe that the goal of life is to attain personal happiness and well-being. This might entail locating pursuits that provide joy, establishing significant connections, caring for one's physical and mental health, and pursuing personal goals and interests.\nMeaningful Contribution: Some believe that the purpose of life is to make a meaningful contribution to the world. This might entail pursuing a profession that benefits others, engaging in volunteer or charitable activities, generating art or literature, or inventing.\nSelf-realization and Personal Growth: The pursuit of self-realization and personal development is another common goal in life. This might entail learning new skills, pushing one's boundaries, confronting personal obstacles, and evolving as a person.\nEthical and Moral Behavior: Some believe that the goal of life is to act ethically and morally. This might entail adhering to one's moral principles, doing the right thing even when it is difficult, and attempting to make the world a better place.\nSpiritual Fulfillment: For some, the purpose of life is connected to spiritual or religious beliefs. This might entail seeking a connection with a higher power, practicing religious rituals, or following spiritual teachings.\nExperiencing Life to the Fullest: Some individuals believe that the goal of life is to experience all that it has to offer. This might entail traveling, trying new things, taking risks, and embracing new encounters.\nLegacy and Impact: Others believe that the purpose of life is to leave a lasting legacy and impact on the world. This might entail accomplishing something noteworthy, being remembered for one's contributions, or inspiring and motivating others.\nFinding Balance and Harmony: For some, the purpose of life is to find balance and harmony in all aspects of their lives. This might entail juggling personal, professional, and social obligations, seeking inner peace and contentment, and living a life that is in accordance with one's values and beliefs.\nUltimately, the meaning of life is a personal journey, and different individuals may discover their own unique purpose through their experiences, reflections, and interactions with the world around them.\nIf the API failed to return a result, use GenerateContentResponse.prompt_feedback to see if it was blocked due to safety concerns regarding the prompt.\nGemini can generate multiple possible responses for a single prompt. These possible responses are called candidates, and you can review them to select the most suitable one as the response.\nView the response candidates with GenerateContentResponse.candidates:\n    text: \"The query of life\\'s purpose has perplexed people across centuries, cultures, and continents. While there is no universally recognized response, many ideas have been put forth, and the response is frequently dependent on individual ideas, beliefs, and life experiences.\\n\\n1. **Happiness and Well-being:** Many individuals believe that the goal of life is to attain personal happiness and well-being. This might entail locating pursuits that provide joy, establishing significant connections, caring for one\\'s physical and mental health, and pursuing personal goals and interests.\\n\\n2. **Meaningful Contribution:** Some believe that the purpose of life is to make a meaningful contribution to the world. This might entail pursuing a profession that benefits others, engaging in volunteer or charitable activities, generating art or literature, or inventing.\\n\\n3. **Self-realization and Personal Growth:** The pursuit of self-realization and personal development is another common goal in life. This might entail learning new skills, pushing one\\'s boundaries, confronting personal obstacles, and evolving as a person.\\n\\n4. **Ethical and Moral Behavior:** Some believe that the goal of life is to act ethically and morally. This might entail adhering to one\\'s moral principles, doing the right thing even when it is difficult, and attempting to make the world a better place.\\n\\n5. **Spiritual Fulfillment:** For some, the purpose of life is connected to spiritual or religious beliefs. This might entail seeking a connection with a higher power, practicing religious rituals, or following spiritual teachings.\\n\\n6. **Experiencing Life to the Fullest:** Some individuals believe that the goal of life is to experience all that it has to offer. This might entail traveling, trying new things, taking risks, and embracing new encounters.\\n\\n7. **Legacy and Impact:** Others believe that the purpose of life is to leave a lasting legacy and impact on the world. This might entail accomplishing something noteworthy, being remembered for one\\'s contributions, or inspiring and motivating others.\\n\\n8. **Finding Balance and Harmony:** For some, the purpose of life is to find balance and harmony in all aspects of their lives. This might entail juggling personal, professional, and social obligations, seeking inner peace and contentment, and living a life that is in accordance with one\\'s values and beliefs.\\n\\nUltimately, the meaning of life is a personal journey, and different individuals may discover their own unique purpose through their experiences, reflections, and interactions with the world around them.\"\nBy default, the model returns a response after completing the entire generation process. You can also stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated.\nTo stream responses, use GenerativeModel.generate_content(..., stream=True).\nCPU times: user 102 ms, sys: 25.1 ms, total: 128 ms\nWall time: 7.94 s\nThe query of life's purpose has perplexed people across centuries, cultures, and\n continents. While there is no universally recognized response, many ideas have been put forth, and the response is frequently dependent on individual ideas, beliefs, and life experiences\n.\n1. **Happiness and Well-being:** Many individuals believe that the goal of life is to attain personal happiness and well-being. This might entail locating pursuits that provide joy, establishing significant connections, caring for one's physical and mental health, and pursuing personal goals and aspirations.\n2. **Meaning\nful Contribution:** Some believe that the purpose of life is to make a meaningful contribution to the world. This might entail pursuing a profession that benefits others, engaging in volunteer or charitable activities, generating art or literature, or inventing.\n3. **Self-realization and Personal Growth:** The pursuit of self-realization and personal development is another common goal in life. This might entail learning new skills, exploring one's interests and abilities, overcoming obstacles, and becoming the best version of oneself.\n4. **Connection and Relationships:** For many individuals, the purpose of life is found in their relationships with others. This might entail building\n strong bonds with family and friends, fostering a sense of community, and contributing to the well-being of those around them.\n5. **Spiritual Fulfillment:** For those with religious or spiritual beliefs, the purpose of life may be centered on seeking spiritual fulfillment or enlightenment. This might entail following religious teachings, engaging in spiritual practices, or seeking a deeper understanding of the divine.\n6. **Experiencing the Journey:** Some believe that the purpose of life is simply to experience the journey itself, with all its joys and sorrows. This perspective emphasizes embracing the present moment, appreciating life's experiences, and finding meaning in the act of living itself.\n7. **Legacy and Impact:** For others, the goal of life is to leave a lasting legacy or impact on the world. This might entail making a significant contribution to a particular field, leaving a positive mark on future generations, or creating something that will be remembered and cherished long after one's lifetime.\nUltimately, the meaning of life is a personal and subjective question, and there is no single, universally accepted answer. It is about discovering what brings you fulfillment, purpose, and meaning in your own life, and living in accordance with those values.\nWhen streaming, some response attributes are not available until you've iterated through all the response chunks. This is demonstrated below:\nThe prompt_feedback attribute works:\nBut attributes like text do not:\ntry:\n  response.text\nexcept Exception as e:\n  print(f'{type(e).__name__}: {e}')\nIncompleteIterationError: Please let the response complete iteration before accessing the final accumulated\nattributes (or call `response.resolve()`)\nGemini provides a multimodal model (gemini-pro-vision) that accepts both text and images and inputs. The GenerativeModel.generate_content API is designed to handle multimodal prompts and returns a text output.\nLet's include an image:\ncurl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100  405k  100  405k    0     0  6982k      0 --:--:-- --:--:-- --:--:-- 7106k\nimport PIL.Image\nimg = PIL.Image.open('image.jpg')\nimg\nUse the gemini-pro-vision model and pass the image to the model with generate_content.\nresponse = model.generate_content(img)\nChicken Teriyaki Meal Prep Bowls with brown rice, roasted broccoli and bell peppers.\nTo provide both text and images in a prompt, pass a list containing the strings and images:\nresponse = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\nMeal prepping is a great way to save time and money, and it can also help you to eat healthier. This meal is a great example of a healthy and delicious meal that can be easily prepped ahead of time.\nThis meal features brown rice, roasted vegetables, and chicken teriyaki. The brown rice is a whole grain that is high in fiber and nutrients. The roasted vegetables are a great way to get your daily dose of vitamins and minerals. And the chicken teriyaki is a lean protein source that is also packed with flavor.\nThis meal is easy to prepare ahead of time. Simply cook the brown rice, roast the vegetables, and cook the chicken teriyaki. Then, divide the meal into individual containers and store them in the refrigerator. When you're ready to eat, simply grab a container and heat it up.\nThis meal is a great option for busy people who are looking for a healthy and delicious way to eat. It's also a great meal for those who are trying to lose weight or maintain a healthy weight.\nIf you're looking for a healthy and delicious meal that can be easily prepped ahead of time, this meal is a great option. Give it a try today!\nGemini enables you to have freeform conversations across multiple turns. The ChatSession class simplifies the process by managing the state of the conversation, so unlike with generate_content, you do not have to store the conversation history as a list.\nInitialize the chat:\nchat = model.start_chat(history=[])\nchat\n<google.generativeai.generative_models.ChatSession at 0x7b7b68250100>\nNote: The vision model gemini-pro-vision is not optimized for multi-turn chat.\nThe ChatSession.send_message method returns the same GenerateContentResponse type as GenerativeModel.generate_content. It also appends your message and the response to the chat history:\nresponse = chat.send_message(\"In one sentence, explain how a computer works to a young child.\")\nA computer is like a very smart machine that can understand and follow our instructions, help us with our work, and even play games with us!\nYou can keep sending messages to continue the conversation. Use the stream=True argument to stream the chat:\nresponse = chat.send_message(\"Okay, how about a more detailed explanation to a high schooler?\", stream=True)\nA computer works by following instructions, called a program, which tells it what to\n do. These instructions are written in a special language that the computer can understand, and they are stored in the computer's memory. The computer's processor\n, or CPU, reads the instructions from memory and carries them out, performing calculations and making decisions based on the program's logic. The results of these calculations and decisions are then displayed on the computer's screen or stored in memory for later use.\nTo give you a simple analogy, imagine a computer as a\n chef following a recipe. The recipe is like the program, and the chef's actions are like the instructions the computer follows. The chef reads the recipe (the program) and performs actions like gathering ingredients (fetching data from memory), mixing them together (performing calculations), and cooking them (processing data). The final dish (the output) is then presented on a plate (the computer screen).\nglm.Content objects contain a list of glm.Part objects that each contain either a text (string) or inline_data (glm.Blob), where a blob contains binary data and a mime_type. The chat history is available as a list of glm.Content objects in ChatSession.history:\nfor message in chat.history:\n  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\nuser: In one sentence, explain how a computer works to a young child.\nmodel: A computer is like a very smart machine that can understand and follow our instructions, help us with our work, and even play games with us!\nuser: Okay, how about a more detailed explanation to a high schooler?\nmodel: A computer works by following instructions, called a program, which tells it what to do. These instructions are written in a special language that the computer can understand, and they are stored in the computer's memory. The computer's processor, or CPU, reads the instructions from memory and carries them out, performing calculations and making decisions based on the program's logic. The results of these calculations and decisions are then displayed on the computer's screen or stored in memory for later use.\nTo give you a simple analogy, imagine a computer as a chef following a recipe. The recipe is like the program, and the chef's actions are like the instructions the computer follows. The chef reads the recipe (the program) and performs actions like gathering ingredients (fetching data from memory), mixing them together (performing calculations), and cooking them (processing data). The final dish (the output) is then presented on a plate (the computer screen).\nLarge language models have a context window, and the context length is often measured in terms of the number of tokens. With the Gemini API, you can determine the number of tokens per any glm.Content object. In the simplest case, you can pass a query string to the GenerativeModel.count_tokens method as follows:\nmodel.count_tokens(\"What is the meaning of life?\")\ntotal_tokens: 7\nSimilarly, you can check token_count for your ChatSession:\nmodel.count_tokens(chat.history)\ntotal_tokens: 501\nEmbedding is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity. For more on how and why you should use embeddings, refer to the Embeddings guide.\nUse the embed_content method to generate embeddings. The method handles embedding for the following tasks (task_type):\nTask Type\tDescription\nRETRIEVAL_QUERY\tSpecifies the given text is a query in a search/retrieval setting.\nRETRIEVAL_DOCUMENT\tSpecifies the given text is a document in a search/retrieval setting. Using this task type requires a title.\nSEMANTIC_SIMILARITY\tSpecifies the given text will be used for Semantic Textual Similarity (STS).\nCLASSIFICATION\tSpecifies that the embeddings will be used for classification.\nCLUSTERING\tSpecifies that the embeddings will be used for clustering.\nThe following generates an embedding for a single string for document retrieval:\n    content=\"What is the meaning of life?\",\n    title=\"Embedding of single string\")\nprint(str(result['embedding'])[:50], '... TRIMMED]')\n[-0.003216741, -0.013358698, -0.017649598, -0.0091 ... TRIMMED]\nNote: The retrieval_document task type is the only task that accepts a title.\nTo handle batches of strings, pass a list of strings in content:\n    content=[\n      'What is the meaning of life?',\n      'How much wood would a woodchuck chuck?',\n      'How does the brain work?'],\n    title=\"Embedding of list of strings\")\n# A list of inputs > A list of vectors output\nfor v in result['embedding']:\n  print(str(v)[:50], '... TRIMMED ...')\n[0.0040260437, 0.004124458, -0.014209415, -0.00183 ... TRIMMED ...\n[-0.004049845, -0.0075574904, -0.0073463684, -0.03 ... TRIMMED ...\n[0.025310587, -0.0080734305, -0.029902633, 0.01160 ... TRIMMED ...\nWhile the genai.embed_content function accepts simple strings or lists of strings, it is actually built around the glm.Content type (like GenerativeModel.generate_content). glm.Content objects are the primary units of conversation in the API.\nWhile the glm.Content object is multimodal, the embed_content method only supports text embeddings. This design gives the API the possibility to expand to multimodal embeddings.\nresponse.candidates[0].content\nparts {\n  text: \"A computer works by following instructions, called a program, which tells it what to do. These instructions are written in a special language that the computer can understand, and they are stored in the computer\\'s memory. The computer\\'s processor, or CPU, reads the instructions from memory and carries them out, performing calculations and making decisions based on the program\\'s logic. The results of these calculations and decisions are then displayed on the computer\\'s screen or stored in memory for later use.\\n\\nTo give you a simple analogy, imagine a computer as a chef following a recipe. The recipe is like the program, and the chef\\'s actions are like the instructions the computer follows. The chef reads the recipe (the program) and performs actions like gathering ingredients (fetching data from memory), mixing them together (performing calculations), and cooking them (processing data). The final dish (the output) is then presented on a plate (the computer screen).\\n\\nIn summary, a computer works by executing a series of instructions, stored in its memory, to perform calculations, make decisions, and display or store the results.\"\nrole: \"model\"\n    content = response.candidates[0].content)\nprint(str(result['embedding'])[:50], '... TRIMMED ...')\n[-0.013921871, -0.03504407, -0.0051786783, 0.03113 ... TRIMMED ...\nSimilarly, the chat history contains a list of glm.Content objects, which you can pass directly to the embed_content function:\n role: \"model\",\n   text: \"Okay, how about a more detailed explanation to a high schooler?\"\n   text: \"A computer works by following instructions, called a program, which tells it what to do. These instructions are written in a special language that the computer can understand, and they are stored in the computer\\'s memory. The computer\\'s processor, or CPU, reads the instructions from memory and carries them out, performing calculations and making decisions based on the program\\'s logic. The results of these calculations and decisions are then displayed on the computer\\'s screen or stored in memory for later use.\\n\\nTo give you a simple analogy, imagine a computer as a chef following a recipe. The recipe is like the program, and the chef\\'s actions are like the instructions the computer follows. The chef reads the recipe (the program) and performs actions like gathering ingredients (fetching data from memory), mixing them together (performing calculations), and cooking them (processing data). The final dish (the output) is then presented on a plate (the computer screen).\\n\\nIn summary, a computer works by executing a series of instructions, stored in its memory, to perform calculations, make decisions, and display or store the results.\"\n    content = chat.history)\nfor i,v in enumerate(result['embedding']):\n  print(str(v)[:50], '... TRIMMED...')\n[-0.014632266, -0.042202696, -0.015757175, 0.01548 ... TRIMMED...\n[-0.010979066, -0.024494737, 0.0092659835, 0.00803 ... TRIMMED...\n[-0.010055617, -0.07208932, -0.00011750793, -0.023 ... TRIMMED...\n[-0.013921871, -0.03504407, -0.0051786783, 0.03113 ... TRIMMED...\nThe following sections discuss advanced use cases and lower-level details of the Python SDK for the Gemini API.\nThe safety_settings argument lets you configure what the model blocks and allows in both prompts and responses. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\nEnter a questionable prompt and run the model with the default safety settings, and it will not return any candidates:\nresponse = model.generate_content('[Questionable prompt here]')\n    text: \"I\\'m sorry, but this prompt involves a sensitive topic and I\\'m not allowed to generate responses that are potentially harmful or inappropriate.\"\nThe prompt_feedback will tell you which safety filter blocked the prompt:\nNow provide the same prompt to the model with newly configured safety settings, and you may get a response.\nresponse = model.generate_content('[Questionable prompt here]',\n                                  safety_settings={'HARASSMENT':'block_none'})\nresponse.text\nAlso note that each candidate has its own safety_ratings, in case the prompt passes but the individual responses fail the safety checks.\nThe previous sections relied on the SDK to make it easy for you to send prompts to the API. This section offers a fully-typed equivalent to the previous example, so you can better understand the lower-level details regarding how the SDK encodes messages.\nUnderlying the Python SDK is the google.ai.generativelanguage client library:\nimport google.ai.generativelanguage as glm\nThe SDK attempts to convert your message to a glm.Content object, which contains a list of glm.Part objects that each contain either:\na text (string)\ninline_data (glm.Blob), where a blob contains binary data and a mime_type.\nYou can also pass any of these classes as an equivalent dictionary.\nNote: The only accepted mime types are some image types, image/*.\nSo, the fully-typed equivalent to the previous example is:\n    glm.Content(\n        parts = [\n            glm.Part(text=\"Write a short, engaging blog post based on this picture.\"),\n            glm.Part(\n                inline_data=glm.Blob(\n                    mime_type='image/jpeg',\n                    data=pathlib.Path('image.jpg').read_bytes()\n                )\n            ),\n        ],\n    ),\n    stream=True)\nto_markdown(response.text[:100] + \"... [TRIMMED] ...\")\nMeal prepping is a great way to save time and money, and it can also help you to eat healthier. By ... [TRIMMED] ...\nWhile the genai.ChatSession class shown earlier can handle many use cases, it does make some assumptions. If your use case doesn't fit into this chat implementation it's good to remember that genai.ChatSession is just a wrapper around GenerativeModel.generate_content. In addition to single requests, it can handle multi-turn conversations.\nThe individual messages are glm.Content objects or compatible dictionaries, as seen in previous sections. As a dictionary, the message requires role and parts keys. The role in a conversation can either be the user, which provides the prompts, or model, which provides the responses.\nPass a list of glm.Content objects and it will be treated as multi-turn chat:\nmessages = [\n    {'role':'user',\n     'parts': [\"Briefly explain how a computer works to a young child.\"]}\nImagine a computer as a really smart friend who can help you with many things. Just like you have a brain to think and learn, a computer has a brain too, called a processor. It's like the boss of the computer, telling it what to do.\nInside the computer, there's a special place called memory, which is like a big storage box. It remembers all the things you tell it to do, like opening games or playing videos.\nWhen you press buttons on the keyboard or click things on the screen with the mouse, you're sending messages to the computer. These messages travel through special wires, called cables, to the processor.\nThe processor reads the messages and tells the computer what to do. It can open programs, show you pictures, or even play music for you.\nAll the things you see on the screen are created by the graphics card, which is like a magic artist inside the computer. It takes the processor's instructions and turns them into colorful pictures and videos.\nTo save your favorite games, videos, or pictures, the computer uses a special storage space called a hard drive. It's like a giant library where the computer can keep all your precious things safe.\nAnd when you want to connect to the internet to play games with friends or watch funny videos, the computer uses something called a network card to send and receive messages through the internet cables or Wi-Fi signals.\nSo, just like your brain helps you learn and play, the computer's processor, memory, graphics card, hard drive, and network card all work together to make your computer a super-smart friend that can help you do amazing things!\nTo continue the conversation, add the response and another message.\nNote: For multi-turn conversations, you need to send the whole conversation history with each request. The API is stateless.\nmessages.append({'role':'model',\n                 'parts':[response.text]})\nmessages.append({'role':'user',\n                 'parts':[\"Okay, how about a more detailed explanation to a high school student?\"]})\nAt its core, a computer is a machine that can be programmed to carry out a set of instructions. It consists of several essential components that work together to process, store, and display information:\n1. Processor (CPU): - The brain of the computer. - Executes instructions and performs calculations. - Speed measured in gigahertz (GHz). - More GHz generally means faster processing.\n2. Memory (RAM): - Temporary storage for data being processed. - Holds instructions and data while the program is running. - Measured in gigabytes (GB). - More GB of RAM allows for more programs to run simultaneously.\n3. Storage (HDD/SSD): - Permanent storage for data. - Stores operating system, programs, and user files. - Measured in gigabytes (GB) or terabytes (TB). - Hard disk drives (HDDs) are traditional, slower, and cheaper. - Solid-state drives (SSDs) are newer, faster, and more expensive.\n4. Graphics Card (GPU): - Processes and displays images. - Essential for gaming, video editing, and other graphics-intensive tasks. - Measured in video RAM (VRAM) and clock speed.\n5. Motherboard: - Connects all the components. - Provides power and communication pathways.\n6. Input/Output (I/O) Devices: - Allow the user to interact with the computer. - Examples: keyboard, mouse, monitor, printer.\n7. Operating System (OS): - Software that manages the computer's resources. - Provides a user interface and basic functionality. - Examples: Windows, macOS, Linux.\nWhen you run a program on your computer, the following happens:\nThe program instructions are loaded from storage into memory.\nThe processor reads the instructions from memory and executes them one by one.\nIf the instruction involves calculations, the processor performs them using its arithmetic logic unit (ALU).\nIf the instruction involves data, the processor reads or writes to memory.\nThe results of the calculations or data manipulation are stored in memory.\nIf the program needs to display something on the screen, it sends the necessary data to the graphics card.\nThe graphics card processes the data and sends it to the monitor, which displays it.\nThis process continues until the program has completed its task or the user terminates it.\nThe generation_config argument allows you to modify the generation parameters. Every prompt you send to the model includes parameter values that control how the model generates responses.\n    'Tell me a story about a magic backpack.',\n    generation_config=genai.types.GenerationConfig(\n        # Only one candidate for now.\n        candidate_count=1,\n        stop_sequences=['x'],\n        max_output_tokens=20,\n        temperature=1.0)\n)\ntext = response.text\nif response.candidates[0].finish_reason.name == \"MAX_TOKENS\":\n    text += '...'\nto_markdown(text)\nOnce upon a time, in a small town nestled amidst lush green hills, lived a young girl named...\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for prompt writing.\nGemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available Gemini models.\nGemini offers options for requesting rate limit increases. The rate limit for Gemini-Pro models is 60 requests per minute (RPM).",
            "filtered_word_count": 4890
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your project\nSet up your API key\nInstall the SDK package\nInitialize the Generative Model\nImplement common use cases\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nImplement advanced use cases\nUse embeddings\nCount tokens\nOptions to control content generation\nConfigure model parameters\nUse safety settings\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with the Gemini API in Go applications \nbookmark_border\n\nThis tutorial demonstrates how to access the Gemini API for your Go application using the Google AI Go SDK.\n\nIn this tutorial, you'll learn how to do the following:\n\nSet up your project, including your API key\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn addition, this tutorial contains sections about advanced use cases (like embeddings and counting tokens) as well as options for controlling content generation.\n\nPrerequisites\n\nThis tutorial assumes that you're familiar with building applications with Go.\n\nTo complete this tutorial, make sure that your development environment meets the following requirements:\n\nGo 1.20+\nSet up your project\n\nBefore calling the Gemini API, you need to set up your project, which includes setting up your API key, installing the SDK package, and initializing the model.\n\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nSecure your API key\n\nIt's strongly recommended that you do not check an API key into your version control system. Instead, you should use a secrets store for your API key.\n\nAll the snippets in this tutorial assume that you're accessing your API key as an environment variable.\n\nInstall the SDK package\n\nTo use the Gemini API in your own application, you need to get the Go SDK package in your module directory:\n\ngo get github.com/google/generative-ai-go\n\nInitialize the Generative Model\n\nBefore you can make any API calls, you need to import and initialize the Generative Model.\n\nimport \"github.com/google/generative-ai-go/genai\"\nimport \"google.golang.org/api/option\"\n\nctx := context.Background()\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nclient, err := genai.NewClient(ctx, option.WithAPIKey(os.Getenv(\"API_KEY\")))\nif err != nil {\n  log.Fatal(err)\n}\ndefer client.Close()\n\nmodel := client.GenerativeModel(\"MODEL_NAME\")\n\n\nWhen specifying a model, note the following:\n\nUse a model that's specific to your use case (for example, gemini-pro-vision is for multimodal input). Within this guide, the instructions for each implementation list the recommended model for each use case.\n\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. The rate limit for Gemini Pro models is 60 requests per minute (RPM), and we offer options for requesting rate limit increases.\nImplement common use cases\n\nNow that your project is set up, you can explore using the Gemini API to implement different use cases:\n\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn the advanced use cases section, you can find information about the Gemini API and embeddings.\n\nGenerate text from text-only input\n\nWhen the prompt input includes only text, use the gemini-pro model with the GenerateContent method to generate text output:\n\nctx := context.Background()\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nclient, err := genai.NewClient(ctx, option.WithAPIKey(os.Getenv(\"API_KEY\")))\nif err != nil {\n  log.Fatal(err)\n}\ndefer client.Close()\n\n// For text-only input, use the gemini-pro model\nmodel := client.GenerativeModel(\"gemini-pro\")\nresp, err := model.GenerateContent(ctx, genai.Text(\"Write a story about a magic backpack.\"))\nif err != nil {\n  log.Fatal(err)\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nGenerate text from text-and-image input (multimodal)\nNote: If your prompts will exceed 20MB in size, upload the media files with the File API.\n\nGemini provides a multimodal model (gemini-pro-vision), so you can input both text and images. Make sure to review the image requirements for prompts.\n\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with the GenerateContent method to generate text output:\n\nctx := context.Background()\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nclient, err := genai.NewClient(ctx, option.WithAPIKey(os.Getenv(\"API_KEY\")))\nif err != nil {\n  log.Fatal(err)\n}\ndefer client.Close()\n\n// For text-and-image input (multimodal), use the gemini-pro-vision model\nmodel := client.GenerativeModel(\"gemini-pro-vision\")\n\nimgData1, err := os.ReadFile(pathToImage1)\nif err != nil {\n  log.Fatal(err)\n}\n\nimgData2, err := os.ReadFile(pathToImage1)\nif err != nil {\n  log.Fatal(err)\n}\n\nprompt := []genai.Part{\n  genai.ImageData(\"jpeg\", imgData1),\n  genai.ImageData(\"jpeg\", imgData2),\n  genai.Text(\"What's different between these two pictures?\"),\n}\nresp, err := model.GenerateContent(ctx, prompt...)\n\nif err != nil {\n  log.Fatal(err)\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nBuild multi-turn conversations (chat)\n\nUsing Gemini, you can build freeform conversations across multiple turns. The SDK simplifies the process by managing the state of the conversation, so unlike with GenerateContent, you don't have to store the conversation history yourself.\n\nTo build a multi-turn conversation (like chat), use the gemini-pro model, and initialize the chat by calling StartChat(). Then use SendMessage() to send a new user message, which will also append the message and the response to the chat history.\n\nThere are two possible options for role associated with the content in a conversation:\n\nuser: the role which provides the prompts. This value is the default for SendMessage calls.\n\nmodel: the role which provides the responses. This role can be used when calling StartChat() with existing history.\n\nNote: The gemini-pro-vision model (for text-and-image input) is not yet optimized for multi-turn conversations. Make sure to use gemini-pro and text-only input for chat use cases.\nctx := context.Background()\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nclient, err := genai.NewClient(ctx, option.WithAPIKey(os.Getenv(\"API_KEY\")))\nif err != nil {\n  log.Fatal(err)\n}\ndefer client.Close()\n\n// For text-only input, use the gemini-pro model\nmodel := client.GenerativeModel(\"gemini-pro\")\n// Initialize the chat\ncs := model.StartChat()\ncs.History = []*genai.Content{\n  &genai.Content{\n    Parts: []genai.Part{\n      genai.Text(\"Hello, I have 2 dogs in my house.\"),\n    },\n    Role: \"user\",\n  },\n  &genai.Content{\n    Parts: []genai.Part{\n      genai.Text(\"Great to meet you. What would you like to know?\"),\n    },\n    Role: \"model\",\n  },\n}\n\nresp, err := cs.SendMessage(ctx, genai.Text(\"How many paws are in my house?\"))\nif err != nil {\n  log.Fatal(err)\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nUse streaming for faster interactions\n\nBy default, the model returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n\nThe following example shows how to implement streaming with the GenerateContentStream method to generate text from a text-and-image input prompt.\n\nctx := context.Background()\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nclient, err := genai.NewClient(ctx, option.WithAPIKey(os.Getenv(\"API_KEY\")))\nif err != nil {\n  log.Fatal(err)\n}\ndefer client.Close()\n\n// For text-and-image input (multimodal), use the gemini-pro-vision model\nmodel := client.GenerativeModel(\"gemini-pro-vision\")\n\nimageBytes, err := os.ReadFile(pathToImage)\n\nimg := genai.ImageData(\"jpeg\", imageBytes)\nprompt := genai.Text(\"Tell me a story about this animal\")\niter := model.GenerateContentStream(ctx, img, prompt)\n\nfor {\n  resp, err := iter.Next()\n  if err == iterator.Done {\n    break\n  }\n  if err != nil {\n    log.Fatal(err)\n  }\n\n  // ... print resp\n}\n\n\nYou can use a similar approach for text-only input and chat use cases.\n\nprompt := genai.Text(\"Tell me a story about a lumberjack and his giant ox\")\niter := model.GenerateContentStream(ctx, prompt)\n\nprompt := genai.Text(\"And how do you feel about that?\")\niter := cs.SendMessageStream(ctx, prompt)\n\nImplement advanced use cases\n\nThe common use cases described in the previous section of this tutorial help you become comfortable with using the Gemini API. This section describes some use cases that might be considered more advanced.\n\nUse embeddings\n\nEmbedding is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity.\n\nUse the embedding-001 model with the EmbedContent method (or the BatchEmbedContent method) to generate embeddings. The following example generates an embedding for a single string:\n\nctx := context.Background()\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nclient, err := genai.NewClient(ctx, option.WithAPIKey(os.Getenv(\"API_KEY\")))\nif err != nil {\n  log.Fatal(err)\n}\ndefer client.Close()\nem := client.EmbeddingModel(\"embedding-001\")\nres, err := em.EmbedContent(ctx, genai.Text(\"The quick brown fox jumps over the lazy dog.\"))\n\nif err != nil {\n  panic(err)\n}\nfmt.Println(res.Embedding.Values)\n\nCount tokens\n\nWhen using long prompts, it might be useful to count tokens before sending any content to the model. The following examples show how to use CountTokens() for various use cases:\n\n// For text-only input\ntext := \"Parrots can be green and live a long time.\"\nresp, err := model.CountTokens(ctx, genai.Text(text))\nif err != nil {\n  log.Fatal(err)\n}\nfmt.Println(resp.TotalTokens)\n\n// For text-and-image input (multimodal)\ntext := \"Parrots can be green and live a long time.\"\nimageBytes, err := os.ReadFile(pathToImage)\nif err != nil {\n  log.Fatal(err)\n}\n\nresp, err := model.CountTokens(\n    ctx,\n    genai.Text(text),\n    genai.ImageData(\"png\", imageBytes))\n  if err != nil {\n    log.Fatal(err)\n}\nfmt.Println(resp.TotalTokens)\n\nOptions to control content generation\n\nYou can control content generation by configuring model parameters and by using safety settings.\n\nConfigure model parameters\n\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about Model parameters. The configuration is maintained for the lifetime of your model instance.\n\n// ...\n\nmodel := client.GenerativeModel(\"MODEL_NAME\")\n\n// Configure model parameters by invoking Set* methods on the model.\nmodel.SetTemperature(0.9)\nmodel.SetTopK(1)\n\n// ...\n\nUse safety settings\n\nYou can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\n\nHere's how to set one safety setting:\n\n// ...\n\nmodel := client.GenerativeModel(\"MODEL_NAME\")\n\nmodel.SafetySettings = []*genai.SafetySetting{\n  {\n    Category:  genai.HarmCategoryHarassment,\n    Threshold: genai.HarmBlockOnlyHigh,\n  },\n}\n\n// ...\n\n\nYou can also set more than one safety setting:\n\n// ...\n\nmodel := client.GenerativeModel(\"MODEL_NAME\")\n\nmodel.SafetySettings = []*genai.SafetySetting{\n  {\n    Category:  genai.HarmCategoryHarassment,\n    Threshold: genai.HarmBlockOnlyHigh,\n  },\n  {\n    Category:  genai.HarmCategoryHateSpeech,\n    Threshold: genai.HarmBlockMediumAndAbove,\n  },\n}\n\n// ...\n\nWhat's next\n\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for prompt writing.\n\nGemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available Gemini models.\n\nGemini offers options for requesting rate limit increases. The rate limit for Gemini Pro models is 60 requests per minute (RPM).\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 2040,
            "filtered_content": "Get started with the Gemini API in Go applications \nThis tutorial demonstrates how to access the Gemini API for your Go application using the Google AI Go SDK.\nIn this tutorial, you'll learn how to do the following:\nSet up your project, including your API key\nIn addition, this tutorial contains sections about advanced use cases (like embeddings and counting tokens) as well as options for controlling content generation.\nThis tutorial assumes that you're familiar with building applications with Go.\nTo complete this tutorial, make sure that your development environment meets the following requirements:\nGo 1.20+\nBefore calling the Gemini API, you need to set up your project, which includes setting up your API key, installing the SDK package, and initializing the model.\nSecure your API key\nIt's strongly recommended that you do not check an API key into your version control system. Instead, you should use a secrets store for your API key.\nAll the snippets in this tutorial assume that you're accessing your API key as an environment variable.\nTo use the Gemini API in your own application, you need to get the Go SDK package in your module directory:\ngo get github.com/google/generative-ai-go\nBefore you can make any API calls, you need to import and initialize the Generative Model.\nimport \"github.com/google/generative-ai-go/genai\"\nimport \"google.golang.org/api/option\"\nWhen specifying a model, note the following:\nUse a model that's specific to your use case (for example, gemini-pro-vision is for multimodal input). Within this guide, the instructions for each implementation list the recommended model for each use case.\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. The rate limit for Gemini Pro models is 60 requests per minute (RPM), and we offer options for requesting rate limit increases.\nNow that your project is set up, you can explore using the Gemini API to implement different use cases:\nIn the advanced use cases section, you can find information about the Gemini API and embeddings.\nWhen the prompt input includes only text, use the gemini-pro model with the GenerateContent method to generate text output:\nresp, err := model.GenerateContent(ctx, genai.Text(\"Write a story about a magic backpack.\"))\nNote: If your prompts will exceed 20MB in size, upload the media files with the File API.\nGemini provides a multimodal model (gemini-pro-vision), so you can input both text and images. Make sure to review the image requirements for prompts.\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with the GenerateContent method to generate text output:\nimgData1, err := os.ReadFile(pathToImage1)\nimgData2, err := os.ReadFile(pathToImage1)\nprompt := []genai.Part{\n  genai.ImageData(\"jpeg\", imgData1),\n  genai.ImageData(\"jpeg\", imgData2),\n  genai.Text(\"What's different between these two pictures?\"),\nresp, err := model.GenerateContent(ctx, prompt...)\nUsing Gemini, you can build freeform conversations across multiple turns. The SDK simplifies the process by managing the state of the conversation, so unlike with GenerateContent, you don't have to store the conversation history yourself.\nTo build a multi-turn conversation (like chat), use the gemini-pro model, and initialize the chat by calling StartChat(). Then use SendMessage() to send a new user message, which will also append the message and the response to the chat history.\nThere are two possible options for role associated with the content in a conversation:\nuser: the role which provides the prompts. This value is the default for SendMessage calls.\nmodel: the role which provides the responses. This role can be used when calling StartChat() with existing history.\nNote: The gemini-pro-vision model (for text-and-image input) is not yet optimized for multi-turn conversations. Make sure to use gemini-pro and text-only input for chat use cases.\n// Initialize the chat\ncs := model.StartChat()\ncs.History = []*genai.Content{\n      genai.Text(\"Hello, I have 2 dogs in my house.\"),\n    Role: \"user\",\n      genai.Text(\"Great to meet you. What would you like to know?\"),\n    Role: \"model\",\nresp, err := cs.SendMessage(ctx, genai.Text(\"How many paws are in my house?\"))\nBy default, the model returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\nThe following example shows how to implement streaming with the GenerateContentStream method to generate text from a text-and-image input prompt.\nimg := genai.ImageData(\"jpeg\", imageBytes)\nprompt := genai.Text(\"Tell me a story about this animal\")\niter := model.GenerateContentStream(ctx, img, prompt)\nfor {\n  resp, err := iter.Next()\n  if err == iterator.Done {\n    break\n  // ... print resp\nYou can use a similar approach for text-only input and chat use cases.\nprompt := genai.Text(\"Tell me a story about a lumberjack and his giant ox\")\niter := model.GenerateContentStream(ctx, prompt)\nprompt := genai.Text(\"And how do you feel about that?\")\niter := cs.SendMessageStream(ctx, prompt)\nThe common use cases described in the previous section of this tutorial help you become comfortable with using the Gemini API. This section describes some use cases that might be considered more advanced.\nEmbedding is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity.\nUse the embedding-001 model with the EmbedContent method (or the BatchEmbedContent method) to generate embeddings. The following example generates an embedding for a single string:\nem := client.EmbeddingModel(\"embedding-001\")\nres, err := em.EmbedContent(ctx, genai.Text(\"The quick brown fox jumps over the lazy dog.\"))\n  panic(err)\nfmt.Println(res.Embedding.Values)\nWhen using long prompts, it might be useful to count tokens before sending any content to the model. The following examples show how to use CountTokens() for various use cases:\n// For text-only input\nresp, err := model.CountTokens(ctx, genai.Text(text))\n// For text-and-image input (multimodal)\nresp, err := model.CountTokens(\n    ctx,\n    genai.Text(text),\n    genai.ImageData(\"png\", imageBytes))\nYou can control content generation by configuring model parameters and by using safety settings.\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about Model parameters. The configuration is maintained for the lifetime of your model instance.\n// Configure model parameters by invoking Set* methods on the model.\nmodel.SetTemperature(0.9)\nmodel.SetTopK(1)\nYou can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\nHere's how to set one safety setting:\nYou can also set more than one safety setting:\n    Category:  genai.HarmCategoryHateSpeech,\n    Threshold: genai.HarmBlockMediumAndAbove,\nGemini offers options for requesting rate limit increases. The rate limit for Gemini Pro models is 60 requests per minute (RPM).",
            "filtered_word_count": 1116
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your project\nSet up your API key\nInstall the SDK package\nInitialize the Generative Model\nImplement common use cases\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nImplement advanced use cases\nUse embeddings\nCount tokens\nOptions to control content generation\nConfigure model parameters\nUse safety settings\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with the Gemini API in Node.js applications \nbookmark_border\n\nThis tutorial demonstrates how to access the Gemini API for your Node.js application using the Google AI JavaScript SDK.\n\nIn this tutorial, you'll learn how to do the following:\n\nSet up your project, including your API key\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn addition, this tutorial contains sections about advanced use cases (like embeddings and counting tokens) as well as options for controlling content generation.\n\nPrerequisites\n\nThis tutorial assumes that you're familiar with building applications with Node.js.\n\nTo complete this tutorial, make sure that your development environment meets the following requirements:\n\nNode.js v18+\nnpm\nSet up your project\n\nBefore calling the Gemini API, you need to set up your project, which includes setting up your API key, installing the SDK package, and initializing the model.\n\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nSecure your API key\n\nIt's strongly recommended that you do not check an API key into your version control system. Instead, you should use a secrets store for your API key.\n\nAll the snippets in this tutorial assume that you're accessing your API key as an environment variable.\n\nInstall the SDK package\n\nTo use the Gemini API in your own application, you need to install the GoogleGenerativeAI package for Node.js:\n\nnpm install @google/generative-ai\n\nInitialize the Generative Model\n\nBefore you can make any API calls, you need to import and initialize the Generative Model.\n\nconst { GoogleGenerativeAI } = require(\"@google/generative-ai\");\n\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nconst genAI = new GoogleGenerativeAI(process.env.API_KEY);\n\n// ...\n\nconst model = genAI.getGenerativeModel({ model: \"MODEL_NAME\"});\n\n// ...\n\n\nWhen specifying a model, note the following:\n\nUse a model that's specific to your use case (for example, gemini-pro-vision is for multimodal input). Within this guide, the instructions for each implementation list the recommended model for each use case.\n\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. The rate limit for Gemini Pro models is 60 requests per minute (RPM), and we offer options for requesting rate limit increases.\nImplement common use cases\n\nNow that your project is set up, you can explore using the Gemini API to implement different use cases:\n\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn the advanced use cases section, you can find information about the Gemini API and embeddings.\n\nGenerate text from text-only input\n\nWhen the prompt input includes only text, use the gemini-pro model with the generateContent method to generate text output:\n\nconst { GoogleGenerativeAI } = require(\"@google/generative-ai\");\n\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nconst genAI = new GoogleGenerativeAI(process.env.API_KEY);\n\nasync function run() {\n  // For text-only input, use the gemini-pro model\n  const model = genAI.getGenerativeModel({ model: \"gemini-pro\"});\n\n  const prompt = \"Write a story about a magic backpack.\"\n\n  const result = await model.generateContent(prompt);\n  const response = await result.response;\n  const text = response.text();\n  console.log(text);\n}\n\nrun();\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nGenerate text from text-and-image input (multimodal)\nNote: If your prompts will exceed 20MB in size, upload the media files with the File API.\n\nGemini provides a multimodal model (gemini-pro-vision), so you can input both text and images. Make sure to review the image requirements for prompts.\n\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with the generateContent method to generate text output:\n\nconst { GoogleGenerativeAI } = require(\"@google/generative-ai\");\nconst fs = require(\"fs\");\n\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nconst genAI = new GoogleGenerativeAI(process.env.API_KEY);\n\n// Converts local file information to a GoogleGenerativeAI.Part object.\nfunction fileToGenerativePart(path, mimeType) {\n  return {\n    inlineData: {\n      data: Buffer.from(fs.readFileSync(path)).toString(\"base64\"),\n      mimeType\n    },\n  };\n}\n\nasync function run() {\n  // For text-and-image input (multimodal), use the gemini-pro-vision model\n  const model = genAI.getGenerativeModel({ model: \"gemini-pro-vision\" });\n\n  const prompt = \"What's different between these pictures?\";\n\n  const imageParts = [\n    fileToGenerativePart(\"image1.png\", \"image/png\"),\n    fileToGenerativePart(\"image2.jpeg\", \"image/jpeg\"),\n  ];\n\n  const result = await model.generateContent([prompt, ...imageParts]);\n  const response = await result.response;\n  const text = response.text();\n  console.log(text);\n}\n\nrun();\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nBuild multi-turn conversations (chat)\n\nUsing Gemini, you can build freeform conversations across multiple turns. The SDK simplifies the process by managing the state of the conversation, so unlike with generateContent, you don't have to store the conversation history yourself.\n\nTo build a multi-turn conversation (like chat), use the gemini-pro model, and initialize the chat by calling startChat(). Then use sendMessage() to send a new user message, which will also append the message and the response to the chat history.\n\nThere are two possible options for role associated with the content in a conversation:\n\nuser: the role which provides the prompts. This value is the default for sendMessage calls.\n\nmodel: the role which provides the responses. This role can be used when calling startChat() with existing history.\n\nNote: The gemini-pro-vision model (for text-and-image input) is not yet optimized for multi-turn conversations. Make sure to use gemini-pro and text-only input for chat use cases.\nconst { GoogleGenerativeAI } = require(\"@google/generative-ai\");\n\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nconst genAI = new GoogleGenerativeAI(process.env.API_KEY);\n\nasync function run() {\n  // For text-only input, use the gemini-pro model\n  const model = genAI.getGenerativeModel({ model: \"gemini-pro\"});\n\n  const chat = model.startChat({\n    history: [\n      {\n        role: \"user\",\n        parts: [{ text: \"Hello, I have 2 dogs in my house.\" }],\n      },\n      {\n        role: \"model\",\n        parts: [{ text: \"Great to meet you. What would you like to know?\" }],\n      },\n    ],\n    generationConfig: {\n      maxOutputTokens: 100,\n    },\n  });\n\n  const msg = \"How many paws are in my house?\";\n\n  const result = await chat.sendMessage(msg);\n  const response = await result.response;\n  const text = response.text();\n  console.log(text);\n}\n\nrun();\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nUse streaming for faster interactions\n\nBy default, the model returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n\nThe following example shows how to implement streaming with the generateContentStream method to generate text from a text-and-image input prompt.\n\n//...\n\nconst result = await model.generateContentStream([prompt, ...imageParts]);\n\nlet text = '';\nfor await (const chunk of result.stream) {\n  const chunkText = chunk.text();\n  console.log(chunkText);\n  text += chunkText;\n}\n\n//...\n\n\nYou can use a similar approach for text-only input and chat use cases.\n\n// Use streaming with text-only input\nconst result = await model.generateContentStream(prompt);\n\n\nSee chat example above for how to instantiate a chat.\n\n// Use streaming with multi-turn conversations (like chat)\nconst result = await chat.sendMessageStream(msg);\n\nImplement advanced use cases\n\nThe common use cases described in the previous section of this tutorial help you become comfortable with using the Gemini API. This section describes some use cases that might be considered more advanced.\n\nUse embeddings\n\nEmbedding is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity.\n\nUse the embedding-001 model with the embedContent method (or the batchEmbedContent method) to generate embeddings. The following example generates an embedding for a single string:\n\nconst { GoogleGenerativeAI } = require(\"@google/generative-ai\");\n\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nconst genAI = new GoogleGenerativeAI(process.env.API_KEY);\n\nasync function run() {\n  // For embeddings, use the embedding-001 model\n  const model = genAI.getGenerativeModel({ model: \"embedding-001\"});\n\n  const text = \"The quick brown fox jumps over the lazy dog.\"\n\n  const result = await model.embedContent(text);\n  const embedding = result.embedding;\n  console.log(embedding.values);\n}\n\nrun();\n\nCount tokens\n\nWhen using long prompts, it might be useful to count tokens before sending any content to the model. The following examples show how to use countTokens() for various use cases:\n\n// For text-only input\nconst { totalTokens } = await model.countTokens(prompt);\n\n// For text-and-image input (multimodal)\nconst { totalTokens } = await model.countTokens([prompt, ...imageParts]);\n\n// For multi-turn conversations (like chat)\nconst history = await chat.getHistory();\nconst msgContent = { role: \"user\", parts: [{ text: msg }] };\nconst contents = [...history, msgContent];\nconst { totalTokens } = await model.countTokens({ contents });\n\nOptions to control content generation\n\nYou can control content generation by configuring model parameters and by using safety settings.\n\nNote that passing generationConfig or safetySettings to a model request method (like generateContent) will fully override the configuration object with the same name passed in getGenerativeModel.\n\nConfigure model parameters\n\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about Model parameters.\n\nconst generationConfig = {\n  stopSequences: [\"red\"],\n  maxOutputTokens: 200,\n  temperature: 0.9,\n  topP: 0.1,\n  topK: 16,\n};\n\nconst model = genAI.getGenerativeModel({ model: \"MODEL_NAME\",  generationConfig });\n\nUse safety settings\n\nYou can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\n\nHere's how to set one safety setting:\n\nimport { HarmBlockThreshold, HarmCategory } from \"@google/generative-ai\";\n\n// ...\n\nconst safetySettings = [\n  {\n    category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n    threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n  },\n];\n\nconst model = genAI.getGenerativeModel({ model: \"MODEL_NAME\", safetySettings });\n\n\nYou can also set more than one safety setting:\n\nconst safetySettings = [\n  {\n    category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n    threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n  },\n  {\n    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n  },\n];\n\nWhat's next\n\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for prompt writing.\n\nGemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available Gemini models.\n\nGemini offers options for requesting rate limit increases. The rate limit for Gemini Pro models is 60 requests per minute (RPM).\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 2039,
            "filtered_content": "Get started with the Gemini API in Node.js applications \nThis tutorial demonstrates how to access the Gemini API for your Node.js application using the Google AI JavaScript SDK.\nThis tutorial assumes that you're familiar with building applications with Node.js.\nNode.js v18+\nnpm\nTo use the Gemini API in your own application, you need to install the GoogleGenerativeAI package for Node.js:\nnpm install @google/generative-ai\nconst model = genAI.getGenerativeModel({ model: \"MODEL_NAME\"});\nWhen the prompt input includes only text, use the gemini-pro model with the generateContent method to generate text output:\n  const prompt = \"Write a story about a magic backpack.\"\n  const result = await model.generateContent(prompt);\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with the generateContent method to generate text output:\nconst fs = require(\"fs\");\n// Converts local file information to a GoogleGenerativeAI.Part object.\nfunction fileToGenerativePart(path, mimeType) {\n  return {\n    inlineData: {\n      data: Buffer.from(fs.readFileSync(path)).toString(\"base64\"),\n      mimeType\n  };\n  // For text-and-image input (multimodal), use the gemini-pro-vision model\n  const model = genAI.getGenerativeModel({ model: \"gemini-pro-vision\" });\n  const prompt = \"What's different between these pictures?\";\n  const imageParts = [\n    fileToGenerativePart(\"image1.png\", \"image/png\"),\n    fileToGenerativePart(\"image2.jpeg\", \"image/jpeg\"),\n  ];\n  const result = await model.generateContent([prompt, ...imageParts]);\nUsing Gemini, you can build freeform conversations across multiple turns. The SDK simplifies the process by managing the state of the conversation, so unlike with generateContent, you don't have to store the conversation history yourself.\nTo build a multi-turn conversation (like chat), use the gemini-pro model, and initialize the chat by calling startChat(). Then use sendMessage() to send a new user message, which will also append the message and the response to the chat history.\nuser: the role which provides the prompts. This value is the default for sendMessage calls.\nmodel: the role which provides the responses. This role can be used when calling startChat() with existing history.\n  const chat = model.startChat({\n    history: [\n        role: \"user\",\n        parts: [{ text: \"Hello, I have 2 dogs in my house.\" }],\n        role: \"model\",\n        parts: [{ text: \"Great to meet you. What would you like to know?\" }],\n    ],\n    generationConfig: {\n      maxOutputTokens: 100,\n  });\n  const msg = \"How many paws are in my house?\";\n  const result = await chat.sendMessage(msg);\nThe following example shows how to implement streaming with the generateContentStream method to generate text from a text-and-image input prompt.\nconst result = await model.generateContentStream([prompt, ...imageParts]);\nlet text = '';\nfor await (const chunk of result.stream) {\n  const chunkText = chunk.text();\n  console.log(chunkText);\n  text += chunkText;\n// Use streaming with text-only input\nconst result = await model.generateContentStream(prompt);\nSee chat example above for how to instantiate a chat.\n// Use streaming with multi-turn conversations (like chat)\nconst result = await chat.sendMessageStream(msg);\nUse the embedding-001 model with the embedContent method (or the batchEmbedContent method) to generate embeddings. The following example generates an embedding for a single string:\n  // For embeddings, use the embedding-001 model\n  const model = genAI.getGenerativeModel({ model: \"embedding-001\"});\n  const text = \"The quick brown fox jumps over the lazy dog.\"\n  const result = await model.embedContent(text);\n  const embedding = result.embedding;\n  console.log(embedding.values);\nWhen using long prompts, it might be useful to count tokens before sending any content to the model. The following examples show how to use countTokens() for various use cases:\nconst { totalTokens } = await model.countTokens(prompt);\nconst { totalTokens } = await model.countTokens([prompt, ...imageParts]);\n// For multi-turn conversations (like chat)\nconst history = await chat.getHistory();\nconst msgContent = { role: \"user\", parts: [{ text: msg }] };\nconst contents = [...history, msgContent];\nconst { totalTokens } = await model.countTokens({ contents });\nNote that passing generationConfig or safetySettings to a model request method (like generateContent) will fully override the configuration object with the same name passed in getGenerativeModel.\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about Model parameters.\nconst generationConfig = {\n  stopSequences: [\"red\"],\n  maxOutputTokens: 200,\n  temperature: 0.9,\n  topP: 0.1,\n  topK: 16,\n};\nconst model = genAI.getGenerativeModel({ model: \"MODEL_NAME\",  generationConfig });\nimport { HarmBlockThreshold, HarmCategory } from \"@google/generative-ai\";\nconst model = genAI.getGenerativeModel({ model: \"MODEL_NAME\", safetySettings });\n    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,",
            "filtered_word_count": 675
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your project\nSet up your API key\nInitialize the Generative Model\nImplement common use cases\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nImplement advanced use cases\nCount tokens\nOptions to control content generation\nConfigure model parameters\nUse safety settings\nWhat's next\nThe Google AI JavaScript SDK is in public preview, which means its behavior and features could change in backward-incompatible ways. Preview releases should not be used in production.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with the Gemini API in web apps \nbookmark_border\n\nCaution: Using the Google AI SDK for JavaScript directly from a client-side app is recommended for prototyping only. If you plan to enable billing, we strongly recommend that you call the Google AI Gemini API only server-side to keep your API key safe. You risk potentially exposing your API key to malicious actors if you embed your API key directly in your JavaScript app or fetch it remotely at runtime.\n\nThis tutorial demonstrates how to access the Gemini API directly from your web app using the Google AI JavaScript SDK. You can use this SDK if you don't want to work directly with REST APIs or server-side code (like Node.js) for accessing Gemini models in your web app.\n\nIn this tutorial, you'll learn how to do the following:\n\nSet up your project, including your API key\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn addition, this tutorial contains sections about advanced use cases (like counting tokens) as well as options for controlling content generation.\n\nTip: Check out the sample app if you want to try out this SDK quickly or see a complete implementation of various use cases. To run the sample app, you'll need the prerequisites and an API key as described in this guide.\nPrerequisites\n\nThis tutorial assumes that you're familiar with using JavaScript to develop web apps. This guide is framework-independent.\n\nTo complete this tutorial, make sure that your development environment meets the following requirements:\n\n(Optional) Node.js\nModern web browser\nSet up your project\n\nBefore calling the Gemini API, you need to set up your project, which includes obtaining an API key and initializing the model.\n\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nSecure your API key\n\nIt's strongly recommended that you do not check an API key into your version control system. Instead, you should pass your API key to your app right before initializing the model.\n\nAll the snippets in this tutorial assume that you're accessing your API key as a global constant.\n\nInitialize the Generative Model\n\nBefore you can make any API calls, you need to import and initialize the Generative Model.\n\n<html>\n  <body>\n    <!-- ... Your HTML and CSS -->\n\n    <script type=\"importmap\">\n      {\n        \"imports\": {\n          \"@google/generative-ai\": \"https://esm.run/@google/generative-ai\"\n        }\n      }\n    </script>\n    <script type=\"module\">\n      import { GoogleGenerativeAI } from \"@google/generative-ai\";\n\n      // Fetch your API_KEY\n      const API_KEY = \"...\";\n\n      // Access your API key (see \"Set up your API key\" above)\n      const genAI = new GoogleGenerativeAI(API_KEY);\n\n      // ...\n\n      const model = genAI.getGenerativeModel({ model: \"MODEL_NAME\"});\n\n      // ...\n    </script>\n  </body>\n</html>\n\n\nWhen specifying a model, note the following:\n\nUse a model that's specific to your use case (for example, gemini-pro-vision is for multimodal input). Within this guide, the instructions for each implementation list the recommended model for each use case.\n\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. The rate limit for Gemini Pro models is 60 requests per minute (RPM), and we offer options for requesting rate limit increases.\nImplement common use cases\n\nNow that your project is set up, you can explore using the Gemini API to implement different use cases:\n\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nGenerate text from text-only input\n\nWhen the prompt input includes only text, use the gemini-pro model with the generateContent method to generate text output:\n\nimport { GoogleGenerativeAI } from \"@google/generative-ai\";\n\n// Access your API key (see \"Set up your API key\" above)\nconst genAI = new GoogleGenerativeAI(API_KEY);\n\nasync function run() {\n  // For text-only input, use the gemini-pro model\n  const model = genAI.getGenerativeModel({ model: \"gemini-pro\"});\n\n  const prompt = \"Write a story about a magic backpack.\"\n\n  const result = await model.generateContent(prompt);\n  const response = await result.response;\n  const text = response.text();\n  console.log(text);\n}\n\nrun();\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nGenerate text from text-and-image input (multimodal)\nNote: If your prompts will exceed 20MB in size, upload the media files with the File API.\n\nGemini provides a multimodal model (gemini-pro-vision), so you can input both text and images. Make sure to review the image requirements for input.\n\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with the generateContent method to generate text output:\n\nimport { GoogleGenerativeAI } from \"@google/generative-ai\";\n\n// Access your API key (see \"Set up your API key\" above)\nconst genAI = new GoogleGenerativeAI(API_KEY);\n\n// Converts a File object to a GoogleGenerativeAI.Part object.\nasync function fileToGenerativePart(file) {\n  const base64EncodedDataPromise = new Promise((resolve) => {\n    const reader = new FileReader();\n    reader.onloadend = () => resolve(reader.result.split(',')[1]);\n    reader.readAsDataURL(file);\n  });\n  return {\n    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },\n  };\n}\n\nasync function run() {\n  // For text-and-images input (multimodal), use the gemini-pro-vision model\n  const model = genAI.getGenerativeModel({ model: \"gemini-pro-vision\" });\n\n  const prompt = \"What's different between these pictures?\";\n\n  const fileInputEl = document.querySelector(\"input[type=file]\");\n  const imageParts = await Promise.all(\n    [...fileInputEl.files].map(fileToGenerativePart)\n  );\n\n  const result = await model.generateContent([prompt, ...imageParts]);\n  const response = await result.response;\n  const text = response.text();\n  console.log(text);\n}\n\nrun();\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nBuild multi-turn conversations (chat)\n\nUsing Gemini, you can build freeform conversations across multiple turns. The SDK simplifies the process by managing the state of the conversation, so unlike with generateContent, you don't have to store the conversation history yourself.\n\nTo build a multi-turn conversation (like chat), use the gemini-pro model, and initialize the chat by calling startChat(). Then use sendMessage() to send a new user message, which will also append the message and the response to the chat history.\n\nThere are two possible options for role associated with the content in a conversation:\n\nuser: the role which provides the prompts. This value is the default for sendMessage calls, and the function will throw an exception if a different role is passed.\n\nmodel: the role which provides the responses. This role can be used when calling startChat() with existing history.\n\nNote: The gemini-pro-vision model (for text-and-image input) is not yet optimized for multi-turn conversations. Make sure to use gemini-pro and text-only input for chat use cases.\nimport { GoogleGenerativeAI } from \"@google/generative-ai\";\n\n// Access your API key (see \"Set up your API key\" above)\nconst genAI = new GoogleGenerativeAI(API_KEY);\n\nasync function run() {\n  // For text-only input, use the gemini-pro model\n  const model = genAI.getGenerativeModel({ model: \"gemini-pro\"});\n\n  const chat = model.startChat({\n    history: [\n      {\n        role: \"user\",\n        parts: [{ text: \"Hello, I have 2 dogs in my house.\" }],\n      },\n      {\n        role: \"model\",\n        parts: [{ text: \"Great to meet you. What would you like to know?\" }],\n      },\n    ],\n    generationConfig: {\n      maxOutputTokens: 100,\n    },\n  });\n\n  const msg = \"How many paws are in my house?\";\n\n  const result = await chat.sendMessage(msg);\n  const response = await result.response;\n  const text = response.text();\n  console.log(text);\n}\n\nrun();\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nUse streaming for faster interactions\n\nBy default, the model returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n\nThe following example shows how to implement streaming with the generateContentStream method to generate text from a text-and-image input prompt.\n\n// ...\n\nconst result = await model.generateContentStream([prompt, ...imageParts]);\n\nlet text = '';\nfor await (const chunk of result.stream) {\n  const chunkText = chunk.text();\n  console.log(chunkText);\n  text += chunkText;\n}\n\n// ...\n\n\nYou can use a similar approach for text-only input and chat use cases.\n\n// Use streaming with text-only input\nconst result = await model.generateContentStream(prompt);\n\n\nSee chat example above for how to instantiate a chat.\n\n// Use streaming with multi-turn conversations (like chat)\nconst result = await chat.sendMessageStream(msg);\n\nImplement advanced use cases\n\nThe common use cases described in the previous section of this tutorial help you become comfortable with using the Gemini API. This section describes some use cases that might be considered more advanced.\n\nCount tokens\n\nWhen using long prompts, it might be useful to count tokens before sending any content to the model. The following examples show how to use countTokens() for various use cases:\n\n// For text-only input\nconst { totalTokens } = await model.countTokens(prompt);\n\n// For text-and-image input (multimodal)\nconst { totalTokens } = await model.countTokens([prompt, ...imageParts]);\n\n// For multi-turn conversations (like chat)\nconst history = await chat.getHistory();\nconst msgContent = { role: \"user\", parts: [{ text: msg }] };\nconst contents = [...history, msgContent];\nconst { totalTokens } = await model.countTokens({ contents });\n\nOptions to control content generation\n\nYou can control content generation by configuring model parameters and by using safety settings.\n\nConfigure model parameters\n\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about Model parameters. The configuration is maintained for the lifetime of your model instance.\n\nconst generationConfig = {\n  stopSequences: [\"red\"],\n  maxOutputTokens: 200,\n  temperature: 0.9,\n  topP: 0.1,\n  topK: 16,\n};\n\nconst model = genAI.getGenerativeModel({ model: \"MODEL_NAME\",  generationConfig });\n\nUse safety settings\n\nYou can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\n\nHere's how to set one safety setting:\n\nimport { HarmBlockThreshold, HarmCategory } from \"@google/generative-ai\";\n\n// ...\n\nconst safetySettings = [\n  {\n    category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n    threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n  },\n];\n\nconst model = genAI.getGenerativeModel({ model: \"MODEL_NAME\", safetySettings });\n\n\nYou can also set more than one safety setting:\n\nconst safetySettings = [\n  {\n    category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n    threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n  },\n  {\n    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n  },\n];\n\nWhat's next\n\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for prompt writing.\n\nGemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available Gemini models.\n\nGemini offers options for requesting rate limit increases. The rate limit for Gemini Pro models is 60 requests per minute (RPM).\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 2025,
            "filtered_content": "The Google AI JavaScript SDK is in public preview, which means its behavior and features could change in backward-incompatible ways. Preview releases should not be used in production.\nGet started with the Gemini API in web apps \nCaution: Using the Google AI SDK for JavaScript directly from a client-side app is recommended for prototyping only. If you plan to enable billing, we strongly recommend that you call the Google AI Gemini API only server-side to keep your API key safe. You risk potentially exposing your API key to malicious actors if you embed your API key directly in your JavaScript app or fetch it remotely at runtime.\nThis tutorial demonstrates how to access the Gemini API directly from your web app using the Google AI JavaScript SDK. You can use this SDK if you don't want to work directly with REST APIs or server-side code (like Node.js) for accessing Gemini models in your web app.\nIn addition, this tutorial contains sections about advanced use cases (like counting tokens) as well as options for controlling content generation.\nTip: Check out the sample app if you want to try out this SDK quickly or see a complete implementation of various use cases. To run the sample app, you'll need the prerequisites and an API key as described in this guide.\nThis tutorial assumes that you're familiar with using JavaScript to develop web apps. This guide is framework-independent.\n(Optional) Node.js\nModern web browser\nBefore calling the Gemini API, you need to set up your project, which includes obtaining an API key and initializing the model.\nIt's strongly recommended that you do not check an API key into your version control system. Instead, you should pass your API key to your app right before initializing the model.\nAll the snippets in this tutorial assume that you're accessing your API key as a global constant.\n<html>\n  <body>\n    <!-- ... Your HTML and CSS -->\n    <script type=\"importmap\">\n        \"imports\": {\n          \"@google/generative-ai\": \"https://esm.run/@google/generative-ai\"\n        }\n      }\n    <script type=\"module\">\n      import { GoogleGenerativeAI } from \"@google/generative-ai\";\n      // Fetch your API_KEY\n      const API_KEY = \"...\";\n      // Access your API key (see \"Set up your API key\" above)\n      const genAI = new GoogleGenerativeAI(API_KEY);\n      const model = genAI.getGenerativeModel({ model: \"MODEL_NAME\"});\n  </body>\n</html>\nGemini provides a multimodal model (gemini-pro-vision), so you can input both text and images. Make sure to review the image requirements for input.\n// Converts a File object to a GoogleGenerativeAI.Part object.\nasync function fileToGenerativePart(file) {\n  const base64EncodedDataPromise = new Promise((resolve) => {\n    const reader = new FileReader();\n    reader.onloadend = () => resolve(reader.result.split(',')[1]);\n    reader.readAsDataURL(file);\n    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },\n  // For text-and-images input (multimodal), use the gemini-pro-vision model\n  const fileInputEl = document.querySelector(\"input[type=file]\");\n  const imageParts = await Promise.all(\n    [...fileInputEl.files].map(fileToGenerativePart)\n  );\nuser: the role which provides the prompts. This value is the default for sendMessage calls, and the function will throw an exception if a different role is passed.",
            "filtered_word_count": 478
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your project\nSet up your API key\nInstall the SDK package\nInitialize the Generative Model\nImplement common use cases\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nImplement advanced use cases\nUse embeddings\nCount tokens\nOptions to control content generation\nConfigure model parameters\nUse safety settings\nWhat's next\nThe Google AI Dart SDK is in public preview, which means its behavior and features could change in backward-incompatible ways. Preview releases should not be used in production.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with the Gemini API in Dart or Flutter apps \nbookmark_border\n\nCaution: Using the Google AI SDK for Dart (Flutter) to call the Google AI Gemini API directly from your app is recommended for prototyping only. If you plan to enable billing, we strongly recommend that you use the SDK to call the Google AI Gemini API only server-side to keep your API key safe. You risk potentially exposing your API key to malicious actors if you embed your API key directly in your mobile or web app or fetch it remotely at runtime.\n\nThis tutorial demonstrates how to access the Gemini API for your Dart or Flutter application using the Google AI Dart SDK. You can use this SDK if you don't want to work directly with REST APIs for accessing Gemini models in your app.\n\nIn this tutorial, you'll learn how to do the following:\n\nSet up your project, including your API key\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn addition, this tutorial contains sections about advanced use cases (like embeddings and counting tokens) as well as options for controlling content generation.\n\nTip: Check out the sample app if you want to try out this SDK quickly or see a complete implementation of various use cases. To run the sample app, you'll need the prerequisites and an API key as described in this guide.\nPrerequisites\n\nThis tutorial assumes you're familiar with building applications with Dart.\n\nTo complete this tutorial, make sure that your development environment meets the following requirements:\n\nDart 3.2.0+\nSet up your project\n\nBefore calling the Gemini API, you need to set up your project, which includes setting up your API key, adding the SDK to your pub dependencies, and initializing the model.\n\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nSecure your API key\n\nKeep your API key secure. We strongly recommend that you do not include the API key directly in your code, or check files that contain the key into version control systems. Instead, you should use a secrets store for your API key.\n\nAll the snippets in this tutorial assume that you're accessing your API key as a process environment variable. If you're developing a Flutter app, you can use String.fromEnvironment and pass --dart-define=API_KEY=$API_KEY to flutter build or flutter run to compile with the API key since the process environment will be different when running the app.\n\nInstall the SDK package\n\nTo use the Gemini API in your own application, you need to add the google_generative_ai package to your Dart or Flutter app:\n\nDart\nFlutter\ndart pub add google_generative_ai\nInitialize the Generative Model\n\nBefore you can make any API calls, you need to import and initialize the Generative Model.\n\nimport 'package:google_generative_ai/google_generative_ai.dart';\n\n// Access your API key as an environment variable (see \"Set up your API key\" above)\nfinal apiKey = Platform.environment['API_KEY'];\nif (apiKey == null) {\n  print('No \\$API_KEY environment variable');\n  exit(1);\n}\n\nfinal model = GenerativeModel(model: 'MODEL_NAME', apiKey: apiKey);\n\n\nWhen specifying a model, note the following:\n\nUse a model that's specific to your use case (for example, gemini-pro-vision is for multimodal input). Within this guide, the instructions for each implementation list the recommended model for each use case.\n\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. The rate limit for Gemini Pro models is 60 requests per minute (RPM), and we offer options for requesting rate limit increases.\nImplement common use cases\n\nNow that your project is set up, you can explore using the Gemini API to implement different use cases:\n\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn the advanced use cases section, you can find information about the Gemini API and embeddings.\n\nGenerate text from text-only input\nNote: If your prompts will exceed 20MB in size, upload the media files with the File API.\n\nWhen the prompt input includes only text, use the gemini-pro model with the generateContent method to generate text output:\n\nimport 'dart:io';\n\nimport 'package:google_generative_ai/google_generative_ai.dart';\n\nvoid main() async {\n  // Access your API key as an environment variable (see \"Set up your API key\" above)\n  final apiKey = Platform.environment['API_KEY'];\n  if (apiKey == null) {\n    print('No \\$API_KEY environment variable');\n    exit(1);\n  }\n  // For text-only input, use the gemini-pro model\n  final model = GenerativeModel(model: 'gemini-pro', apiKey: apiKey);\n  final content = [Content.text('Write a story about a magic backpack.')];\n  final response = await model.generateContent(content);\n  print(response.text);\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nGenerate text from text-and-image input (multimodal)\n\nGemini provides a multimodal model (gemini-pro-vision), so you can input both text and images. Make sure to review the image requirements for input.\n\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with the generateContent method to generate text output:\n\nimport 'dart:io';\n\nimport 'package:google_generative_ai/google_generative_ai.dart';\n\nvoid main() async {\n  // Access your API key as an environment variable (see \"Set up your API key\" above)\n  final apiKey = Platform.environment['API_KEY'];\n  if (apiKey == null) {\n    print('No \\$API_KEY environment variable');\n    exit(1);\n  }\n  // For text-and-image input (multimodal), use the gemini-pro-vision model\n  final model = GenerativeModel(model: 'gemini-pro-vision', apiKey: apiKey);\n  final (firstImage, secondImage) = await (\n    File('image0.jpg').readAsBytes(),\n    File('image1.jpg').readAsBytes()\n  ).wait;\n  final prompt = TextPart(\"What's different between these pictures?\");\n  final imageParts = [\n    DataPart('image/jpeg', firstImage),\n    DataPart('image/jpeg', secondImage),\n  ];\n  final response = await model.generateContent([\n    Content.multi([prompt, ...imageParts])\n  ]);\n  print(response.text);\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nBuild multi-turn conversations (chat)\n\nUsing Gemini, you can build freeform conversations across multiple turns. The SDK simplifies the process by managing the state of the conversation, so unlike with generateContent, you don't have to store the conversation history yourself.\n\nTo build a multi-turn conversation (like chat), use the gemini-pro model, and initialize the chat by calling startChat(). Then use sendMessage() to send a new user message, which will also append the message and the response to the chat history.\n\nThere are two possible options for role associated with the content in a conversation:\n\nuser: the role which provides the prompts. This value is the default for sendMessage calls, and the function will throw an exception if a different role is passed.\n\nmodel: the role which provides the responses. This role can be used when calling startChat() with existing history.\n\nNote: The gemini-pro-vision model (for text-and-image input) is not yet optimized for multi-turn conversations. Make sure to use gemini-pro and text-only input for chat use cases.\nimport 'dart:io';\n\nimport 'package:google_generative_ai/google_generative_ai.dart';\n\nFuture<void> main() async {\n  // Access your API key as an environment variable (see \"Set up your API key\" above)\n  final apiKey = Platform.environment['API_KEY'];\n  if (apiKey == null) {\n    print('No \\$API_KEY environment variable');\n    exit(1);\n  }\n  // For text-only input, use the gemini-pro model\n  final model = GenerativeModel(\n      model: 'gemini-pro',\n      apiKey: apiKey,\n      generationConfig: GenerationConfig(maxOutputTokens: 100));\n  // Initialize the chat\n  final chat = model.startChat(history: [\n    Content.text('Hello, I have 2 dogs in my house.'),\n    Content.model([TextPart('Great to meet you. What would you like to know?')])\n  ]);\n  var content = Content.text('How many paws are in my house?');\n  var response = await chat.sendMessage(content);\n  print(response.text);\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nUse streaming for faster interactions\n\nBy default, the model returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n\nThe following example shows how to implement streaming with the generateContentStream method to generate text from a text-and-image input prompt.\n\n// ...\n\nfinal response = model.generateContentStream([\n  Content.multi([prompt, ...imageParts])\n]);\nawait for (final chunk in response) {\n  print(chunk.text);\n}\n\n// ...\n\n\nYou can use a similar approach for text-only input and chat use cases.\n\n// Use streaming with text-only input\nfinal response = model.generateContentStream(content);\n\n// Use streaming with multi-turn conversations (like chat)\nfinal response = chat.sendMessageStream(content);\n\nImplement advanced use cases\n\nThe common use cases described in the previous section of this tutorial help you become comfortable with using the Gemini API. This section describes some use cases that might be considered more advanced.\n\nUse embeddings\n\nEmbedding is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity.\n\nUse the embedding-001 model with the embedContent method (or the batchEmbedContent method) to generate embeddings. The following example generates an embedding for a single string:\n\nfinal model = GenerativeModel(model: 'embedding-001', apiKey: apiKey);\nfinal content = Content.text('The quick brown fox jumps over the lazy dog.');\nfinal result = await model.embedContent(content);\nprint(result.embedding.values);\n\nCount tokens\n\nWhen using long prompts, it might be useful to count tokens before sending any content to the model. The following examples show how to use countTokens() for various use cases:\n\n// For text-only input\nfinal tokenCount = await model.countTokens(Content.text(prompt));\nprint('Token count: ${tokenCount.totalTokens}');\n\n// For text-and-image input (multimodal)\nfinal tokenCount = await model.countTokens([\n  Content.multi([prompt, ...imageParts])\n]);\nprint('Token count: ${tokenCount.totalTokens}');\n\n// For multi-turn conversations (like chat)\nfinal prompt = Content.text(message);\nfinal allContent = [...chat.history, prompt];\nfinal tokenCount = await model.countTokens(allContent);\nprint('Token count: ${tokenCount.totalTokens}');\n\nOptions to control content generation\n\nYou can control content generation by configuring model parameters and by using safety settings.\n\nNote that passing generationConfig or safetySettings to a model request method (like generateContent) will fully override the configuration object with the same name passed in getGenerativeModel.\n\nConfigure model parameters\n\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about Model parameters. The configuration is maintained for the lifetime of your model instance.\n\nfinal generationConfig = GenerationConfig(\n  stopSequences: [\"red\"],\n  maxOutputTokens: 200,\n  temperature: 0.9,\n  topP: 0.1,\n  topK: 16,\n);\nfinal model = GenerativeModel(\n  model: 'MODEL_NAME',\n  apiKey: apiKey,\n  generationConfig: generationConfig,\n);\n\nUse safety settings\n\nYou can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\n\nHere's how to set one safety setting:\n\nfinal safetySettings = [\n  SafetySetting(HarmCategory.harassment, HarmBlockThreshold.high)\n];\nfinal model = GenerativeModel(\n  model: 'MODEL_NAME',\n  apiKey: apiKey,\n  safetySettings: safetySettings,\n);\n\n\nYou can also set more than one safety setting:\n\nfinal safetySettings = [\n  SafetySetting(HarmCategory.harassment, HarmBlockThreshold.high),\n  SafetySetting(HarmCategory.hateSpeech, HarmBlockThreshold.high),\n];\n\nWhat's next\n\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for prompt writing.\n\nGemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available Gemini models.\n\nGemini offers options for requesting rate limit increases. The rate limit for Gemini Pro models is 60 requests per minute (RPM).\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 2171,
            "filtered_content": "The Google AI Dart SDK is in public preview, which means its behavior and features could change in backward-incompatible ways. Preview releases should not be used in production.\nGet started with the Gemini API in Dart or Flutter apps \nCaution: Using the Google AI SDK for Dart (Flutter) to call the Google AI Gemini API directly from your app is recommended for prototyping only. If you plan to enable billing, we strongly recommend that you use the SDK to call the Google AI Gemini API only server-side to keep your API key safe. You risk potentially exposing your API key to malicious actors if you embed your API key directly in your mobile or web app or fetch it remotely at runtime.\nThis tutorial demonstrates how to access the Gemini API for your Dart or Flutter application using the Google AI Dart SDK. You can use this SDK if you don't want to work directly with REST APIs for accessing Gemini models in your app.\nThis tutorial assumes you're familiar with building applications with Dart.\nDart 3.2.0+\nBefore calling the Gemini API, you need to set up your project, which includes setting up your API key, adding the SDK to your pub dependencies, and initializing the model.\nKeep your API key secure. We strongly recommend that you do not include the API key directly in your code, or check files that contain the key into version control systems. Instead, you should use a secrets store for your API key.\nAll the snippets in this tutorial assume that you're accessing your API key as a process environment variable. If you're developing a Flutter app, you can use String.fromEnvironment and pass --dart-define=API_KEY=$API_KEY to flutter build or flutter run to compile with the API key since the process environment will be different when running the app.\nTo use the Gemini API in your own application, you need to add the google_generative_ai package to your Dart or Flutter app:\nDart\nFlutter\ndart pub add google_generative_ai\nfinal apiKey = Platform.environment['API_KEY'];\nif (apiKey == null) {\n  print('No \\$API_KEY environment variable');\n  exit(1);\nfinal model = GenerativeModel(model: 'MODEL_NAME', apiKey: apiKey);\n  final model = GenerativeModel(model: 'gemini-pro', apiKey: apiKey);\n  final content = [Content.text('Write a story about a magic backpack.')];\n  final response = await model.generateContent(content);\n  final model = GenerativeModel(model: 'gemini-pro-vision', apiKey: apiKey);\n  final (firstImage, secondImage) = await (\n    File('image0.jpg').readAsBytes(),\n    File('image1.jpg').readAsBytes()\n  ).wait;\n  final prompt = TextPart(\"What's different between these pictures?\");\n  final imageParts = [\n    DataPart('image/jpeg', firstImage),\n    DataPart('image/jpeg', secondImage),\n  final response = await model.generateContent([\n    Content.multi([prompt, ...imageParts])\nFuture<void> main() async {\n  final model = GenerativeModel(\n      model: 'gemini-pro',\n      apiKey: apiKey,\n      generationConfig: GenerationConfig(maxOutputTokens: 100));\n  // Initialize the chat\n  final chat = model.startChat(history: [\n    Content.text('Hello, I have 2 dogs in my house.'),\n    Content.model([TextPart('Great to meet you. What would you like to know?')])\n  var content = Content.text('How many paws are in my house?');\n  var response = await chat.sendMessage(content);\nfinal response = model.generateContentStream([\nawait for (final chunk in response) {\n  print(chunk.text);\nfinal response = model.generateContentStream(content);\nfinal response = chat.sendMessageStream(content);\nfinal model = GenerativeModel(model: 'embedding-001', apiKey: apiKey);\nfinal content = Content.text('The quick brown fox jumps over the lazy dog.');\nfinal result = await model.embedContent(content);\nprint(result.embedding.values);\nfinal tokenCount = await model.countTokens(Content.text(prompt));\nfinal tokenCount = await model.countTokens([\nfinal prompt = Content.text(message);\nfinal allContent = [...chat.history, prompt];\nfinal tokenCount = await model.countTokens(allContent);\nfinal generationConfig = GenerationConfig(\n  generationConfig: generationConfig,\n  SafetySetting(HarmCategory.harassment, HarmBlockThreshold.high)\n  safetySettings: safetySettings,\n  SafetySetting(HarmCategory.harassment, HarmBlockThreshold.high),\n  SafetySetting(HarmCategory.hateSpeech, HarmBlockThreshold.high),",
            "filtered_word_count": 553
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your project\nSet up your API key\nAdd the SDK package to your project\nInitialize the Generative Model\nImplement common use cases\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nImplement advanced use cases\nCount tokens\nOptions to control content generation\nConfigure model parameters\nUse safety settings\nWhat's next\nThe Google AI Swift SDK is in public preview, which means its behavior and features could change in backward-incompatible ways. Preview releases should not be used in production.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with the Gemini API in Swift apps \nbookmark_border\n\nCaution: The Google AI Swift SDK is recommended for prototyping only. If you plan to enable billing, we strongly recommend that you use a backend SDK to access the Google AI Gemini API. You risk potentially exposing your API key to malicious actors if you embed your API key directly in your Swift app or fetch it remotely at runtime.\n\nThis tutorial demonstrates how to access the Gemini API directly from your Swift app using the Google AI Swift SDK. You can use this SDK if you don't want to work directly with REST APIs or server-side code (like Python) for accessing Gemini models in your Swift app.\n\nIn this tutorial, you'll learn how to do the following:\n\nSet up your project, including your API key\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn addition, this tutorial contains sections about advanced use cases (like counting tokens) as well as options for controlling content generation.\n\nTip: Check out the sample app if you want to try out this SDK quickly or see a complete implementation of various use cases. To run the sample app, you'll need the prerequisites and an API key as described in this guide.\nPrerequisites\n\nThis tutorial assumes that you're familiar with using Xcode to develop Swift apps.\n\nTo complete this tutorial, make sure that your development environment and Swift app meet the following requirements:\n\nXcode 15.0 or higher\nYour Swift app must target iOS 15 or higher, or macOS 12 or higher.\nSet up your project\n\nBefore calling the Gemini API, you need to set up your Xcode project, which includes setting up your API key, adding the SDK package to your Xcode project, and initializing the model.\n\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nSecure your API key\n\nIt's strongly recommended that you do not check an API key into your version control system. One alternative option is to store it in a GenerativeAI-Info.plist file, and then read the API key from the .plist file. Make sure to put this .plist file in the root folder of your app and exclude it from version control.\n\nExpand to view how to store and read the API key from a\n.plist\nfile\n\nYou can also review the sample app to learn how to store your API key in a .plist file.\n\nAll the snippets in this tutorial assume that you're accessing your API key from this on-demand resource .plist file.\n\nAdd the SDK package to your project\n\nTo use the Gemini API in your own Swift app, add the GoogleGenerativeAI package to your app:\n\nIn Xcode, right-click on your project in the project navigator.\n\nSelect Add Packages from the context menu.\n\nIn the Add Packages dialog, paste the package URL in the search bar:\n\nhttps://github.com/google/generative-ai-swift\n\n\nClick Add Package. Xcode will now add the GoogleGenerativeAI package to your project.\n\nInitialize the Generative Model\n\nBefore you can make any API calls, you need to initialize the Generative Model.\n\nImport the GoogleGenerativeAI module:\n\nimport GoogleGenerativeAI\n\n\nInitialize the Generative Model:\n\n// Access your API key from your on-demand resource .plist file\n// (see \"Set up your API key\" above)\nlet model = GenerativeModel(name: \"MODEL_NAME\", apiKey: APIKey.default)\n\n\nWhen specifying a model, note the following:\n\nUse a model that's specific to your use case (for example, gemini-pro-vision is for multimodal input). Within this guide, the instructions for each implementation list the recommended model for each use case.\n\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. The rate limit for Gemini Pro models is 60 requests per minute (RPM), and we offer options for requesting rate limit increases.\nImplement common use cases\n\nNow that your project is set up, you can explore using the Gemini API to implement different use cases:\n\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nGenerate text from text-only input\n\nWhen the prompt input includes only text, use the gemini-pro model with the generateContent method to generate text output:\n\nimport GoogleGenerativeAI\n\n// For text-only input, use the gemini-pro model\n// Access your API key from your on-demand resource .plist file (see \"Set up your API key\" above)\nlet model = GenerativeModel(name: \"gemini-pro\", apiKey: APIKey.default)\n\nlet prompt = \"Write a story about a magic backpack.\"\nlet response = try await model.generateContent(prompt)\nif let text = response.text {\n  print(text)\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nGenerate text from text-and-image input (multimodal)\nNote: If your prompts will exceed 20MB in size, upload the media files with the File API.\n\nGemini provides a multimodal model (gemini-pro-vision), so you can input both text and images. Make sure to review the image requirements for prompts.\n\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with the generateContent method to generate text output:\n\nimport GoogleGenerativeAI\n\n// For text-and-image input (multimodal), use the gemini-pro-vision model\n// Access your API key from your on-demand resource .plist file (see \"Set up your API key\" above)\nlet model = GenerativeModel(name: \"gemini-pro-vision\", apiKey: APIKey.default)\n\nlet image1 = UIImage(...)\nlet image2 = UIImage(...)\n\nlet prompt = \"What's different between these pictures?\"\n\nlet response = try await model.generateContent(prompt, image1, image2)\nif let text = response.text {\n  print(text)\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nBuild multi-turn conversations (chat)\n\nUsing Gemini, you can build freeform conversations across multiple turns. The SDK simplifies the process by managing the state of the conversation, so unlike with generateContent, you don't have to store the conversation history yourself.\n\nTo build a multi-turn conversation (like chat), use the gemini-pro model, and initialize the chat by calling startChat(). Then use sendMessage() to send a new user message, which will also append the message and the response to the chat history.\n\nThere are two possible options for role associated with the content in a conversation:\n\nuser: the role which provides the prompts. This value is the default for sendMessage calls.\n\nmodel: the role which provides the responses. This role can be used when calling startChat() with existing history.\n\nNote: The gemini-pro-vision model (for text-and-image input) is not yet optimized for multi-turn conversations. Make sure to use gemini-pro and text-only input for chat use cases.\nimport GoogleGenerativeAI\n\nlet config = GenerationConfig(\n  maxOutputTokens: 100\n)\n\n// For text-only input, use the gemini-pro model\n// Access your API key from your on-demand resource .plist file (see \"Set up your API key\" above)\nlet model = GenerativeModel(\n  name: \"gemini-pro\",\n  apiKey: APIKey.default,\n  generationConfig: config\n)\n\nlet history = [\n  ModelContent(role: \"user\", parts: \"Hello, I have 2 dogs in my house.\"),\n  ModelContent(role: \"model\", parts: \"Great to meet you. What would you like to know?\"),\n]\n\n// Initialize the chat\nlet chat = model.startChat(history: history)\nlet response = try await chat.sendMessage(\"How many paws are in my house?\")\nif let text = response.text {\n  print(text)\n}\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nUse streaming for faster interactions\n\nBy default, the model returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n\nThe following example shows how to implement streaming with the generateContentStream method to generate text from a text-and-image input prompt.\n\nimport GoogleGenerativeAI\n\n// For text-and-image input (multimodal), use the gemini-pro-vision model\n// Access your API key from your on-demand resource .plist file (see \"Set up your API key\" above)\nlet model = GenerativeModel(name: \"gemini-pro-vision\", apiKey: APIKey.default)\n\nlet image1 = UIImage(named: \"\")!\nlet image2 = UIImage(named: \"\")!\n\nlet prompt = \"What's different between these pictures?\"\nvar fullResponse = \"\"\nlet contentStream = model.generateContentStream(prompt, image1, image2)\nfor try await chunk in contentStream {\n  if let text = chunk.text {\n    print(text)\n    fullResponse += text\n  }\n}\nprint(fullResponse)\n\n\nYou can use a similar approach for text-only input and chat use cases.\n\n// Use streaming with text-only input\nlet contentStream = model.generateContentStream(prompt)\n\n// Use streaming with multi-turn conversations (like chat)\nlet responseStream = chat.sendMessageStream(message)\n\nImplement advanced use cases\n\nThe common use cases described in the previous section of this tutorial help you become comfortable with using the Gemini API. This section describes some use cases that might be considered more advanced.\n\nCount tokens\n\nWhen using long prompts, it might be useful to count tokens before sending any content to the model. The following examples show how to use countTokens() for various use cases:\n\n// For text-only input\nlet response = try await model.countTokens(\"Why is the sky blue?\")\nprint(response.totalTokens)\n\n// For text-and-image input (multi-modal)\nlet response = try await model.countTokens(prompt, image1, image2)\nprint(response.totalTokens)\n\n// For multi-turn conversations (like chat)\nlet chat = model.startChat()\nlet history = chat.history\nlet message = ModelContent(role: \"user\", \"Why is the sky blue?\")\nlet contents = history + [message]\nlet response = try await model.countTokens(contents)\nprint(response.totalTokens)\n\nOptions to control content generation\n\nYou can control content generation by configuring model parameters and by using safety settings.\n\nConfigure model parameters\n\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about Model parameters. The configuration is maintained for the lifetime of your model instance.\n\nlet config = GenerationConfig(\n  temperature: 0.9,\n  topP: 0.1,\n  topK: 16,\n  maxOutputTokens: 200,\n  stopSequences: [\"red\"]\n)\n\n// Access your API key from your on-demand resource .plist file (see \"Set up your API key\" above)\nlet model = GenerativeModel(\n  name: \"MODEL_NAME\",\n  apiKey: APIKey.default,\n  generationConfig: config\n)\n\nUse safety settings\n\nYou can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\n\nHere's how to set one safety setting:\n\n// Access your API key from your on-demand resource .plist file (see \"Set up your API key\" above)\nlet model = GenerativeModel(\n  name: \"MODEL_NAME\",\n  apiKey: APIKey.default,\n  safetySettings: [\n    SafetySetting(harmCategory: .harassment, threshold: .blockOnlyHigh)\n  ]\n)\n\n\nYou can also set more than one safety setting:\n\nlet harassmentSafety = SafetySetting(harmCategory: .harassment, threshold: .blockOnlyHigh)\nlet hateSpeechSafety = SafetySetting(harmCategory: .hateSpeech, threshold: .blockMediumAndAbove)\n\n// Access your API key from your on-demand resource .plist file (see \"Set up your API key\" above)\nlet model = GenerativeModel(\n  name: \"MODEL_NAME\",\n  apiKey: APIKey.default,\n    safetySettings: [harassmentSafety, hateSpeechSafety]\n)\n\nWhat's next\n\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for prompt writing.\n\nGemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available Gemini models.\n\nGemini offers options for requesting rate limit increases. The rate limit for Gemini Pro models is 60 requests per minute (RPM).\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 2155,
            "filtered_content": "The Google AI Swift SDK is in public preview, which means its behavior and features could change in backward-incompatible ways. Preview releases should not be used in production.\nGet started with the Gemini API in Swift apps \nCaution: The Google AI Swift SDK is recommended for prototyping only. If you plan to enable billing, we strongly recommend that you use a backend SDK to access the Google AI Gemini API. You risk potentially exposing your API key to malicious actors if you embed your API key directly in your Swift app or fetch it remotely at runtime.\nThis tutorial demonstrates how to access the Gemini API directly from your Swift app using the Google AI Swift SDK. You can use this SDK if you don't want to work directly with REST APIs or server-side code (like Python) for accessing Gemini models in your Swift app.\nThis tutorial assumes that you're familiar with using Xcode to develop Swift apps.\nTo complete this tutorial, make sure that your development environment and Swift app meet the following requirements:\nXcode 15.0 or higher\nYour Swift app must target iOS 15 or higher, or macOS 12 or higher.\nBefore calling the Gemini API, you need to set up your Xcode project, which includes setting up your API key, adding the SDK package to your Xcode project, and initializing the model.\nIt's strongly recommended that you do not check an API key into your version control system. One alternative option is to store it in a GenerativeAI-Info.plist file, and then read the API key from the .plist file. Make sure to put this .plist file in the root folder of your app and exclude it from version control.\nExpand to view how to store and read the API key from a\n.plist\nfile\nYou can also review the sample app to learn how to store your API key in a .plist file.\nAll the snippets in this tutorial assume that you're accessing your API key from this on-demand resource .plist file.\nTo use the Gemini API in your own Swift app, add the GoogleGenerativeAI package to your app:\nIn Xcode, right-click on your project in the project navigator.\nSelect Add Packages from the context menu.\nIn the Add Packages dialog, paste the package URL in the search bar:\nhttps://github.com/google/generative-ai-swift\nClick Add Package. Xcode will now add the GoogleGenerativeAI package to your project.\nBefore you can make any API calls, you need to initialize the Generative Model.\nImport the GoogleGenerativeAI module:\nInitialize the Generative Model:\n// Access your API key from your on-demand resource .plist file\n// (see \"Set up your API key\" above)\nlet model = GenerativeModel(name: \"MODEL_NAME\", apiKey: APIKey.default)\nlet model = GenerativeModel(name: \"gemini-pro\", apiKey: APIKey.default)\nlet prompt = \"Write a story about a magic backpack.\"\nlet response = try await model.generateContent(prompt)\nlet image1 = UIImage(...)\nlet image2 = UIImage(...)\nlet response = try await model.generateContent(prompt, image1, image2)\n  maxOutputTokens: 100\n  name: \"gemini-pro\",\nlet history = [\n  ModelContent(role: \"user\", parts: \"Hello, I have 2 dogs in my house.\"),\n  ModelContent(role: \"model\", parts: \"Great to meet you. What would you like to know?\"),\nlet chat = model.startChat(history: history)\nlet response = try await chat.sendMessage(\"How many paws are in my house?\")\nlet image1 = UIImage(named: \"\")!\nlet image2 = UIImage(named: \"\")!\nvar fullResponse = \"\"\nlet contentStream = model.generateContentStream(prompt, image1, image2)\nfor try await chunk in contentStream {\n  if let text = chunk.text {\n    print(text)\n    fullResponse += text\nprint(fullResponse)\nlet contentStream = model.generateContentStream(prompt)\nlet responseStream = chat.sendMessageStream(message)\nlet response = try await model.countTokens(\"Why is the sky blue?\")\n// For text-and-image input (multi-modal)\nlet response = try await model.countTokens(prompt, image1, image2)\nlet chat = model.startChat()\nlet history = chat.history\nlet message = ModelContent(role: \"user\", \"Why is the sky blue?\")\nlet contents = history + [message]\nlet response = try await model.countTokens(contents)\n  stopSequences: [\"red\"]\n  safetySettings: [\n    SafetySetting(harmCategory: .harassment, threshold: .blockOnlyHigh)\n  ]\nlet harassmentSafety = SafetySetting(harmCategory: .harassment, threshold: .blockOnlyHigh)\nlet hateSpeechSafety = SafetySetting(harmCategory: .hateSpeech, threshold: .blockMediumAndAbove)\n    safetySettings: [harassmentSafety, hateSpeechSafety]",
            "filtered_word_count": 657
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your project\nSet up your API key\nAdd the SDK dependency to your project\nInitialize the Generative Model\nImplement common use cases\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nImplement advanced use cases\nCount tokens\nOptions to control content generation\nConfigure model parameters\nUse safety settings\nWhat's next\nThe Google AI Android SDK is in public preview, which means its behavior and features could change in backward-incompatible ways. Preview releases should not be used in production.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with the Gemini API in Android apps (client SDK) \nbookmark_border\n\nCaution: The Google AI client SDK for Android is recommended for prototyping only. If you plan to enable billing, we strongly recommend that you use a backend SDK to access the Google AI Gemini API. You risk potentially exposing your API key to malicious actors if you embed your API key directly in your Android app or fetch it remotely at runtime.\n\nThis tutorial demonstrates how to access the Gemini API directly from your Android app using the Google AI client SDK for Android. You can use this client SDK if you don't want to work directly with REST APIs or server-side code (like Python) for accessing Gemini models in your Android app.\n\nIn this tutorial, you'll learn how to do the following:\n\nSet up your project, including your API key\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\n\nIn addition, this tutorial contains sections about advanced use cases (like counting tokens) as well as options for controlling content generation.\n\nTip: Check out the sample app or the built-in template in Android Studio if you want to try out this SDK quickly or see a complete implementation of various use cases.\n\nTo run the sample app or template, you'll need the prerequisites and an API key as described in this guide. To access the Gemini API Starter template in the New Project wizard, you'll need the latest preview version of Android Studio Iguana.\n\nConsider accessing Gemini on-device\n\nThe client SDK for Android described in this tutorial lets you access the Gemini Pro models which run on Google's servers. For use cases that involve processing sensitive data, offline availability, or for cost savings for frequently used user flows, you may want to consider accessing Gemini Nano which runs on-device. For more details, refer to the Android (on-device) tutorial.\n\nPrerequisites\n\nThis tutorial assumes that you're familiar with using Android Studio to develop Android apps.\n\nTo complete this tutorial, make sure that your development environment and Android app meet the following requirements:\n\nAndroid Studio (latest version)\nYour Android app must target API level 21 or higher.\nSet up your project\n\nBefore calling the Gemini API, you need to set up your Android project, which includes setting up your API key, adding the SDK dependencies to your Android project, and initializing the model.\n\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nSecure your API key\n\nIt's strongly recommended that you do not check an API key into your version control system. Instead, you should store it in a local.properties file (which is located in your project's root directory, but excluded from version control), and then use the Secrets Gradle plugin for Android to read your API key as a Build Configuration variable.\n\nKotlin\nJava\n// Access your API key as a Build Configuration variable\nval apiKey = BuildConfig.apiKey\n\n\nAll the snippets in this tutorial utilize this best practice. Also, if you want to see the implementation of the Secrets Gradle plugin, you can review the sample app for this SDK or use the latest preview of Android Studio Iguana which has a Gemini API Starter template (which includes the local.properties file to get you started).\n\nAdd the SDK dependency to your project\n\nIn your module (app-level) Gradle configuration file (like <project>/<app-module>/build.gradle.kts), add the dependency for the Google AI SDK for Android:\n\nKotlin\nJava\ndependencies {\n  // ... other androidx dependencies\n\n  // add the dependency for the Google AI client SDK for Android\n  implementation(\"com.google.ai.client.generativeai:generativeai:0.3.0\")\n}\n\n\nSync your Android project with Gradle files.\n\nInitialize the Generative Model\n\nBefore you can make any API calls, you need to initialize the GenerativeModel object:\n\nKotlin\nJava\nval generativeModel = GenerativeModel(\n    // Use a model that's applicable for your use case (see \"Implement basic use cases\" below)\n    modelName = \"MODEL_NAME\",\n    // Access your API key as a Build Configuration variable (see \"Set up your API key\" above)\n    apiKey = BuildConfig.apiKey\n)\n\n\nWhen specifying a model, note the following:\n\nUse a model that's specific to your use case (for example, gemini-pro-vision is for multimodal input). Within this guide, the instructions for each implementation list the recommended model for each use case.\n\nNote: For detailed information about the available models, including their capabilities and rate limits, see Gemini models. The rate limit for Gemini Pro models is 60 requests per minute (RPM), and we offer options for requesting rate limit increases.\nImplement common use cases\n\nNow that your project is set up, you can explore using the Gemini API to implement different use cases:\n\nGenerate text from text-only input\nGenerate text from text-and-image input (multimodal)\nBuild multi-turn conversations (chat)\nUse streaming for faster interactions\nGenerate text from text-only input\n\nWhen the prompt input includes only text, use the gemini-pro model with generateContent to generate text output:\n\nKotlin\nJava\n\nNote that generateContent() is a suspend function and needs to be called from a Coroutine scope. If you're unfamiliar with Coroutines, read Kotlin Coroutines on Android.\n\nval generativeModel = GenerativeModel(\n    // For text-only input, use the gemini-pro model\n    modelName = \"gemini-pro\",\n    // Access your API key as a Build Configuration variable (see \"Set up your API key\" above)\n    apiKey = BuildConfig.apiKey\n)\n\nval prompt = \"Write a story about a magic backpack.\"\nval response = generativeModel.generateContent(prompt)\nprint(response.text)\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nGenerate text from text-and-image input (multimodal)\nNote: If your prompts will exceed 20MB in size, upload the media files with the File API.\n\nGemini provides a multimodal model (gemini-pro-vision), so you can input both text and images. Make sure to review the image requirements for prompts.\n\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with generateContent to generate text output:\n\nKotlin\nJava\n\nNote that generateContent() is a suspend function and needs to be called from a Coroutine scope. If you're unfamiliar with Coroutines, read Kotlin Coroutines on Android.\n\nval generativeModel = GenerativeModel(\n    // For text-and-images input (multimodal), use the gemini-pro-vision model\n    modelName = \"gemini-pro-vision\",\n    // Access your API key as a Build Configuration variable (see \"Set up your API key\" above)\n    apiKey = BuildConfig.apiKey\n)\n\nval image1: Bitmap = // ...\nval image2: Bitmap = // ...\n\nval inputContent = content {\n    image(image1)\n    image(image2)\n    text(\"What's different between these pictures?\")\n}\n\nval response = generativeModel.generateContent(inputContent)\nprint(response.text)\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nBuild multi-turn conversations (chat)\n\nUsing Gemini, you can build freeform conversations across multiple turns. The SDK simplifies the process by managing the state of the conversation, so unlike with generateContent, you don't have to store the conversation history yourself.\n\nTo build a multi-turn conversation (like chat), use the gemini-pro model, and initialize the chat by calling startChat(). Then use sendMessage() to send a new user message, which will also append the message and the response to the chat history.\n\nThere are two possible options for role associated with the content in a conversation:\n\nuser: the role which provides the prompts. This value is the default for sendMessage calls.\n\nmodel: the role which provides the responses. This role can be used when calling startChat() with existing history.\n\nNote: The gemini-pro-vision model (for text-and-image input) is not yet optimized for multi-turn conversations. Make sure to use gemini-pro and text-only input for chat use cases.\nKotlin\nJava\n\nNote that generateContent() is a suspend function and needs to be called from a Coroutine scope. If you're unfamiliar with Coroutines, read Kotlin Coroutines on Android.\n\nval generativeModel = GenerativeModel(\n    // For text-only input, use the gemini-pro model\n    modelName = \"gemini-pro\",\n    // Access your API key as a Build Configuration variable (see \"Set up your API key\" above)\n    apiKey = BuildConfig.apiKey\n)\n\nval chat = generativeModel.startChat(\n    history = listOf(\n        content(role = \"user\") { text(\"Hello, I have 2 dogs in my house.\") },\n        content(role = \"model\") { text(\"Great to meet you. What would you like to know?\") }\n    )\n)\n\nchat.sendMessage(\"How many paws are in my house?\")\n\nNote: The Gemini API also supports streaming; for details, see Use streaming for faster interactions (in this guide).\nUse streaming for faster interactions\n\nBy default, the model returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n\nThe following example shows how to implement streaming with generateContentStream to generate text from a text-and-image input prompt.\n\nKotlin\nJava\n\nNote that generateContentStream() is a suspend function and needs to be called from a Coroutine scope. If you're unfamiliar with Coroutines, read Kotlin Coroutines on Android.\n\nval generativeModel = GenerativeModel(\n    // For text-and-image input (multimodal), use the gemini-pro-vision model\n    modelName = \"gemini-pro-vision\",\n    // Access your API key as a Build Configuration variable (see \"Set up your API key\" above)\n    apiKey = BuildConfig.apiKey\n)\n\nval image1: Bitmap = // ...\nval image2: Bitmap = // ...\n\nval inputContent = content {\n    image(image1)\n    image(image2)\n    text(\"What's the difference between these pictures?\")\n}\n\nvar fullResponse = \"\"\ngenerativeModel.generateContentStream(inputContent).collect { chunk ->\n    print(chunk.text)\n    fullResponse += chunk.text\n}\n\n\nYou can use a similar approach for text-only input and chat use cases:\n\nKotlin\nJava\n\nNote that generateContentStream() is a suspend function and needs to be called from a Coroutine scope. If you're unfamiliar with Coroutines, read Kotlin Coroutines on Android.\n\n// Use streaming with text-only input\ngenerativeModel.generateContentStream(inputContent).collect { chunk ->\n    print(chunk.text)\n}\n\n// Use streaming with multi-turn conversations (like chat)\nval chat = generativeModel.startChat()\nchat.sendMessageStream(inputContent).collect { chunk ->\n    print(chunk.text)\n}\n\nImplement advanced use cases\n\nThe common use cases described in the previous section of this tutorial help you become comfortable with using the Gemini API. This section describes some use cases that might be considered more advanced.\n\nCount tokens\n\nWhen using long prompts, it might be useful to count tokens before sending any content to the model. The following examples show how to use countTokens() for various use cases:\n\nKotlin\nJava\n\nNote that countTokens() is a suspend function and needs to be called from a Coroutine scope. If you're unfamiliar with Coroutines, read Kotlin Coroutines on Android.\n\n// For text-only input\nval (totalTokens) = generativeModel.countTokens(\"Write a story about a magic backpack.\")\n\n// For text-and-image input (multi-modal)\nval multiModalContent = content {\n    image(image1)\n    image(image2)\n    text(\"What's the difference between these pictures?\")\n}\n\nval (totalTokens) = generativeModel.countTokens(multiModalContent)\n\n// For multi-turn conversations (like chat)\nval history = chat.history\nval messageContent = content { text(\"This is the message I intend to send\")}\nval (totalTokens) = generativeModel.countTokens(*history.toTypedArray(), messageContent)\n\nOptions to control content generation\n\nYou can control content generation by configuring model parameters and by using safety settings.\n\nConfigure model parameters\n\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about Model parameters.\n\nKotlin\nJava\nval config = generationConfig {\n    temperature = 0.9f\n    topK = 16\n    topP = 0.1f\n    maxOutputTokens = 200\n    stopSequences = listOf(\"red\")\n}\n\nval generativeModel = GenerativeModel(\n    modelName = \"MODEL_NAME\",\n    apiKey = BuildConfig.apiKey,\n    generationConfig = config\n)\n\nUse safety settings\n\nYou can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about Safety settings.\n\nHere's how to set one safety setting:\n\nKotlin\nJava\nval generativeModel = GenerativeModel(\n    modelName = \"MODEL_NAME\",\n    apiKey = BuildConfig.apiKey,\n    safetySettings = listOf(\n        SafetySetting(HarmCategory.HARASSMENT, BlockThreshold.ONLY_HIGH)\n    )\n)\n\n\nYou can also set more than one safety setting:\n\nKotlin\nJava\nval harassmentSafety = SafetySetting(HarmCategory.HARASSMENT, BlockThreshold.ONLY_HIGH)\n\nval hateSpeechSafety = SafetySetting(HarmCategory.HATE_SPEECH, BlockThreshold.MEDIUM_AND_ABOVE)\n\nval generativeModel = GenerativeModel(\n    modelName = \"MODEL_NAME\",\n    apiKey = BuildConfig.apiKey,\n    safetySettings = listOf(harassmentSafety, hateSpeechSafety)\n)\n\nWhat's next\n\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for prompt writing.\n\nGemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available Gemini models.\n\nGemini offers options for requesting rate limit increases. The rate limit for Gemini Pro models is 60 requests per minute (RPM).\n\nThe client SDK for Android described in this tutorial lets you access the Gemini Pro models which run on Google's servers. For use cases that involve processing sensitive data, offline availability, or for cost savings for frequently used user flows, you may want to consider accessing Gemini Nano which runs on-device. For more details, refer to the Android (on-device) tutorial.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 2410,
            "filtered_content": "The Google AI Android SDK is in public preview, which means its behavior and features could change in backward-incompatible ways. Preview releases should not be used in production.\nGet started with the Gemini API in Android apps (client SDK) \nCaution: The Google AI client SDK for Android is recommended for prototyping only. If you plan to enable billing, we strongly recommend that you use a backend SDK to access the Google AI Gemini API. You risk potentially exposing your API key to malicious actors if you embed your API key directly in your Android app or fetch it remotely at runtime.\nThis tutorial demonstrates how to access the Gemini API directly from your Android app using the Google AI client SDK for Android. You can use this client SDK if you don't want to work directly with REST APIs or server-side code (like Python) for accessing Gemini models in your Android app.\nTip: Check out the sample app or the built-in template in Android Studio if you want to try out this SDK quickly or see a complete implementation of various use cases.\nTo run the sample app or template, you'll need the prerequisites and an API key as described in this guide. To access the Gemini API Starter template in the New Project wizard, you'll need the latest preview version of Android Studio Iguana.\nConsider accessing Gemini on-device\nThis tutorial assumes that you're familiar with using Android Studio to develop Android apps.\nTo complete this tutorial, make sure that your development environment and Android app meet the following requirements:\nAndroid Studio (latest version)\nYour Android app must target API level 21 or higher.\nBefore calling the Gemini API, you need to set up your Android project, which includes setting up your API key, adding the SDK dependencies to your Android project, and initializing the model.\nIt's strongly recommended that you do not check an API key into your version control system. Instead, you should store it in a local.properties file (which is located in your project's root directory, but excluded from version control), and then use the Secrets Gradle plugin for Android to read your API key as a Build Configuration variable.\n// Access your API key as a Build Configuration variable\nval apiKey = BuildConfig.apiKey\nAll the snippets in this tutorial utilize this best practice. Also, if you want to see the implementation of the Secrets Gradle plugin, you can review the sample app for this SDK or use the latest preview of Android Studio Iguana which has a Gemini API Starter template (which includes the local.properties file to get you started).\nIn your module (app-level) Gradle configuration file (like <project>/<app-module>/build.gradle.kts), add the dependency for the Google AI SDK for Android:\ndependencies {\n  // ... other androidx dependencies\n  // add the dependency for the Google AI client SDK for Android\n  implementation(\"com.google.ai.client.generativeai:generativeai:0.3.0\")\nSync your Android project with Gradle files.\nBefore you can make any API calls, you need to initialize the GenerativeModel object:\n    // Use a model that's applicable for your use case (see \"Implement basic use cases\" below)\nWhen the prompt input includes only text, use the gemini-pro model with generateContent to generate text output:\nval prompt = \"Write a story about a magic backpack.\"\nval response = generativeModel.generateContent(prompt)\nWhen the prompt input includes both text and images, use the gemini-pro-vision model with generateContent to generate text output:\n    // For text-and-images input (multimodal), use the gemini-pro-vision model\n    text(\"What's different between these pictures?\")\nval response = generativeModel.generateContent(inputContent)\nval chat = generativeModel.startChat(\n    history = listOf(\n        content(role = \"user\") { text(\"Hello, I have 2 dogs in my house.\") },\n        content(role = \"model\") { text(\"Great to meet you. What would you like to know?\") }\nchat.sendMessage(\"How many paws are in my house?\")\nThe following example shows how to implement streaming with generateContentStream to generate text from a text-and-image input prompt.\n    // For text-and-image input (multimodal), use the gemini-pro-vision model\n    fullResponse += chunk.text\nYou can use a similar approach for text-only input and chat use cases:\nval chat = generativeModel.startChat()\nchat.sendMessageStream(inputContent).collect { chunk ->\nNote that countTokens() is a suspend function and needs to be called from a Coroutine scope. If you're unfamiliar with Coroutines, read Kotlin Coroutines on Android.\nval (totalTokens) = generativeModel.countTokens(\"Write a story about a magic backpack.\")\nval multiModalContent = content {\nval (totalTokens) = generativeModel.countTokens(multiModalContent)\nval history = chat.history\nval messageContent = content { text(\"This is the message I intend to send\")}\nval (totalTokens) = generativeModel.countTokens(*history.toTypedArray(), messageContent)\nval config = generationConfig {\n    temperature = 0.9f\n    topK = 16\n    topP = 0.1f\n    maxOutputTokens = 200\n    stopSequences = listOf(\"red\")\n    generationConfig = config\n    safetySettings = listOf(\n        SafetySetting(HarmCategory.HARASSMENT, BlockThreshold.ONLY_HIGH)\nval harassmentSafety = SafetySetting(HarmCategory.HARASSMENT, BlockThreshold.ONLY_HIGH)\nval hateSpeechSafety = SafetySetting(HarmCategory.HATE_SPEECH, BlockThreshold.MEDIUM_AND_ABOVE)\n    safetySettings = listOf(harassmentSafety, hateSpeechSafety)",
            "filtered_word_count": 780
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nBenefits of on-device execution\nHow it works\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with Gemini Nano on Android (on-device) \nbookmark_border\n\nGemini Nano, the smallest version of the Gemini model family, can be executed on-device on capable Android devices starting with Google Pixel 8 Pro and Samsung S24 Series.\n\nTo execute the Gemini Nano model on Android, you need to use the Google AI Edge SDK for Android, which provides APIs to:\n\nDetermine if the underlying Android-powered device is supported.\nGet access to Gemini Nano model.\nTune safety settings.\nRun inference at high performance and implement fallbacks.\nOptionally, provide a LoRA fine-tuning block to improve performance of the model for your use case.\n\nThe APIs for accessing Gemini Nano support text-to-text modality, with more modalities coming in the future.\n\nImportant: The Google AI Edge SDK for Android is under early access preview for developers building innovative applications using Gemini Nano. If you are interested in building such applications, apply to our Early Access Preview.\nBenefits of on-device execution\n\nOn-device execution enables the following:\n\nLocal processing of sensitive data: Processing data locally can help you avoid sending user data to the cloud. This is important for apps that handle sensitive data, such as messaging apps with end-to-end encryption.\nOffline access: Users can access AI features even when there is no internet connection. This is useful for applications that need to work offline or with variable connectivity.\nCost savings: You can reduce inference costs by offloading execution to consumer hardware. This can produce significant savings for frequently used user flows.\n\nOn-device execution of Gemini has many benefits; however, for use cases that require larger Gemini models, and to support a wide range of devices, you may want to consider using the Gemini API for accessing Gemini on the server. You can do this either through backend integration (with Python, Go, Node.js, or REST) or directly from your Android app through the new Google AI client SDK for Android.\n\nHow it works\n\nOn-device execution of Gemini Nano is powered by Android AICore, a new system-level capability that provides access to foundation models for on-device execution, introduced in Android 14. Foundation models are pre-installed using AICore, so you don't need to download or distribute them within your app. You can fine-tune these models for downstream tasks using LoRa. Android AICore is now available in production on Google Pixel 8 Pro and Samsung S24 Series devices and is already powering innovative features in Google apps.\n\nFor more information, see Android AICore.\n\nFigure 1. AICore architecture\nWhat's next\n\nTo start using Gemini Nano on-device with your app, apply to our Early Access Preview of the Google AI Edge SDK for Android.\n\nTo learn how to take advantage of Gemini Pro inference on Google's servers in your Android app, read the quickstart for the Google AI client SDK for Android.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 664,
            "filtered_content": "Get started with Gemini Nano on Android (on-device) \nGemini Nano, the smallest version of the Gemini model family, can be executed on-device on capable Android devices starting with Google Pixel 8 Pro and Samsung S24 Series.\nTo execute the Gemini Nano model on Android, you need to use the Google AI Edge SDK for Android, which provides APIs to:\nDetermine if the underlying Android-powered device is supported.\nGet access to Gemini Nano model.\nTune safety settings.\nRun inference at high performance and implement fallbacks.\nOptionally, provide a LoRA fine-tuning block to improve performance of the model for your use case.\nThe APIs for accessing Gemini Nano support text-to-text modality, with more modalities coming in the future.\nImportant: The Google AI Edge SDK for Android is under early access preview for developers building innovative applications using Gemini Nano. If you are interested in building such applications, apply to our Early Access Preview.\nOn-device execution enables the following:\nLocal processing of sensitive data: Processing data locally can help you avoid sending user data to the cloud. This is important for apps that handle sensitive data, such as messaging apps with end-to-end encryption.\nOffline access: Users can access AI features even when there is no internet connection. This is useful for applications that need to work offline or with variable connectivity.\nCost savings: You can reduce inference costs by offloading execution to consumer hardware. This can produce significant savings for frequently used user flows.\nOn-device execution of Gemini has many benefits; however, for use cases that require larger Gemini models, and to support a wide range of devices, you may want to consider using the Gemini API for accessing Gemini on the server. You can do this either through backend integration (with Python, Go, Node.js, or REST) or directly from your Android app through the new Google AI client SDK for Android.\nOn-device execution of Gemini Nano is powered by Android AICore, a new system-level capability that provides access to foundation models for on-device execution, introduced in Android 14. Foundation models are pre-installed using AICore, so you don't need to download or distribute them within your app. You can fine-tune these models for downstream tasks using LoRa. Android AICore is now available in production on Google Pixel 8 Pro and Samsung S24 Series devices and is already powering innovative features in Google apps.\nFor more information, see Android AICore.\nFigure 1. AICore architecture\nTo start using Gemini Nano on-device with your app, apply to our Early Access Preview of the Google AI Edge SDK for Android.\nTo learn how to take advantage of Gemini Pro inference on Google's servers in your Android app, read the quickstart for the Google AI client SDK for Android.",
            "filtered_word_count": 451
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nSet up your API key\nGemini and Content based APIs\nText-only input\nText-and-image input\nMulti-turn conversations (chat)\nConfiguration\nStream Generate Content\nCount tokens\nEmbedding\nModel info\nGet model\nList models\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with Gemini using the REST API \nbookmark_border\n\nRun in Google Colab\n\t\nView source on GitHub\n\nIf you want to quickly try out the Gemini API, you can use curl commands to call the methods in the REST API. The examples in this tutorial show calls for each API method.\n\nThe Colab uses Python code to set an environment variable and to display an image, but you don't need Colab to work with the REST API. You should be able to run all of the curl examples outside of Colab, without modification, as long as you have API_KEY set as described in the next section.\n\nFor each curl command, you must specify the applicable model name and your API key.\n\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nIn Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name GOOGLE_API_KEY. You can then add it as an environment variable to pass the key in your curl call.\n\nIn a terminal, you can just run GOOGLE_API_KEY=\"Your API Key\".\n\nimport os\nfrom google.colab import userdata\n\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n\nGemini and Content based APIs\nText-only input\n\nUse the generateContent method to generate a response from the model given an input message. If the input contains only text, use the gemini-pro model.\n\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=$GOOGLE_API_KEY \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"contents\": [{\n        \"parts\":[{\n          \"text\": \"Write a story about a magic backpack.\"}]}]}' 2> /dev/null\n\n{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"In the quaint town of Willow Creek, nestled amidst rolling hills and whispering willows, there lived an ordinary boy named Ethan. Ethan's life took an extraordinary turn the day he stumbled upon an enigmatic backpack hidden in the depths of his attic.\\n\\nCuriosity ignited within Ethan as he lifted the worn leather straps and unzipped its mysterious contents. Inside lay a shimmering array of vibrant objects and peculiar trinkets. There was a glowing orb that pulsated with an ethereal glow, a feather that seemed to have a life of its own, and a small, enigmatic key.\\n\\nAs Ethan explored each item, he realized they possessed astonishing abilities. The orb illuminated his path, casting a warm glow in the darkest of nights. The feather granted him the power of flight, allowing him to soar through the skies with newfound freedom. And the key opened a portal to a hidden world, a realm of endless wonder.\\n\\nArmed with his magical backpack, Ethan embarked on countless adventures. He flew over the towering mountains of Willow Creek, exploring their hidden secrets. He navigated the treacherous depths of the Enchanted Forest, where he encountered mythical creatures and ancient spirits. And he ventured into distant, unknown lands, uncovering lost civilizations and forgotten treasures.\\n\\nWith each adventure, Ethan's knowledge and abilities grew. He learned to harness the power of his backpack wisely, using its magic to help others and protect the world from evil forces. The backpack became an extension of himself, a symbol of hope and wonder in the face of adversity.\\n\\nAs the years went by, Ethan's reputation as the boy with the magic backpack spread far and wide. People from all walks of life came to him, seeking his guidance and protection. And Ethan never hesitated to lend a helping hand, using his extraordinary abilities to make the world a better place.\\n\\nIn the end, the magic backpack became more than just a collection of objects. It was a representation of Ethan's unwavering spirit, his boundless imagination, and his unwavering belief in the power of dreams. And as long as Ethan carried it with him, the magic of Willow Creek would live on, illuminating the darkest corners of the world with hope, wonder, and the limitless possibilities that resided within the heart of a child.\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0,\n      \"safetyRatings\": [\n        {\n          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n          \"probability\": \"NEGLIGIBLE\"\n        }\n      ]\n    }\n  ],\n  \"promptFeedback\": {\n    \"safetyRatings\": [\n      {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"probability\": \"NEGLIGIBLE\"\n      }\n    ]\n  }\n}\n\nText-and-image input\n\nIf the input contains both text and image, use the gemini-pro-vision model. The following snippets help you build a request and send it to the REST API.\n\ncurl -o image.jpg https://storage.googleapis.com/generativeai-downloads/images/scones.jpg\n\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  385k  100  385k    0     0  2053k      0 --:--:-- --:--:-- --:--:-- 2050k\n\nimport PIL.Image\n\nimg = PIL.Image.open(\"image.jpg\")\nimg.resize((512, int(img.height*512/img.width)))\n\n\necho '{\n  \"contents\":[\n    {\n      \"parts\":[\n        {\"text\": \"What is this picture?\"},\n        {\n          \"inline_data\": {\n            \"mime_type\":\"image/jpeg\",\n            \"data\": \"'$(base64 -w0 image.jpg)'\"\n          }\n        }\n      ]\n    }\n  ]\n}' > request.json\n\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-vision:generateContent?key=${GOOGLE_API_KEY} \\\n        -H 'Content-Type: application/json' \\\n        -d @request.json 2> /dev/null | grep \"text\"\n\n\"text\": \" The picture shows a table with a white tablecloth. On the table are two cups of coffee, a bowl of blueberries, and a plate of scones. There are also some flowers on the table.\"\n\nMulti-turn conversations (chat)\n\nUsing Gemini, you can build freeform conversations across multiple turns.\n\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=$GOOGLE_API_KEY \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"contents\": [\n        {\"role\":\"user\",\n         \"parts\":[{\n           \"text\": \"Write the first line of a story about a magic backpack.\"}]},\n        {\"role\": \"model\",\n         \"parts\":[{\n           \"text\": \"In the bustling city of Meadow brook, lived a young girl named Sophie. She was a bright and curious soul with an imaginative mind.\"}]},\n        {\"role\": \"user\",\n         \"parts\":[{\n           \"text\": \"Can you set it in a quiet village in 1600s France?\"}]},\n      ]\n    }' 2> /dev/null | grep \"text\"\n\n\"text\": \"In the quaint village of Fleur-de-Lys, nestled amidst the rolling hills of 17th century France, lived a young maiden named Antoinette. She possessed a heart brimming with curiosity and a spirit as vibrant as the wildflowers that bloomed in the meadows.\\n\\nOne sunny morn, as Antoinette strolled through the cobblestone streets, her gaze fell upon a peculiar sight—a weathered leather backpack resting atop a mossy stone bench. Intrigued, she cautiously approached the bag, her fingers tracing the intricate carvings etched into its surface. As her fingertips grazed the worn leather, a surge of warmth coursed through her body, and the backpack began to emit a soft, ethereal glow.\"\n\nNote: The gemini-pro-vision model (for text-and-image input) is not yet optimized for multi-turn conversations. Make sure to use gemini-pro and text-only input for chat use cases.\nConfiguration\n\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about model parameters.\n\nAlso, you can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about safety settings.\n\nThe following example specifies values for all the parameters of the generateContent method.\n\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=$GOOGLE_API_KEY \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n        \"contents\": [{\n            \"parts\":[\n                {\"text\": \"Write a story about a magic backpack.\"}\n            ]\n        }],\n        \"safetySettings\": [\n            {\n                \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n                \"threshold\": \"BLOCK_ONLY_HIGH\"\n            }\n        ],\n        \"generationConfig\": {\n            \"stopSequences\": [\n                \"Title\"\n            ],\n            \"temperature\": 1.0,\n            \"maxOutputTokens\": 800,\n            \"topP\": 0.8,\n            \"topK\": 10\n        }\n    }'  2> /dev/null | grep \"text\"\n\n\"text\": \"Once upon a time, in a small town nestled at the foot of a majestic mountain range, lived a young girl named Lily. Lily was a bright and curious child who loved to explore the world around her. One day, while playing in the forest near her home, she stumbled upon a hidden cave. Intrigued, she stepped inside, and to her amazement, she discovered a dusty old backpack lying in a corner.\\n\\nCuriosity piqued, Lily reached out and picked up the backpack. As soon as her fingers brushed against the worn leather, she felt a strange tingling sensation coursing through her body. Suddenly, the backpack began to glow, emitting a soft, ethereal light that filled the cave.\\n\\nWith wide-eyed wonder, Lily opened the backpack to find it filled with an assortment of magical objects. There was a compass that always pointed to the nearest adventure, a magnifying glass that could reveal hidden secrets, a telescope that allowed her to see distant lands, and a book that contained the knowledge of the universe.\\n\\nOverjoyed with her discovery, Lily took the magic backpack home and began using its contents to explore the world in ways she had never imagined. She followed the compass to discover hidden treasures, used the magnifying glass to uncover the secrets of nature, gazed through the telescope to witness the wonders of the cosmos, and delved into the book to learn about the mysteries of the universe.\\n\\nAs Lily's adventures continued, she realized that the magic backpack was more than just a collection of enchanted items. It was a symbol of her own limitless potential and the power of her imagination. It taught her that with curiosity, courage, and a touch of magic, anything was possible.\\n\\nNews of Lily's magical backpack spread throughout the town, and soon, children from all around came to her, eager to learn about its wonders. Lily welcomed them with open arms, sharing her stories and inspiring them to embark on their own adventures.\\n\\nAnd so, the magic backpack became a beacon of hope and wonder, reminding everyone that the world is full of hidden treasures waiting to be discovered, if only one has the courage to step into the unknown.\"\n\nStream Generate Content\n\nThe generateContent method returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streamGenerateContent to return partial results.\n\nImportant: Be sure to set alt=sse in the URL parameters. Each line is a GenerateContentResponse object with a chunk of the output text in candidates[0].content.parts[0].text.\n!curl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:streamGenerateContent?alt=sse&key=${GOOGLE_API_KEY}\" \\\n        -H 'Content-Type: application/json' \\\n        --no-buffer \\\n        -d '{ \"contents\":[{\"parts\":[{\"text\": \"Write long a story about a magic backpack.\"}]}]}' \\\n        2> /dev/null\n\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"In the quaint little town of Willow Creek, nestled among rolling hills and whispering willows\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}],\"promptFeedback\": {\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]} }\n\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \", there existed an extraordinary backpack that possessed an astonishing secret. Its unassuming canvas exterior and worn leather straps held a hidden realm brimming with wonder and endless possibilities.\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\n\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"\\n\\nYoung Oliver, a curious and imaginative boy, stumbled upon this magical backpack in the dusty attic of his grandmother's house. Intrigued by its enigmatic aura, he unzipped it cautiously, revealing a seemingly ordinary interior. But as his fingers brushed against the lining, an ethereal glow emanated from within.\\n\\n\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\n\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"With a gasp of surprise, Oliver watched as the backpack transformed before his very eyes. Its fabric shimmered and flowed like liquid silver, morphing into a portal that connected him to a hidden dimension. Step by step, he ventured into this enchanted realm, his heart pounding with a mixture of trepidation and exhilaration.\\n\\nThe backpack's interior was a vast and wondrous labyrinth filled with towering bookshelves, bubbling potions, and ethereal artifacts. Each turn offered a new discovery: a self-playing piano, a talking mirror that whispered ancient wisdom, and a compass that pointed to the furthest reaches of the imagination.\\n\\nOliver soon realized\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\n\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" that this backpack was no mere container but a sentient being, capable of aiding him in his quests and expanding his horizons. It granted him the gift of tongues, allowing him to speak with animals and creatures from distant lands. It gifted him a quill that wrote stories that danced off the page, bringing his wildest dreams to life.\\n\\nTogether, Oliver and the backpack embarked on extraordinary adventures. They soared through the skies on the back of a majestic griffon, traversed treacherous terrains with the aid of a shape-shifting fox, and solved mysteries that had long baffled the wisest minds in Willow Creek.\\n\\nAs the days turned into weeks, Oliver's imagination flourished beyond measure. He painted vibrant landscapes with words, composed symphonies that echoed through the hidden realm, and invented gadgets that defied the laws of physics. The backpack became an extension of his boundless creativity, nurturing his wonder and fueling his aspirations.\\n\\nNews of Oliver's extraordinary backpack spread throughout the town and beyond. People flocked from far and wide to witness its marvels. Scholars sought its wisdom, artists sought its inspiration, and children dreamed of experiencing its boundless adventures.\\n\\nHowever, not all who approached the backpack with pure intentions. One fateful day, a greedy sorcerer named Maldred attempted to seize its power for himself. But\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\n\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" the backpack, sensing his malevolent nature, resisted his grasp and summoned a legion of fantastical creatures to its defense.\\n\\nIn a fierce battle that shook the very fabric of the hidden realm, Oliver and the backpack allied with brave heroes and wise wizards to defeat Maldred and his wicked forces. The town of Willow Creek was forever grateful, and the backpack became a symbol of hope and imagination for all who knew of its existence.\\n\\nAs the years passed, Oliver grew into a wise and compassionate leader, using the magic backpack to spread joy, inspire creativity, and unlock the potential of those around him. The hidden realm within its depths became a sanctuary for dreamers, inventors, and anyone who dared to embrace the wonders of the unknown.\\n\\nAnd so, the tale of the magic backpack was passed down through generations, a timeless testament to the power of imagination and the boundless possibilities that lie when wonder and curiosity ignite the human spirit.\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\n\nNote: You will need a streaming json parser to handle this without reading the whole stream first.\nCount tokens\n\nWhen using long prompts, it might be useful to count tokens before sending any content to the model.\n\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:countTokens?key=$GOOGLE_API_KEY \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"contents\": [{\n        \"parts\":[{\n          \"text\": \"Write a story about a magic backpack.\"}]}]}' > response.json\n\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100   127    0    23  100   104    105    477 --:--:-- --:--:-- --:--:--   585\n\ncat response.json\n\n{\n  \"totalTokens\": 8\n}\n\nEmbedding\n\nEmbedding is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity.\n\nUse the embedding-001 model with either embedContents or batchEmbedContents:\n\ncurl https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent?key=$GOOGLE_API_KEY \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n        \"model\": \"models/embedding-001\",\n        \"content\": {\n        \"parts\":[{\n          \"text\": \"Write a story about a magic backpack.\"}]} }' 2> /dev/null | head\n\n{\n  \"embedding\": {\n    \"values\": [\n      0.008624583,\n      -0.030451821,\n      -0.042496547,\n      -0.029230341,\n      0.05486475,\n      0.006694871,\n      0.004025645,\n\ncurl https://generativelanguage.googleapis.com/v1beta/models/embedding-001:batchEmbedContents?key=$GOOGLE_API_KEY \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"requests\": [{\n        \"model\": \"models/embedding-001\",\n        \"content\": {\n        \"parts\":[{\n          \"text\": \"Write a story about a magic backpack.\"}]} }]}' 2> /dev/null | head\n\n{\n  \"embeddings\": [\n    {\n      \"values\": [\n        0.008624583,\n        -0.030451821,\n        -0.042496547,\n        -0.029230341,\n        0.05486475,\n        0.006694871,\n\nModel info\nGet model\n\nIf you GET a model's URL, the API uses the get method to return information about that model such as version, display name, input token limit, etc.\n\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro?key=$GOOGLE_API_KEY\n\n{\n  \"name\": \"models/gemini-pro\",\n  \"version\": \"001\",\n  \"displayName\": \"Gemini Pro\",\n  \"description\": \"The best model for scaling across a wide range of tasks\",\n  \"inputTokenLimit\": 30720,\n  \"outputTokenLimit\": 2048,\n  \"supportedGenerationMethods\": [\n    \"generateContent\",\n    \"countTokens\"\n  ],\n  \"temperature\": 0.9,\n  \"topP\": 1,\n  \"topK\": 1\n}\n\nList models\n\nIf you GET the models directory, it uses the list method to list all of the models available through the API, including both the Gemini and PaLM family models.\n\ncurl https://generativelanguage.googleapis.com/v1beta/models?key=$GOOGLE_API_KEY\n\n{\n  \"models\": [\n    {\n      \"name\": \"models/chat-bison-001\",\n      \"version\": \"001\",\n      \"displayName\": \"Chat Bison\",\n      \"description\": \"Chat-optimized generative language model.\",\n      \"inputTokenLimit\": 4096,\n      \"outputTokenLimit\": 1024,\n      \"supportedGenerationMethods\": [\n        \"generateMessage\",\n        \"countMessageTokens\"\n      ],\n      \"temperature\": 0.25,\n      \"topP\": 0.95,\n      \"topK\": 40\n    },\n    {\n      \"name\": \"models/text-bison-001\",\n      \"version\": \"001\",\n      \"displayName\": \"Text Bison\",\n      \"description\": \"Model targeted for text generation.\",\n      \"inputTokenLimit\": 8196,\n      \"outputTokenLimit\": 1024,\n      \"supportedGenerationMethods\": [\n        \"generateText\",\n        \"countTextTokens\",\n        \"createTunedTextModel\"\n      ],\n      \"temperature\": 0.7,\n      \"topP\": 0.95,\n      \"topK\": 40\n    },\n    {\n      \"name\": \"models/embedding-gecko-001\",\n      \"version\": \"001\",\n      \"displayName\": \"Embedding Gecko\",\n      \"description\": \"Obtain a distributed representation of a text.\",\n      \"inputTokenLimit\": 1024,\n      \"outputTokenLimit\": 1,\n      \"supportedGenerationMethods\": [\n        \"embedText\",\n        \"countTextTokens\"\n      ]\n    },\n    {\n      \"name\": \"models/embedding-gecko-002\",\n      \"version\": \"002\",\n      \"displayName\": \"Embedding Gecko 002\",\n      \"description\": \"Obtain a distributed representation of a text.\",\n      \"inputTokenLimit\": 2048,\n      \"outputTokenLimit\": 1,\n      \"supportedGenerationMethods\": [\n        \"embedText\",\n        \"countTextTokens\"\n      ]\n    },\n    {\n      \"name\": \"models/gemini-pro\",\n      \"version\": \"001\",\n      \"displayName\": \"Gemini Pro\",\n      \"description\": \"The best model for scaling across a wide range of tasks\",\n      \"inputTokenLimit\": 30720,\n      \"outputTokenLimit\": 2048,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\"\n      ],\n      \"temperature\": 0.9,\n      \"topP\": 1,\n      \"topK\": 1\n    },\n    {\n      \"name\": \"models/gemini-pro-vision\",\n      \"version\": \"001\",\n      \"displayName\": \"Gemini Pro Vision\",\n      \"description\": \"The best image understanding model to handle a broad range of applications\",\n      \"inputTokenLimit\": 12288,\n      \"outputTokenLimit\": 4096,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\"\n      ],\n      \"temperature\": 0.4,\n      \"topP\": 1,\n      \"topK\": 32\n    },\n    {\n      \"name\": \"models/gemini-ultra\",\n      \"version\": \"001\",\n      \"displayName\": \"Gemini Ultra\",\n      \"description\": \"The most capable model for highly complex tasks\",\n      \"inputTokenLimit\": 30720,\n      \"outputTokenLimit\": 2048,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\"\n      ],\n      \"temperature\": 0.9,\n      \"topP\": 1,\n      \"topK\": 32\n    },\n    {\n      \"name\": \"models/embedding-001\",\n      \"version\": \"001\",\n      \"displayName\": \"Embedding 001\",\n      \"description\": \"Obtain a distributed representation of a text.\",\n      \"inputTokenLimit\": 2048,\n      \"outputTokenLimit\": 1,\n      \"supportedGenerationMethods\": [\n        \"embedContent\",\n        \"countTextTokens\"\n      ]\n    },\n    {\n      \"name\": \"models/aqa\",\n      \"version\": \"001\",\n      \"displayName\": \"Model that performs Attributed Question Answering.\",\n      \"description\": \"Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\",\n      \"inputTokenLimit\": 7168,\n      \"outputTokenLimit\": 1024,\n      \"supportedGenerationMethods\": [\n        \"generateAnswer\"\n      ],\n      \"temperature\": 0.2,\n      \"topP\": 1,\n      \"topK\": 40\n    }\n  ]\n}\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 3257,
            "filtered_content": "Get started with Gemini using the REST API \nIf you want to quickly try out the Gemini API, you can use curl commands to call the methods in the REST API. The examples in this tutorial show calls for each API method.\nThe Colab uses Python code to set an environment variable and to display an image, but you don't need Colab to work with the REST API. You should be able to run all of the curl examples outside of Colab, without modification, as long as you have API_KEY set as described in the next section.\nFor each curl command, you must specify the applicable model name and your API key.\nIn Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name GOOGLE_API_KEY. You can then add it as an environment variable to pass the key in your curl call.\nIn a terminal, you can just run GOOGLE_API_KEY=\"Your API Key\".\nimport os\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\nUse the generateContent method to generate a response from the model given an input message. If the input contains only text, use the gemini-pro model.\n          \"text\": \"Write a story about a magic backpack.\"}]}]}' 2> /dev/null\n  \"candidates\": [\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"In the quaint town of Willow Creek, nestled amidst rolling hills and whispering willows, there lived an ordinary boy named Ethan. Ethan's life took an extraordinary turn the day he stumbled upon an enigmatic backpack hidden in the depths of his attic.\\n\\nCuriosity ignited within Ethan as he lifted the worn leather straps and unzipped its mysterious contents. Inside lay a shimmering array of vibrant objects and peculiar trinkets. There was a glowing orb that pulsated with an ethereal glow, a feather that seemed to have a life of its own, and a small, enigmatic key.\\n\\nAs Ethan explored each item, he realized they possessed astonishing abilities. The orb illuminated his path, casting a warm glow in the darkest of nights. The feather granted him the power of flight, allowing him to soar through the skies with newfound freedom. And the key opened a portal to a hidden world, a realm of endless wonder.\\n\\nArmed with his magical backpack, Ethan embarked on countless adventures. He flew over the towering mountains of Willow Creek, exploring their hidden secrets. He navigated the treacherous depths of the Enchanted Forest, where he encountered mythical creatures and ancient spirits. And he ventured into distant, unknown lands, uncovering lost civilizations and forgotten treasures.\\n\\nWith each adventure, Ethan's knowledge and abilities grew. He learned to harness the power of his backpack wisely, using its magic to help others and protect the world from evil forces. The backpack became an extension of himself, a symbol of hope and wonder in the face of adversity.\\n\\nAs the years went by, Ethan's reputation as the boy with the magic backpack spread far and wide. People from all walks of life came to him, seeking his guidance and protection. And Ethan never hesitated to lend a helping hand, using his extraordinary abilities to make the world a better place.\\n\\nIn the end, the magic backpack became more than just a collection of objects. It was a representation of Ethan's unwavering spirit, his boundless imagination, and his unwavering belief in the power of dreams. And as long as Ethan carried it with him, the magic of Willow Creek would live on, illuminating the darkest corners of the world with hope, wonder, and the limitless possibilities that resided within the heart of a child.\"\n          }\n        ],\n        \"role\": \"model\"\n      \"finishReason\": \"STOP\",\n      \"index\": 0,\n      \"safetyRatings\": [\n          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        }\n  \"promptFeedback\": {\n    \"safetyRatings\": [\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n      }\n    ]\nIf the input contains both text and image, use the gemini-pro-vision model. The following snippets help you build a request and send it to the REST API.\ncurl -o image.jpg https://storage.googleapis.com/generativeai-downloads/images/scones.jpg\n100  385k  100  385k    0     0  2053k      0 --:--:-- --:--:-- --:--:-- 2050k\nimg = PIL.Image.open(\"image.jpg\")\nimg.resize((512, int(img.height*512/img.width)))\necho '{\n  \"contents\":[\n    {\n      \"parts\":[\n        {\"text\": \"What is this picture?\"},\n        {\n          \"inline_data\": {\n            \"mime_type\":\"image/jpeg\",\n            \"data\": \"'$(base64 -w0 image.jpg)'\"\n          }\n    }\n}' > request.json\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-vision:generateContent?key=${GOOGLE_API_KEY} \\\n        -d @request.json 2> /dev/null | grep \"text\"\n\"text\": \" The picture shows a table with a white tablecloth. On the table are two cups of coffee, a bowl of blueberries, and a plate of scones. There are also some flowers on the table.\"\nUsing Gemini, you can build freeform conversations across multiple turns.\n      \"contents\": [\n        {\"role\":\"user\",\n           \"text\": \"Write the first line of a story about a magic backpack.\"}]},\n        {\"role\": \"model\",\n           \"text\": \"In the bustling city of Meadow brook, lived a young girl named Sophie. She was a bright and curious soul with an imaginative mind.\"}]},\n        {\"role\": \"user\",\n           \"text\": \"Can you set it in a quiet village in 1600s France?\"}]},\n    }' 2> /dev/null | grep \"text\"\n\"text\": \"In the quaint village of Fleur-de-Lys, nestled amidst the rolling hills of 17th century France, lived a young maiden named Antoinette. She possessed a heart brimming with curiosity and a spirit as vibrant as the wildflowers that bloomed in the meadows.\\n\\nOne sunny morn, as Antoinette strolled through the cobblestone streets, her gaze fell upon a peculiar sight—a weathered leather backpack resting atop a mossy stone bench. Intrigued, she cautiously approached the bag, her fingers tracing the intricate carvings etched into its surface. As her fingertips grazed the worn leather, a surge of warmth coursed through her body, and the backpack began to emit a soft, ethereal glow.\"\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Learn more about model parameters.\nAlso, you can use safety settings to adjust the likelihood of getting responses that may be considered harmful. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about safety settings.\nThe following example specifies values for all the parameters of the generateContent method.\n        \"contents\": [{\n            \"parts\":[\n                {\"text\": \"Write a story about a magic backpack.\"}\n            ]\n        }],\n        \"safetySettings\": [\n            {\n                \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n                \"threshold\": \"BLOCK_ONLY_HIGH\"\n            }\n        \"generationConfig\": {\n            \"stopSequences\": [\n                \"Title\"\n            ],\n            \"temperature\": 1.0,\n            \"maxOutputTokens\": 800,\n            \"topP\": 0.8,\n            \"topK\": 10\n    }'  2> /dev/null | grep \"text\"\n\"text\": \"Once upon a time, in a small town nestled at the foot of a majestic mountain range, lived a young girl named Lily. Lily was a bright and curious child who loved to explore the world around her. One day, while playing in the forest near her home, she stumbled upon a hidden cave. Intrigued, she stepped inside, and to her amazement, she discovered a dusty old backpack lying in a corner.\\n\\nCuriosity piqued, Lily reached out and picked up the backpack. As soon as her fingers brushed against the worn leather, she felt a strange tingling sensation coursing through her body. Suddenly, the backpack began to glow, emitting a soft, ethereal light that filled the cave.\\n\\nWith wide-eyed wonder, Lily opened the backpack to find it filled with an assortment of magical objects. There was a compass that always pointed to the nearest adventure, a magnifying glass that could reveal hidden secrets, a telescope that allowed her to see distant lands, and a book that contained the knowledge of the universe.\\n\\nOverjoyed with her discovery, Lily took the magic backpack home and began using its contents to explore the world in ways she had never imagined. She followed the compass to discover hidden treasures, used the magnifying glass to uncover the secrets of nature, gazed through the telescope to witness the wonders of the cosmos, and delved into the book to learn about the mysteries of the universe.\\n\\nAs Lily's adventures continued, she realized that the magic backpack was more than just a collection of enchanted items. It was a symbol of her own limitless potential and the power of her imagination. It taught her that with curiosity, courage, and a touch of magic, anything was possible.\\n\\nNews of Lily's magical backpack spread throughout the town, and soon, children from all around came to her, eager to learn about its wonders. Lily welcomed them with open arms, sharing her stories and inspiring them to embark on their own adventures.\\n\\nAnd so, the magic backpack became a beacon of hope and wonder, reminding everyone that the world is full of hidden treasures waiting to be discovered, if only one has the courage to step into the unknown.\"\nThe generateContent method returns a response after completing the entire generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streamGenerateContent to return partial results.\nImportant: Be sure to set alt=sse in the URL parameters. Each line is a GenerateContentResponse object with a chunk of the output text in candidates[0].content.parts[0].text.\n!curl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:streamGenerateContent?alt=sse&key=${GOOGLE_API_KEY}\" \\\n        --no-buffer \\\n        -d '{ \"contents\":[{\"parts\":[{\"text\": \"Write long a story about a magic backpack.\"}]}]}' \\\n        2> /dev/null\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"In the quaint little town of Willow Creek, nestled among rolling hills and whispering willows\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}],\"promptFeedback\": {\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]} }\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \", there existed an extraordinary backpack that possessed an astonishing secret. Its unassuming canvas exterior and worn leather straps held a hidden realm brimming with wonder and endless possibilities.\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"\\n\\nYoung Oliver, a curious and imaginative boy, stumbled upon this magical backpack in the dusty attic of his grandmother's house. Intrigued by its enigmatic aura, he unzipped it cautiously, revealing a seemingly ordinary interior. But as his fingers brushed against the lining, an ethereal glow emanated from within.\\n\\n\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"With a gasp of surprise, Oliver watched as the backpack transformed before his very eyes. Its fabric shimmered and flowed like liquid silver, morphing into a portal that connected him to a hidden dimension. Step by step, he ventured into this enchanted realm, his heart pounding with a mixture of trepidation and exhilaration.\\n\\nThe backpack's interior was a vast and wondrous labyrinth filled with towering bookshelves, bubbling potions, and ethereal artifacts. Each turn offered a new discovery: a self-playing piano, a talking mirror that whispered ancient wisdom, and a compass that pointed to the furthest reaches of the imagination.\\n\\nOliver soon realized\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" that this backpack was no mere container but a sentient being, capable of aiding him in his quests and expanding his horizons. It granted him the gift of tongues, allowing him to speak with animals and creatures from distant lands. It gifted him a quill that wrote stories that danced off the page, bringing his wildest dreams to life.\\n\\nTogether, Oliver and the backpack embarked on extraordinary adventures. They soared through the skies on the back of a majestic griffon, traversed treacherous terrains with the aid of a shape-shifting fox, and solved mysteries that had long baffled the wisest minds in Willow Creek.\\n\\nAs the days turned into weeks, Oliver's imagination flourished beyond measure. He painted vibrant landscapes with words, composed symphonies that echoed through the hidden realm, and invented gadgets that defied the laws of physics. The backpack became an extension of his boundless creativity, nurturing his wonder and fueling his aspirations.\\n\\nNews of Oliver's extraordinary backpack spread throughout the town and beyond. People flocked from far and wide to witness its marvels. Scholars sought its wisdom, artists sought its inspiration, and children dreamed of experiencing its boundless adventures.\\n\\nHowever, not all who approached the backpack with pure intentions. One fateful day, a greedy sorcerer named Maldred attempted to seize its power for himself. But\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" the backpack, sensing his malevolent nature, resisted his grasp and summoned a legion of fantastical creatures to its defense.\\n\\nIn a fierce battle that shook the very fabric of the hidden realm, Oliver and the backpack allied with brave heroes and wise wizards to defeat Maldred and his wicked forces. The town of Willow Creek was forever grateful, and the backpack became a symbol of hope and imagination for all who knew of its existence.\\n\\nAs the years passed, Oliver grew into a wise and compassionate leader, using the magic backpack to spread joy, inspire creativity, and unlock the potential of those around him. The hidden realm within its depths became a sanctuary for dreamers, inventors, and anyone who dared to embrace the wonders of the unknown.\\n\\nAnd so, the tale of the magic backpack was passed down through generations, a timeless testament to the power of imagination and the boundless possibilities that lie when wonder and curiosity ignite the human spirit.\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"safetyRatings\": [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_HARASSMENT\",\"probability\": \"NEGLIGIBLE\"},{\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"probability\": \"NEGLIGIBLE\"}]}]}\nNote: You will need a streaming json parser to handle this without reading the whole stream first.\nWhen using long prompts, it might be useful to count tokens before sending any content to the model.\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:countTokens?key=$GOOGLE_API_KEY \\\n          \"text\": \"Write a story about a magic backpack.\"}]}]}' > response.json\n100   127    0    23  100   104    105    477 --:--:-- --:--:-- --:--:--   585\ncat response.json\n  \"totalTokens\": 8\nUse the embedding-001 model with either embedContents or batchEmbedContents:\ncurl https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent?key=$GOOGLE_API_KEY \\\n          \"text\": \"Write a story about a magic backpack.\"}]} }' 2> /dev/null | head\n  \"embedding\": {\n    \"values\": [\n      0.008624583,\n      -0.030451821,\n      -0.042496547,\n      -0.029230341,\n      0.05486475,\n      0.006694871,\n      0.004025645,\ncurl https://generativelanguage.googleapis.com/v1beta/models/embedding-001:batchEmbedContents?key=$GOOGLE_API_KEY \\\n      \"requests\": [{\n          \"text\": \"Write a story about a magic backpack.\"}]} }]}' 2> /dev/null | head\n  \"embeddings\": [\n      \"values\": [\n        0.008624583,\n        -0.030451821,\n        -0.042496547,\n        -0.029230341,\n        0.05486475,\n        0.006694871,\nIf you GET a model's URL, the API uses the get method to return information about that model such as version, display name, input token limit, etc.\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro?key=$GOOGLE_API_KEY\n  \"name\": \"models/gemini-pro\",\n  \"version\": \"001\",\n  \"displayName\": \"Gemini Pro\",\n  \"description\": \"The best model for scaling across a wide range of tasks\",\n  \"inputTokenLimit\": 30720,\n  \"outputTokenLimit\": 2048,\n  \"supportedGenerationMethods\": [\n    \"generateContent\",\n    \"countTokens\"\n  \"temperature\": 0.9,\n  \"topP\": 1,\n  \"topK\": 1\nIf you GET the models directory, it uses the list method to list all of the models available through the API, including both the Gemini and PaLM family models.\ncurl https://generativelanguage.googleapis.com/v1beta/models?key=$GOOGLE_API_KEY\n  \"models\": [\n      \"name\": \"models/chat-bison-001\",\n      \"displayName\": \"Chat Bison\",\n      \"description\": \"Chat-optimized generative language model.\",\n      \"inputTokenLimit\": 4096,\n        \"generateMessage\",\n        \"countMessageTokens\"\n      \"temperature\": 0.25,\n      \"name\": \"models/text-bison-001\",\n      \"displayName\": \"Text Bison\",\n      \"description\": \"Model targeted for text generation.\",\n      \"inputTokenLimit\": 8196,\n        \"generateText\",\n        \"countTextTokens\",\n        \"createTunedTextModel\"\n      \"temperature\": 0.7,\n      \"name\": \"models/embedding-gecko-001\",\n      \"displayName\": \"Embedding Gecko\",\n      \"inputTokenLimit\": 1024,\n      \"name\": \"models/embedding-gecko-002\",\n      \"version\": \"002\",\n      \"displayName\": \"Embedding Gecko 002\",\n      \"name\": \"models/gemini-pro\",\n      \"displayName\": \"Gemini Pro\",\n      \"description\": \"The best model for scaling across a wide range of tasks\",\n      \"topK\": 1\n      \"name\": \"models/gemini-pro-vision\",\n      \"displayName\": \"Gemini Pro Vision\",\n      \"description\": \"The best image understanding model to handle a broad range of applications\",\n      \"inputTokenLimit\": 12288,\n      \"outputTokenLimit\": 4096,\n      \"temperature\": 0.4,\n      \"name\": \"models/gemini-ultra\",\n      \"displayName\": \"Gemini Ultra\",\n      \"description\": \"The most capable model for highly complex tasks\",\n      \"name\": \"models/embedding-001\",\n      \"displayName\": \"Embedding 001\",\n        \"embedContent\",\n      \"name\": \"models/aqa\",\n      \"displayName\": \"Model that performs Attributed Question Answering.\",\n      \"description\": \"Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\",\n      \"inputTokenLimit\": 7168,\n        \"generateAnswer\"\n      \"temperature\": 0.2,\n  ]",
            "filtered_word_count": 2527
        },
        "https://ai.google.dev/gemini-api/docs/downloads": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nOverview\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\nREST API\nDownloads\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nDownload or install libraries to access Gemini \nbookmark_border\n\nThis page provides information about how to download or install the libraries for accessing Gemini.\n\nNote: If you're new to the Gemini API, try out one of the quickstarts, like the Python quickstart.\nPython\nThe SDK: pip install google-generativeai\nThe low-level client library: pip install google-ai-generativelanguage\nGo\nRun go get github.com/google/generative-ai-go\nNode.js\nnpm install @google/generative-ai\nWeb\nAdd import { GoogleGenerativeAI } from 'https://esm.run/@google/generative-ai' to you web app\nDart (Flutter)\nFor Dart: Run dart pub add google_generative_ai\nFor Flutter: Run flutter pub add google_generative_ai\nSwift\nAdd generative-ai-swift to your Xcode project using Swift Package Manager.\nAndroid\nAdd the dependency implementation(\"com.google.ai.client.generativeai:generativeai:0.3.0\") to your Android project.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 302,
            "filtered_content": "Download or install libraries to access Gemini \nThis page provides information about how to download or install the libraries for accessing Gemini.\nNote: If you're new to the Gemini API, try out one of the quickstarts, like the Python quickstart.\nThe SDK: pip install google-generativeai\nThe low-level client library: pip install google-ai-generativelanguage\nRun go get github.com/google/generative-ai-go\nAdd import { GoogleGenerativeAI } from 'https://esm.run/@google/generative-ai' to you web app\nFor Dart: Run dart pub add google_generative_ai\nFor Flutter: Run flutter pub add google_generative_ai\nAdd generative-ai-swift to your Xcode project using Swift Package Manager.\nAdd the dependency implementation(\"com.google.ai.client.generativeai:generativeai:0.3.0\") to your Android project.",
            "filtered_word_count": 99
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nExample applications\nGenerate a poem\nGenerate a list\nPrompt design 101\nPrompting versus traditional software development\nModel parameters\nTypes of prompts\nZero-shot prompts\nOne-shot prompts\nFew-shot prompts\nGenerative models under the hood\nFurther reading\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nAbout generative models \nbookmark_border\n\nGenerative artificial intelligence (AI) models such as the Gemini family of models are able to create content from varying types of data input, including text, images, and audio. At their most basic level, these models operate like sophisticated autocomplete applications. Given input text (\"You can lead a horse to water,\"), a generative model can predict that the output text that's statistically likely to follow (\"but you can't make it drink\"), based on patterns learned from their training data. You can use this basic property of generative models for various applications:\n\nGenerate creative writing such as poetry, short stories, metaphors, and blog posts\nConvert structured data to freeform text\nExtract and summarize information from freeform text\nGenerate code\nTranslate between languages\n\nUsing generative models to build these features doesn't require any machine learning (ML) expertise. You don't need to collect a large dataset or train a model. All it takes to start your first prototype is to describe what you want the model to do in a few sentences.\n\nGenerative models that only handle text input and output are also known as large language models (LLMs). The Gemini family of models can process more than text data, and while they can perform the functions of an LLM, they are more properly known as generative models.\n\nExample applications\n\nThe following examples show typical text inputs to, and outputs from, a generative model.\n\nGenerate a poem\n\nUser input: Write me a four-line poem about puppies and Android phones. Make sure it rhymes.\n\nModel output:\n\nPuppies are cute,\nAndroid phones are neat,\nThey both bring joy,\nAnd make life complete.\n\nGenerate a list\n\nUser input: Generate a bulleted list of items I need to pack for a three-day camping trip.\n\nModel output:\n\n*   Tent\n*   Sleeping bag\n*   Sleeping pad\n*   Camp stove\n*   Pots and pans\n*   Utensils\n*   Food\n*   Water\n*   First-aid kit\n*   Sunscreen\n*   Insect repellent\n*   ...\n\n\nYou can get generative models to produce all sorts of useful behaviors like this, just by crafting the right input text, also called a prompt. The art and science of figuring out the right wording to get generative models to do what you want is called prompt design (also called \"prompt engineering\" or simply \"prompting\").\n\nPrompt design 101\n\nThe previous section showed some examples of prompts that contain an instruction, like 'Write me a poem'. This kind of instruction may work well for certain types of tasks. However, for other applications, another prompting technique called few-shot prompting may work better. Few-shot prompts take advantage of the fact that large language models are incredibly good at recognizing and replicating patterns in text data. The idea is to send the generative model a text pattern that it learns to complete. For example, say you want to build an application that takes as input a country name and outputs its capital city. Here's a text prompt designed to do just that:\n\nItaly : Rome\nFrance : Paris\nGermany :\n\n\nIn this prompt, you establish a pattern: [country] : [capital]. If you send this prompt to a large language model, it will autocomplete the pattern and return something like this:\n\n     Berlin\nTurkey : Ankara\nGreece : Athens\n\n\nThis model response may look a little strange. The model returned not only the capital of Germany (the last country in your hand-written prompt), but also a whole list of additional country and capital pairs. That's because the generative model is \"continuing the pattern.\" If all you're trying to do is build a function that tells you the capital of an input country (\"Germany : Berlin\"), you probably don't really care about any of the text the model generates after \"Berlin.\" Indeed, as application designers, you'd probably want to truncate those extraneous examples. What's more, you'd probably want to parameterize the input, so that Germany is not a fixed string but a variable that the end user provides:\n\nItaly : Rome\nFrance : Paris\n<user input here> :\n\n\nYou have just written a few-shot prompt for generating country capitals.\n\nYou can accomplish a large number of tasks by following this few-shot prompt template. Here's a few-shot prompt with a slightly different format that converts Python to JavaScript:\n\nConvert Python to JavaScript.\nPython: print(\"hello world\")\nJavaScript: console.log(\"hello world\")\nPython: for x in range(0, 100):\nJavaScript: for(var i = 0; i < 100; i++) {\nPython: ${USER INPUT HERE}\nJavaScript:\n\n\nOr, take this \"reverse dictionary\" prompt. Given a definition, it returns the word that fits that definition:\n\nGiven a definition, return the word it defines.\nDefinition: When you're happy that other people are also sad.\nWord: schadenfreude\nDefinition: existing purely in the mind, but not in physical reality\nWord: abstract\nDefinition: ${USER INPUT HERE}\nWord:\n\n\nYou might have noticed that the exact pattern of these few-shot prompts varies slightly. In addition to containing examples, providing instructions in your prompts is an additional strategy to consider when writing your own prompts, as it helps to communicate your intent to the model.\n\nPrompting versus traditional software development\n\nUnlike traditional software that's designed to a carefully written spec, the behavior of generative models is largely opaque even to the model trainers. As a result, you often can't predict in advance what types of prompt structures will work best for a particular model. What's more, the behavior of a generative model is determined in large part by its training data, and since models are continually tuned on new datasets, sometimes the model changes enough that it inadvertently changes which prompt structures work best. What does this mean for you? Experiment! Try different prompt formats.\n\nModel parameters\n\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. The most common model parameters are:\n\nMax output tokens: Specifies the maximum number of tokens that can be generated in the response. A token is approximately four characters. 100 tokens correspond to roughly 60-80 words.\n\nTemperature: The temperature controls the degree of randomness in token selection. The temperature is used for sampling during response generation, which occurs when topP and topK are applied. Lower temperatures are good for prompts that require a more deterministic or less open-ended response, while higher temperatures can lead to more diverse or creative results. A temperature of 0 is deterministic, meaning that the highest probability response is always selected.\n\ntopK: The topK parameter changes how the model selects tokens for output. A topK of 1 means the selected token is the most probable among all the tokens in the model's vocabulary (also called greedy decoding), while a topK of 3 means that the next token is selected from among the 3 most probable using the temperature. For each token selection step, the topK tokens with the highest probabilities are sampled. Tokens are then further filtered based on topP with the final token selected using temperature sampling.\n\ntopP: The topP parameter changes how the model selects tokens for output. Tokens are selected from the most to least probable until the sum of their probabilities equals the topP value. For example, if tokens A, B, and C have a probability of 0.3, 0.2, and 0.1 and the topP value is 0.5, then the model will select either A or B as the next token by using the temperature and exclude C as a candidate. The default topP value is 0.95.\n\nstop_sequences: Set a stop sequence to tell the model to stop generating content. A stop sequence can be any sequence of characters. Try to avoid using a sequence of characters that may appear in the generated content.\n\nTypes of prompts\n\nDepending on the level of contextual information contained in them, prompts are broadly classified into three types.\n\nZero-shot prompts\n\nThese prompts don't contain examples for the model to replicate. Zero-shot prompts essentially show the model's ability to complete the prompt without any additional examples or information. It means the model has to rely on its pre-existing knowledge to generate a plausible answer.\n\nSome commonly used zero-shot prompt patterns are:\n\nInstruction-content\n<Overall instruction>\n<Content to operate on>\n\n\nFor example,\n\nSummarize the following into two sentences at the third-grade level:\n\nHummingbirds are the smallest birds in the world, and they are also one of the\nmost fascinating. They are found in North and South America, and they are known\nfor their long, thin beaks and their ability to fly at high speeds.\n\nHummingbirds are made up of three main parts: the head, the body, and the tail.\nThe head is small and round, and it contains the eyes, the beak, and the brain.\nThe body is long and slender, and it contains the wings, the legs, and the\nheart. The tail is long and forked, and it helps the hummingbird to balance\nwhile it is flying.\n\nHummingbirds are also known for their coloration. They come in a variety of\ncolors, including green, blue, red, and purple. Some hummingbirds are even able\nto change their color!\n\nHummingbirds are very active creatures. They spend most of their time flying,\nand they are also very good at hovering. Hummingbirds need to eat a lot of food\nin order to maintain their energy, and they often visit flowers to drink nectar.\n\nHummingbirds are amazing creatures. They are small, but they are also very\npowerful. They are beautiful, and they are very important to the ecosystem.\n\nInstruction-content-instruction\n<Overall instruction or context setting>\n<Content to operate on>\n<Final instruction>\n\n\nFor example,\n\nHere is some text I'd like you to summarize:\n\nHummingbirds are the smallest birds in the world, and they are also one of the\nmost fascinating. They are found in North and South America, and they are known\nfor their long, thin beaks and their ability to fly at high speeds. Hummingbirds\nare made up of three main parts: the head, the body, and the tail. The head is\nsmall and round, and it contains the eyes, the beak, and the brain. The body is\nlong and slender, and it contains the wings, the legs, and the heart. The tail\nis long and forked, and it helps the hummingbird to balance while it is flying.\nHummingbirds are also known for their coloration. They come in a variety of\ncolors, including green, blue, red, and purple. Some hummingbirds are even able\nto change their color! Hummingbirds are very active creatures. They spend most\nof their time flying, and they are also very good at hovering. Hummingbirds need\nto eat a lot of food in order to maintain their energy, and they often visit\nflowers to drink nectar. Hummingbirds are amazing creatures. They are small, but\nthey are also very powerful. They are beautiful, and they are very important to\nthe ecosystem.\n\nSummarize it in two sentences at the third-grade reading level.\n\nContinuation. Sometimes, you can have the model continue text without any instructions. For example, here is a zero-shot prompt where the model is intended to continue the input provided:\nOnce upon a time, there was a little sparrow building a nest in a farmer's\nbarn. This sparrow\n\n\nUse zero-shot prompts to generate creative text formats, such as poems, code, scripts, musical pieces, email, or letters.\n\nOne-shot prompts\n\nThese prompts provide the model with a single example to replicate and continue the pattern. This allows for the generation of predictable responses from the model.\n\nFor example, you can generate food pairings like:\n\nFood: Apple\nPairs with: Cheese\nFood: Pear\nPairs with:\n\nFew-shot prompts\n\nThese prompts provide the model with multiple examples to replicate. Use few-shot prompts to complete complicated tasks, such as synthesizing data based on a pattern.\n\nAn example prompt may be:\n\nGenerate a grocery shopping list for a week for one person. Use the JSON format\ngiven below.\n{\"item\": \"eggs\", \"quantity\": \"6\"}\n{\"item\": \"bread\", \"quantity\": \"one loaf\"}\n\nGenerative models under the hood\n\nThis section aims to answer the question - Is there randomness in generative models' responses, or are they deterministic?\n\nThe short answer - yes to both. When you prompt a generative model, a text response is generated in two stages. In the first stage, the generative model processes the input prompt and generates a probability distribution over possible tokens (words) that are likely to come next. For example, if you prompt with the input text \"The dog jumped over the ... \", the generative model will produce an array of probable next words:\n\n[(\"fence\", 0.77), (\"ledge\", 0.12), (\"blanket\", 0.03), ...]\n\n\nThis process is deterministic; a generative model will produce this same distribution every time it's input the same prompt text.\n\nIn the second stage, the generative model converts these distributions into actual text responses through one of several decoding strategies. A simple decoding strategy might select the most likely token at every timestep. This process would always be deterministic. However, you could instead choose to generate a response by randomly sampling over the distribution returned by the model. This process would be stochastic (random). Control the degree of randomness allowed in this decoding process by setting the temperature. A temperature of 0 means only the most likely tokens are selected, and there's no randomness. Conversely, a high temperature injects a high degree of randomness into the tokens selected by the model, leading to more unexpected, surprising model responses.\n\nFurther reading\nNow that you have a deeper understanding of prompts and generative models, try writing your own prompts using Google AI Studio.\nRefer to the Prompt guidelines to learn more about best practices for creating prompts.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 2462,
            "filtered_content": "About generative models \nGenerative artificial intelligence (AI) models such as the Gemini family of models are able to create content from varying types of data input, including text, images, and audio. At their most basic level, these models operate like sophisticated autocomplete applications. Given input text (\"You can lead a horse to water,\"), a generative model can predict that the output text that's statistically likely to follow (\"but you can't make it drink\"), based on patterns learned from their training data. You can use this basic property of generative models for various applications:\nGenerate creative writing such as poetry, short stories, metaphors, and blog posts\nConvert structured data to freeform text\nExtract and summarize information from freeform text\nGenerate code\nTranslate between languages\nUsing generative models to build these features doesn't require any machine learning (ML) expertise. You don't need to collect a large dataset or train a model. All it takes to start your first prototype is to describe what you want the model to do in a few sentences.\nGenerative models that only handle text input and output are also known as large language models (LLMs). The Gemini family of models can process more than text data, and while they can perform the functions of an LLM, they are more properly known as generative models.\nThe following examples show typical text inputs to, and outputs from, a generative model.\nUser input: Write me a four-line poem about puppies and Android phones. Make sure it rhymes.\nPuppies are cute,\nAndroid phones are neat,\nThey both bring joy,\nAnd make life complete.\nUser input: Generate a bulleted list of items I need to pack for a three-day camping trip.\n*   Tent\n*   Sleeping bag\n*   Sleeping pad\n*   Camp stove\n*   Pots and pans\n*   Utensils\n*   Food\n*   Water\n*   First-aid kit\n*   Sunscreen\n*   Insect repellent\n*   ...\nYou can get generative models to produce all sorts of useful behaviors like this, just by crafting the right input text, also called a prompt. The art and science of figuring out the right wording to get generative models to do what you want is called prompt design (also called \"prompt engineering\" or simply \"prompting\").\nThe previous section showed some examples of prompts that contain an instruction, like 'Write me a poem'. This kind of instruction may work well for certain types of tasks. However, for other applications, another prompting technique called few-shot prompting may work better. Few-shot prompts take advantage of the fact that large language models are incredibly good at recognizing and replicating patterns in text data. The idea is to send the generative model a text pattern that it learns to complete. For example, say you want to build an application that takes as input a country name and outputs its capital city. Here's a text prompt designed to do just that:\nGermany :\nIn this prompt, you establish a pattern: [country] : [capital]. If you send this prompt to a large language model, it will autocomplete the pattern and return something like this:\n     Berlin\nTurkey : Ankara\nGreece : Athens\nThis model response may look a little strange. The model returned not only the capital of Germany (the last country in your hand-written prompt), but also a whole list of additional country and capital pairs. That's because the generative model is \"continuing the pattern.\" If all you're trying to do is build a function that tells you the capital of an input country (\"Germany : Berlin\"), you probably don't really care about any of the text the model generates after \"Berlin.\" Indeed, as application designers, you'd probably want to truncate those extraneous examples. What's more, you'd probably want to parameterize the input, so that Germany is not a fixed string but a variable that the end user provides:\n<user input here> :\nYou have just written a few-shot prompt for generating country capitals.\nYou can accomplish a large number of tasks by following this few-shot prompt template. Here's a few-shot prompt with a slightly different format that converts Python to JavaScript:\nConvert Python to JavaScript.\nPython: print(\"hello world\")\nJavaScript: console.log(\"hello world\")\nPython: for x in range(0, 100):\nJavaScript: for(var i = 0; i < 100; i++) {\nPython: ${USER INPUT HERE}\nJavaScript:\nOr, take this \"reverse dictionary\" prompt. Given a definition, it returns the word that fits that definition:\nGiven a definition, return the word it defines.\nDefinition: When you're happy that other people are also sad.\nWord: schadenfreude\nDefinition: existing purely in the mind, but not in physical reality\nWord: abstract\nDefinition: ${USER INPUT HERE}\nWord:\nYou might have noticed that the exact pattern of these few-shot prompts varies slightly. In addition to containing examples, providing instructions in your prompts is an additional strategy to consider when writing your own prompts, as it helps to communicate your intent to the model.\nUnlike traditional software that's designed to a carefully written spec, the behavior of generative models is largely opaque even to the model trainers. As a result, you often can't predict in advance what types of prompt structures will work best for a particular model. What's more, the behavior of a generative model is determined in large part by its training data, and since models are continually tuned on new datasets, sometimes the model changes enough that it inadvertently changes which prompt structures work best. What does this mean for you? Experiment! Try different prompt formats.\nEvery prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. The most common model parameters are:\nMax output tokens: Specifies the maximum number of tokens that can be generated in the response. A token is approximately four characters. 100 tokens correspond to roughly 60-80 words.\nTemperature: The temperature controls the degree of randomness in token selection. The temperature is used for sampling during response generation, which occurs when topP and topK are applied. Lower temperatures are good for prompts that require a more deterministic or less open-ended response, while higher temperatures can lead to more diverse or creative results. A temperature of 0 is deterministic, meaning that the highest probability response is always selected.\ntopK: The topK parameter changes how the model selects tokens for output. A topK of 1 means the selected token is the most probable among all the tokens in the model's vocabulary (also called greedy decoding), while a topK of 3 means that the next token is selected from among the 3 most probable using the temperature. For each token selection step, the topK tokens with the highest probabilities are sampled. Tokens are then further filtered based on topP with the final token selected using temperature sampling.\ntopP: The topP parameter changes how the model selects tokens for output. Tokens are selected from the most to least probable until the sum of their probabilities equals the topP value. For example, if tokens A, B, and C have a probability of 0.3, 0.2, and 0.1 and the topP value is 0.5, then the model will select either A or B as the next token by using the temperature and exclude C as a candidate. The default topP value is 0.95.\nstop_sequences: Set a stop sequence to tell the model to stop generating content. A stop sequence can be any sequence of characters. Try to avoid using a sequence of characters that may appear in the generated content.\nDepending on the level of contextual information contained in them, prompts are broadly classified into three types.\nThese prompts don't contain examples for the model to replicate. Zero-shot prompts essentially show the model's ability to complete the prompt without any additional examples or information. It means the model has to rely on its pre-existing knowledge to generate a plausible answer.\nSome commonly used zero-shot prompt patterns are:\nInstruction-content\n<Overall instruction>\nSummarize the following into two sentences at the third-grade level:\nfor their long, thin beaks and their ability to fly at high speeds.\nHummingbirds are made up of three main parts: the head, the body, and the tail.\nThe head is small and round, and it contains the eyes, the beak, and the brain.\nThe body is long and slender, and it contains the wings, the legs, and the\nheart. The tail is long and forked, and it helps the hummingbird to balance\nwhile it is flying.\nto change their color!\nHummingbirds are very active creatures. They spend most of their time flying,\nand they are also very good at hovering. Hummingbirds need to eat a lot of food\nin order to maintain their energy, and they often visit flowers to drink nectar.\nHummingbirds are amazing creatures. They are small, but they are also very\npowerful. They are beautiful, and they are very important to the ecosystem.\nInstruction-content-instruction\n<Overall instruction or context setting>\n<Final instruction>\nHere is some text I'd like you to summarize:\nfor their long, thin beaks and their ability to fly at high speeds. Hummingbirds\nare made up of three main parts: the head, the body, and the tail. The head is\nsmall and round, and it contains the eyes, the beak, and the brain. The body is\nlong and slender, and it contains the wings, the legs, and the heart. The tail\nis long and forked, and it helps the hummingbird to balance while it is flying.\nto change their color! Hummingbirds are very active creatures. They spend most\nof their time flying, and they are also very good at hovering. Hummingbirds need\nto eat a lot of food in order to maintain their energy, and they often visit\nflowers to drink nectar. Hummingbirds are amazing creatures. They are small, but\nthey are also very powerful. They are beautiful, and they are very important to\nthe ecosystem.\nSummarize it in two sentences at the third-grade reading level.\nContinuation. Sometimes, you can have the model continue text without any instructions. For example, here is a zero-shot prompt where the model is intended to continue the input provided:\nOnce upon a time, there was a little sparrow building a nest in a farmer's\nbarn. This sparrow\nUse zero-shot prompts to generate creative text formats, such as poems, code, scripts, musical pieces, email, or letters.\nThese prompts provide the model with a single example to replicate and continue the pattern. This allows for the generation of predictable responses from the model.\nFor example, you can generate food pairings like:\nFood: Apple\nPairs with: Cheese\nFood: Pear\nPairs with:\nThese prompts provide the model with multiple examples to replicate. Use few-shot prompts to complete complicated tasks, such as synthesizing data based on a pattern.\nAn example prompt may be:\nGenerate a grocery shopping list for a week for one person. Use the JSON format\ngiven below.\n{\"item\": \"eggs\", \"quantity\": \"6\"}\n{\"item\": \"bread\", \"quantity\": \"one loaf\"}\nThis section aims to answer the question - Is there randomness in generative models' responses, or are they deterministic?\nThe short answer - yes to both. When you prompt a generative model, a text response is generated in two stages. In the first stage, the generative model processes the input prompt and generates a probability distribution over possible tokens (words) that are likely to come next. For example, if you prompt with the input text \"The dog jumped over the ... \", the generative model will produce an array of probable next words:\n[(\"fence\", 0.77), (\"ledge\", 0.12), (\"blanket\", 0.03), ...]\nThis process is deterministic; a generative model will produce this same distribution every time it's input the same prompt text.\nIn the second stage, the generative model converts these distributions into actual text responses through one of several decoding strategies. A simple decoding strategy might select the most likely token at every timestep. This process would always be deterministic. However, you could instead choose to generate a response by randomly sampling over the distribution returned by the model. This process would be stochastic (random). Control the degree of randomness allowed in this decoding process by setting the temperature. A temperature of 0 means only the most likely tokens are selected, and there's no randomness. Conversely, a high temperature injects a high degree of randomness into the tokens selected by the model, leading to more unexpected, surprising model responses.\nNow that you have a deeper understanding of prompts and generative models, try writing your own prompts using Google AI Studio.\nRefer to the Prompt guidelines to learn more about best practices for creating prompts.",
            "filtered_word_count": 2077
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nSafety and intended use\nModel sizes\nModel versions\nModel variations\nModel metadata\nModel attributes\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini models \nbookmark_border\n\nGemini is a family of generative AI models that lets developers generate content and solve problems. These models are designed and trained to handle both text and images as input. This guide provides information about each model variant to help you decide which is the best fit for your use case.\n\nHere is a quick summary of the available models and their capabilities:\n\nModels\tInput\tOutput\nGemini\t\t\n\nGemini 1.5 Pro (Preview only)\n\tText and images\tText\n\nGemini 1.0 Pro\n\tText\tText\n\nGemini 1.0 Pro Vision\n\tText and images\tText\nEmbeddings\t\t\n\nEmbedding\n\tText\tText embeddings\nRetrieval\t\t\n\nAQA\n\tText\tText\nSafety and intended use\n\nGenerative artificial intelligence models are powerful tools, but they are not without their limitations. Their versatility and applicability can sometimes lead to unexpected outputs, such as outputs that are inaccurate, biased, or offensive. Post-processing, and rigorous manual evaluation are essential to limit the risk of harm from such outputs. See the safety guidance for additional safe use suggestions.\n\nThe models provide by the Gemini API can be used for a wide variety of generative AI and natural language processing (NLP) applications. Use of these functions is only available through the Gemini API or the Google AI Studio web app. Your use of Gemini API is also subject to the Generative AI Prohibited Use Policy and the Gemini API terms of service.\n\nModel sizes\n\nThe following table shows the available sizes and what they mean relative to each other.\n\nModel size\tDescription\tServices\nGemini 1.0 Pro\tA model size that balances capability and efficiency.\t\ntext\nchat\nModel versions\n\nGemini models are available in either preview or stable versions. In your code, you can use one of the following model name formats to specify which model and version you want to use.\n\nLatest: Points to the cutting-edge version of the model for a specified generation and variation. The underlying model is updated regularly and might be a preview version. Only exploratory testing apps and prototypes should use this alias.\n\nTo specify the latest version, use the following pattern: <model>-<generation>-<variation>-latest. For example, gemini-1.0-pro-latest.\n\nLatest stable: Points to the most recent stable version released for the specified model generation and variation.\n\nTo specify the latest stable version, use the following pattern: <model>-<generation>-<variation>. For example, gemini-1.0-pro.\n\nStable: Points to a specific stable model. Stable models don't change. Most production apps should use a specific stable model.\n\nTo specify a stable version, use the following pattern: <model>-<generation>-<variation>-<version>. For example, gemini-1.0-pro-001.\n\nNote: gemini-pro is an alias for gemini-1.0-pro.\n\nFor models that have a stable version, see the \"Model names\" row for the model in Model variations.\n\nModel variations\n\nThe Gemini API offers different models optimized for specific use cases. The following table describes attributes of each.\n\nNote: For Gemini models, a token is equivalent to about 4 characters. 100 tokens are about 60-80 English words.\nVariation\tAttribute\tDescription\nGemini 1.5 Pro (Preview only)\tModel last updated\tApril 2024\nModel code\tmodels/gemini-1.5-pro-latest\nModel capabilities\t\nInput: audio, image, text\nOutput: text\nOptimized for language tasks such as:\nCode generation\nText generation\nText editing\nProblem solving\nRecommendations generation\nInformation extraction\nData extraction or generation\nAI agent\nCan handle zero, one, and few-shot tasks.\n\nSupported generation methods\tgenerateContent\nInput token limit\t1048576\nOutput token limit\t8192\nModel safety\tAutomatically applied safety settings which are adjustable by developers. See the safety settings topic for details.\nRate limit\t2 queries per minute, 1000 queries per day [1]\n\nGemini Pro\tModel last updated\tFebruary 2024\nModel code\tmodels/gemini-pro\nModel capabilities\t\nInput: text\nOutput: text\nGenerates text.\nCan handle multi-turn conversational format.\nCan handle zero, one, and few-shot tasks.\n\nSupported generation methods\tgenerateContent\nInput token limit\t30720\nOutput token limit\t2048\nModel safety\tAutomatically applied safety settings which are adjustable by developers. See the safety settings topic for details.\nRate limit\t60 requests per minute [1]\nModel names\t\nLatest version: gemini-1.0-pro-latest\nLatest stable version: gemini-1.0-pro\nStable versions:\ngemini-1.0-pro-001\n\n\nGemini 1.0 Pro Vision\tModel last updated\tDecember 2023\nModel code\tmodels/gemini-pro-vision\nModel capabilities\t\nInput: text and images\nOutput: text\nCan take multimodal inputs, text and image.\nCan handle zero, one, and few-shot tasks.\n\nSupported generation methods\tgenerateContent\nInput token limit\t12288\nOutput token limit\t4096\nModel safety\tAutomatically applied safety settings which are adjustable by developers. See the safety settings topic for details.\nRate limit\t60 requests per minute [1]\n\nEmbedding\tModel last updated\tDecember 2023\nModel code\tmodels/embedding-001\nModel capabilities\t\nInput: text\nOutput: text\nGenerates text embeddings for the input text.\nOptimized for creating embeddings for text of up to 2048 tokens.\n\nSupported generation methods\tembedContent\nModel safety\tNo adjustable safety settings.\nRate limit\t1500 requests per minute [1]\n\nText Embedding\tModel last updated\tApril 2024\nModel code\tmodels/text-embedding-004 (text-embedding-preview-0409 in Vertex AI)\nModel capabilities\t\nInput: text\nOutput: text\nGenerates text embeddings for the input text.\nSupports elastic embedding sizes under 768.\n\nSupported generation methods\tembedContent\nModel safety\tNo adjustable safety settings.\nRate limit\t1500 requests per minute [1]\n\nAQA\tModel last updated\tDecember 2023\nModel code\tmodels/aqa\nModel capabilities\t\nInput: text\nOutput: text\nModel that performs Attributed Question Answering.\nModel trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n\nSupported generation methods\tgenerateAnswer\nSupported languages\tEnglish\nInput token limit\t7168\nOutput token limit\t1024\nModel safety\tAutomatically applied safety settings which are adjustable by developers. See the safety settings topic for details.\nRate limit\t60 requests per minute [1]\n\nSee the examples to explore the capabilities of these model variations.\n\nModel metadata\n\nUse the ModelService API to get additional metadata about the latest models such as input and output token limits. The following table displays the metadata for the Gemini Pro model variant.\n\nAttribute\tValue\nDisplay name\tGemini 1.0 Pro\nModel code\tmodels/gemini-1.0-pro\nDescription\tModel targeted for text generation\nSupported generation methods\tgenerateContent\nTemperature\t0.9\ntop_p\t1\ntop_k\t1\nModel attributes\n\nThe following table describes the attributes of the Gemini models which are common to all model variations.\n\nNote: The configurable parameters apply only to the text and chat model variations, but not embeddings.\nAttribute\tDescription\nTraining data\tGemini's knowledge cutoff is early 2023. Knowledge about events after that time is limited.\nSupported languages\tSee available languages\nConfigurable model parameters\t\nTop p\nTop k\nTemperature\nStop sequence\nMax output length\nNumber of response candidates\n\n[1] Due to capacity limitations, specified maximum rate limits are not guaranteed.\n\nSee the model parameters section of the Intro to LLMs guide for information about each of these parameters.\n\nNext steps\nFor a no-code way to get started, see the Google AI Studio quickstart.\nTo get started using the API, see the Python quickstart.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 1294,
            "filtered_content": "Gemini models \nGemini is a family of generative AI models that lets developers generate content and solve problems. These models are designed and trained to handle both text and images as input. This guide provides information about each model variant to help you decide which is the best fit for your use case.\nHere is a quick summary of the available models and their capabilities:\nModels\tInput\tOutput\nGemini\t\t\nGemini 1.5 Pro (Preview only)\nGemini 1.0 Pro\nGemini 1.0 Pro Vision\nEmbeddings\t\t\n\tText\tText embeddings\nRetrieval\t\t\nAQA\nGenerative artificial intelligence models are powerful tools, but they are not without their limitations. Their versatility and applicability can sometimes lead to unexpected outputs, such as outputs that are inaccurate, biased, or offensive. Post-processing, and rigorous manual evaluation are essential to limit the risk of harm from such outputs. See the safety guidance for additional safe use suggestions.\nThe models provide by the Gemini API can be used for a wide variety of generative AI and natural language processing (NLP) applications. Use of these functions is only available through the Gemini API or the Google AI Studio web app. Your use of Gemini API is also subject to the Generative AI Prohibited Use Policy and the Gemini API terms of service.\nThe following table shows the available sizes and what they mean relative to each other.\nModel size\tDescription\tServices\nGemini 1.0 Pro\tA model size that balances capability and efficiency.\t\ntext\nGemini models are available in either preview or stable versions. In your code, you can use one of the following model name formats to specify which model and version you want to use.\nLatest: Points to the cutting-edge version of the model for a specified generation and variation. The underlying model is updated regularly and might be a preview version. Only exploratory testing apps and prototypes should use this alias.\nTo specify the latest version, use the following pattern: <model>-<generation>-<variation>-latest. For example, gemini-1.0-pro-latest.\nLatest stable: Points to the most recent stable version released for the specified model generation and variation.\nTo specify the latest stable version, use the following pattern: <model>-<generation>-<variation>. For example, gemini-1.0-pro.\nStable: Points to a specific stable model. Stable models don't change. Most production apps should use a specific stable model.\nTo specify a stable version, use the following pattern: <model>-<generation>-<variation>-<version>. For example, gemini-1.0-pro-001.\nNote: gemini-pro is an alias for gemini-1.0-pro.\nFor models that have a stable version, see the \"Model names\" row for the model in Model variations.\nThe Gemini API offers different models optimized for specific use cases. The following table describes attributes of each.\nNote: For Gemini models, a token is equivalent to about 4 characters. 100 tokens are about 60-80 English words.\nVariation\tAttribute\tDescription\nGemini 1.5 Pro (Preview only)\tModel last updated\tApril 2024\nModel code\tmodels/gemini-1.5-pro-latest\nInput: audio, image, text\nOptimized for language tasks such as:\nCode generation\nText generation\nText editing\nProblem solving\nRecommendations generation\nInformation extraction\nData extraction or generation\nAI agent\nInput token limit\t1048576\nOutput token limit\t8192\nRate limit\t2 queries per minute, 1000 queries per day [1]\nGemini Pro\tModel last updated\tFebruary 2024\nModel code\tmodels/gemini-pro\nGenerates text.\nCan handle multi-turn conversational format.\nInput token limit\t30720\nOutput token limit\t2048\nModel names\t\nLatest version: gemini-1.0-pro-latest\nLatest stable version: gemini-1.0-pro\nStable versions:\ngemini-1.0-pro-001\nGemini 1.0 Pro Vision\tModel last updated\tDecember 2023\nModel code\tmodels/gemini-pro-vision\nInput: text and images\nCan take multimodal inputs, text and image.\nInput token limit\t12288\nOutput token limit\t4096\nEmbedding\tModel last updated\tDecember 2023\nModel code\tmodels/embedding-001\nOptimized for creating embeddings for text of up to 2048 tokens.\nText Embedding\tModel last updated\tApril 2024\nModel code\tmodels/text-embedding-004 (text-embedding-preview-0409 in Vertex AI)\nSupports elastic embedding sizes under 768.\nAQA\tModel last updated\tDecember 2023\nModel code\tmodels/aqa\nModel that performs Attributed Question Answering.\nModel trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\nSupported generation methods\tgenerateAnswer\nSupported languages\tEnglish\nInput token limit\t7168\nOutput token limit\t1024\nSee the examples to explore the capabilities of these model variations.\nUse the ModelService API to get additional metadata about the latest models such as input and output token limits. The following table displays the metadata for the Gemini Pro model variant.\nAttribute\tValue\nDisplay name\tGemini 1.0 Pro\nModel code\tmodels/gemini-1.0-pro\nDescription\tModel targeted for text generation\nTemperature\t0.9\ntop_p\t1\ntop_k\t1\nThe following table describes the attributes of the Gemini models which are common to all model variations.\nNote: The configurable parameters apply only to the text and chat model variations, but not embeddings.\nAttribute\tDescription\nTraining data\tGemini's knowledge cutoff is early 2023. Knowledge about events after that time is limited.\nSupported languages\tSee available languages\nConfigurable model parameters\t\nTop p\nTop k\nTemperature\nStop sequence\nMax output length\nNumber of response candidates\n[1] Due to capacity limitations, specified maximum rate limits are not guaranteed.\nSee the model parameters section of the Intro to LLMs guide for information about each of these parameters.\nFor a no-code way to get started, see the Google AI Studio quickstart.\nTo get started using the API, see the Python quickstart.",
            "filtered_word_count": 857
        },
        "https://ai.google.dev/gemini-api/docs/api-overview": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nModels\nPrompt data and design\nPrompt design and text input\nGenerate content\nText and image input\nText only input\nMulti-turn conversations (chat)\nStreamed responses\nJSON format responses\nEmbeddings\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API Overview \nbookmark_border\n\nThe Gemini API gives you access to the latest generative models from Google. Once you're familiar with the general features available to you through the API, try a tutorial for your language of choice to start developing.\n\nNote: If you're new to generative AI models, visit the generative models guide or start prototyping your prompts in the Google AI Studio.\nModels\n\nGemini is a series of multimodal generative AI models developed by Google. Gemini models can accept text and image in prompts, depending on what model variation you choose, and output text responses.\n\nTo get more detailed model information refer to the Gemini models page. You can also use the list_models method to list all the models available and then the get_model method to get the metadata for a particular model.\n\nPrompt data and design\n\nSpecific Gemini models accept both text data and media files as input. This capability creates many additional possibilities for generating content, analyzing data, and solving problems. There are some limitations and requirements to consider, including the general input token limit for the model you are using. For information on the token limits for specific models, see Gemini models.\n\nPrompts using the Gemini API cannot exceed 20MB in size. The Gemini API provides a File API for temporarily storing media files for use in prompting, which lets you provide prompt data beyond the 20MB limit. For more information on using the Files API and file formats supported for prompting, see Prompting with media files.\n\nPrompt design and text input\n\nCreating effective prompts, or prompt engineering, is a combination of art and science. See the intro to prompting for guidance on how to approach prompting and the prompt 101 guide to learn about different approaches to prompting.\n\nGenerate content\n\nThe Gemini API lets you use both text and image data for prompting, depending on what model variation you use. For example, you can generate text using text prompts with the gemini-pro model and use both text and image data to prompt the gemini-pro-vision model. This section gives simple code examples of each. Refer to the generateContent API reference for a more detailed example that covers all of the parameters.\n\nText and image input\n\nYou can send a text prompt with an image to the gemini-pro-vision model to perform a vision related task. For example, captioning an image or identifying what's in an image.\n\nNote: You can't send a text-only prompt to the gemini-pro-vision model. Use the gemini-pro model for text-only prompts.\n\nThe following code examples demonstrate a simple implementation of a text and image prompt for each supported language:\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\ncURL\nmodel = genai.GenerativeModel('gemini-pro-vision')\n\ncookie_picture = [{\n    'mime_type': 'image/png',\n    'data': pathlib.Path('cookie.png').read_bytes()\n}]\nprompt = \"Do these look store-bought or homemade?\"\n\nresponse = model.generate_content(\n    model=\"gemini-pro-vision\",\n    content=[prompt, cookie_picture]\n)\nprint(response.text)\n\n\nSee the Python tutorial to see the complete code snippet.\n\nText only input\n\nThe Gemini API can also handle text-only input. This feature lets you perform natural language processing (NLP) tasks such as text completion and summarization.\n\nThe following code examples demonstrate a simple implementation of a text-only prompt for each supported language:\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\ncURL\nmodel = genai.GenerativeModel('gemini-pro-vision')\n\nprompt = \"Write a story about a magic backpack.\"\n\nresponse = model.generate_content(prompt)\n\n\nSee the Python tutorial for the full example.\n\nMulti-turn conversations (chat)\n\nYou can use the Gemini API to build interactive chat experiences for your users. Using the chat feature of the API lets you collect multiple rounds of questions and responses, allowing users to incrementally step toward answers or get help with multi-part problems. This feature is ideal for applications that require ongoing communication, such as chatbots, interactive tutors, or customer support assistants.\n\nThe following code examples demonstrate a simple implementation of chat interaction for each supported language:\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\ncURL\n  model = genai.GenerativeModel('gemini-pro')\n  chat = model.start_chat(history=[])\n\n  response = chat.send_message(\n      \"Pretend you\\'re a snowman and stay in character for each response.\")\n  print(response.text)\n\n  response = chat.send_message(\n      \"What\\'s your favorite season of the year?\")\n  print(response.text)\n\n\nSee the chat demo in the Python tutorial for a full example.\n\nStreamed responses\n\nThe Gemini API provides an additional way to receive responses from generative AI models: as a data stream. A streamed response sends incremental pieces of data back to your application as it is generated by the model. This feature lets you respond quickly to a user request to show progress and create a more interactive experience.\n\nStreamed responses are an option for freeform prompting and chats with Gemini models. The following code examples show how to request a streamed response for a prompt for each supported language:\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\ncURL\nprompt = \"Write a story about a magic backpack.\"\n\nresponse = genai.stream_generate_content(\n    model=\"models/gemini-pro\",\n    prompt=prompt\n)\n\n\nSee the Python tutorial to see the complete code snippet.\n\nJSON format responses\n\nDepending on your application, you may want the response to a prompt to be returned in a structured data format, particularly if you are using the responses to populate programming interfaces. The Gemini API provides a configuration parameter to request a response in JSON format.\n\nNote: This response configuration option is supported only with the Gemini 1.5 Pro model.\n\nYou use this output feature by setting the response_mime_type configuration option to application/json and including a JSON format specification in the body of your request. The following code example shows how to request a JSON response for a prompt:\n\ncURL\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=$API_KEY \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{ \"contents\":[{\n            \"parts\":[{\"text\": \"List 5 popular cookie recipes using this JSON schema: \\{ \\\"type\\\": \\\"object\\\", \\\"properties\\\": \\{ \\\"recipe_name\\\": \\{ \\\"type\\\": \\\"string\\\" \\},\\}\\}\"}] }],\n          \"generationConfig\": {\n            \"response_mime_type\": \"application/json\",\n          } }'\n\nEmbeddings\n\nThe embedding service in the Gemini API generates state-of-the-art embeddings for words, phrases, and sentences. The resulting embeddings can then be used for NLP tasks, such as semantic search, text classification, and clustering, among many others. See the embeddings guide to learn what embeddings are and some key use cases for the embedding service to help you get started.\n\nNext steps\nGet started with the Google AI Studio UI using the Google AI Studio quickstart.\nTry out server-side access to the Gemini API with the tutorials for Python, Go, or Node.js.\nStart building for the web with the web tutorial.\nStart building for mobile apps with the Swift tutorial or the Android tutorial.\nIf you're an existing Google Cloud user (or you would like to use Gemini on Vertex to take advantage of the powerful Google Cloud ecosystem), check out Generative AI on Vertex AI to learn more.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 1314,
            "filtered_content": "Gemini API Overview \nThe Gemini API gives you access to the latest generative models from Google. Once you're familiar with the general features available to you through the API, try a tutorial for your language of choice to start developing.\nNote: If you're new to generative AI models, visit the generative models guide or start prototyping your prompts in the Google AI Studio.\nGemini is a series of multimodal generative AI models developed by Google. Gemini models can accept text and image in prompts, depending on what model variation you choose, and output text responses.\nTo get more detailed model information refer to the Gemini models page. You can also use the list_models method to list all the models available and then the get_model method to get the metadata for a particular model.\nSpecific Gemini models accept both text data and media files as input. This capability creates many additional possibilities for generating content, analyzing data, and solving problems. There are some limitations and requirements to consider, including the general input token limit for the model you are using. For information on the token limits for specific models, see Gemini models.\nPrompts using the Gemini API cannot exceed 20MB in size. The Gemini API provides a File API for temporarily storing media files for use in prompting, which lets you provide prompt data beyond the 20MB limit. For more information on using the Files API and file formats supported for prompting, see Prompting with media files.\nCreating effective prompts, or prompt engineering, is a combination of art and science. See the intro to prompting for guidance on how to approach prompting and the prompt 101 guide to learn about different approaches to prompting.\nThe Gemini API lets you use both text and image data for prompting, depending on what model variation you use. For example, you can generate text using text prompts with the gemini-pro model and use both text and image data to prompt the gemini-pro-vision model. This section gives simple code examples of each. Refer to the generateContent API reference for a more detailed example that covers all of the parameters.\nYou can send a text prompt with an image to the gemini-pro-vision model to perform a vision related task. For example, captioning an image or identifying what's in an image.\nNote: You can't send a text-only prompt to the gemini-pro-vision model. Use the gemini-pro model for text-only prompts.\nThe following code examples demonstrate a simple implementation of a text and image prompt for each supported language:\ncookie_picture = [{\n    'mime_type': 'image/png',\n    'data': pathlib.Path('cookie.png').read_bytes()\n}]\nprompt = \"Do these look store-bought or homemade?\"\n    model=\"gemini-pro-vision\",\n    content=[prompt, cookie_picture]\nThe Gemini API can also handle text-only input. This feature lets you perform natural language processing (NLP) tasks such as text completion and summarization.\nThe following code examples demonstrate a simple implementation of a text-only prompt for each supported language:\nresponse = model.generate_content(prompt)\nSee the Python tutorial for the full example.\nYou can use the Gemini API to build interactive chat experiences for your users. Using the chat feature of the API lets you collect multiple rounds of questions and responses, allowing users to incrementally step toward answers or get help with multi-part problems. This feature is ideal for applications that require ongoing communication, such as chatbots, interactive tutors, or customer support assistants.\nThe following code examples demonstrate a simple implementation of chat interaction for each supported language:\n  model = genai.GenerativeModel('gemini-pro')\n  chat = model.start_chat(history=[])\n      \"Pretend you\\'re a snowman and stay in character for each response.\")\n      \"What\\'s your favorite season of the year?\")\nSee the chat demo in the Python tutorial for a full example.\nThe Gemini API provides an additional way to receive responses from generative AI models: as a data stream. A streamed response sends incremental pieces of data back to your application as it is generated by the model. This feature lets you respond quickly to a user request to show progress and create a more interactive experience.\nStreamed responses are an option for freeform prompting and chats with Gemini models. The following code examples show how to request a streamed response for a prompt for each supported language:\nresponse = genai.stream_generate_content(\n    model=\"models/gemini-pro\",\n    prompt=prompt\nDepending on your application, you may want the response to a prompt to be returned in a structured data format, particularly if you are using the responses to populate programming interfaces. The Gemini API provides a configuration parameter to request a response in JSON format.\nNote: This response configuration option is supported only with the Gemini 1.5 Pro model.\nYou use this output feature by setting the response_mime_type configuration option to application/json and including a JSON format specification in the body of your request. The following code example shows how to request a JSON response for a prompt:\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=$API_KEY \\\n    -d '{ \"contents\":[{\n            \"parts\":[{\"text\": \"List 5 popular cookie recipes using this JSON schema: \\{ \\\"type\\\": \\\"object\\\", \\\"properties\\\": \\{ \\\"recipe_name\\\": \\{ \\\"type\\\": \\\"string\\\" \\},\\}\\}\"}] }],\n          \"generationConfig\": {\n            \"response_mime_type\": \"application/json\",\n          } }'\nThe embedding service in the Gemini API generates state-of-the-art embeddings for words, phrases, and sentences. The resulting embeddings can then be used for NLP tasks, such as semantic search, text classification, and clustering, among many others. See the embeddings guide to learn what embeddings are and some key use cases for the embedding service to help you get started.\nGet started with the Google AI Studio UI using the Google AI Studio quickstart.\nTry out server-side access to the Gemini API with the tutorials for Python, Go, or Node.js.\nStart building for the web with the web tutorial.\nStart building for mobile apps with the Swift tutorial or the Android tutorial.\nIf you're an existing Google Cloud user (or you would like to use Gemini on Vertex to take advantage of the powerful Google Cloud ecosystem), check out Generative AI on Vertex AI to learn more.",
            "filtered_word_count": 971
        },
        "https://ai.google.dev/gemini-api/docs/api-versions": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nAPI versions explained \nbookmark_border\n\nThis document provides a high-level overview of the differences between the v1 and v1beta versions of the Gemini API.\n\nv1: Stable version of the API. Features in the stable version are fully-supported over the lifetime of the major version. If there are any breaking changes, then the next major version of the API will be created and the existing version will be deprecated after a reasonable period of time. Non-breaking changes may be introduced to the API without changing the major version.\nv1beta: This version includes early-access features that may be under development and is subject to rapid and breaking changes. There is also no guarantee that the features in the Beta version will move to the stable version. Due to this instability, you shouldn't launch production applications with this version.\nFeature\tv1\tv1beta\nGenerate Content - Text-only input\t\t\nGenerate Content - Text-and-image input\t\t\nGenerate Content - Text output\t\t\nGenerate Content - Multi-turn conversations (chat)\t\t\nGenerate Content - Function calls\t\t\nGenerate Content - Streaming\t\t\nEmbed Content - Text-only input\t\t\nGenerate Answer\t\t\nSemantic retriever\t\t\nGenerate Text (PaLM)\t\t\nGenerate Embedding (PaLM)\t\t\nGenerate Message (PaLM)\t\t\nTuning (PaLM)\t\t\n - Supported\n - Will never be supported\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 372,
            "filtered_content": "API versions explained \nThis document provides a high-level overview of the differences between the v1 and v1beta versions of the Gemini API.\nv1: Stable version of the API. Features in the stable version are fully-supported over the lifetime of the major version. If there are any breaking changes, then the next major version of the API will be created and the existing version will be deprecated after a reasonable period of time. Non-breaking changes may be introduced to the API without changing the major version.\nv1beta: This version includes early-access features that may be under development and is subject to rapid and breaking changes. There is also no guarantee that the features in the Beta version will move to the stable version. Due to this instability, you shouldn't launch production applications with this version.\nFeature\tv1\tv1beta\nGenerate Content - Text-only input\t\t\nGenerate Content - Text-and-image input\t\t\nGenerate Content - Text output\t\t\nGenerate Content - Multi-turn conversations (chat)\t\t\nGenerate Content - Function calls\t\t\nGenerate Content - Streaming\t\t\nEmbed Content - Text-only input\t\t\nGenerate Answer\t\t\nSemantic retriever\t\t\nGenerate Text (PaLM)\t\t\nGenerate Embedding (PaLM)\t\t\nGenerate Message (PaLM)\t\t\nTuning (PaLM)\t\t\n - Supported\n - Will never be supported",
            "filtered_word_count": 194
        },
        "https://ai.google.dev/gemini-api/docs/changelog": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nDecember 13 2023\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nRelease notes \nbookmark_border\n\nThis page documents updates to the Gemini API.\n\nDecember 13 2023\n\n4 new models:\n\ngemini-pro: New text model for a wide variety of tasks. Balances capability and efficiency.\ngemini-pro-vision: New multimodal model for a wide variety of tasks. Balances capability and efficiency.\nembedding-001: New embeddings model.\naqa: A new specially tuned model that is trained to answer questions using text passages for grounding generated answers.\n\nSee Gemini models for more details.\n\nAPI version updates:\n\nv1: The stable API channel.\nv1beta: Beta channel. This channel has features that may be under development.\n\nSee the API versions topic for more details.\n\nCapabilities updates\n\nGenerateContent is a single unified endpoint for chat and text.\nStreaming available through the StreamGenerateContent method.\nMultimodal capability: Image is a new supported modality\nNew beta features:\nFunction Calling\nSemantic Retriever\nAttributed Question Answering (AQA)\nUpdated candidate count: Gemini models only return 1 candidate.\nDifferent Safety Settings and SafetyRating categories. See safety settings for more details.\nTuning models is not yet supported for Gemini models (Work in progress).\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 355,
            "filtered_content": "Release notes \nThis page documents updates to the Gemini API.\n4 new models:\ngemini-pro: New text model for a wide variety of tasks. Balances capability and efficiency.\ngemini-pro-vision: New multimodal model for a wide variety of tasks. Balances capability and efficiency.\nembedding-001: New embeddings model.\naqa: A new specially tuned model that is trained to answer questions using text passages for grounding generated answers.\nSee Gemini models for more details.\nAPI version updates:\nv1: The stable API channel.\nv1beta: Beta channel. This channel has features that may be under development.\nSee the API versions topic for more details.\nCapabilities updates\nGenerateContent is a single unified endpoint for chat and text.\nStreaming available through the StreamGenerateContent method.\nMultimodal capability: Image is a new supported modality\nNew beta features:\nFunction Calling\nSemantic Retriever\nAttributed Question Answering (AQA)\nUpdated candidate count: Gemini models only return 1 candidate.\nDifferent Safety Settings and SafetyRating categories. See safety settings for more details.\nTuning models is not yet supported for Gemini models (Work in progress).",
            "filtered_word_count": 168
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nIntro to model tuning\nTuning with AI Studio\nTuning with Python\nTuning with REST\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nHow model tuning works\nSupported models\nWorkflow for model tuning\nPrepare your dataset\nFormat\nTraining data size\nUpload tuning dataset\nAdvanced tuning settings\nRecommended configurations\nCheck tuning job status\nTroubleshoot errors\nAuthentication\nCanceled models\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nIntro to model tuning \nbookmark_border\n\nPrompt design strategies such as few shot prompting may not always produce the results you need. Use model tuning to improve a model's performance on specific tasks or help the model adhere to specific output requirements when instructions aren't sufficient and you have a set of examples that demonstrate the outputs you want.\n\nThis page provides guidance on tuning the text model behind the Gemini API text service.\n\nNote: Tuning is available for the gemini-1.0-pro-001 and text-bison-001 models.\nHow model tuning works\n\nThe goal of model tuning is to further improve the performance of the model for your specific task. Model tuning works by providing the model with a training dataset containing many examples of the task. For niche tasks, you can get significant improvements in model performance by tuning the model on a modest number of examples.\n\nYour training data should be structured as examples with prompt inputs and expected response outputs. You can also tune models using example data directly in Google AI Studio. The goal is to teach the model to mimic the wanted behavior or task, by giving it many examples illustrating that behavior or task.\n\nWhen you run a tuning job, the model learns additional parameters that help it encode the necessary information to perform the wanted task or learn the wanted behavior. These parameters can then be used at inference time. The output of the tuning job is a new model, which is effectively a combination of the newly learned parameters, and the original model.\n\nSupported models\n\nThe following foundation models support model tuning. Only single-turn text completion is supported.\n\nGemini 1.0 Pro\ntext-bison-001\nWorkflow for model tuning\n\nThe model tuning workflow is as follows:\n\nPrepare your dataset.\nImport the dataset if you're using Google AI Studio.\nStart a tuning job.\n\nAfter model tuning completes, the name of your tuned model is displayed. You can also select it in Google AI Studio as the model to use when creating a new prompt.\n\nPrepare your dataset\n\nBefore you can start tuning, you need a dataset to tune the model with. For best performance, the examples in the dataset should be of high quality, diverse and representative of real inputs and outputs.\n\nFormat\n\nThe examples included in your dataset should match your expected production traffic. If your dataset contains specific formatting, keywords, instructions, or information, the production data should be formatted in the same way and contain the same instructions.\n\nFor example, if the examples in your dataset include a \"question:\" and a \"context:\", production traffic should also be formatted to include a \"question:\" and a \"context:\" in the same order as it appears in the dataset examples. If you exclude the context, the model can't recognize the pattern, even if the exact question was in an example in the dataset.\n\nAdding a prompt or preamble to each example in your dataset can also help improve the performance of the tuned model. Note, if a prompt or preamble is included in your dataset, it should also be included in the prompt to the tuned model at inference time.\n\nTraining data size\n\nYou can tune a model with as little as 20 examples, and additional data generally improves the quality of the responses. You should target between 100 and 500 examples, depending on your application. The following table shows recommended dataset sizes for tuning a text model for various common tasks:\n\nTask\tNo. of examples in dataset\nClassification\t100+\nSummarization\t100-500+\nDocument search\t100+\nUpload tuning dataset\n\nData is either passed inline using the API or through files uploaded in Google AI Studio.\n\nUse the Import button to import data from a file or choose a structured prompt with examples to import as your tuning dataset.\n\nClient library\n\nTo use the client library, provide the data file in the createTunedModel call. File size limit is 4MB. See the tuning quickstart with Python to get started.\n\nCurl\n\nTo call the REST API using Curl, provide training examples in JSON format to the training_data argument. See the tuning quickstart with Curl to get started.\n\nAdvanced tuning settings\n\nWhen creating a tuning job, you can specify the following advanced settings:\n\nEpochs - A full training pass over the entire training set such that each example has been processed once.\nBatch size - The set of examples used in one training iteration. The batch size determines the number of examples in a batch.\nLearning rate - A floating-point number that tells the algorithm how strongly to adjust the model parameters on each iteration. For example, a learning rate of 0.3 would adjust weights and biases three times more powerfully than a learning rate of 0.1. High and low learning rates have their own unique trade-offs and should be adjusted based on your use case.\nLearning rate multiplier - The rate multiplier modifies the model's original learning rate. A value of 1 uses the original learning rate of the model. Values greater than 1 increase the learning rate and values between 1 and 0 lower the learning rate.\nRecommended configurations\n\nThe following table shows the recommended configurations for tuning a foundation model:\n\nHyperparameter\tDefault value\tRecommended adjustments\nEpoch\t5\tIf the loss starts to plateau before 5 epochs, use a smaller value.\nIf the loss is converging and doesn't seem to plateau, use a higher value.\nBatch size\t4\t\nLearning rate\t0.001\tUse a smaller value for smaller datasets.\n\nThe loss curve shows how much the model's prediction deviates from the ideal predictions in the training examples after each epoch. Ideally you want to stop training at the lowest point in the curve right before it plateaus. For example, the graph below shows the loss curve plateauing at about epoch 4-6 which means you can set the Epoch parameter to 4 and still get the same performance.\n\nCheck tuning job status\n\nYou can check the status of your tuning job in Google AI Studio UI under the My Library tab or using the metadata property of the tuned model in the Gemini API.\n\nTroubleshoot errors\n\nThis section includes tips on how to resolve errors you may encounter while creating your tuned model.\n\nAuthentication\n\nTuning using the API and client library requires user authentication. An API key alone is not sufficient. If you see a 'PermissionDenied: 403 Request had insufficient authentication scopes' error, you need to set up user authentication.\n\nTo configure OAuth credentials for Python refer to the OAuth setup tutorial.\n\nCanceled models\n\nYou can cancel a model tuning job any time before the job is finished. However, the inference performance of a canceled model is unpredictable, particularly if the tuning job is canceled early in the training. If you canceled because you want to stop the training at an earlier epoch, you should create a new tuning job and set the epoch to a lower value.\n\nWhat's next\nLearn about responsible AI best practices.\nGet started with the tuning quickstart with Python or the tuning quickstart with Curl.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 1392,
            "filtered_content": "Intro to model tuning\nTuning with AI Studio\nTuning with Python\nTuning with REST\nIntro to model tuning \nPrompt design strategies such as few shot prompting may not always produce the results you need. Use model tuning to improve a model's performance on specific tasks or help the model adhere to specific output requirements when instructions aren't sufficient and you have a set of examples that demonstrate the outputs you want.\nThis page provides guidance on tuning the text model behind the Gemini API text service.\nNote: Tuning is available for the gemini-1.0-pro-001 and text-bison-001 models.\nThe goal of model tuning is to further improve the performance of the model for your specific task. Model tuning works by providing the model with a training dataset containing many examples of the task. For niche tasks, you can get significant improvements in model performance by tuning the model on a modest number of examples.\nYour training data should be structured as examples with prompt inputs and expected response outputs. You can also tune models using example data directly in Google AI Studio. The goal is to teach the model to mimic the wanted behavior or task, by giving it many examples illustrating that behavior or task.\nWhen you run a tuning job, the model learns additional parameters that help it encode the necessary information to perform the wanted task or learn the wanted behavior. These parameters can then be used at inference time. The output of the tuning job is a new model, which is effectively a combination of the newly learned parameters, and the original model.\nThe following foundation models support model tuning. Only single-turn text completion is supported.\ntext-bison-001\nThe model tuning workflow is as follows:\nPrepare your dataset.\nImport the dataset if you're using Google AI Studio.\nStart a tuning job.\nAfter model tuning completes, the name of your tuned model is displayed. You can also select it in Google AI Studio as the model to use when creating a new prompt.\nBefore you can start tuning, you need a dataset to tune the model with. For best performance, the examples in the dataset should be of high quality, diverse and representative of real inputs and outputs.\nThe examples included in your dataset should match your expected production traffic. If your dataset contains specific formatting, keywords, instructions, or information, the production data should be formatted in the same way and contain the same instructions.\nFor example, if the examples in your dataset include a \"question:\" and a \"context:\", production traffic should also be formatted to include a \"question:\" and a \"context:\" in the same order as it appears in the dataset examples. If you exclude the context, the model can't recognize the pattern, even if the exact question was in an example in the dataset.\nAdding a prompt or preamble to each example in your dataset can also help improve the performance of the tuned model. Note, if a prompt or preamble is included in your dataset, it should also be included in the prompt to the tuned model at inference time.\nYou can tune a model with as little as 20 examples, and additional data generally improves the quality of the responses. You should target between 100 and 500 examples, depending on your application. The following table shows recommended dataset sizes for tuning a text model for various common tasks:\nTask\tNo. of examples in dataset\nClassification\t100+\nSummarization\t100-500+\nDocument search\t100+\nData is either passed inline using the API or through files uploaded in Google AI Studio.\nUse the Import button to import data from a file or choose a structured prompt with examples to import as your tuning dataset.\nClient library\nTo use the client library, provide the data file in the createTunedModel call. File size limit is 4MB. See the tuning quickstart with Python to get started.\nCurl\nTo call the REST API using Curl, provide training examples in JSON format to the training_data argument. See the tuning quickstart with Curl to get started.\nWhen creating a tuning job, you can specify the following advanced settings:\nEpochs - A full training pass over the entire training set such that each example has been processed once.\nBatch size - The set of examples used in one training iteration. The batch size determines the number of examples in a batch.\nLearning rate - A floating-point number that tells the algorithm how strongly to adjust the model parameters on each iteration. For example, a learning rate of 0.3 would adjust weights and biases three times more powerfully than a learning rate of 0.1. High and low learning rates have their own unique trade-offs and should be adjusted based on your use case.\nLearning rate multiplier - The rate multiplier modifies the model's original learning rate. A value of 1 uses the original learning rate of the model. Values greater than 1 increase the learning rate and values between 1 and 0 lower the learning rate.\nThe following table shows the recommended configurations for tuning a foundation model:\nHyperparameter\tDefault value\tRecommended adjustments\nEpoch\t5\tIf the loss starts to plateau before 5 epochs, use a smaller value.\nIf the loss is converging and doesn't seem to plateau, use a higher value.\nBatch size\t4\t\nLearning rate\t0.001\tUse a smaller value for smaller datasets.\nThe loss curve shows how much the model's prediction deviates from the ideal predictions in the training examples after each epoch. Ideally you want to stop training at the lowest point in the curve right before it plateaus. For example, the graph below shows the loss curve plateauing at about epoch 4-6 which means you can set the Epoch parameter to 4 and still get the same performance.\nYou can check the status of your tuning job in Google AI Studio UI under the My Library tab or using the metadata property of the tuned model in the Gemini API.\nThis section includes tips on how to resolve errors you may encounter while creating your tuned model.\nTuning using the API and client library requires user authentication. An API key alone is not sufficient. If you see a 'PermissionDenied: 403 Request had insufficient authentication scopes' error, you need to set up user authentication.\nTo configure OAuth credentials for Python refer to the OAuth setup tutorial.\nYou can cancel a model tuning job any time before the job is finished. However, the inference performance of a canceled model is unpredictable, particularly if the tuning job is canceled early in the training. If you canceled because you want to stop the training at an earlier epoch, you should create a new tuning job and set the epoch to a lower value.\nLearn about responsible AI best practices.\nGet started with the tuning quickstart with Python or the tuning quickstart with Curl.",
            "filtered_word_count": 1136
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nIntro to model tuning\nTuning with AI Studio\nTuning with Python\nTuning with REST\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nCreate tuning dataset\nCreate a tuned model\nUse the tuned model\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nTune a model with Google AI Studio \nbookmark_border\n\nWhen building an application with Gemini artificial intelligence (AI) models, you may want to provide stronger guidance for how the model responds to instructions or requests than what is possible with freeform prompts or structured prompts. Model tuning lets you change the behavior of a model more substantially and also requires significantly more training example data than what fits in a typical prompt. Another benefit of tuned models is they can be used with more than one prompt. For more information about model tuning, see the model tuning guide.\n\nThis guide describes how to create and use a tuned model with Google AI Studio.\n\nCreate tuning dataset\n\nTuning a model requires more examples, or training data, than standard prompting techniques. You can tune a model with as few as 20 examples. In general, you need between 100 and 500 examples to significantly change the behavior of the model. If you do not have a training dataset of this size or larger, try using structured prompts first, as this feature lets you guide the behavior of the model with as little as 3 or 4 training examples.\n\nThe training examples you provide in your tuning dataset guide the generative model in producing responses. At the minimum, each record in your dataset must have an input value, representing the prompt instruction, and an output value, representing the expected response from the generative model.\n\nHere's an example of input and output values for this prompt. In this case, the Product name is the input, or prompt, for the model, and the Product copy is the expected output:\n\nProduct name (input)\tProduct copy (output)\nOld-school sneaker\tLet's lace up! These kicks bring an iconic look and a one of a kind color palette, while supporting you in style and function like no other shoe before.\nSupersoft hoodie\tStay cozy and stylish in our new unisex hoodie! Made from 100% cotton, this hoodie is soft and comfortable to wear all day long. The semi-brushed inside will keep you warm on even the coldest days.\n\nA training dataset can have more than one input and more than one output, and you must have at least one input and one output for each record. You can create datasets using the structured prompts user interface in AI Studio, or import data from a Comma Separated Value (CSV) data file or Google Sheets spreadsheet.\n\nCreate a tuned model\n\nAfter you create a tuning dataset, you can build a tuned version of a Gemini model in AI Studio by providing your dataset and setting some configuration parameters. Once you have provided the required input, the system creates the tuned model, and then you can use it with your prompts.\n\nTo create a tuned model:\n\nIn the AI Studio web app, on the left side of the interface, select the Tuned model option.\nIn the Select Data for tuning dialog, connect your tuning dataset by selecting a Structured prompt or click the Import button to load a data in a comma separated value (.CSV) format file or a Google Sheets spreadsheet.\nIn the Tuned model name field, enter a name for your tuned model. This name appears as a selectable model once the tuning operation is complete.\nIn the Description field, enter an optional description of the tuned model.\nIn the Model field select the foundation model you want to use as the base for your tuned model.\nYou can optionally set Advanced settings for creating the tuned model. For more information about these settings, see the Model tuning guide.\nStart the process to create the tuned model by selecting Tune.\n\nThe system might take a few minutes or longer to build the tuned version depending on the size or your dataset, number of Epochs specified, and current system load. You can check on the status of the tuning process by selecting My Library on the left side of the application and looking for the name of the tuned model.\n\nNote: If you want to tune the PaLM legacy models in Google AI Studio, turn on the Show legacy models option in Settings.\nUse the tuned model\n\nAfter the model tuning build is complete, you can select the model for use with your prompts. You can use the tuned model with existing or new freeform or structured prompts, as long as those the prompts conform to the example structure of your tuned dataset.\n\nTo use a tuned model:\n\nIn the AI Studio web app, open an existing prompt or start a new one.\nIn the Run settings section, select the Model drop down, and select the name of the tuned model.\nCompose or update your prompt and select Run to use tuned model.\n\nTuning requires a significant amount of data to change the behavior of the generative model. If your prompts are not producing the behavior you want, evaluate your tuning dataset, your tuning parameters, and consider adding more examples.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 1032,
            "filtered_content": "Tune a model with Google AI Studio \nWhen building an application with Gemini artificial intelligence (AI) models, you may want to provide stronger guidance for how the model responds to instructions or requests than what is possible with freeform prompts or structured prompts. Model tuning lets you change the behavior of a model more substantially and also requires significantly more training example data than what fits in a typical prompt. Another benefit of tuned models is they can be used with more than one prompt. For more information about model tuning, see the model tuning guide.\nThis guide describes how to create and use a tuned model with Google AI Studio.\nTuning a model requires more examples, or training data, than standard prompting techniques. You can tune a model with as few as 20 examples. In general, you need between 100 and 500 examples to significantly change the behavior of the model. If you do not have a training dataset of this size or larger, try using structured prompts first, as this feature lets you guide the behavior of the model with as little as 3 or 4 training examples.\nThe training examples you provide in your tuning dataset guide the generative model in producing responses. At the minimum, each record in your dataset must have an input value, representing the prompt instruction, and an output value, representing the expected response from the generative model.\nHere's an example of input and output values for this prompt. In this case, the Product name is the input, or prompt, for the model, and the Product copy is the expected output:\nProduct name (input)\tProduct copy (output)\nA training dataset can have more than one input and more than one output, and you must have at least one input and one output for each record. You can create datasets using the structured prompts user interface in AI Studio, or import data from a Comma Separated Value (CSV) data file or Google Sheets spreadsheet.\nAfter you create a tuning dataset, you can build a tuned version of a Gemini model in AI Studio by providing your dataset and setting some configuration parameters. Once you have provided the required input, the system creates the tuned model, and then you can use it with your prompts.\nTo create a tuned model:\nIn the AI Studio web app, on the left side of the interface, select the Tuned model option.\nIn the Select Data for tuning dialog, connect your tuning dataset by selecting a Structured prompt or click the Import button to load a data in a comma separated value (.CSV) format file or a Google Sheets spreadsheet.\nIn the Tuned model name field, enter a name for your tuned model. This name appears as a selectable model once the tuning operation is complete.\nIn the Description field, enter an optional description of the tuned model.\nIn the Model field select the foundation model you want to use as the base for your tuned model.\nYou can optionally set Advanced settings for creating the tuned model. For more information about these settings, see the Model tuning guide.\nStart the process to create the tuned model by selecting Tune.\nThe system might take a few minutes or longer to build the tuned version depending on the size or your dataset, number of Epochs specified, and current system load. You can check on the status of the tuning process by selecting My Library on the left side of the application and looking for the name of the tuned model.\nNote: If you want to tune the PaLM legacy models in Google AI Studio, turn on the Show legacy models option in Settings.\nAfter the model tuning build is complete, you can select the model for use with your prompts. You can use the tuned model with existing or new freeform or structured prompts, as long as those the prompts conform to the example structure of your tuned dataset.\nTo use a tuned model:\nIn the AI Studio web app, open an existing prompt or start a new one.\nIn the Run settings section, select the Model drop down, and select the name of the tuned model.\nCompose or update your prompt and select Run to use tuned model.\nTuning requires a significant amount of data to change the behavior of the generative model. If your prompts are not producing the behavior you want, evaluate your tuning dataset, your tuning parameters, and consider adding more examples.",
            "filtered_word_count": 746
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nIntro to model tuning\nTuning with AI Studio\nTuning with Python\nTuning with REST\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nSetup\nAuthenticate\nInstall the client library\nImport libraries\nCreate tuned model\nCheck tuning progress\nEvaluate your model\nUpdate the description\nDelete the model\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API: Model tuning with Python \nbookmark_border\n\nRun in Google Colab\n\t\nView source on GitHub\n\nIn this notebook, you'll learn how to get started with the tuning service using the Python client library for the Gemini API. Here, you'll learn how to tune the text model behind the Gemini API's text generation service.\n\nNote: At this time, tuning is only available for the gemini-1.0-pro-001 model.\nSetup\nAuthenticate\n\nThe Gemini API lets you tune models on your own data. Since it's your data and your tuned models this needs stricter access controls than API-Keys can provide.\n\nBefore you can run this tutorial, you'll need to setup OAuth for your project.\n\nIn Colab the easiest wat to get setup is to copy the contents of your client_secret.json file into Colab's \"Secrets manager\" (under the key icon in the left panel) with the secret name CLIENT_SECRET.\n\nThis gcloud command turns the client_secret.json file into credentials that can be used to authenticate with the service.\n\nImportant: If you're running this in Colab, don't just click the link it prints. That will fail. Follow the instructions and copy the gcloud command it prints to your local machine and run it there, then paste the output from your local machine back here.\nimport os\nif 'COLAB_RELEASE_TAG' in os.environ:\n  from google.colab import userdata\n  import pathlib\n  pathlib.Path('client_secret.json').write_text(userdata.get('CLIENT_SECRET'))\n\n  # Use `--no-browser` in colab\n  !gcloud auth application-default login --no-browser --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'\nelse:\n  !gcloud auth application-default login --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'\n\nInstall the client library\npip install -q google-generativeai\n\nImport libraries\nimport google.generativeai as genai\n\n\nYou can check you existing tuned models with the genai.list_tuned_model method.\n\nfor i, m in zip(range(5), genai.list_tuned_models()):\n  print(m.name)\n\ntunedModels/my-model-8527\ntunedModels/my-model-7092\ntunedModels/my-model-2778\ntunedModels/my-model-1298\ntunedModels/my-model-3883\n\nCreate tuned model\n\nTo create a tuned model, you need to pass your dataset to the model in the genai.create_tuned_model method. You can do this be directly defining the input and output values in the call or importing from a file into a dataframe to pass to the method.\n\nFor this example, you will tune a model to generate the next number in the sequence. For example, if the input is 1, the model should output 2. If the input is one hundred, the output should be one hundred one.\n\nbase_model = [\n    m for m in genai.list_models()\n    if \"createTunedModel\" in m.supported_generation_methods][0]\nbase_model\n\nModel(name='models/gemini-1.0-pro-001',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.0 Pro',\n      description=('The best model for scaling across a wide range of tasks. This is a stable '\n                   'model that supports tuning.'),\n      input_token_limit=30720,\n      output_token_limit=2048,\n      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n      temperature=0.9,\n      top_p=1.0,\n      top_k=1)\n\nimport random\n\nname = f'generate-num-{random.randint(0,10000)}'\noperation = genai.create_tuned_model(\n    # You can use a tuned model here too. Set `source_model=\"tunedModels/...\"`\n    source_model=base_model.name,\n    training_data=[\n        {\n             'text_input': '1',\n             'output': '2',\n        },{\n             'text_input': '3',\n             'output': '4',\n        },{\n             'text_input': '-3',\n             'output': '-2',\n        },{\n             'text_input': 'twenty two',\n             'output': 'twenty three',\n        },{\n             'text_input': 'two hundred',\n             'output': 'two hundred one',\n        },{\n             'text_input': 'ninety nine',\n             'output': 'one hundred',\n        },{\n             'text_input': '8',\n             'output': '9',\n        },{\n             'text_input': '-98',\n             'output': '-97',\n        },{\n             'text_input': '1,000',\n             'output': '1,001',\n        },{\n             'text_input': '10,100,000',\n             'output': '10,100,001',\n        },{\n             'text_input': 'thirteen',\n             'output': 'fourteen',\n        },{\n             'text_input': 'eighty',\n             'output': 'eighty one',\n        },{\n             'text_input': 'one',\n             'output': 'two',\n        },{\n             'text_input': 'three',\n             'output': 'four',\n        },{\n             'text_input': 'seven',\n             'output': 'eight',\n        }\n    ],\n    id = name,\n    epoch_count = 100,\n    batch_size=4,\n    learning_rate=0.001,\n)\n\n\nYour tuned model is immediately added to the list of tuned models, but its status is set to \"creating\" while the model is tuned.\n\nmodel = genai.get_tuned_model(f'tunedModels/{name}')\n\nmodel\n\nTunedModel(name='tunedModels/generate-num-2946',\n           source_model='models/gemini-1.0-pro-001',\n           base_model='models/gemini-1.0-pro-001',\n           display_name='',\n           description='',\n           temperature=0.9,\n           top_p=1.0,\n           top_k=1,\n           state=<State.CREATING: 1>,\n           create_time=datetime.datetime(2024, 2, 21, 20, 4, 16, 448050, tzinfo=datetime.timezone.utc),\n           update_time=datetime.datetime(2024, 2, 21, 20, 4, 16, 448050, tzinfo=datetime.timezone.utc),\n           tuning_task=TuningTask(start_time=datetime.datetime(2024, 2, 21, 20, 4, 16, 890698, tzinfo=datetime.timezone.utc),\n                                  complete_time=None,\n                                  snapshots=[],\n                                  hyperparameters=Hyperparameters(epoch_count=100,\n                                                                  batch_size=4,\n                                                                  learning_rate=0.001)))\n\nmodel.state\n\n<State.CREATING: 1>\n\nCheck tuning progress\n\nUse metadata to check the state:\n\noperation.metadata\n\ntotal_steps: 375\ntuned_model: \"tunedModels/generate-num-2946\"\n\n\nWait for the training to finish using operation.result(), or operation.wait_bar()\n\nimport time\n\nfor status in operation.wait_bar():\n  time.sleep(30)\n\n0%|          | 0/375 [00:00<?, ?it/s]\n\n\nYou can cancel your tuning job any time using the cancel() method. Uncomment the line below and run the code cell to cancel your job before it finishes.\n\n# operation.cancel()\n\n\nOnce the tuning is complete, you can view the loss curve from the tuning results. The loss curve shows how much the model's predictions deviate from the ideal outputs.\n\nimport pandas as pd\nimport seaborn as sns\n\nmodel = operation.result()\n\nsnapshots = pd.DataFrame(model.tuning_task.snapshots)\n\nsns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')\n\n<Axes: xlabel='epoch', ylabel='mean_loss'>\n\n\nEvaluate your model\n\nYou can use the genai.generate_text method and specify the name of your model to test your model performance.\n\nmodel = genai.GenerativeModel(model_name=f'tunedModels/{name}')\n\nresult = model.generate_content('55')\nresult.text\n\n'56'\n\nresult = model.generate_content('123455')\nresult.text\n\n'123456'\n\nresult = model.generate_content('four')\nresult.text\n\n'five'\n\nresult = model.generate_content('quatre') # French 4\nresult.text                               # French 5 is \"cinq\"\n\n'cinq'\n\nresult = model.generate_content('III')    # Roman numeral 3\nresult.text                               # Roman numeral 4 is IV\n\n'IV'\n\nresult = model.generate_content('七')  # Japanese 7\nresult.text                            # Japanese 8 is 八!\n\n'八'\n\n\nIt really seems to have picked up the task despite the limited examples, but \"next\" is a simple concept, see the tuning guide for more guidance on improving performance.\n\nUpdate the description\n\nYou can update the description of your tuned model any time using the genai.update_tuned_model method.\n\ngenai.update_tuned_model(f'tunedModels/{name}', {\"description\":\"This is my model.\"});\n\nmodel = genai.get_tuned_model(f'tunedModels/{name}')\n\nmodel.description\n\n'This is my model.'\n\nDelete the model\n\nYou can clean up your tuned model list by deleting models you no longer need. Use the genai.delete_tuned_model method to delete a model. If you canceled any tuning jobs, you may want to delete those as their performance may be unpredictable.\n\ngenai.delete_tuned_model(f'tunedModels/{name}')\n\n\nThe model no longer exists:\n\ntry:\n  m = genai.get_tuned_model(f'tunedModels/{name}')\n  print(m)\nexcept Exception as e:\n  print(f\"{type(e)}: {e}\")\n\n<class 'google.api_core.exceptions.NotFound'>: 404 Tuned model tunedModels/generate-num-2946 does not exist.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 1143,
            "filtered_content": "Gemini API: Model tuning with Python \nIn this notebook, you'll learn how to get started with the tuning service using the Python client library for the Gemini API. Here, you'll learn how to tune the text model behind the Gemini API's text generation service.\nNote: At this time, tuning is only available for the gemini-1.0-pro-001 model.\nThe Gemini API lets you tune models on your own data. Since it's your data and your tuned models this needs stricter access controls than API-Keys can provide.\nBefore you can run this tutorial, you'll need to setup OAuth for your project.\nIn Colab the easiest wat to get setup is to copy the contents of your client_secret.json file into Colab's \"Secrets manager\" (under the key icon in the left panel) with the secret name CLIENT_SECRET.\nThis gcloud command turns the client_secret.json file into credentials that can be used to authenticate with the service.\nImportant: If you're running this in Colab, don't just click the link it prints. That will fail. Follow the instructions and copy the gcloud command it prints to your local machine and run it there, then paste the output from your local machine back here.\nif 'COLAB_RELEASE_TAG' in os.environ:\n  from google.colab import userdata\n  import pathlib\n  pathlib.Path('client_secret.json').write_text(userdata.get('CLIENT_SECRET'))\n  # Use `--no-browser` in colab\n  !gcloud auth application-default login --no-browser --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'\nelse:\n  !gcloud auth application-default login --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'\npip install -q google-generativeai\nYou can check you existing tuned models with the genai.list_tuned_model method.\nfor i, m in zip(range(5), genai.list_tuned_models()):\n  print(m.name)\ntunedModels/my-model-8527\ntunedModels/my-model-7092\ntunedModels/my-model-2778\ntunedModels/my-model-1298\ntunedModels/my-model-3883\nTo create a tuned model, you need to pass your dataset to the model in the genai.create_tuned_model method. You can do this be directly defining the input and output values in the call or importing from a file into a dataframe to pass to the method.\nFor this example, you will tune a model to generate the next number in the sequence. For example, if the input is 1, the model should output 2. If the input is one hundred, the output should be one hundred one.\nbase_model = [\n    m for m in genai.list_models()\n    if \"createTunedModel\" in m.supported_generation_methods][0]\nbase_model\nModel(name='models/gemini-1.0-pro-001',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.0 Pro',\n      description=('The best model for scaling across a wide range of tasks. This is a stable '\n                   'model that supports tuning.'),\n      input_token_limit=30720,\n      output_token_limit=2048,\n      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n      temperature=0.9,\n      top_p=1.0,\n      top_k=1)\nimport random\nname = f'generate-num-{random.randint(0,10000)}'\noperation = genai.create_tuned_model(\n    # You can use a tuned model here too. Set `source_model=\"tunedModels/...\"`\n    source_model=base_model.name,\n    training_data=[\n             'text_input': '1',\n             'output': '2',\n             'text_input': '3',\n             'output': '4',\n             'text_input': '-3',\n             'output': '-2',\n             'text_input': 'twenty two',\n             'output': 'twenty three',\n             'text_input': 'two hundred',\n             'output': 'two hundred one',\n             'text_input': 'ninety nine',\n             'output': 'one hundred',\n             'text_input': '8',\n             'output': '9',\n             'text_input': '-98',\n             'output': '-97',\n             'text_input': '1,000',\n             'output': '1,001',\n             'text_input': '10,100,000',\n             'output': '10,100,001',\n             'text_input': 'thirteen',\n             'output': 'fourteen',\n             'text_input': 'eighty',\n             'output': 'eighty one',\n             'text_input': 'one',\n             'output': 'two',\n             'text_input': 'three',\n             'output': 'four',\n             'text_input': 'seven',\n             'output': 'eight',\n    id = name,\n    epoch_count = 100,\n    batch_size=4,\n    learning_rate=0.001,\nYour tuned model is immediately added to the list of tuned models, but its status is set to \"creating\" while the model is tuned.\nmodel\nTunedModel(name='tunedModels/generate-num-2946',\n           source_model='models/gemini-1.0-pro-001',\n           base_model='models/gemini-1.0-pro-001',\n           display_name='',\n           description='',\n           temperature=0.9,\n           top_p=1.0,\n           top_k=1,\n           state=<State.CREATING: 1>,\n           create_time=datetime.datetime(2024, 2, 21, 20, 4, 16, 448050, tzinfo=datetime.timezone.utc),\n           update_time=datetime.datetime(2024, 2, 21, 20, 4, 16, 448050, tzinfo=datetime.timezone.utc),\n           tuning_task=TuningTask(start_time=datetime.datetime(2024, 2, 21, 20, 4, 16, 890698, tzinfo=datetime.timezone.utc),\n                                  complete_time=None,\n                                  snapshots=[],\n                                  hyperparameters=Hyperparameters(epoch_count=100,\n                                                                  batch_size=4,\n                                                                  learning_rate=0.001)))\nmodel.state\n<State.CREATING: 1>\nUse metadata to check the state:\noperation.metadata\ntotal_steps: 375\ntuned_model: \"tunedModels/generate-num-2946\"\nWait for the training to finish using operation.result(), or operation.wait_bar()\nimport time\nfor status in operation.wait_bar():\n  time.sleep(30)\n0%|          | 0/375 [00:00<?, ?it/s]\nYou can cancel your tuning job any time using the cancel() method. Uncomment the line below and run the code cell to cancel your job before it finishes.\n# operation.cancel()\nOnce the tuning is complete, you can view the loss curve from the tuning results. The loss curve shows how much the model's predictions deviate from the ideal outputs.\nimport pandas as pd\nimport seaborn as sns\nmodel = operation.result()\nsnapshots = pd.DataFrame(model.tuning_task.snapshots)\nsns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')\n<Axes: xlabel='epoch', ylabel='mean_loss'>\nYou can use the genai.generate_text method and specify the name of your model to test your model performance.\nmodel = genai.GenerativeModel(model_name=f'tunedModels/{name}')\nresult = model.generate_content('55')\n'56'\nresult = model.generate_content('123455')\n'123456'\nresult = model.generate_content('four')\n'five'\nresult = model.generate_content('quatre') # French 4\nresult.text                               # French 5 is \"cinq\"\n'cinq'\nresult = model.generate_content('III')    # Roman numeral 3\nresult.text                               # Roman numeral 4 is IV\n'IV'\nresult = model.generate_content('七')  # Japanese 7\nresult.text                            # Japanese 8 is 八!\n'八'\nIt really seems to have picked up the task despite the limited examples, but \"next\" is a simple concept, see the tuning guide for more guidance on improving performance.\nYou can update the description of your tuned model any time using the genai.update_tuned_model method.\ngenai.update_tuned_model(f'tunedModels/{name}', {\"description\":\"This is my model.\"});\nmodel.description\n'This is my model.'\nYou can clean up your tuned model list by deleting models you no longer need. Use the genai.delete_tuned_model method to delete a model. If you canceled any tuning jobs, you may want to delete those as their performance may be unpredictable.\ngenai.delete_tuned_model(f'tunedModels/{name}')\nThe model no longer exists:\n  m = genai.get_tuned_model(f'tunedModels/{name}')\n  print(m)\n  print(f\"{type(e)}: {e}\")\n<class 'google.api_core.exceptions.NotFound'>: 404 Tuned model tunedModels/generate-num-2946 does not exist.",
            "filtered_word_count": 856
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nIntro to model tuning\nTuning with AI Studio\nTuning with Python\nTuning with REST\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nSetup\nAuthenticate\nCalling the REST API with CURL\nSet variables\nList tuned models\nCreate tuned model\nGet tuned model state\nRun inference\nCall the REST API with Python requests\nSet variables\nList tuned models\nCreate tuned model\nGet tuned model state\nRun inference\nConclusion\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nREST API: Model tuning \nbookmark_border\n\nRun in Google Colab\n\t\nView source on GitHub\n\nIn this notebook, you'll learn how to get started with the Gemini API tuning service using curl commands or the Python request API to call the Gemini API. Here, you'll learn how to tune the text model behind the Gemini API's text generation service.\n\nNote: At this time, tuning is only available for the gemini-1.0-pro-001 model.\nSetup\nAuthenticate\n\nThe Gemini API lets you tune models on your own data. Since it's your data and your tuned models this needs stricter access controls than API-Keys can provide.\n\nBefore you can run this tutorial, you'll need to setup OAuth for your project.\n\nIn Colab the easiest wat to get setup is to copy the contents of your client_secret.json file into Colab's \"Secrets manager\" (under the key icon in the left panel) with the secret name CLIENT_SECRET.\n\nThis gcloud command turns the client_secret.json file into credentials that can be used to authenticate with the service.\n\nImportant: If you're running this in Colab, don't just click the link it prints. That will fail. Follow the instructions and copy the gcloud command it prints to your local machine and run it there, then paste the output from your local machine back here.\ntry:\n  from google.colab import userdata\n  import pathlib\n  pathlib.Path('client_secret.json').write_text(userdata.get('CLIENT_SECRET'))\n\n  # Use `--no-browser` in colab\n  !gcloud auth application-default login --no-browser --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'\nexcept ImportError:\n  !gcloud auth application-default login --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'\n\nYou are authorizing client libraries without access to a web browser. Please run the following command on a machine with a web browser and copy its output back here. Make sure the installed gcloud version is 372.0.0 or newer.\n\ngcloud auth application-default login --remote-bootstrap=\"https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=87071151422-n1a3cb6c7fvkfg4gmhdtmn5ulol2l4be.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgenerative-language.tuning&state=QIyNibWSaTIsozjmvZEkVBo6EcoW0G&access_type=offline&code_challenge=76c1ZiGvKN8cvlYfj3BmbCwE4e7tvrlwaX3REUX25gY&code_challenge_method=S256&token_usage=remote\"\n\n\nEnter the output of the above command: https://localhost:8085/?state=QIyNibWSaTIsozjmvZEkVBo6EcoW0G&code=4/0AeaYSHBKrY911S466QjKQIFODoOPXlO1mWyTYYdrbELIDV6Hw2DKRAyro62BugroSvIWsA&scope=https://www.googleapis.com/auth/cloud-platform%20https://www.googleapis.com/auth/generative-language.tuning\n\nCredentials saved to file: [/content/.config/application_default_credentials.json]\n\nThese credentials will be used by any library that requests Application Default Credentials (ADC).\n\nCalling the REST API with CURL\n\nThis section gives example curl statements to call the REST API. You will learn how to create a tuning job, check its status and once complete, make an inference call.\n\nSet variables\n\nSet variables for recurring values to use for the rest of the REST API calls. The code is using the Python os library to set environment variables which is accessible in all the code cells.\n\nThis is specific to the Colab notebook environment. The code in the next code cell is equivalent to running the following commands in a bash terminal.\n\nexport access_token=$(gcloud auth application-default print-access-token)\nexport project_id=my-project-id\nexport base_url=https://generativelanguage.googleapis.com\n\nimport os\n\naccess_token = !gcloud auth application-default print-access-token\naccess_token = '\\n'.join(access_token)\n\nos.environ['access_token'] = access_token\nos.environ['project_id'] = \"[Enter your project-id here]\"\nos.environ['base_url'] = \"https://generativelanguage.googleapis.com\"\n\nList tuned models\n\nVerify your authentication setup by listing the currently available tuned models.\n\n\ncurl -X GET ${base_url}/v1beta/tunedModels \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer ${access_token}\" \\\n    -H \"x-goog-user-project: ${project_id}\"\n\nCreate tuned model\n\nTo create a tuned model, you need to pass your dataset to the model in the training_data field.\n\nFor this example, you will tune a model to generate the next number in the sequence. For example, if the input is 1, the model should output 2. If the input is one hundred, the output should be one hundred one.\n\n\ncurl -X POST $base_url/v1beta/tunedModels \\\n    -H 'Content-Type: application/json' \\\n    -H \"Authorization: Bearer ${access_token}\" \\\n    -H \"x-goog-user-project: ${project_id}\" \\\n    -d '\n      {\n        \"display_name\": \"number generator model\",\n        \"base_model\": \"models/gemini-1.0-pro-001\",\n        \"tuning_task\": {\n          \"hyperparameters\": {\n            \"batch_size\": 2,\n            \"learning_rate\": 0.001,\n            \"epoch_count\":5,\n          },\n          \"training_data\": {\n            \"examples\": {\n              \"examples\": [\n                {\n                    \"text_input\": \"1\",\n                    \"output\": \"2\",\n                },{\n                    \"text_input\": \"3\",\n                    \"output\": \"4\",\n                },{\n                    \"text_input\": \"-3\",\n                    \"output\": \"-2\",\n                },{\n                    \"text_input\": \"twenty two\",\n                    \"output\": \"twenty three\",\n                },{\n                    \"text_input\": \"two hundred\",\n                    \"output\": \"two hundred one\",\n                },{\n                    \"text_input\": \"ninety nine\",\n                    \"output\": \"one hundred\",\n                },{\n                    \"text_input\": \"8\",\n                    \"output\": \"9\",\n                },{\n                    \"text_input\": \"-98\",\n                    \"output\": \"-97\",\n                },{\n                    \"text_input\": \"1,000\",\n                    \"output\": \"1,001\",\n                },{\n                    \"text_input\": \"10,100,000\",\n                    \"output\": \"10,100,001\",\n                },{\n                    \"text_input\": \"thirteen\",\n                    \"output\": \"fourteen\",\n                },{\n                    \"text_input\": \"eighty\",\n                    \"output\": \"eighty one\",\n                },{\n                    \"text_input\": \"one\",\n                    \"output\": \"two\",\n                },{\n                    \"text_input\": \"three\",\n                    \"output\": \"four\",\n                },{\n                    \"text_input\": \"seven\",\n                    \"output\": \"eight\",\n                }\n              ]\n            }\n          }\n        }\n      }' | tee tunemodel.json\n\n{\n  \"name\": \"tunedModels/number-generator-model-dzlmi0gswwqb/operations/bvl8dymw0fhw\",\n  \"metadata\": {\n    \"@type\": \"type.googleapis.com/google.ai.generativelanguage.v1beta.CreateTunedModelMetadata\",\n    \"totalSteps\": 38,\n    \"tunedModel\": \"tunedModels/number-generator-model-dzlmi0gswwqb\"\n  }\n}\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  2280    0   296  100  1984    611   4098 --:--:-- --:--:-- --:--:--  4720\n\nGet tuned model state\n\nThe state of the model is set to CREATING during training and will change to ACTIVE once its complete.\n\nBelow is a bit of python code to parse out the generated model name from the response JSON. If you're running this in a terminal you can try using a bash JSON parser to parse the response.\n\nimport json\n\nfirst_page = json.load(open('tunemodel.json'))\nos.environ['modelname'] = first_page['metadata']['tunedModel']\n\nprint(os.environ['modelname'])\n\ntunedModels/number-generator-model-dzlmi0gswwqb\n\n\nDo another GET request with the model name to get the model metadata which includes the state field.\n\n\ncurl -X GET ${base_url}/v1beta/${modelname} \\\n    -H 'Content-Type: application/json' \\\n    -H \"Authorization: Bearer ${access_token}\" \\\n    -H \"x-goog-user-project: ${project_id}\" | grep state\n\n\"state\": \"ACTIVE\",\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  5921    0  5921    0     0  13164      0 --:--:-- --:--:-- --:--:-- 13157\n\nRun inference\n\nOnce your tuning job is finished, you can use it to generate text with the text service. Try to input a Roman numeral, say, 63 (LXIII)\n\n\ncurl -X POST $base_url/v1beta/$modelname:generateContent \\\n    -H 'Content-Type: application/json' \\\n    -H \"Authorization: Bearer ${access_token}\" \\\n    -H \"x-goog-user-project: ${project_id}\" \\\n    -d '{\n        \"contents\": [{\n        \"parts\": [{\n          \"text\": \"LXIII\"\n          }]\n        }]\n        }' 2> /dev/null\n\n{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"LXIV\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0,\n      \"safetyRatings\": [\n        {\n          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n          \"probability\": \"NEGLIGIBLE\"\n        }\n      ]\n    }\n  ],\n  \"promptFeedback\": {\n    \"safetyRatings\": [\n      {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"probability\": \"NEGLIGIBLE\"\n      }\n    ]\n  }\n}\n\n\nThe output from your model may or may not be correct. If the tuned model isn't performing up to your required standards, you can try adding more high quality examples, tweaking the hyperparameters or adding a preamble to your examples. You can even create another tuned model based on the first one you created.\n\nSee the tuning guide for more guidance on improving performance.\n\nCall the REST API with Python requests\n\nYou can call the rest API with any library that allows you to send http requests. The next set of examples use the Python requests library, and demonstrates some of the more advanced features.\n\nSet variables\naccess_token = !gcloud auth application-default print-access-token\naccess_token = '\\n'.join(access_token)\n\nproject = '[Enter your project-id here]'\nbase_url = \"https://generativelanguage.googleapis.com\"\n\n\nImport the requests library.\n\nimport requests\nimport json\n\nList tuned models\n\nVerify your authentication setup by listing the currently available tuned models.\n\nheaders={\n  'Authorization': 'Bearer ' + access_token,\n  'Content-Type': 'application/json',\n  'x-goog-user-project': project\n}\n\nresult = requests.get(\n  url=f'{base_url}/v1beta/tunedModels',\n  headers = headers,\n)\n\nresult.json()\n\nCreate tuned model\n\nSame as for the Curl example, you pass in the dataset through the training_data field.\n\noperation = requests.post(\n    url = f'{base_url}/v1beta/tunedModels',\n    headers=headers,\n    json= {\n        \"display_name\": \"number generator\",\n        \"base_model\": \"models/gemini-1.0-pro-001\",\n        \"tuning_task\": {\n          \"hyperparameters\": {\n            \"batch_size\": 4,\n            \"learning_rate\": 0.001,\n            \"epoch_count\":5,\n          },\n          \"training_data\": {\n            \"examples\": {\n              \"examples\": [\n                {\n                    'text_input': '1',\n                    'output': '2',\n                },{\n                    'text_input': '3',\n                    'output': '4',\n                },{\n                    'text_input': '-3',\n                    'output': '-2',\n                },{\n                    'text_input': 'twenty two',\n                    'output': 'twenty three',\n                },{\n                    'text_input': 'two hundred',\n                    'output': 'two hundred one',\n                },{\n                    'text_input': 'ninety nine',\n                    'output': 'one hundred',\n                },{\n                    'text_input': '8',\n                    'output': '9',\n                },{\n                    'text_input': '-98',\n                    'output': '-97',\n                },{\n                    'text_input': '1,000',\n                    'output': '1,001',\n                },{\n                    'text_input': '10,100,000',\n                    'output': '10,100,001',\n                },{\n                    'text_input': 'thirteen',\n                    'output': 'fourteen',\n                },{\n                    'text_input': 'eighty',\n                    'output': 'eighty one',\n                },{\n                    'text_input': 'one',\n                    'output': 'two',\n                },{\n                    'text_input': 'three',\n                    'output': 'four',\n                },{\n                    'text_input': 'seven',\n                    'output': 'eight',\n                }\n              ]\n            }\n          }\n        }\n      }\n)\n\noperation\n\n<Response [200]>\n\noperation.json()\n\n{'name': 'tunedModels/number-generator-wl1qr34x2py/operations/41vni3zk0a47',\n 'metadata': {'@type': 'type.googleapis.com/google.ai.generativelanguage.v1beta.CreateTunedModelMetadata',\n  'totalSteps': 19,\n  'tunedModel': 'tunedModels/number-generator-wl1qr34x2py'} }\n\n\nSet a variable with the name of your tuned model to use for the rest of the calls.\n\nname=operation.json()[\"metadata\"][\"tunedModel\"]\nname\n\n'tunedModels/number-generator-wl1qr34x2py'\n\nGet tuned model state\n\nYou can check the progress of your tuning job by checking the state field. CREATING means the tuning job is still ongoing and ACTIVE means the trainins is complete and the tuned model is ready to use.\n\ntuned_model = requests.get(\n    url = f'{base_url}/v1beta/{name}',\n    headers=headers,\n)\n\ntuned_model.json()\n\n\nThe code below checks the state field every 5 seconds until it is no longer in the CREATING state.\n\nimport time\nimport pprint\n\nop_json = operation.json()\nresponse = op_json.get('response')\nerror = op_json.get('error')\n\nwhile response is None and error is None:\n    time.sleep(5)\n\n    operation = requests.get(\n        url = f'{base_url}/v1/{op_json[\"name\"]}',\n        headers=headers,\n    )\n\n    op_json = operation.json()\n    response = op_json.get('response')\n    error = op_json.get('error')\n\n    percent = op_json['metadata'].get('completedPercent')\n    if percent is not None:\n      print(f\"{percent:.2f}% - {op_json['metadata']['snapshots'][-1]}\")\n      print()\n\nif error is not None:\n    raise Exception(error)\n\n100.00% - {'step': 19, 'epoch': 5, 'meanLoss': 1.402067, 'computeTime': '2024-03-14T15:11:23.766989274Z'}\n\nRun inference\n\nOnce the tuning job is finished, you can use it to generate text in the same way you would use the base text model. Try to input a Japanese numeral, say, 6 (六).\n\nimport time\n\nm = requests.post(\n    url = f'{base_url}/v1beta/{name}:generateContent',\n    headers=headers,\n    json= {\n         \"contents\": [{\n             \"parts\": [{\n                 \"text\": \"六\"\n             }]\n          }]\n    })\n\nimport pprint\npprint.pprint(m.json())\n\n{'candidates': [{'content': {'parts': [{'text': '七'}], 'role': 'model'},\n                 'finishReason': 'STOP',\n                 'index': 0,\n                 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n                                    'probability': 'NEGLIGIBLE'},\n                                   {'category': 'HARM_CATEGORY_HATE_SPEECH',\n                                    'probability': 'NEGLIGIBLE'},\n                                   {'category': 'HARM_CATEGORY_HARASSMENT',\n                                    'probability': 'LOW'},\n                                   {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n                                    'probability': 'NEGLIGIBLE'}]}],\n 'promptFeedback': {'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n                                       'probability': 'NEGLIGIBLE'},\n                                      {'category': 'HARM_CATEGORY_HATE_SPEECH',\n                                       'probability': 'NEGLIGIBLE'},\n                                      {'category': 'HARM_CATEGORY_HARASSMENT',\n                                       'probability': 'NEGLIGIBLE'},\n                                      {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n                                       'probability': 'NEGLIGIBLE'}]} }\n\n\nThe output from your model may or may not be correct. If the tuned model isn't performing up to your required standards, you can try adding more high quality examples, tweaking the hyperparameters or adding a preamble to your examples.\n\nConclusion\n\nEven though the training data did not contain any reference to Roman or Japanese numerals, the model was able to generalize well after fine-tuning. This way, you can fine-tune models to cater to your use cases.\n\nNext steps\n\nTo learn how to use the tuning service with the help of Python SDK for the Gemini API, visit the tuning quickstart with Python. To learn how to use other services in the Gemini API, visit the Python quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 1932,
            "filtered_content": "REST API: Model tuning \nIn this notebook, you'll learn how to get started with the Gemini API tuning service using curl commands or the Python request API to call the Gemini API. Here, you'll learn how to tune the text model behind the Gemini API's text generation service.\nexcept ImportError:\nYou are authorizing client libraries without access to a web browser. Please run the following command on a machine with a web browser and copy its output back here. Make sure the installed gcloud version is 372.0.0 or newer.\ngcloud auth application-default login --remote-bootstrap=\"https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=87071151422-n1a3cb6c7fvkfg4gmhdtmn5ulol2l4be.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgenerative-language.tuning&state=QIyNibWSaTIsozjmvZEkVBo6EcoW0G&access_type=offline&code_challenge=76c1ZiGvKN8cvlYfj3BmbCwE4e7tvrlwaX3REUX25gY&code_challenge_method=S256&token_usage=remote\"\nEnter the output of the above command: https://localhost:8085/?state=QIyNibWSaTIsozjmvZEkVBo6EcoW0G&code=4/0AeaYSHBKrY911S466QjKQIFODoOPXlO1mWyTYYdrbELIDV6Hw2DKRAyro62BugroSvIWsA&scope=https://www.googleapis.com/auth/cloud-platform%20https://www.googleapis.com/auth/generative-language.tuning\nCredentials saved to file: [/content/.config/application_default_credentials.json]\nThese credentials will be used by any library that requests Application Default Credentials (ADC).\nThis section gives example curl statements to call the REST API. You will learn how to create a tuning job, check its status and once complete, make an inference call.\nSet variables for recurring values to use for the rest of the REST API calls. The code is using the Python os library to set environment variables which is accessible in all the code cells.\nThis is specific to the Colab notebook environment. The code in the next code cell is equivalent to running the following commands in a bash terminal.\nexport access_token=$(gcloud auth application-default print-access-token)\nexport project_id=my-project-id\nexport base_url=https://generativelanguage.googleapis.com\nos.environ['access_token'] = access_token\nos.environ['project_id'] = \"[Enter your project-id here]\"\nos.environ['base_url'] = \"https://generativelanguage.googleapis.com\"\ncurl -X GET ${base_url}/v1beta/tunedModels \\\n    -H \"Content-Type: application/json\" \\\n    -H \"x-goog-user-project: ${project_id}\"\nTo create a tuned model, you need to pass your dataset to the model in the training_data field.\ncurl -X POST $base_url/v1beta/tunedModels \\\n    -d '\n        \"display_name\": \"number generator model\",\n            \"batch_size\": 2,\n                    \"text_input\": \"1\",\n                    \"output\": \"2\",\n                    \"text_input\": \"3\",\n                    \"output\": \"4\",\n                    \"text_input\": \"-3\",\n                    \"output\": \"-2\",\n                    \"text_input\": \"twenty two\",\n                    \"output\": \"twenty three\",\n                    \"text_input\": \"two hundred\",\n                    \"output\": \"two hundred one\",\n                    \"text_input\": \"ninety nine\",\n                    \"output\": \"one hundred\",\n                    \"text_input\": \"8\",\n                    \"output\": \"9\",\n                    \"text_input\": \"-98\",\n                    \"output\": \"-97\",\n                    \"text_input\": \"1,000\",\n                    \"output\": \"1,001\",\n                    \"text_input\": \"10,100,000\",\n                    \"output\": \"10,100,001\",\n                    \"text_input\": \"thirteen\",\n                    \"output\": \"fourteen\",\n                    \"text_input\": \"eighty\",\n                    \"output\": \"eighty one\",\n                    \"text_input\": \"one\",\n                    \"output\": \"two\",\n                    \"text_input\": \"three\",\n                    \"output\": \"four\",\n                    \"text_input\": \"seven\",\n                    \"output\": \"eight\",\n      }' | tee tunemodel.json\n  \"name\": \"tunedModels/number-generator-model-dzlmi0gswwqb/operations/bvl8dymw0fhw\",\n  \"metadata\": {\n    \"@type\": \"type.googleapis.com/google.ai.generativelanguage.v1beta.CreateTunedModelMetadata\",\n    \"totalSteps\": 38,\n    \"tunedModel\": \"tunedModels/number-generator-model-dzlmi0gswwqb\"\n100  2280    0   296  100  1984    611   4098 --:--:-- --:--:-- --:--:--  4720\nThe state of the model is set to CREATING during training and will change to ACTIVE once its complete.\nBelow is a bit of python code to parse out the generated model name from the response JSON. If you're running this in a terminal you can try using a bash JSON parser to parse the response.\nfirst_page = json.load(open('tunemodel.json'))\nos.environ['modelname'] = first_page['metadata']['tunedModel']\nprint(os.environ['modelname'])\ntunedModels/number-generator-model-dzlmi0gswwqb\nDo another GET request with the model name to get the model metadata which includes the state field.\ncurl -X GET ${base_url}/v1beta/${modelname} \\\n    -H \"x-goog-user-project: ${project_id}\" | grep state\n\"state\": \"ACTIVE\",\n100  5921    0  5921    0     0  13164      0 --:--:-- --:--:-- --:--:-- 13157\nOnce your tuning job is finished, you can use it to generate text with the text service. Try to input a Roman numeral, say, 63 (LXIII)\ncurl -X POST $base_url/v1beta/$modelname:generateContent \\\n        \"parts\": [{\n          \"text\": \"LXIII\"\n        }]\n        }' 2> /dev/null\n            \"text\": \"LXIV\"\nThe output from your model may or may not be correct. If the tuned model isn't performing up to your required standards, you can try adding more high quality examples, tweaking the hyperparameters or adding a preamble to your examples. You can even create another tuned model based on the first one you created.\nSee the tuning guide for more guidance on improving performance.\nYou can call the rest API with any library that allows you to send http requests. The next set of examples use the Python requests library, and demonstrates some of the more advanced features.\nproject = '[Enter your project-id here]'\nbase_url = \"https://generativelanguage.googleapis.com\"\nImport the requests library.\nimport requests\nheaders={\n  'Authorization': 'Bearer ' + access_token,\n  'Content-Type': 'application/json',\n  'x-goog-user-project': project\nresult = requests.get(\n  url=f'{base_url}/v1beta/tunedModels',\n  headers = headers,\nresult.json()\nSame as for the Curl example, you pass in the dataset through the training_data field.\noperation = requests.post(\n    url = f'{base_url}/v1beta/tunedModels',\n        \"display_name\": \"number generator\",\n            \"batch_size\": 4,\n                    'text_input': '1',\n                    'output': '2',\n                    'text_input': '3',\n                    'output': '4',\n                    'text_input': '-3',\n                    'output': '-2',\n                    'text_input': 'twenty two',\n                    'output': 'twenty three',\n                    'text_input': 'two hundred',\n                    'output': 'two hundred one',\n                    'text_input': 'ninety nine',\n                    'output': 'one hundred',\n                    'text_input': '8',\n                    'output': '9',\n                    'text_input': '-98',\n                    'output': '-97',\n                    'text_input': '1,000',\n                    'output': '1,001',\n                    'text_input': '10,100,000',\n                    'output': '10,100,001',\n                    'text_input': 'thirteen',\n                    'output': 'fourteen',\n                    'text_input': 'eighty',\n                    'output': 'eighty one',\n                    'text_input': 'one',\n                    'output': 'two',\n                    'text_input': 'three',\n                    'output': 'four',\n                    'text_input': 'seven',\n                    'output': 'eight',\noperation\n<Response [200]>\noperation.json()\n{'name': 'tunedModels/number-generator-wl1qr34x2py/operations/41vni3zk0a47',\n 'metadata': {'@type': 'type.googleapis.com/google.ai.generativelanguage.v1beta.CreateTunedModelMetadata',\n  'totalSteps': 19,\n  'tunedModel': 'tunedModels/number-generator-wl1qr34x2py'} }\nSet a variable with the name of your tuned model to use for the rest of the calls.\nname=operation.json()[\"metadata\"][\"tunedModel\"]\nname\n'tunedModels/number-generator-wl1qr34x2py'\nYou can check the progress of your tuning job by checking the state field. CREATING means the tuning job is still ongoing and ACTIVE means the trainins is complete and the tuned model is ready to use.\ntuned_model = requests.get(\n    url = f'{base_url}/v1beta/{name}',\ntuned_model.json()\nThe code below checks the state field every 5 seconds until it is no longer in the CREATING state.\nop_json = operation.json()\nresponse = op_json.get('response')\nerror = op_json.get('error')\nwhile response is None and error is None:\n    time.sleep(5)\n    operation = requests.get(\n        url = f'{base_url}/v1/{op_json[\"name\"]}',\n        headers=headers,\n    op_json = operation.json()\n    response = op_json.get('response')\n    error = op_json.get('error')\n    percent = op_json['metadata'].get('completedPercent')\n    if percent is not None:\n      print(f\"{percent:.2f}% - {op_json['metadata']['snapshots'][-1]}\")\n      print()\nif error is not None:\n    raise Exception(error)\n100.00% - {'step': 19, 'epoch': 5, 'meanLoss': 1.402067, 'computeTime': '2024-03-14T15:11:23.766989274Z'}\nOnce the tuning job is finished, you can use it to generate text in the same way you would use the base text model. Try to input a Japanese numeral, say, 6 (六).\nm = requests.post(\n    url = f'{base_url}/v1beta/{name}:generateContent',\n         \"contents\": [{\n             \"parts\": [{\n                 \"text\": \"六\"\n             }]\n    })\npprint.pprint(m.json())\n{'candidates': [{'content': {'parts': [{'text': '七'}], 'role': 'model'},\n                 'finishReason': 'STOP',\n                 'index': 0,\n                 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n                                   {'category': 'HARM_CATEGORY_HATE_SPEECH',\n                                   {'category': 'HARM_CATEGORY_HARASSMENT',\n                                    'probability': 'LOW'},\n                                   {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n                                    'probability': 'NEGLIGIBLE'}]}],\n 'promptFeedback': {'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n                                      {'category': 'HARM_CATEGORY_HATE_SPEECH',\n                                      {'category': 'HARM_CATEGORY_HARASSMENT',\n                                      {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n                                       'probability': 'NEGLIGIBLE'}]} }\nThe output from your model may or may not be correct. If the tuned model isn't performing up to your required standards, you can try adding more high quality examples, tweaking the hyperparameters or adding a preamble to your examples.\nEven though the training data did not contain any reference to Roman or Japanese numerals, the model was able to generalize well after fine-tuning. This way, you can fine-tune models to cater to your use cases.\nTo learn how to use the tuning service with the help of Python SDK for the Gemini API, visit the tuning quickstart with Python. To learn how to use other services in the Gemini API, visit the Python quickstart.",
            "filtered_word_count": 1104
        },
        "https://ai.google.dev/gemini-api/docs/function-calling": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nIntro to function calling\nFunction calling with Python\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nHow function calling works\nSupported models\nFunction calling mode\nFunction calling cURL samples\nSingle-turn curl sample\nSingle-turn example using ANY mode\nSingle-turn example using ANY mode and allowed functions\nMulti-turn curl examples\nBest practices\nFunction key fields\nUser prompt\nSampling parameters\nAPI invocation\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nFunction calling \nbookmark_border\n\nCustom functions can be defined and provided to a generative AI model using function calling. The model does not directly invoke these functions, but instead generates structured data output that specifies the function name and suggested arguments. This output enables the calling of external APIs, and the resulting API output can then be incorporated back into the model, allowing for more comprehensive query responses. Function calling empowers LLMs to interact with real-time information and various services, such as databases, customer relationship management systems, and document repositories, enhancing their ability to provide relevant and contextual answers.\n\nBeta: This feature is in Beta release. For more information, see the API versions page.\nHow function calling works\n\nFunctions are described using function declarations. After you pass a list of function declarations in a query to a language model, the model returns an object in an OpenAPI compatible schema format that includes the names of functions and their arguments and tries to answer the user query with one of the returned functions. The language model understands the purpose of a function by analyzing its function declaration. The model doesn't actually call the function. Instead, a developer uses the OpenAPI compatible schema object in the response to call the function that the model returns.\n\nWhen you implement function calling, you create one or more function declarations, then add the function declarations to a tools object that's passed to the model. Each function declaration contains information about one function that includes the following:\n\nFunction name\nFunction parameters in an OpenAPI compatible schema format. A select subset is supported. When using curl, the schema is specified using JSON.\nFunction description (optional). For the best results, we recommend that you include a description.\n\nThis document includes curl examples that make REST calls with the GenerativeModel class and its methods.\n\nFunction calling curl samples\nSupported models\n\nThe following models support function calling:\n\ngemini-1.0-pro\ngemini-1.0-pro-001\ngemini-1.5-pro-latest\nFunction calling mode\n\nYou can use the function calling mode to define the execution behavior for function calling. There are three modes available:\n\nAUTO: The default model behavior. The model decides to predict either a function call or a natural language response.\nANY: The model is constrained to always predict a function call. If allowed_function_names is not provided, the model picks from all of the available function declarations. If allowed_function_names is provided, the model picks from the set of allowed functions.\nNONE: The model won't predict a function call. In this case, the model behavior is the same as if you don't pass any function declarations.\n\nYou can also pass a set of allowed_function_names that, when provided, limits the functions that the model will call. You should only include allowed_function_names when the mode is ANY. Function names should match function declaration names. With the mode set to ANY and the allowed_function_names set, the model will predict a function call from the set of function names provided.\n\nHere's part of an example request that sets the mode to ANY and specifies a list of allowed functions:\n\n\"tool_config\": {\n  \"function_calling_config\": {\n    \"mode\": \"ANY\",\n    \"allowed_function_names\": [\"find_theaters\", \"get_showtimes\"]\n  },\n}\n\nFunction calling cURL samples\n\nWhen you use cURL, the function and parameter information is included in the tools element. Each function declaration in the tools element contains the function name, its parameters specified using the OpenAPI compatible schema, and a function description. The following samples demonstrate how to use curl commands with function calling:\n\nSingle-turn curl sample\n\nSingle-turn is when you call the language model one time. With function calling, a single-turn use case might be when you provide the model a natural language query and a list of functions. In this case, the model uses the function declaration, which includes the function name, parameters, and description, to predict which function to call and the arguments to call it with.\n\nThe following curl sample is an example of passing in a description of a function that returns information about where a movie is playing. Several function declarations are included in the request, such as find_movies and find_theaters.\n\nSingle-turn function calling curl example request\n\nThe response to this curl example might be similar to the following.\n\nSingle-turn function calling curl example response\nSingle-turn example using ANY mode\n\nThe following curl example is similar to the single-turn example, but it sets the mode to ANY:\n\n\"tool_config\": {\n  \"function_calling_config\": {\n    \"mode\": \"ANY\"\n  },\n}\n\nSingle-turn function calling using ANY mode (request)\n\nThe response might be similar to the following:\n\nSingle-turn function calling using ANY mode (response)\nSingle-turn example using ANY mode and allowed functions\n\nThe following curl example is similar to the single-turn example, but it sets the mode to ANY and includes a list of allowed functions:\n\n\"tool_config\": {\n  \"function_calling_config\": {\n    \"mode\": \"ANY\",\n    \"allowed_function_names\": [\"find_theaters\", \"get_showtimes\"]\n  },\n}\n\nSingle-turn function calling using ANY mode and allowed functions (request)\n\nThe model can't predict the find_movies function, because it's not on the list of allowed functions, so it predicts a different function instead. The response might be similar to the following:\n\nSingle-turn function calling using ANY mode and allowed functions (response)\nMulti-turn curl examples\n\nYou can implement a multi-turn function calling scenario by doing the following:\n\nGet a function call response by calling the language model. This is the first turn.\nCall the language model using the function call response from the first turn and the function response you get from calling that function. This is the second turn.\n\nThe response from the second turn either summarizes the results to answer your query in the first turn, or contains a second function call you can use to get more information for your query.\n\nThis topic includes two multi-turn curl examples:\n\nCurl example that uses a function response from a previous turn\nCurl example that calls a language model multiple times\nCurl example that uses a response from a previous turn\n\nThe following curl sample calls the function and arguments returned by the previous single-turn example to get a response. The method and parameters returned by the single-turn example are in this JSON.\n\n\"functionCall\": {\n  \"name\": \"find_theaters\",\n  \"args\": {\n    \"movie\": \"Barbie\",\n    \"location\": \"Mountain View, CA\"\n  }\n}\n\nMulti-turn function calling curl example request\n\nThe response to this curl example includes the result of calling the find_theaters method. The response might be similar to the following:\n\nMulti-turn function calling curl example response\nCurl example that calls a language model multiple times\n\nThe following curl example calls the language model multiple times to call a function. Each time the model calls the function, it can use a different function to answer a different user query in the request.\n\nMulti-turn function calling curl example request\nMulti-turn function calling curl example response\nBest practices\n\nFollow these best practices to improve the accuracy and reliability of your function calls.\n\nFunction key fields\n\nAccurately defining your functions is essential when integrating them into your requests. Each function relies on specific parameters that guide its behavior and interaction with the model. Here's a breakdown of the key parameters used within the functions_declarations array.\n\nfunction_declarations (array):\n\nContains one or more objects, each representing a distinct function.\n\nWithin each function_declarations object:\n\nname (string): The unique identifier for the function within the API call.\nBest practice: Use clear, descriptive names without space, period (.), or dash (-) characters. Instead, use underscore (_) characters or camel case.\ndescription (string): A comprehensive explanation of the function's purpose and capabilities.\nBest practice: Be detailed, clear, and specific in function descriptions, providing examples if necessary. For example, instead of find theaters, use find theaters based on location and optionally movie title that is currently playing in theaters. Avoid overly broad or ambiguous descriptions.\nparameters (object): Defines the input data required by the function.\ntype (string): Specifies the overall data type (e.g., object).\nproperties (object):\nLists individual parameters, each with:\ntype (string): The data type of the parameter (e.g., string, integer, boolean).\nBest practice: Use strongly typed parameters to reduce model hallucinations. For example, if the parameter values are from a finite set, use an enum field instead of listing the values in the description (e.g., \"type\": \"enum\", \"values\": [\"now_playing\", \"upcoming\"]). If the parameter value is always an integer, set the type to integer rather than number.\ndescription (string): A clear explanation of the parameter's purpose and expected format.\nBest practice: Provide concrete examples and constraints. For example, instead of the location to search, use The city and state, e.g. San Francisco, CA or a zip code e.g. 95616.\nrequired (array):\nAn array of strings listing the parameter names that are mandatory for the function to operate.\nUser prompt\n\nFor best results, prepend the user query with the following details:\n\nAdditional context for the model. For example, You are a movie API assistant to help users find movies and showtimes based on their preferences.\nDetails or instructions on how and when to use the functions. For example, Don't make assumptions on showtimes. Always use a future date for showtimes.\nInstructions to ask clarifying questions if user queries are ambiguous. For example, Ask clarifying questions if not enough information is available to complete the request.\nSampling parameters\n\nFor the temperature parameter, use 0 or another low value. This instructs the model to generate more confident results and reduces hallucinations.\n\nAPI invocation\n\nIf the model proposes the invocation of a function that would send an order, update a database, or otherwise have significant consequences, validate the function call with the user before executing it.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 1798,
            "filtered_content": "Intro to function calling\nFunction calling with Python\nFunction calling \nCustom functions can be defined and provided to a generative AI model using function calling. The model does not directly invoke these functions, but instead generates structured data output that specifies the function name and suggested arguments. This output enables the calling of external APIs, and the resulting API output can then be incorporated back into the model, allowing for more comprehensive query responses. Function calling empowers LLMs to interact with real-time information and various services, such as databases, customer relationship management systems, and document repositories, enhancing their ability to provide relevant and contextual answers.\nBeta: This feature is in Beta release. For more information, see the API versions page.\nFunctions are described using function declarations. After you pass a list of function declarations in a query to a language model, the model returns an object in an OpenAPI compatible schema format that includes the names of functions and their arguments and tries to answer the user query with one of the returned functions. The language model understands the purpose of a function by analyzing its function declaration. The model doesn't actually call the function. Instead, a developer uses the OpenAPI compatible schema object in the response to call the function that the model returns.\nWhen you implement function calling, you create one or more function declarations, then add the function declarations to a tools object that's passed to the model. Each function declaration contains information about one function that includes the following:\nFunction name\nFunction parameters in an OpenAPI compatible schema format. A select subset is supported. When using curl, the schema is specified using JSON.\nFunction description (optional). For the best results, we recommend that you include a description.\nThis document includes curl examples that make REST calls with the GenerativeModel class and its methods.\nFunction calling curl samples\nThe following models support function calling:\ngemini-1.0-pro\ngemini-1.5-pro-latest\nYou can use the function calling mode to define the execution behavior for function calling. There are three modes available:\nAUTO: The default model behavior. The model decides to predict either a function call or a natural language response.\nANY: The model is constrained to always predict a function call. If allowed_function_names is not provided, the model picks from all of the available function declarations. If allowed_function_names is provided, the model picks from the set of allowed functions.\nNONE: The model won't predict a function call. In this case, the model behavior is the same as if you don't pass any function declarations.\nYou can also pass a set of allowed_function_names that, when provided, limits the functions that the model will call. You should only include allowed_function_names when the mode is ANY. Function names should match function declaration names. With the mode set to ANY and the allowed_function_names set, the model will predict a function call from the set of function names provided.\nHere's part of an example request that sets the mode to ANY and specifies a list of allowed functions:\nWhen you use cURL, the function and parameter information is included in the tools element. Each function declaration in the tools element contains the function name, its parameters specified using the OpenAPI compatible schema, and a function description. The following samples demonstrate how to use curl commands with function calling:\nSingle-turn is when you call the language model one time. With function calling, a single-turn use case might be when you provide the model a natural language query and a list of functions. In this case, the model uses the function declaration, which includes the function name, parameters, and description, to predict which function to call and the arguments to call it with.\nThe following curl sample is an example of passing in a description of a function that returns information about where a movie is playing. Several function declarations are included in the request, such as find_movies and find_theaters.\nSingle-turn function calling curl example request\nThe response to this curl example might be similar to the following.\nSingle-turn function calling curl example response\nThe following curl example is similar to the single-turn example, but it sets the mode to ANY:\n    \"mode\": \"ANY\"\nSingle-turn function calling using ANY mode (request)\nThe response might be similar to the following:\nSingle-turn function calling using ANY mode (response)\nThe following curl example is similar to the single-turn example, but it sets the mode to ANY and includes a list of allowed functions:\nSingle-turn function calling using ANY mode and allowed functions (request)\nThe model can't predict the find_movies function, because it's not on the list of allowed functions, so it predicts a different function instead. The response might be similar to the following:\nSingle-turn function calling using ANY mode and allowed functions (response)\nYou can implement a multi-turn function calling scenario by doing the following:\nGet a function call response by calling the language model. This is the first turn.\nCall the language model using the function call response from the first turn and the function response you get from calling that function. This is the second turn.\nThe response from the second turn either summarizes the results to answer your query in the first turn, or contains a second function call you can use to get more information for your query.\nThis topic includes two multi-turn curl examples:\nCurl example that uses a function response from a previous turn\nCurl example that uses a response from a previous turn\nThe following curl sample calls the function and arguments returned by the previous single-turn example to get a response. The method and parameters returned by the single-turn example are in this JSON.\n\"functionCall\": {\n  \"name\": \"find_theaters\",\n  \"args\": {\n    \"movie\": \"Barbie\",\n    \"location\": \"Mountain View, CA\"\nThe response to this curl example includes the result of calling the find_theaters method. The response might be similar to the following:\nThe following curl example calls the language model multiple times to call a function. Each time the model calls the function, it can use a different function to answer a different user query in the request.\nFollow these best practices to improve the accuracy and reliability of your function calls.\nAccurately defining your functions is essential when integrating them into your requests. Each function relies on specific parameters that guide its behavior and interaction with the model. Here's a breakdown of the key parameters used within the functions_declarations array.\nfunction_declarations (array):\nContains one or more objects, each representing a distinct function.\nWithin each function_declarations object:\nname (string): The unique identifier for the function within the API call.\nBest practice: Use clear, descriptive names without space, period (.), or dash (-) characters. Instead, use underscore (_) characters or camel case.\ndescription (string): A comprehensive explanation of the function's purpose and capabilities.\nBest practice: Be detailed, clear, and specific in function descriptions, providing examples if necessary. For example, instead of find theaters, use find theaters based on location and optionally movie title that is currently playing in theaters. Avoid overly broad or ambiguous descriptions.\nparameters (object): Defines the input data required by the function.\ntype (string): Specifies the overall data type (e.g., object).\nproperties (object):\nLists individual parameters, each with:\ntype (string): The data type of the parameter (e.g., string, integer, boolean).\nBest practice: Use strongly typed parameters to reduce model hallucinations. For example, if the parameter values are from a finite set, use an enum field instead of listing the values in the description (e.g., \"type\": \"enum\", \"values\": [\"now_playing\", \"upcoming\"]). If the parameter value is always an integer, set the type to integer rather than number.\ndescription (string): A clear explanation of the parameter's purpose and expected format.\nBest practice: Provide concrete examples and constraints. For example, instead of the location to search, use The city and state, e.g. San Francisco, CA or a zip code e.g. 95616.\nrequired (array):\nAn array of strings listing the parameter names that are mandatory for the function to operate.\nFor best results, prepend the user query with the following details:\nAdditional context for the model. For example, You are a movie API assistant to help users find movies and showtimes based on their preferences.\nDetails or instructions on how and when to use the functions. For example, Don't make assumptions on showtimes. Always use a future date for showtimes.\nInstructions to ask clarifying questions if user queries are ambiguous. For example, Ask clarifying questions if not enough information is available to complete the request.\nFor the temperature parameter, use 0 or another low value. This instructs the model to generate more confident results and reduces hallucinations.\nIf the model proposes the invocation of a function that would send an order, update a database, or otherwise have significant consequences, validate the function call with the user before executing it.",
            "filtered_word_count": 1458
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nIntro to function calling\nFunction calling with Python\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nSetup\nInstall the Python SDK\nImport packages\nSet up your API key\nFunction Basics\n[Optional] Low level access\nSummary\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API: Function calling with Python \nbookmark_border\n\nRun in Google Colab\n\t\nView source on GitHub\n\nYou can provide Gemini models with descriptions of functions. The model may ask you to call a function and send back the result to help the model handle your query.\n\nSetup\nInstall the Python SDK\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -U -q google-generativeai\n\nImport packages\n\nImport the necessary packages.\n\nimport pathlib\nimport textwrap\nimport time\n\nimport google.generativeai as genai\n\n\nfrom IPython import display\nfrom IPython.display import Markdown\n\ndef to_markdown(text):\n  text = text.replace('•', '  *')\n  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n\nSet up your API key\n\nBefore you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n\nGet an API key\n\nIn Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name API_KEY.\n\nOnce you have the API key, pass it to the SDK. You can do this in two ways:\n\nPut the key in the GOOGLE_API_KEY environment variable (the SDK will automatically pick it up from there).\nPass the key to genai.configure(api_key=...)\ntry:\n    # Used to securely store your API key\n    from google.colab import userdata\n\n    # Or use `os.getenv('API_KEY')` to fetch an environment variable.\n    GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nexcept ImportError:\n    import os\n    GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\n\ngenai.configure(api_key=GOOGLE_API_KEY)\n\nFunction Basics\n\nYou can pass a list of functions to the tools argument when creating a genai.GenerativeModel.\n\nImportant: The SDK converts the function's argument's type annotations to a format the API understands. The API only supports a limited selection of argument types, and this automatic conversion only supports a subset of that: int | float | bool | str | list | dict\ndef multiply(a:float, b:float):\n    \"\"\"returns a * b.\"\"\"\n    return a*b\n\nmodel = genai.GenerativeModel(model_name='gemini-1.0-pro',\n                              tools=[multiply])\n\nmodel\n\ngenai.GenerativeModel(\n    model_name='models/gemini-1.0-pro',\n    generation_config={},\n    safety_settings={},\n    tools=<google.generativeai.types.content_types.FunctionLibrary object at 0x10e73fe90>,\n)\n\n\nThe recomended way to use function calling is through the chat interface. The main reason is that FunctionCalls fit nicely into chat's multi-turn structure.\n\nchat = model.start_chat(enable_automatic_function_calling=True)\n\n\nWith automatic function calling enabled chat.send_message automatically calls your function if the model asks it to.\n\nIt appears to simply return a text response, containing the correct answer:\n\nresponse = chat.send_message('I have 57 cats, each owns 44 mittens, how many mittens is that in total?')\nresponse.text\n\n'The total number of mittens is 2508.'\n\n57*44\n\n2508\n\n\nIf you look in the ChatSession.history you can see the sequence of events:\n\nYou sent the question.\nThe model replied with a glm.FunctionCall.\nThe genai.ChatSession executed the function locally and sent the model back a glm.FunctionResponse.\nThe model used the function output in its answer.\nfor content in chat.history:\n    part = content.parts[0]\n    print(content.role, \"->\", type(part).to_dict(part))\n    print('-'*80)\n\nuser -> {'text': 'I have 57 cats, each owns 44 mittens, how many mittens is that in total?'}\n--------------------------------------------------------------------------------\nmodel -> {'function_call': {'name': 'multiply', 'args': {'a': 57.0, 'b': 44.0} } }\n--------------------------------------------------------------------------------\nuser -> {'function_response': {'name': 'multiply', 'response': {'result': 2508.0} } }\n--------------------------------------------------------------------------------\nmodel -> {'text': 'The total number of mittens is 2508.'}\n--------------------------------------------------------------------------------\n\n\nIn general the state diagram is:\n\nThe model can respond with multiple function calls before returning a text response, and function calls come before the text response.\n\nWhile this was all handled automatically, if you need more control, you can:\n\nLeave the default enable_automatic_function_calling=False and process the glm.FunctionCall responses yourself.\nOr use GenerativeModel.generate_content, where you also need to manage the chat history.\n[Optional] Low level access\n\nThe automatic extraction of the schema from python functions doesn't work in all cases. For example: it doesn't handle cases where you describe the fields of a nested dictionary-object, but the API does support this. The API is able to describe any of the follwing types:\n\nAllowedType = (int | float | bool | str | list['AllowedType'] | dict[str, AllowedType]\n\n\nThe google.ai.generativelanguage client library provides access to the low level types giving you full control.\n\nimport google.ai.generativelanguage as glm\n\n\nFirst peek inside the model's _tools attribute, you can see how it describes the function(s) you passed it to the model:\n\ndef multiply(a:float, b:float):\n    \"\"\"returns a * b.\"\"\"\n    return a*b\n\nmodel = genai.GenerativeModel(model_name='gemini-1.0-pro',\n                             tools=[multiply])\n\nmodel._tools.to_proto()\n\n[function_declarations {\n   name: \"multiply\"\n   description: \"returns a * b.\"\n   parameters {\n     type_: OBJECT\n     properties {\n       key: \"b\"\n       value {\n         type_: NUMBER\n       }\n     }\n     properties {\n       key: \"a\"\n       value {\n         type_: NUMBER\n       }\n     }\n     required: \"a\"\n     required: \"b\"\n   }\n }]\n\n\nThis returns the list of glm.Tool objects that would be sent to the API. If the printed format is not familiar, it's because these are Google protobuf classes. Each glm.Tool (1 in this case) contains a list of glm.FunctionDeclarations, which describe a function and its arguments.\n\nHere is a declaration for the same multiply function written using the glm classes.\n\nNote that these classes just describe the function for the API, they don't include an implementation of it. So using this doesn't work with automatic function calling, but functions don't always need an implementation.\n\ncalculator = glm.Tool(\n    function_declarations=[\n      glm.FunctionDeclaration(\n        name='multiply',\n        description=\"Returns the product of two numbers.\",\n        parameters=glm.Schema(\n            type=glm.Type.OBJECT,\n            properties={\n                'a':glm.Schema(type=glm.Type.NUMBER),\n                'b':glm.Schema(type=glm.Type.NUMBER)\n            },\n            required=['a','b']\n        )\n      )\n    ])\n\n\nEquivalently, you can describe this as a JSON-compatible object:\n\ncalculator = {'function_declarations': [\n      {'name': 'multiply',\n       'description': 'Returns the product of two numbers.',\n       'parameters': {'type_': 'OBJECT',\n       'properties': {\n         'a': {'type_': 'NUMBER'},\n         'b': {'type_': 'NUMBER'} },\n       'required': ['a', 'b']} }]}\n\nglm.Tool(calculator)\n\nfunction_declarations {\n  name: \"multiply\"\n  description: \"Returns the product of two numbers.\"\n  parameters {\n    type_: OBJECT\n    properties {\n      key: \"b\"\n      value {\n        type_: NUMBER\n      }\n    }\n    properties {\n      key: \"a\"\n      value {\n        type_: NUMBER\n      }\n    }\n    required: \"a\"\n    required: \"b\"\n  }\n}\n\n\nEither way, you pass a representation of a glm.Tool or list of tools to\n\nmodel = genai.GenerativeModel('gemini-pro', tools=calculator)\nchat = model.start_chat()\n\nresponse = chat.send_message(\n    f\"What's 234551 X 325552 ?\",\n)\n\n\nLike before the model returns a glm.FunctionCall invoking the calculator's multiply function:\n\nresponse.candidates\n\n[index: 0\ncontent {\n  parts {\n    function_call {\n      name: \"multiply\"\n      args {\n        fields {\n          key: \"b\"\n          value {\n            number_value: 325552\n          }\n        }\n        fields {\n          key: \"a\"\n          value {\n            number_value: 234551\n          }\n        }\n      }\n    }\n  }\n  role: \"model\"\n}\nfinish_reason: STOP\n]\n\n\nExecute the function yourself:\n\nfc = response.candidates[0].content.parts[0].function_call\nassert fc.name == 'multiply'\n\nresult = fc.args['a'] * fc.args['b']\nresult\n\n76358547152.0\n\n\nSend the result to the model, to continue the conversation:\n\nresponse = chat.send_message(\n    glm.Content(\n    parts=[glm.Part(\n        function_response = glm.FunctionResponse(\n          name='multiply',\n          response={'result': result}))]))\n\nSummary\n\nBasic function calling is supported in the SDK. Remember that it is easier to manage using chat-mode, because of the natural back and forth structure. You're in charge of actually calling the functions and sending results back to the model so it can produce a text-response.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 1312,
            "filtered_content": "Gemini API: Function calling with Python \nYou can provide Gemini models with descriptions of functions. The model may ask you to call a function and send back the result to help the model handle your query.\npip install -U -q google-generativeai\nfrom IPython import display\nIn Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name API_KEY.\n    # Used to securely store your API key\n    from google.colab import userdata\n    # Or use `os.getenv('API_KEY')` to fetch an environment variable.\n    GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n    import os\n    GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\nYou can pass a list of functions to the tools argument when creating a genai.GenerativeModel.\nImportant: The SDK converts the function's argument's type annotations to a format the API understands. The API only supports a limited selection of argument types, and this automatic conversion only supports a subset of that: int | float | bool | str | list | dict\n                              tools=[multiply])\ngenai.GenerativeModel(\n    model_name='models/gemini-1.0-pro',\n    generation_config={},\n    safety_settings={},\n    tools=<google.generativeai.types.content_types.FunctionLibrary object at 0x10e73fe90>,\nThe recomended way to use function calling is through the chat interface. The main reason is that FunctionCalls fit nicely into chat's multi-turn structure.\nchat = model.start_chat(enable_automatic_function_calling=True)\nWith automatic function calling enabled chat.send_message automatically calls your function if the model asks it to.\nIt appears to simply return a text response, containing the correct answer:\nresponse = chat.send_message('I have 57 cats, each owns 44 mittens, how many mittens is that in total?')\n'The total number of mittens is 2508.'\n57*44\n2508\nIf you look in the ChatSession.history you can see the sequence of events:\nYou sent the question.\nThe model replied with a glm.FunctionCall.\nThe genai.ChatSession executed the function locally and sent the model back a glm.FunctionResponse.\nThe model used the function output in its answer.\nfor content in chat.history:\n    part = content.parts[0]\n    print(content.role, \"->\", type(part).to_dict(part))\n    print('-'*80)\nuser -> {'text': 'I have 57 cats, each owns 44 mittens, how many mittens is that in total?'}\nmodel -> {'function_call': {'name': 'multiply', 'args': {'a': 57.0, 'b': 44.0} } }\nuser -> {'function_response': {'name': 'multiply', 'response': {'result': 2508.0} } }\nmodel -> {'text': 'The total number of mittens is 2508.'}\nIn general the state diagram is:\nThe model can respond with multiple function calls before returning a text response, and function calls come before the text response.\nWhile this was all handled automatically, if you need more control, you can:\nLeave the default enable_automatic_function_calling=False and process the glm.FunctionCall responses yourself.\nOr use GenerativeModel.generate_content, where you also need to manage the chat history.\nThe automatic extraction of the schema from python functions doesn't work in all cases. For example: it doesn't handle cases where you describe the fields of a nested dictionary-object, but the API does support this. The API is able to describe any of the follwing types:\nAllowedType = (int | float | bool | str | list['AllowedType'] | dict[str, AllowedType]\nThe google.ai.generativelanguage client library provides access to the low level types giving you full control.\nFirst peek inside the model's _tools attribute, you can see how it describes the function(s) you passed it to the model:\n                             tools=[multiply])\nmodel._tools.to_proto()\n[function_declarations {\n   name: \"multiply\"\n   description: \"returns a * b.\"\n   parameters {\n     type_: OBJECT\n       key: \"b\"\n       key: \"a\"\n     required: \"a\"\n     required: \"b\"\n   }\n }]\nThis returns the list of glm.Tool objects that would be sent to the API. If the printed format is not familiar, it's because these are Google protobuf classes. Each glm.Tool (1 in this case) contains a list of glm.FunctionDeclarations, which describe a function and its arguments.\nHere is a declaration for the same multiply function written using the glm classes.\nNote that these classes just describe the function for the API, they don't include an implementation of it. So using this doesn't work with automatic function calling, but functions don't always need an implementation.\ncalculator = glm.Tool(\n    function_declarations=[\n      glm.FunctionDeclaration(\n        name='multiply',\n        description=\"Returns the product of two numbers.\",\n        parameters=glm.Schema(\n            type=glm.Type.OBJECT,\n            properties={\n                'a':glm.Schema(type=glm.Type.NUMBER),\n                'b':glm.Schema(type=glm.Type.NUMBER)\n            },\n            required=['a','b']\n        )\n      )\n    ])\nEquivalently, you can describe this as a JSON-compatible object:\ncalculator = {'function_declarations': [\n      {'name': 'multiply',\n       'description': 'Returns the product of two numbers.',\n       'parameters': {'type_': 'OBJECT',\n       'properties': {\n         'a': {'type_': 'NUMBER'},\n         'b': {'type_': 'NUMBER'} },\n       'required': ['a', 'b']} }]}\nglm.Tool(calculator)\nfunction_declarations {\n  name: \"multiply\"\n  description: \"Returns the product of two numbers.\"\n  parameters {\n    type_: OBJECT\n      key: \"b\"\n      key: \"a\"\n    required: \"a\"\n    required: \"b\"\nEither way, you pass a representation of a glm.Tool or list of tools to\nmodel = genai.GenerativeModel('gemini-pro', tools=calculator)\nchat = model.start_chat()\n    f\"What's 234551 X 325552 ?\",\nLike before the model returns a glm.FunctionCall invoking the calculator's multiply function:\n[index: 0\ncontent {\n    function_call {\n      name: \"multiply\"\n      args {\n          key: \"b\"\n            number_value: 325552\n          key: \"a\"\n            number_value: 234551\nExecute the function yourself:\nfc = response.candidates[0].content.parts[0].function_call\nassert fc.name == 'multiply'\nresult = fc.args['a'] * fc.args['b']\nresult\n76358547152.0\nSend the result to the model, to continue the conversation:\n    parts=[glm.Part(\n        function_response = glm.FunctionResponse(\n          name='multiply',\n          response={'result': result}))]))\nBasic function calling is supported in the SDK. Remember that it is easier to manage using chat-mode, because of the natural back and forth structure. You're in charge of actually calling the functions and sending results back to the model so it can produce a text-response.",
            "filtered_word_count": 848
        },
        "https://ai.google.dev/gemini-api/docs/embeddings": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nIntro to embeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nWhat are embeddings?\nUse cases\nElastic embeddings\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nEmbeddings guide \nbookmark_border\n\nThe embedding service in the Gemini API generates state-of-the-art embeddings for words, phrases, and sentences. The resulting embeddings can then be used for NLP tasks, such as semantic search, text classification and clustering among many others. This page describes what embeddings are and highlights some key use cases for the embedding service to help you get started.\n\nWhat are embeddings?\n\nText embeddings are a natural language processing (NLP) technique that converts text into numerical vectors. Embeddings capture semantic meaning and context which results in text with similar meanings having closer embeddings. For example, the sentence \"I took my dog to the vet\" and \"I took my cat to the vet\" would have embeddings that are close to each other in the vector space since they both describe similar context.\n\nThis is important because it unlocks many algorithms that can operate on vectors but not directly on text.\n\nYou can use these embeddings or vectors to compare different texts and understand how they relate. For example, if the embeddings of the text \"cat\" and \"dog\" are close together you can infer that these words are similar in meaning or context or both. This ability allows a variety of uses cases described in the next section.\n\nUse cases\n\nText embeddings power a variety of NLP use cases. For example:\n\nInformation Retrieval: The goal is to retrieve semantically similar text given a piece of input text. A variety of applications can be supported by an information retrieval system such as semantic search, answering questions, or summarization. Refer to the document search notebook for an example.\nClassification: You can use embeddings to train a model to classify documents into categories. For example, if you want to classify user comments as negative or positive, you can use the embeddings service to get the vector representation of each comment to train the classifier. Refer to the Gemini classifier example for more details.\nClustering: Comparing vectors of text can show how similar or different they are. This feature can be used to train a clustering model that groups similar text or documents together and to detect anomalies in your data.\nVector DB: You can store your generated embeddings in a vector DB to improve the accuracy and efficiency of your NLP application. Refer to this page to learn how to use a vector DB to translate text prompts into numerical vectors.\nElastic embeddings\n\nThe Gemini Text Embedding model, starting with text-embedding-004, offers elastic embedding sizes under 768. You can use elastic embeddings to generate smaller output dimensions and potentially save computing and storage costs with minor performance loss.\n\nWhat's next\nIf you're ready to start developing, you can find complete runnable code in the quickstarts for Python, Go, Node.js, and Dart (Flutter).\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 650,
            "filtered_content": "Intro to embeddings\nEmbeddings guide \nThe embedding service in the Gemini API generates state-of-the-art embeddings for words, phrases, and sentences. The resulting embeddings can then be used for NLP tasks, such as semantic search, text classification and clustering among many others. This page describes what embeddings are and highlights some key use cases for the embedding service to help you get started.\nText embeddings are a natural language processing (NLP) technique that converts text into numerical vectors. Embeddings capture semantic meaning and context which results in text with similar meanings having closer embeddings. For example, the sentence \"I took my dog to the vet\" and \"I took my cat to the vet\" would have embeddings that are close to each other in the vector space since they both describe similar context.\nThis is important because it unlocks many algorithms that can operate on vectors but not directly on text.\nYou can use these embeddings or vectors to compare different texts and understand how they relate. For example, if the embeddings of the text \"cat\" and \"dog\" are close together you can infer that these words are similar in meaning or context or both. This ability allows a variety of uses cases described in the next section.\nText embeddings power a variety of NLP use cases. For example:\nInformation Retrieval: The goal is to retrieve semantically similar text given a piece of input text. A variety of applications can be supported by an information retrieval system such as semantic search, answering questions, or summarization. Refer to the document search notebook for an example.\nClassification: You can use embeddings to train a model to classify documents into categories. For example, if you want to classify user comments as negative or positive, you can use the embeddings service to get the vector representation of each comment to train the classifier. Refer to the Gemini classifier example for more details.\nClustering: Comparing vectors of text can show how similar or different they are. This feature can be used to train a clustering model that groups similar text or documents together and to detect anomalies in your data.\nVector DB: You can store your generated embeddings in a vector DB to improve the accuracy and efficiency of your NLP application. Refer to this page to learn how to use a vector DB to translate text prompts into numerical vectors.\nThe Gemini Text Embedding model, starting with text-embedding-004, offers elastic embedding sizes under 768. You can use elastic embeddings to generate smaller output dimensions and potentially save computing and storage costs with minor performance loss.\nIf you're ready to start developing, you can find complete runnable code in the quickstarts for Python, Go, Node.js, and Dart (Flutter).",
            "filtered_word_count": 451
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nSafety settings\nSafety guidance\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nSafety filters\nProbability versus severity\nSafety Settings\nSafety feedback\nSafety settings in Google AI Studio\nCode examples\nRequest example\nResponse example\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nSafety settings \nbookmark_border\n\nThis guide describes the adjustable safety settings available for the Gemini API. During the prototyping stage, you can adjust safety settings on 4 dimensions to quickly assess if your application requires more or less restrictive configuration. By default, safety settings block content (including prompts) with medium or higher probability of being unsafe across any dimension. This baseline safety is designed to work for most use cases, so you should only adjust your safety settings if it's consistently required for your application.\n\nNote: Adjusting to lower safety settings will trigger a more indepth review process of your application.\nSafety filters\n\nIn addition to the adjustable safety filters, the Gemini API has built-in protections against core harms, such as content that endangers child safety. These types of harm are always blocked and cannot be adjusted.\n\nThe adjustable safety filters cover the following categories:\n\nHarassment\nHate speech\nSexually explicit\nDangerous\n\nThese settings allow you, the developer, to determine what is appropriate for your use case. For example, if you're building a video game dialogue, you may deem it acceptable to allow more content that's rated as dangerous due to the nature of the game. Here are a few other example use cases that may need some flexibility in these safety settings:\n\nUse Case\tCategory\nAnti-Harassment Training App\tHate speech, Sexually explicit\nScreenplay Writer\tSexually explicit, Dangerous\nToxicity classifier\tHarassment, Dangerous\nProbability versus severity\n\nThe Gemini API blocks content based on the probability of content being unsafe and not the severity. This is important to consider because some content can have low probability of being unsafe even though the severity of harm could still be high. For example, comparing the sentences:\n\nThe robot punched me.\nThe robot slashed me up.\n\nSentence 1 might result in a higher probability of being unsafe but you might consider sentence 2 to be a higher severity in terms of violence.\n\nGiven this, it is important for each developer to carefully test and consider what the appropriate level of blocking is needed to support their key use cases while minimizing harm to end users.\n\nSafety Settings\n\nSafety settings are part of the request you send to the generative service. The settings can be adjusted for each request you make to the API. The following table lists the categories that you can set and describes the type of harm that each category encompasses.\n\nCategories\tDescriptions\nHarassment\tNegative or harmful comments targeting identity and/or protected attributes.\nHate speech\tContent that is rude, disrespectful, or profane.\nSexually explicit\tContains references to sexual acts or other lewd content.\nDangerous\tPromotes, facilitates, or encourages harmful acts.\n\nThese definitions are in the API reference as well. The Gemini models only support HARM_CATEGORY_HARASSMENT, HARM_CATEGORY_HATE_SPEECH, HARM_CATEGORY_SEXUALLY_EXPLICIT, and HARM_CATEGORY_DANGEROUS_CONTENT. The other categories are used by PaLM 2 (Legacy) models.\n\nThe following table describes the block settings you can adjust for each category. For example, if you set the block setting to Block few for the Hate speech category, everything that has a high probability of being hate speech content is blocked. But anything with a lower probability is allowed.\n\nIf not set, the default block setting is Block some for all categories.\n\nThreshold (Google AI Studio)\tThreshold (API)\tDescription\nBlock none\tBLOCK_NONE\tAlways show regardless of probability of unsafe content\nBlock few\tBLOCK_ONLY_HIGH\tBlock when high probability of unsafe content\nBlock some\tBLOCK_MEDIUM_AND_ABOVE\tBlock when medium or high probability of unsafe content\nBlock most\tBLOCK_LOW_AND_ABOVE\tBlock when low, medium or high probability of unsafe content\n\tHARM_BLOCK_THRESHOLD_UNSPECIFIED\tThreshold is unspecified, block using default threshold\n\nYou can set these settings for each request you make to the generative service. See the HarmBlockThreshold API reference for details.\n\nSafety feedback\n\ngenerateContent returns a GenerateContentResponse which includes safety feedback.\n\nPrompt feedback is included in promptFeedback. If promptFeedback.blockReason is set, then the content of the prompt was blocked.\n\nResponse candidate feedback is included in finishReason and safetyRatings. If response content was blocked and the finishReason was SAFETY, you can inspect safetyRatings for more details. The safety rating includes the category and the probability of the harm classification. The content that was blocked is not returned.\n\nThe probability returned correspond to the block confidence levels as shown in the following table:\n\nProbability\tDescription\nNEGLIGIBLE\tContent has a negligible probability of being unsafe\nLOW\tContent has a low probability of being unsafe\nMEDIUM\tContent has a medium probability of being unsafe\nHIGH\tContent has a high probability of being unsafe\n\nFor example, if the content was blocked due to the harassment category having a high probability, the safety rating returned would have category equal to HARASSMENT and harm probability set to HIGH.\n\nSafety settings in Google AI Studio\n\nYou can also adjust safety settings in Google AI Studio, but you cannot turn them off. To do so, in the Run settings, click Edit safety settings:\n\nAnd use the knobs to adjust each setting:\n\nA warning No Content message appears if the content is blocked. To see more details, hold the pointer over No Content and click warning Safety.\n\nCode examples\n\nThis section shows how to use the safety settings in code using the python client library.\n\nRequest example\n\nThe following is a python code snippet showing how to set safety settings in your GenerateContent call. This sets the harm categories Harassment and Hate speech to BLOCK_LOW_AND_ABOVE which blocks any content that has a low or higher probability of being harassment or hate speech.\n\nfrom google.generativeai.types import HarmCategory, HarmBlockThreshold\n\nmodel = genai.GenerativeModel(model_name='gemini-pro-vision')\nresponse = model.generate_content(\n    ['Do these look store-bought or homemade?', img],\n    safety_settings={\n        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    }\n)\n\nResponse example\n\nThe following shows a code snippet for parsing the safety feedback from the response.\n\ntry:\n  print(response.text)\nexcept ValueError:\n  # If the response doesn't contain text, check if the prompt was blocked.\n  print(response.prompt_feedback)\n  # Also check the finish reason to see if the response was blocked.\n  print(response.candidates[0].finish_reason)\n  # If the finish reason was SAFETY, the safety ratings have more details.\n  print(response.candidates[0].safety_ratings)\n\nNext steps\nSee the API reference to learn more about the full API.\nReview the safety guidance for a general look at safety considerations when developing with LLMs.\nLearn more about assessing probability versus severity from the Jigsaw team\nLearn more about the products that contribute to safety solutions like the Perspective API.\nYou can use these safety settings to create a toxicity classifier. See the classification example to get started.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-19 UTC.\n\nTerms\nPrivacy",
            "word_count": 1265,
            "filtered_content": "Safety guidance\nSafety settings \nThis guide describes the adjustable safety settings available for the Gemini API. During the prototyping stage, you can adjust safety settings on 4 dimensions to quickly assess if your application requires more or less restrictive configuration. By default, safety settings block content (including prompts) with medium or higher probability of being unsafe across any dimension. This baseline safety is designed to work for most use cases, so you should only adjust your safety settings if it's consistently required for your application.\nNote: Adjusting to lower safety settings will trigger a more indepth review process of your application.\nIn addition to the adjustable safety filters, the Gemini API has built-in protections against core harms, such as content that endangers child safety. These types of harm are always blocked and cannot be adjusted.\nThe adjustable safety filters cover the following categories:\nHarassment\nHate speech\nSexually explicit\nDangerous\nThese settings allow you, the developer, to determine what is appropriate for your use case. For example, if you're building a video game dialogue, you may deem it acceptable to allow more content that's rated as dangerous due to the nature of the game. Here are a few other example use cases that may need some flexibility in these safety settings:\nUse Case\tCategory\nAnti-Harassment Training App\tHate speech, Sexually explicit\nScreenplay Writer\tSexually explicit, Dangerous\nToxicity classifier\tHarassment, Dangerous\nThe Gemini API blocks content based on the probability of content being unsafe and not the severity. This is important to consider because some content can have low probability of being unsafe even though the severity of harm could still be high. For example, comparing the sentences:\nThe robot punched me.\nThe robot slashed me up.\nSentence 1 might result in a higher probability of being unsafe but you might consider sentence 2 to be a higher severity in terms of violence.\nGiven this, it is important for each developer to carefully test and consider what the appropriate level of blocking is needed to support their key use cases while minimizing harm to end users.\nSafety settings are part of the request you send to the generative service. The settings can be adjusted for each request you make to the API. The following table lists the categories that you can set and describes the type of harm that each category encompasses.\nCategories\tDescriptions\nHarassment\tNegative or harmful comments targeting identity and/or protected attributes.\nHate speech\tContent that is rude, disrespectful, or profane.\nSexually explicit\tContains references to sexual acts or other lewd content.\nDangerous\tPromotes, facilitates, or encourages harmful acts.\nThese definitions are in the API reference as well. The Gemini models only support HARM_CATEGORY_HARASSMENT, HARM_CATEGORY_HATE_SPEECH, HARM_CATEGORY_SEXUALLY_EXPLICIT, and HARM_CATEGORY_DANGEROUS_CONTENT. The other categories are used by PaLM 2 (Legacy) models.\nThe following table describes the block settings you can adjust for each category. For example, if you set the block setting to Block few for the Hate speech category, everything that has a high probability of being hate speech content is blocked. But anything with a lower probability is allowed.\nIf not set, the default block setting is Block some for all categories.\nThreshold (Google AI Studio)\tThreshold (API)\tDescription\nBlock none\tBLOCK_NONE\tAlways show regardless of probability of unsafe content\nBlock few\tBLOCK_ONLY_HIGH\tBlock when high probability of unsafe content\nBlock some\tBLOCK_MEDIUM_AND_ABOVE\tBlock when medium or high probability of unsafe content\nBlock most\tBLOCK_LOW_AND_ABOVE\tBlock when low, medium or high probability of unsafe content\n\tHARM_BLOCK_THRESHOLD_UNSPECIFIED\tThreshold is unspecified, block using default threshold\nYou can set these settings for each request you make to the generative service. See the HarmBlockThreshold API reference for details.\ngenerateContent returns a GenerateContentResponse which includes safety feedback.\nPrompt feedback is included in promptFeedback. If promptFeedback.blockReason is set, then the content of the prompt was blocked.\nResponse candidate feedback is included in finishReason and safetyRatings. If response content was blocked and the finishReason was SAFETY, you can inspect safetyRatings for more details. The safety rating includes the category and the probability of the harm classification. The content that was blocked is not returned.\nThe probability returned correspond to the block confidence levels as shown in the following table:\nProbability\tDescription\nNEGLIGIBLE\tContent has a negligible probability of being unsafe\nLOW\tContent has a low probability of being unsafe\nMEDIUM\tContent has a medium probability of being unsafe\nHIGH\tContent has a high probability of being unsafe\nFor example, if the content was blocked due to the harassment category having a high probability, the safety rating returned would have category equal to HARASSMENT and harm probability set to HIGH.\nYou can also adjust safety settings in Google AI Studio, but you cannot turn them off. To do so, in the Run settings, click Edit safety settings:\nAnd use the knobs to adjust each setting:\nA warning No Content message appears if the content is blocked. To see more details, hold the pointer over No Content and click warning Safety.\nThis section shows how to use the safety settings in code using the python client library.\nThe following is a python code snippet showing how to set safety settings in your GenerateContent call. This sets the harm categories Harassment and Hate speech to BLOCK_LOW_AND_ABOVE which blocks any content that has a low or higher probability of being harassment or hate speech.\nfrom google.generativeai.types import HarmCategory, HarmBlockThreshold\nmodel = genai.GenerativeModel(model_name='gemini-pro-vision')\n    ['Do these look store-bought or homemade?', img],\n    safety_settings={\n        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\nThe following shows a code snippet for parsing the safety feedback from the response.\nexcept ValueError:\n  # If the response doesn't contain text, check if the prompt was blocked.\n  print(response.prompt_feedback)\n  # Also check the finish reason to see if the response was blocked.\n  print(response.candidates[0].finish_reason)\n  # If the finish reason was SAFETY, the safety ratings have more details.\n  print(response.candidates[0].safety_ratings)\nSee the API reference to learn more about the full API.\nReview the safety guidance for a general look at safety considerations when developing with LLMs.\nLearn more about assessing probability versus severity from the Jigsaw team\nLearn more about the products that contribute to safety solutions like the Perspective API.\nYou can use these safety settings to create a toxicity classifier. See the classification example to get started.\nLast updated 2024-04-19 UTC.",
            "filtered_word_count": 1033
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nSafety settings\nSafety guidance\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nUnderstand the safety risks of your application\nConsider adjustments to mitigate safety risks\nPerform safety testing appropriate to your use case\nMonitor for problems\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nSafety guidance \nbookmark_border\n\nPart of what makes large language models (LLMs) so useful is that they’re creative tools that can address many different language tasks. Unfortunately, this also means that large language models can generate output that you don't expect, including text that's offensive, insensitive, or factually incorrect. What's more, the incredible versatility of these models is also what makes it difficult to predict exactly what kinds of undesirable output they might produce. While the Gemini API has been designed with Google's AI principles in mind, the onus is on developers to apply these models responsibly. To aid developers in creating safe, responsible applications, the Gemini API has some built-in content filtering as well as adjustable safety settings across 4 dimensions of harm. Refer to the safety settings guide to learn more.\n\nThis document is meant to introduce you to some safety risks that can arise when using LLMs, and recommend emerging safety design and development recommendations. (Note that laws and regulations may also impose restrictions, but such considerations are beyond the scope of this guide.)\n\nThe following steps are recommended when building applications with LLMs:\n\nUnderstanding the safety risks of your application\nConsidering adjustments to mitigate safety risks\nPerforming safety testing appropriate to your use case\nSoliciting feedback from users and monitoring usage\n\nThe adjustment and testing phases should be iterative until you reach performance appropriate for your application.\n\nUnderstand the safety risks of your application\n\nIn this context, safety is being defined as the ability of an LLM to avoid causing harm to its users, for example, by generating toxic language or content that promotes stereotypes. The models available through the Gemini API have been designed with Google’s AI principles in mind and your use of it is subject to the Generative AI Prohibited Use Policy. The API provides built-in safety filters to help address some common language model problems such as toxic language and hate speech, and striving for inclusiveness and avoidance of stereotypes. However, each application can pose a different set of risks to its users. So as the application owner, you are responsible for knowing your users and the potential harms your application may cause, and ensuring that your application uses LLMs safely and responsibly.\n\nAs part of this assessment, you should consider the likelihood that harm could occur and determine its seriousness and mitigation steps. For example, an app that generates essays based on factual events would need to be more careful about avoiding misinformation, as compared to an app that generates fictional stories for entertainment. A good way to begin exploring potential safety risks is to research your end users, and others who might be affected by your application's results. This can take many forms including researching state of the art studies in your app domain, observing how people are using similar apps, or running a user study, survey, or conducting informal interviews with potential users.\n\nAdvanced tips\nConsider adjustments to mitigate safety risks\n\nNow that you have an understanding of the risks, you can decide how to mitigate them. Determining which risks to prioritize and how much you should do to try to prevent them is a critical decision, similar to triaging bugs in a software project. Once you've determined priorities, you can start thinking about the types of mitigations that would be most appropriate. Often simple changes can make a difference and reduce risks.\n\nFor example, when designing an application consider:\n\nTuning the model output to better reflect what is acceptable in your application context. Tuning can make the output of the model more predictable and consistent and therefore can help mitigate certain risks.\nProviding an input method that facilities safer outputs. The exact input you give to an LLM can make a difference in the quality of the output. Experimenting with input prompts to find what works most safely in your use-case is well worth the effort, as you can then provide a UX that facilitates it. For example, you could restrict users to choose only from a drop-down list of input prompts, or offer pop-up suggestions with descriptive phrases which you've found perform safely in your application context.\n\nBlocking unsafe inputs and filtering output before it is shown to the user. In simple situations, blocklists can be used to identify and block unsafe words or phrases in prompts or responses, or require human reviewers to manually alter or block such content.\n\nNote: Automatically blocking based on a static list can have unintended results such as targeting a particular group that commonly uses vocabulary in the blocklist.\n\nUsing trained classifiers to label each prompt with potential harms or adversarial signals. Different strategies can then be employed on how to handle the request based on the type of harm detected. For example, If the input is overtly adversarial or abusive in nature, it could be blocked and instead output a pre-scripted response.\n\nAdvanced tip\n\nPutting safeguards in place against deliberate misuse such as assigning each user a unique ID and imposing a limit on the volume of user queries that can be submitted in a given period. Another safeguard is to try and protect against possible prompt injection. Prompt injection, much like SQL injection, is a way for malicious users to design an input prompt that manipulates the output of the model, for example, by sending an input prompt that instructs the model to ignore any previous examples. See the Generative AI Prohibited Use Policy for details about deliberate misuse.\n\nAdjusting functionality to something that is inherently lower risk. Tasks that are narrower in scope (e.g., extracting keywords from passages of text) or that have greater human oversight (e.g., generating short-form content that will be reviewed by a human), often pose a lower risk. So for instance, instead of creating an application to write an email reply from scratch, you might instead limit it to expanding on an outline or suggesting alternative phrasings.\n\nPerform safety testing appropriate to your use case\n\nTesting is a key part of building robust and safe applications, but the extent, scope and strategies for testing will vary. For example, a just-for-fun haiku generator is likely to pose less severe risks than, say, an application designed for use by law firms to summarize legal documents and help draft contracts. But the haiku generator may be used by a wider variety of users which means the potential for adversarial attempts or even unintended harmful inputs can be greater. The implementation context also matters. For instance, an application with outputs that are reviewed by human experts prior to any action being taken might be deemed less likely to produce harmful outputs than the identical application without such oversight.\n\nIt's not uncommon to go through several iterations of making changes and testing before feeling confident that you're ready to launch, even for applications that are relatively low risk. Two kinds of testing are particularly useful for AI applications:\n\nSafety benchmarking involves designing safety metrics that reflect the ways your application could be unsafe in the context of how it is likely to get used, then testing how well your application performs on the metrics using evaluation datasets. It's good practice to think about the minimum acceptable levels of safety metrics before testing so that 1) you can evaluate the test results against those expectations and 2) you can gather the evaluation dataset based on the tests that evaluate the metrics you care about most.\n\nAdvanced tips\n\nAdversarial testing involves proactively trying to break your application. The goal is to identify points of weakness so that you can take steps to remedy them as appropriate. Adversarial testing can take significant time/effort from evaluators with expertise in your application — but the more you do, the greater your chance of spotting problems, especially those occurring rarely or only after repeated runs of the application.\n\nAdversarial testing is a method for systematically evaluating an ML model with the intent of learning how it behaves when provided with malicious or inadvertently harmful input:\nAn input may be malicious when the input is clearly designed to produce an unsafe or harmful output-- for example, asking a text generation model to generate a hateful rant about a particular religion.\nAn input is inadvertently harmful when the input itself may be innocuous, but produces harmful output -- for example, asking a text generation model to describe a person of a particular ethnicity and receiving a racist output.\nWhat distinguishes an adversarial test from a standard evaluation is the composition of the data used for testing. For adversarial tests, select test data that is most likely to elicit problematic output from the model. This means probing the model's behavior for all the types of harms that are possible, including rare or unusual examples and edge-cases that are relevant to safety policies. It should also include diversity in the different dimensions of a sentence such as structure, meaning and length. You can refer to the Google's Responsible AI practices in fairness for more details on what to consider when building a test dataset.\nAdvanced tips\nNote: LLMs are known to sometimes produce different outputs for the same input prompt. Multiple rounds of testing may be needed to catch more of the problematic outputs.\nMonitor for problems\n\nNo matter how much you test and mitigate, you can never guarantee perfection, so plan upfront how you'll spot and deal with problems that arise. Common approaches include setting up a monitored channel for users to share feedback (e.g., thumbs up/down rating) and running a user study to proactively solicit feedback from a diverse mix of users — especially valuable if usage patterns are different to expectations.\n\nAdvanced tips\nNext steps\nRefer to the safety settings guide to learn about the adjustable safety settings available through the Gemini API.\nSee the intro to prompting to get started writing your first prompts.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-19 UTC.\n\nTerms\nPrivacy",
            "word_count": 1848,
            "filtered_content": "Safety guidance \nPart of what makes large language models (LLMs) so useful is that they’re creative tools that can address many different language tasks. Unfortunately, this also means that large language models can generate output that you don't expect, including text that's offensive, insensitive, or factually incorrect. What's more, the incredible versatility of these models is also what makes it difficult to predict exactly what kinds of undesirable output they might produce. While the Gemini API has been designed with Google's AI principles in mind, the onus is on developers to apply these models responsibly. To aid developers in creating safe, responsible applications, the Gemini API has some built-in content filtering as well as adjustable safety settings across 4 dimensions of harm. Refer to the safety settings guide to learn more.\nThis document is meant to introduce you to some safety risks that can arise when using LLMs, and recommend emerging safety design and development recommendations. (Note that laws and regulations may also impose restrictions, but such considerations are beyond the scope of this guide.)\nThe following steps are recommended when building applications with LLMs:\nUnderstanding the safety risks of your application\nConsidering adjustments to mitigate safety risks\nPerforming safety testing appropriate to your use case\nSoliciting feedback from users and monitoring usage\nThe adjustment and testing phases should be iterative until you reach performance appropriate for your application.\nIn this context, safety is being defined as the ability of an LLM to avoid causing harm to its users, for example, by generating toxic language or content that promotes stereotypes. The models available through the Gemini API have been designed with Google’s AI principles in mind and your use of it is subject to the Generative AI Prohibited Use Policy. The API provides built-in safety filters to help address some common language model problems such as toxic language and hate speech, and striving for inclusiveness and avoidance of stereotypes. However, each application can pose a different set of risks to its users. So as the application owner, you are responsible for knowing your users and the potential harms your application may cause, and ensuring that your application uses LLMs safely and responsibly.\nAs part of this assessment, you should consider the likelihood that harm could occur and determine its seriousness and mitigation steps. For example, an app that generates essays based on factual events would need to be more careful about avoiding misinformation, as compared to an app that generates fictional stories for entertainment. A good way to begin exploring potential safety risks is to research your end users, and others who might be affected by your application's results. This can take many forms including researching state of the art studies in your app domain, observing how people are using similar apps, or running a user study, survey, or conducting informal interviews with potential users.\nNow that you have an understanding of the risks, you can decide how to mitigate them. Determining which risks to prioritize and how much you should do to try to prevent them is a critical decision, similar to triaging bugs in a software project. Once you've determined priorities, you can start thinking about the types of mitigations that would be most appropriate. Often simple changes can make a difference and reduce risks.\nFor example, when designing an application consider:\nTuning the model output to better reflect what is acceptable in your application context. Tuning can make the output of the model more predictable and consistent and therefore can help mitigate certain risks.\nProviding an input method that facilities safer outputs. The exact input you give to an LLM can make a difference in the quality of the output. Experimenting with input prompts to find what works most safely in your use-case is well worth the effort, as you can then provide a UX that facilitates it. For example, you could restrict users to choose only from a drop-down list of input prompts, or offer pop-up suggestions with descriptive phrases which you've found perform safely in your application context.\nBlocking unsafe inputs and filtering output before it is shown to the user. In simple situations, blocklists can be used to identify and block unsafe words or phrases in prompts or responses, or require human reviewers to manually alter or block such content.\nNote: Automatically blocking based on a static list can have unintended results such as targeting a particular group that commonly uses vocabulary in the blocklist.\nUsing trained classifiers to label each prompt with potential harms or adversarial signals. Different strategies can then be employed on how to handle the request based on the type of harm detected. For example, If the input is overtly adversarial or abusive in nature, it could be blocked and instead output a pre-scripted response.\nAdvanced tip\nPutting safeguards in place against deliberate misuse such as assigning each user a unique ID and imposing a limit on the volume of user queries that can be submitted in a given period. Another safeguard is to try and protect against possible prompt injection. Prompt injection, much like SQL injection, is a way for malicious users to design an input prompt that manipulates the output of the model, for example, by sending an input prompt that instructs the model to ignore any previous examples. See the Generative AI Prohibited Use Policy for details about deliberate misuse.\nAdjusting functionality to something that is inherently lower risk. Tasks that are narrower in scope (e.g., extracting keywords from passages of text) or that have greater human oversight (e.g., generating short-form content that will be reviewed by a human), often pose a lower risk. So for instance, instead of creating an application to write an email reply from scratch, you might instead limit it to expanding on an outline or suggesting alternative phrasings.\nTesting is a key part of building robust and safe applications, but the extent, scope and strategies for testing will vary. For example, a just-for-fun haiku generator is likely to pose less severe risks than, say, an application designed for use by law firms to summarize legal documents and help draft contracts. But the haiku generator may be used by a wider variety of users which means the potential for adversarial attempts or even unintended harmful inputs can be greater. The implementation context also matters. For instance, an application with outputs that are reviewed by human experts prior to any action being taken might be deemed less likely to produce harmful outputs than the identical application without such oversight.\nIt's not uncommon to go through several iterations of making changes and testing before feeling confident that you're ready to launch, even for applications that are relatively low risk. Two kinds of testing are particularly useful for AI applications:\nSafety benchmarking involves designing safety metrics that reflect the ways your application could be unsafe in the context of how it is likely to get used, then testing how well your application performs on the metrics using evaluation datasets. It's good practice to think about the minimum acceptable levels of safety metrics before testing so that 1) you can evaluate the test results against those expectations and 2) you can gather the evaluation dataset based on the tests that evaluate the metrics you care about most.\nAdversarial testing involves proactively trying to break your application. The goal is to identify points of weakness so that you can take steps to remedy them as appropriate. Adversarial testing can take significant time/effort from evaluators with expertise in your application — but the more you do, the greater your chance of spotting problems, especially those occurring rarely or only after repeated runs of the application.\nAdversarial testing is a method for systematically evaluating an ML model with the intent of learning how it behaves when provided with malicious or inadvertently harmful input:\nAn input may be malicious when the input is clearly designed to produce an unsafe or harmful output-- for example, asking a text generation model to generate a hateful rant about a particular religion.\nAn input is inadvertently harmful when the input itself may be innocuous, but produces harmful output -- for example, asking a text generation model to describe a person of a particular ethnicity and receiving a racist output.\nWhat distinguishes an adversarial test from a standard evaluation is the composition of the data used for testing. For adversarial tests, select test data that is most likely to elicit problematic output from the model. This means probing the model's behavior for all the types of harms that are possible, including rare or unusual examples and edge-cases that are relevant to safety policies. It should also include diversity in the different dimensions of a sentence such as structure, meaning and length. You can refer to the Google's Responsible AI practices in fairness for more details on what to consider when building a test dataset.\nNote: LLMs are known to sometimes produce different outputs for the same input prompt. Multiple rounds of testing may be needed to catch more of the problematic outputs.\nNo matter how much you test and mitigate, you can never guarantee perfection, so plan upfront how you'll spot and deal with problems that arise. Common approaches include setting up a monitored channel for users to share feedback (e.g., thumbs up/down rating) and running a user study to proactively solicit feedback from a diverse mix of users — especially valuable if usage patterns are different to expectations.\nRefer to the safety settings guide to learn about the adjustable safety settings available through the Gemini API.\nSee the intro to prompting to get started writing your first prompts.",
            "filtered_word_count": 1603
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nIntro to prompting\nPrompting with media files\nPrompting strategies\nFile prompting strategies\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nWhat is a prompt\nPrompt content types\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nIntroduction to prompt design \nbookmark_border\n\nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. This page introduces some basic concepts, strategies, and best practices to get you started in designing prompts.\n\nWhat is a prompt\n\nA prompt is a natural language request submitted to a language model to receive a response back. Prompts can contain questions, instructions, contextual information, examples, and partial input for the model to complete or continue. After the model receives a prompt, depending on the type of model being used, it can generate text, embeddings, code, images, videos, music, and more.\n\nPrompt content types\n\nPrompts can include one or more of the following types of content:\n\nInput (required)\nContext (optional)\nExamples (optional)\nInput\n\nAn input is the text in the prompt that you want the model to provide a response for, and it's a required content type. Inputs can be a question that the model answers (question input), a task the model performs (task input), an entity the model operates on (entity input), or partial input that the model completes or continues (completion input).\n\nQuestion input\n\nA question input is a question that you ask the model that the model provides an answer to.\n\nPrompt:\nWhat's a good name for a flower shop that specializes in selling bouquets of\ndried flowers?\n\nResponse:\n1. Everlasting Blooms\n2. Timeless Petals\n3. Dried Flower Paradise\n4. Eternal Flora\n5. Vintage Floral Treasures\n6. Rustic Bloom Gallery\n7. Ardent Adornment\n8. Potpourri Dreams\n9. Dried Daisy Days\n10. Forever Floral Art\n\n(gemini-pro)\nTask input\n\nA task input is a task that you want the model to perform. For example, you can tell the model to give you ideas or suggestions for something.\n\nPrompt:\nGive me a simple list of things that I must bring on a camping trip.\n\nResponse:\n1. Tent\n2. Sleeping bag\n3. Sleeping pad\n4. Pillow\n5. Lantern or flashlight\n6. Headlamp\n7. Camp stove\n8. Fuel for camp stove\n9. Cooking pot and utensils\n10. Food and water\n11. First aid kit\n12. Sunscreen\n13. Insect repellent\n14. Toiletries\n15. Toilet paper\n16. Fire starter\n17. Map\n18. Compass\n19. Whistle\n20. Multi-tool\n21. Tarpaulin\n22. Rope\n23. Garbage bags\n24. Camera\n25. Binoculars\n\n(gemini-pro)\nEntity input\n\nAn entity input is what the model performs an action on, such as classify or summarize. This type of input can benefit from the inclusion of instructions.\n\nPrompt:\nClassify the following items as [large, small].\nElephant\nMouse\nSnail\n\nResponse:\n- Elephant: Large\n- Mouse: Small\n- Snail: Small\n\n(gemini-pro)\nCompletion input\n\nA completion input is text that the model is expected to complete or continue.\n\nPrompt:\nSome simple strategies for overcoming writer's block include\n\nResponse:\n1. **Take a Break:** Step away from your writing for a bit. Go for a walk, listen to music, or do something else that helps you relax and clear your mind. When you come back to your writing, you may find that your thoughts are more organized and your ideas are flowing more easily.\n\n2. **Change Your Environment:** Sometimes, a change of scenery can help spark creativity. Try writing in a different location, such as a coffee shop, a library, or a park. Being in a new environment can help you see things from a different perspective and break out of your writer's block.\n\n3. **Freewrite or Brainstorm:** Set a timer for 10-15 minutes and just write whatever comes to mind, without worrying about grammar or spelling. This can help you get started and generate new ideas. You can also try brainstorming by writing down a list of words or phrases that are related to your topic. This can help you to free associate and come up with new ideas.\n\n4. **Read or Research:** Sometimes, the best way to overcome writer's block is to read or research your topic. Reading can help you to learn new things and get inspired. Research can help you to gather information and facts that you can use in your writing.\n\n5. **Talk to Someone:** Talk to a friend, family member, or writing partner about what you're struggling with. Sometimes, just talking about your ideas can help you to clarify them and see them from a new perspective. You can also ask for feedback and suggestions, which can help you to move forward with your writing.\n\n6. **Try a Different Writing Style:** If you're stuck in a rut, try experimenting with a different writing style. For example, if you're used to writing formal essays, try writing a poem or a short story. Changing your writing style can help you to break out of your comfort zone and come up with new ideas.\n\n7. **Set a Deadline:** Sometimes, the best way to overcome writer's block is to set a deadline for yourself. This can help you to focus and motivate yourself to finish your writing. When you know that you have a deadline, you're more likely to start writing and keep going until you're finished.\n\n(text-bison@001)\nContext\n\nContext can be one of the following:\n\nInstructions that specify how the model should behave.\nInformation that the model uses or references to generate a response.\n\nAdd contextual information in your prompt when you need to give information to the model, or restrict the boundaries of the responses to only what's within the prompt.\n\nPrompt:\nMarbles:\nColor: red\nNumber: 12\nColor: blue\nNumber: 28\nColor: yellow\nNumber: 15\nColor: green\nNumber: 17\n\nHow many green marbles are there?\n\nResponse:\nThere are 17 green marbles.\n\n(text-bison@001)\nExamples\n\nExamples are input-output pairs that you include in the prompt to give the model an example of an ideal response. Including examples in the prompt is an effective strategy for customizing the response format.\n\nPrompt:\nClassify the following.\nOptions:\n- red wine\n- white wine\n\nText: Chardonnay\nThe answer is: white wine\nText: Cabernet\nThe answer is: red wine\nText: Moscato\nThe answer is: white wine\n\nText: Riesling\nThe answer is:\n\nResponse:\nwhite wine\n\n(text-bison@001)\nNext steps\nNow that you have an understanding of prompt design, try writing your own prompts using Google AI Studio.\nFor a deeper understanding of prompt design, see the prompt strategies topic.\nTo learn about multimodal prompting, see Prompting with media files.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 1256,
            "filtered_content": "Intro to prompting\nPrompting with media files\nPrompting strategies\nFile prompting strategies\nIntroduction to prompt design \nPrompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. This page introduces some basic concepts, strategies, and best practices to get you started in designing prompts.\nA prompt is a natural language request submitted to a language model to receive a response back. Prompts can contain questions, instructions, contextual information, examples, and partial input for the model to complete or continue. After the model receives a prompt, depending on the type of model being used, it can generate text, embeddings, code, images, videos, music, and more.\nPrompts can include one or more of the following types of content:\nInput (required)\nContext (optional)\nExamples (optional)\nInput\nAn input is the text in the prompt that you want the model to provide a response for, and it's a required content type. Inputs can be a question that the model answers (question input), a task the model performs (task input), an entity the model operates on (entity input), or partial input that the model completes or continues (completion input).\nQuestion input\nA question input is a question that you ask the model that the model provides an answer to.\nWhat's a good name for a flower shop that specializes in selling bouquets of\ndried flowers?\n1. Everlasting Blooms\n2. Timeless Petals\n3. Dried Flower Paradise\n4. Eternal Flora\n5. Vintage Floral Treasures\n6. Rustic Bloom Gallery\n7. Ardent Adornment\n8. Potpourri Dreams\n9. Dried Daisy Days\n10. Forever Floral Art\nTask input\nA task input is a task that you want the model to perform. For example, you can tell the model to give you ideas or suggestions for something.\nGive me a simple list of things that I must bring on a camping trip.\n1. Tent\n2. Sleeping bag\n3. Sleeping pad\n4. Pillow\n5. Lantern or flashlight\n6. Headlamp\n7. Camp stove\n8. Fuel for camp stove\n9. Cooking pot and utensils\n10. Food and water\n11. First aid kit\n12. Sunscreen\n13. Insect repellent\n14. Toiletries\n15. Toilet paper\n16. Fire starter\n17. Map\n18. Compass\n19. Whistle\n20. Multi-tool\n21. Tarpaulin\n22. Rope\n23. Garbage bags\n24. Camera\n25. Binoculars\nEntity input\nAn entity input is what the model performs an action on, such as classify or summarize. This type of input can benefit from the inclusion of instructions.\nClassify the following items as [large, small].\nElephant\nMouse\nSnail\n- Elephant: Large\n- Mouse: Small\n- Snail: Small\nCompletion input\nA completion input is text that the model is expected to complete or continue.\nSome simple strategies for overcoming writer's block include\n1. **Take a Break:** Step away from your writing for a bit. Go for a walk, listen to music, or do something else that helps you relax and clear your mind. When you come back to your writing, you may find that your thoughts are more organized and your ideas are flowing more easily.\n2. **Change Your Environment:** Sometimes, a change of scenery can help spark creativity. Try writing in a different location, such as a coffee shop, a library, or a park. Being in a new environment can help you see things from a different perspective and break out of your writer's block.\n3. **Freewrite or Brainstorm:** Set a timer for 10-15 minutes and just write whatever comes to mind, without worrying about grammar or spelling. This can help you get started and generate new ideas. You can also try brainstorming by writing down a list of words or phrases that are related to your topic. This can help you to free associate and come up with new ideas.\n4. **Read or Research:** Sometimes, the best way to overcome writer's block is to read or research your topic. Reading can help you to learn new things and get inspired. Research can help you to gather information and facts that you can use in your writing.\n5. **Talk to Someone:** Talk to a friend, family member, or writing partner about what you're struggling with. Sometimes, just talking about your ideas can help you to clarify them and see them from a new perspective. You can also ask for feedback and suggestions, which can help you to move forward with your writing.\n6. **Try a Different Writing Style:** If you're stuck in a rut, try experimenting with a different writing style. For example, if you're used to writing formal essays, try writing a poem or a short story. Changing your writing style can help you to break out of your comfort zone and come up with new ideas.\n7. **Set a Deadline:** Sometimes, the best way to overcome writer's block is to set a deadline for yourself. This can help you to focus and motivate yourself to finish your writing. When you know that you have a deadline, you're more likely to start writing and keep going until you're finished.\nContext\nContext can be one of the following:\nInstructions that specify how the model should behave.\nInformation that the model uses or references to generate a response.\nAdd contextual information in your prompt when you need to give information to the model, or restrict the boundaries of the responses to only what's within the prompt.\nMarbles:\nColor: red\nNumber: 12\nColor: blue\nNumber: 28\nColor: yellow\nNumber: 15\nColor: green\nNumber: 17\nHow many green marbles are there?\nThere are 17 green marbles.\nExamples are input-output pairs that you include in the prompt to give the model an example of an ideal response. Including examples in the prompt is an effective strategy for customizing the response format.\nClassify the following.\nOptions:\n- red wine\n- white wine\nText: Chardonnay\nText: Cabernet\nThe answer is: red wine\nText: Moscato\nText: Riesling\nThe answer is:\nwhite wine\nNow that you have an understanding of prompt design, try writing your own prompts using Google AI Studio.\nFor a deeper understanding of prompt design, see the prompt strategies topic.\nTo learn about multimodal prompting, see Prompting with media files.",
            "filtered_word_count": 1028
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nIntro to prompting\nPrompting with media files\nPrompting strategies\nFile prompting strategies\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nSetup\nInstall the Python SDK and import packages\nSetup your API key\nUpload a file to the File API\nGet file\nGenerate content\nDelete files\nSupported file formats\nImage formats\nAudio formats\nVideo formats\nAppendix: Uploading files to Colab\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nPrompting with media files \nbookmark_border\n\nRun in Google Colab\n\t\nView source on GitHub\n\nThe Gemini API supports prompting with text, image, and audio data, also known as multimodal prompting. You can include text, image, and audio in your prompts. For small images, you can point the Gemini model directly to a local file when providing a prompt. For larger images, videos (sequences of image frames), and audio, upload the files with the File API before including them in prompts.\n\nThe File API lets you store up to 20GB of files per project, with each file not exceeding 2GB in size. Files are stored for 48 hours and can be accessed with your API key for generation within that time period. It is available at no cost in all regions where the Gemini API is available.\n\nFor information on valid file formats (MIME types) and supported models, see Supported file formats.\n\nNote: Videos must be converted into image frames before uploading to the File API.\n\nThis guide shows how to use the File API to upload a media file and include it in a GenerateContent call to the Gemini API. For more information, see the code samples.\n\nSetup\n\nBefore you use the File API, you need to install the Gemini API SDK package and configure an API key. This section describes how to complete these setup steps.\n\nInstall the Python SDK and import packages\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip.\n\npip install -q -U google-generativeai\n\n\nImport the necessary packages.\n\nimport google.generativeai as genai\nfrom IPython.display import Markdown\n\nSetup your API key\n\nThe File API uses API keys for authentication and access. Uploaded files are associated with the project linked to the API key. Unlike other Gemini APIs that use API keys, your API key also grants access to data you've uploaded to the File API, so take extra care in keeping your API key secure. For more on keeping your keys secure, see Best practices for using API keys.\n\nStore your API key in a Colab Secret named GOOGLE_API_KEY. If you don't already have an API key, or are unfamiliar with Colab Secrets, refer to the Authentication quickstart.\n\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\ngenai.configure(api_key=GOOGLE_API_KEY)\n\nUpload a file to the File API\n\nThe File API lets you upload a variety of multimodal MIME types, including images and audio formats. The File API handles inputs that can be used to generate content with model.generateContent or model.streamGenerateContent.\n\nThe File API accepts files under 2GB in size and can store up to 20GB of files per project. Files last for 2 days and cannot be downloaded from the API.\n\nFirst, you will prepare a sample image to upload to the API.\n\nTo upload your own file, see the Appendix section.\n\ncurl -o image.jpg https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\n\n\nNext, you'll upload that file to the File API.\n\nsample_file = genai.upload_file(path=\"image.jpg\",\n                            display_name=\"Sample drawing\")\n\nprint(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")\n\nUploaded file 'Sample drawing' as: https://generativelanguage.googleapis.com/v1beta/files/ui00j5zfuqe0\n\n\nThe response shows that the File API stored the specified display_name for the uploaded file and a uri to reference the file in Gemini API calls. Use response to track how uploaded files are mapped to URIs.\n\nDepending on your use cases, you could store the URIs in structures such as a dict or a database.\n\nGet file\n\nAfter uploading the file, you can verify the API has successfully received the files by calling files.get.\n\nIt lets you get the file metadata that have been uploaded to the File API that are associated with the Cloud project your API key belongs to. Only the name (and by extension, the uri) are unique. Only use the displayName to identify files if you manage uniqueness yourself.\n\nfile = genai.get_file(name=sample_file.name)\nprint(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")\n\nGenerate content\n\nAfter uploading the file, you can make GenerateContent requests that reference the File API URI. In this example, you create prompt that starts with a text followed by the uploaded image.\n\n# Set the model to Gemini 1.5 Pro.\nmodel = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n\nresponse = model.generate_content([\"Describe the image with a creative description.\", sample_file])\n\nMarkdown(\">\" + response.text)\n\nDelete files\n\nFiles are automatically deleted after 2 days. You can also manually delete them using files.delete().\n\ngenai.delete_file(sample_file.name)\nprint(f'Deleted {sample_file.display_name}.')\n\nSupported file formats\n\nGemini models support prompting with multiple file formats. This section explains considerations in using general media formats for prompting, specifically image, audio, and video files. You can use media files for prompting only with specific model versions, as shown in the following table.\n\nModel\tImages\tAudio\tVideo\nGemini 1.5 Pro (release 008 and later)\t✔ (3600 max image files)\t✔\t✔\nGemini Pro Vision\t✔ (16 max image files)\t\t\nImage formats\n\nYou can use image data for prompting with the gemini-pro-vision and gemini-1.5-pro models. When you use images for prompting, they are subject to the following limitations and requirements:\n\nImages must be in one of the following image data MIME types:\nPNG - image/png\nJPEG - image/jpeg\nWEBP - image/webp\nHEIC - image/heic\nHEIF - image/heif\nMaximum of 16 individual images for the gemini-pro-vision and 3600 images for gemini-1.5-pro\nNo specific limits to the number of pixels in an image; however, larger images are scaled down to fit a maximum resolution of 3072 x 3072 while preserving their original aspect ratio.\nAudio formats\n\nYou can use audio data for prompting with the gemini-1.5-pro model. When you use audio for prompting, they are subject to the following limitations and requirements:\n\nAudio data is supported in the following common audio format MIME types:\nWAV - audio/wav\nMP3 - audio/mp3\nAIFF - audio/aiff\nAAC - audio/aac\nOGG Vorbis - audio/ogg\nFLAC - audio/flac\nThe maximum supported length of audio data in a single prompt is 9.5 hours.\nAudio files are resampled down to a 16 Kbps data resolution, and multiple channels of audio are combined into a single channel.\nThere is no specific limit to the number of audio files in a single prompt, however the total combined length of all audio files in a single prompt cannot exceed 9.5 hours.\nVideo formats\n\nYou can use video data for prompting with the gemini-1.5-pro model. However, video file formats are not supported as direct inputs by the Gemini API. You can use video data as prompt input by breaking down the video into a series of still frame images and a separate audio file. This approach lets you manage the amount of data, and the level of detail provided by the video, by choosing how many frames per second are included in your prompt from the video file.\n\nNote: Video files added to a prompt as constituent parts, audio file and image frames, are considered as separate prompt data inputs by the model. For this reason, requests or questions that specify the time when both an audio snippet and video frames appear in the source video may not produce useful results.\nAppendix: Uploading files to Colab\n\nThis notebook uses the File API with files that were downloaded from the internet. If you're running this in Colab and want to use your own files, you first need to upload them to the colab instance.\n\nFirst, click Files on the left sidebar, then click the Upload button:\n\nNext, you'll upload that file to the File API. In the form for the code cell below, enter the filename for the file you uploaded and provide an appropriate display name for the file, then run the cell.\n\nmy_filename = \"gemini_logo.png\" # @param {type:\"string\"}\nmy_file_display_name = \"Gemini Logo\" # @param {type:\"string\"}\n\nmy_file = genai.upload_file(path=my_filename,\n                            display_name=my_file_display_name)\nprint(f\"Uploaded file '{my_file.display_name}' as: {my_file.uri}\")\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 1490,
            "filtered_content": "Prompting with media files \nThe Gemini API supports prompting with text, image, and audio data, also known as multimodal prompting. You can include text, image, and audio in your prompts. For small images, you can point the Gemini model directly to a local file when providing a prompt. For larger images, videos (sequences of image frames), and audio, upload the files with the File API before including them in prompts.\nThe File API lets you store up to 20GB of files per project, with each file not exceeding 2GB in size. Files are stored for 48 hours and can be accessed with your API key for generation within that time period. It is available at no cost in all regions where the Gemini API is available.\nFor information on valid file formats (MIME types) and supported models, see Supported file formats.\nNote: Videos must be converted into image frames before uploading to the File API.\nThis guide shows how to use the File API to upload a media file and include it in a GenerateContent call to the Gemini API. For more information, see the code samples.\nBefore you use the File API, you need to install the Gemini API SDK package and configure an API key. This section describes how to complete these setup steps.\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip.\nThe File API uses API keys for authentication and access. Uploaded files are associated with the project linked to the API key. Unlike other Gemini APIs that use API keys, your API key also grants access to data you've uploaded to the File API, so take extra care in keeping your API key secure. For more on keeping your keys secure, see Best practices for using API keys.\nStore your API key in a Colab Secret named GOOGLE_API_KEY. If you don't already have an API key, or are unfamiliar with Colab Secrets, refer to the Authentication quickstart.\nThe File API lets you upload a variety of multimodal MIME types, including images and audio formats. The File API handles inputs that can be used to generate content with model.generateContent or model.streamGenerateContent.\nThe File API accepts files under 2GB in size and can store up to 20GB of files per project. Files last for 2 days and cannot be downloaded from the API.\nFirst, you will prepare a sample image to upload to the API.\nTo upload your own file, see the Appendix section.\ncurl -o image.jpg https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\nNext, you'll upload that file to the File API.\nsample_file = genai.upload_file(path=\"image.jpg\",\n                            display_name=\"Sample drawing\")\nprint(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")\nUploaded file 'Sample drawing' as: https://generativelanguage.googleapis.com/v1beta/files/ui00j5zfuqe0\nThe response shows that the File API stored the specified display_name for the uploaded file and a uri to reference the file in Gemini API calls. Use response to track how uploaded files are mapped to URIs.\nDepending on your use cases, you could store the URIs in structures such as a dict or a database.\nAfter uploading the file, you can verify the API has successfully received the files by calling files.get.\nIt lets you get the file metadata that have been uploaded to the File API that are associated with the Cloud project your API key belongs to. Only the name (and by extension, the uri) are unique. Only use the displayName to identify files if you manage uniqueness yourself.\nfile = genai.get_file(name=sample_file.name)\nprint(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")\nAfter uploading the file, you can make GenerateContent requests that reference the File API URI. In this example, you create prompt that starts with a text followed by the uploaded image.\n# Set the model to Gemini 1.5 Pro.\nmodel = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\nresponse = model.generate_content([\"Describe the image with a creative description.\", sample_file])\nMarkdown(\">\" + response.text)\nFiles are automatically deleted after 2 days. You can also manually delete them using files.delete().\ngenai.delete_file(sample_file.name)\nprint(f'Deleted {sample_file.display_name}.')\nGemini models support prompting with multiple file formats. This section explains considerations in using general media formats for prompting, specifically image, audio, and video files. You can use media files for prompting only with specific model versions, as shown in the following table.\nModel\tImages\tAudio\tVideo\nGemini 1.5 Pro (release 008 and later)\t✔ (3600 max image files)\t✔\t✔\nGemini Pro Vision\t✔ (16 max image files)\t\t\nYou can use image data for prompting with the gemini-pro-vision and gemini-1.5-pro models. When you use images for prompting, they are subject to the following limitations and requirements:\nImages must be in one of the following image data MIME types:\nPNG - image/png\nJPEG - image/jpeg\nWEBP - image/webp\nHEIC - image/heic\nHEIF - image/heif\nMaximum of 16 individual images for the gemini-pro-vision and 3600 images for gemini-1.5-pro\nNo specific limits to the number of pixels in an image; however, larger images are scaled down to fit a maximum resolution of 3072 x 3072 while preserving their original aspect ratio.\nYou can use audio data for prompting with the gemini-1.5-pro model. When you use audio for prompting, they are subject to the following limitations and requirements:\nAudio data is supported in the following common audio format MIME types:\nWAV - audio/wav\nMP3 - audio/mp3\nAIFF - audio/aiff\nAAC - audio/aac\nOGG Vorbis - audio/ogg\nFLAC - audio/flac\nThe maximum supported length of audio data in a single prompt is 9.5 hours.\nAudio files are resampled down to a 16 Kbps data resolution, and multiple channels of audio are combined into a single channel.\nThere is no specific limit to the number of audio files in a single prompt, however the total combined length of all audio files in a single prompt cannot exceed 9.5 hours.\nYou can use video data for prompting with the gemini-1.5-pro model. However, video file formats are not supported as direct inputs by the Gemini API. You can use video data as prompt input by breaking down the video into a series of still frame images and a separate audio file. This approach lets you manage the amount of data, and the level of detail provided by the video, by choosing how many frames per second are included in your prompt from the video file.\nNote: Video files added to a prompt as constituent parts, audio file and image frames, are considered as separate prompt data inputs by the model. For this reason, requests or questions that specify the time when both an audio snippet and video frames appear in the source video may not produce useful results.\nThis notebook uses the File API with files that were downloaded from the internet. If you're running this in Colab and want to use your own files, you first need to upload them to the colab instance.\nFirst, click Files on the left sidebar, then click the Upload button:\nNext, you'll upload that file to the File API. In the form for the code cell below, enter the filename for the file you uploaded and provide an appropriate display name for the file, then run the cell.\nmy_filename = \"gemini_logo.png\" # @param {type:\"string\"}\nmy_file_display_name = \"Gemini Logo\" # @param {type:\"string\"}\nmy_file = genai.upload_file(path=my_filename,\n                            display_name=my_file_display_name)\nprint(f\"Uploaded file '{my_file.display_name}' as: {my_file.uri}\")",
            "filtered_word_count": 1188
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nIntro to prompting\nPrompting with media files\nPrompting strategies\nFile prompting strategies\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nGive clear and specific instructions\nDefine the task to perform\nSpecify any constraints\nDefine the format of the response\nInclude few-shot examples\nZero-shot vs few-shot prompts\nFind the optimal number of examples\nUse examples to show patterns instead of antipatterns\nUse consistent formatting across examples\nAdd contextual information\nAdd prefixes\nLet the model complete partial input\nBreak down prompts into simple components\nBreak down instructions\nChain prompts\nAggregate responses\nExperiment with different parameter values\nMax output tokens\nTemperature\nTop-K\nTop-P\nPrompt iteration strategies\nUse different phrasing\nSwitch to an analogous task\nChange the order of prompt content\nFallback responses\nThings to avoid\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nPrompt design strategies \nbookmark_border\n\nThis page introduces you to some general prompt design strategies that you can employ when designing prompts. While there's no right or wrong way to design a prompt, there are common strategies that you can use to affect the model's responses. Rigorous testing and evaluation remain crucial for optimizing model performance.\n\nLarge language models (LLM) are trained on vast amounts of text data to learn the patterns and relationships between units of language. When given some text (the prompt), language models can predict what is likely to come next, like a sophisticated autocompletion tool. Therefore, when designing prompts, consider the different factors that can influence what a model predicts comes next.\n\nGive clear and specific instructions\n\nGiving the model instructions on what to do is an effective and efficient way to customize model behavior. Ensure that the instructions you give are clear and specific. Instructions can be as simple as a list of step-by-step instructions or as complex as mapping out a user's experience and mindset.\n\nDefine the task to perform\n\nDescribe in detail the task that you want the model to perform. The task can be as simple as a step-by-step list of instructions or as complex as mapping out a user's experience and mindset. The following prompt tells the model to summarize a block of text:\n\nPrompt:\nSummarize this text.\nText: A quantum computer exploits quantum mechanical phenomena to perform calculations exponentially\nfaster than any modern traditional computer. At very tiny scales, physical matter acts as both\nparticles and as waves, and quantum computing uses specialized hardware to leverage this behavior.\nThe operating principles of quantum devices is beyond the scope of classical physics. When deployed\nat scale, quantum computers could be used in a wide variety of applications such as: in\ncybersecurity to break existing encryption methods while helping researchers create new ones, in\nmeteorology to develop better weather forecasting etc. However, the current state of the art quantum\ncomputers are still largely experimental and impractical.\n\nResponse:\nQuantum computers utilize quantum mechanical phenomena to perform computations significantly faster\nthan traditional computers. By exploiting the particle-wave duality of matter at tiny scales,\nquantum computers leverage specialized hardware to solve problems beyond classical physics.\nPotential applications include breaking encryption, developing better weather forecasting, and more.\nHowever, current quantum computers are still largely experimental and impractical.\n\n(gemini-pro)\nSpecify any constraints\n\nSpecify any constraints on reading the prompt or generating a response. You can tell the model what to do and not to do. From the previous example, the summarization is shorter than the original text, but maybe you want the summary to be shorter. In this case, you can specify a constraint in the prompt on how long you want the summary to be:\n\nPrompt:\n\nSummarize this text in two sentences.\nText: A quantum computer exploits quantum mechanical phenomena to perform calculations exponentially\nfaster than any modern traditional computer. At very tiny scales, physical matter acts as both\nparticles and as waves, and quantum computing uses specialized hardware to leverage this behavior.\nThe operating principles of quantum devices is beyond the scope of classical physics. When deployed\nat scale, quantum computers could be used in a wide variety of applications such as: in\ncybersecurity to break existing encryption methods while helping researchers create new ones, in\nmeteorology to develop better weather forecasting etc. However, the current state of the art quantum\ncomputers are still largely experimental and impractical.\n\n\nResponse:\n\nQuantum computers use quantum mechanical phenomena to perform calculations much faster than\ntraditional computers. They have the potential to revolutionize various fields, but current quantum\ncomputers are still experimental and impractical.\n\n(gemini-pro)\n\nDefine the format of the response\n\nYou can also give instructions that specify the format of the response. For example, you can ask for the response to be formatted as a table, bulleted list, elevator pitch, keywords, sentence, or paragraph. The following prompt instructs the model to give bullet points of the key information in the text:\n\nPrompt:\nSummarize this text as bullets points of key information.\nText: A quantum computer exploits quantum mechanical phenomena to perform calculations exponentially\nfaster than any modern traditional computer. At very tiny scales, physical matter acts as both\nparticles and as waves, and quantum computing uses specialized hardware to leverage this behavior.\nThe operating principles of quantum devices is beyond the scope of classical physics. When deployed\nat scale, quantum computers could be used in a wide variety of applications such as: in\ncybersecurity to break existing encryption methods while helping researchers create new ones, in\nmeteorology to develop better weather forecasting etc. However, the current state of the art quantum\ncomputers are still largely experimental and impractical.\n\nResponse:\n- Quantum computers leverage quantum mechanical phenomena for exponentially faster calculations than\ntraditional computers.\n- Quantum devices utilize specialized hardware to exploit tiny-scale matter behavior as both\nparticles and waves.\n- Their operating principles transcend classical physics.\n- Potential applications include cybersecurity, weather forecasting, and more.\n- Current quantum computers are largely experimental and impractical.\n\n(gemini-pro)\nSummary\nGive the models instructions on what to do.\nMake the instructions clear and specific.\nSpecify any constraints or formatting requirements for the output.\nInclude few-shot examples\n\nYou can include examples in the prompt that show the model what getting it right looks like. The model attempts to identify patterns and relationships from the examples and applies them when generating a response. Prompts that contain a few examples are called few-shot prompts, while prompts that provide no examples are called zero-shot prompts. Few-shot prompts are often used to regulate the formatting, phrasing, scoping, or general patterning of model responses. Use specific and varied examples to help the model narrow its focus and generate more accurate results.\n\nWe recommend to always include few-shot examples in your prompts. Prompts without few-shot examples are likely to be less effective, because they show the model how to apply instructions. In fact, you can remove instructions from your prompt if your examples are clear enough in showing the task at hand.\n\nZero-shot vs few-shot prompts\n\nThe following zero-shot prompt asks the model to choose the best explanation.\n\nPrompt:\nPlease choose the best explanation to the question:\n\nQuestion: How is snow formed?\nExplanation1: Snow is formed when water vapor in the air freezes into ice crystals in the\natmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and\naccumulate on the ground.\nExplanation2: Water vapor freezes into ice crystals forming snow.\nAnswer:\n\nResponse:\nExplanation1\n\n(gemini-pro)\n\nIf your use case requires the model to produce concise responses, you can include examples in the prompt that give preference to concise responses.\n\nThe following prompt provides two examples that show preference to the shorter explanations. In the response, you can see that the examples guided the model to choose the shorter explanation (Explanation2) as opposed to the longer explanation (Explanation1) like it did previously.\n\nPrompt:\nPlease choose the best explanation to the question:\n\nQuestion: Why is sky blue?\nExplanation1: The sky appears blue because of Rayleigh scattering, which causes shorter blue\nwavelengths of light to be scattered more easily than longer red wavelengths, making the sky look\nblue.\nExplanation2: Due to Rayleigh scattering effect.\nAnswer: Explanation2\n\nQuestion: What is the cause of earthquakes?\nExplanation1: Sudden release of energy in the Earth's crust.\nExplanation2: Earthquakes happen when tectonic plates suddenly slip or break apart, causing a\nrelease of energy that creates seismic waves that can shake the ground and cause damage.\nAnswer: Explanation1\n\nQuestion: How is snow formed?\nExplanation1: Snow is formed when water vapor in the air freezes into ice crystals in the\natmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and\naccumulate on the ground.\nExplanation2: Water vapor freezes into ice crystals forming snow.\nAnswer:\n\nResponse:\nExplanation2\n\n(gemini-pro)\nFind the optimal number of examples\n\nYou can experiment with the number of examples to provide in the prompt for the most desired results. Models like PaLM and Gemini can often pick up on patterns using a few examples, though you may need to experiment with what number of examples lead to the desired results. For simpler models like BERT, you may need more examples. At the same time, if you include too many examples, the model may start to overfit the response to the examples.\n\nUse examples to show patterns instead of antipatterns\n\nUsing examples to show the model a pattern to follow is more effective than using examples to show the model an antipattern to avoid.\n\n⛔ Negative pattern:\n\nExample\nDon't end haikus with a question:\nHaiku are fun\nA short and simple poem\nDon't you enjoy them?\n\n\n\n\n✅ Positive pattern:\n\nExample\nAlways end haikus with an assertion:\nHaiku are fun\nA short and simple poem\nA joy to write\n\n\n\nUse consistent formatting across examples\n\nMake sure that the structure and formatting of few-shot examples are the same to avoid responses with undesired formats. One of the primary objectives of adding few-shot examples in prompts is to show the model the response format. Therefore, it is essential to ensure a consistent format across all examples, especially paying attention to XML tags, white spaces, newlines, and example splitters.\n\nSummary\nIncluding prompt-response examples in the prompt helps the model learn how to respond.\nGive the model examples of the patterns to follow instead of examples of patterns to avoid.\nExperiment with the number of prompts to include. Depending on the model, too few examples are ineffective at changing model behavior. Too many examples cause the model to overfit.\nUse consistent formatting across examples\nAdd contextual information\n\nYou can include in the prompt instructions and information that the model needs to solve a problem instead of assuming that the model has all of the required information. This contextual information helps the model understand the constraints and details of what you're asking for it to do.\n\nThe following example asks the model to give troubleshooting guidance for a router:\n\nPrompt:\nWhat should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and\nblinking slowly.\n\nResponse:\n1. **Check the Cables:**\n- Make sure that all cables are securely connected to your Google Wifi router and modem.\n- Try replacing the cables with new ones to ensure they are not faulty.\n\n\n2. **Reboot the Router:**\n- Unplug your Google Wifi router and modem from the power outlet.\n- Wait for at least 30 seconds.\n- Plug the modem and router back in and wait for them to start up.\n\n\n3. **Factory Reset the Router:**\n- Resetting the router will restore it to its default settings.\n- Find the small reset button on the back of the router.\n- Press and hold the reset button with a paper clip or similar object for 10 seconds.\n- Release the button and wait for the router to restart.\n\n\n4. **Check Your Internet Connection:**\n- Use a wired connection to connect a device directly to your modem.\n- If the internet works, the issue may be with your router.\n- If the internet still doesn't work, contact your Internet Service Provider (ISP).\n\n\n5. **Update Router's Firmware:**\n- Check if there is a firmware update available for your Google Wifi router.\n- Download and install the latest firmware update from the Google Wifi app.\n\n\n6. **Interference and Obstacles:**\n- Make sure the router is not near electronic devices that can cause interference, like microwaves or cordless phones.\n- Remove any obstacles between the router and your devices, such as furniture or thick walls.\n\n\n7. **Change Wi-Fi Channel:**\n- In the Google Wifi app, go to Settings > Network & General > Advanced Networking.\n- Try changing the Wi-Fi channel to a less congested one.\n\n\n8. **Contact Google Support:**\n- If you've tried the above steps and the issue persists, contact Google support for further assistance.\n\n(gemini-pro)\n\nThe response looks like generic troubleshooting information that's not specific to the router or the status of the LED indicator lights.\n\nTo customize the response for the specific router, you can add to the prompt the router's troubleshooting guide as context for it to refer to when providing a response.\n\nPrompt:\nAnswer the question using the text below. Respond with only the text provided.\nQuestion: What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and blinking slowly.\n\nText:\nColor: Slowly pulsing yellow\nWhat it means: There is a network error.\nWhat to do:\nCheck that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.\n\nColor: Fast blinking yellow\nWhat it means: You are holding down the reset button and are factory resetting this device.\nWhat to do:\nIf you keep holding down the reset button, after about 12 seconds, the light will turn solid yellow. Once it is solid yellow, let go of the factory reset button.\n\nColor: Solid yellow\nWhat it means: Router is factory resetting.\nWhat to do:\nThis can take up to 10 minutes. When it's done, the device will reset itself and start pulsing white, letting you know it's ready for setup.\n\nColor: Solid red\nWhat it means: Something is wrong.\nWhat to do:\nCritical failure. Factory reset the router. If the light stays red, contact Wifi customer support.\n\nResponse:\nCheck that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.\n\n(gemini-pro)\nSummary\nInclude information (context) in the prompt that you want the model to use when generating a response.\nGive the model instructions on how to use the contextual information.\nAdd prefixes\n\nA prefix is a word or phrase that you add to the prompt content that can serve several purposes, depending on where you put the prefix:\n\nInput prefix: Adding a prefix to the input signals semantically meaningful parts of the input to the model. For example, the prefixes \"English:\" and \"French:\" demarcate two different languages.\nOutput prefix: Even though the output is generated by the model, you can add a prefix for the output in the prompt. The output prefix gives the model information about what's expected as a response. For example, the output prefix \"JSON:\" signals to the model that the output should be in JSON format.\nExample prefix: In few-shot prompts, adding prefixes to the examples provides labels that the model can use when generating the output, which makes it easier to parse output content.\n\nIn the following example, \"Text:\" is the input prefix and \"The answer is:\" is the output prefix.\n\nPrompt:\nClassify the text as one of the following categories.\n- large\n- small\nText: Rhino\nThe answer is: large\nText: Mouse\nThe answer is: small\nText: Snail\nThe answer is: small\nText: Elephant\nThe answer is:\n\nResponse:\nlarge\n\n(gemini-pro)\nLet the model complete partial input\n\nGenerative language models work like an advanced autocompletion tool. When you provide partial content, the model can provide the rest of the content or what it thinks is a continuation of that content as a response. When doing so, if you include any examples or context, the model can take those examples or context into account.\n\nThe following example provides a prompt with an instruction and an entity input:\n\nPrompt:\nFor the given order, return a JSON object that has the fields cheeseburger, hamburger, fries, or\ndrink, with the value being the quantity.\n\nOrder: A burger and a drink.\n\nResponse:\n```\n{\n\"cheeseburger\": 0,\n\"hamburger\": 1,\n\"fries\": 0,\n\"drink\": 1\n}\n```\n\n(gemini-pro)\n\nWhile the model did as prompted, writing out the instructions in natural language can sometimes be challenging and it leaves a lot to the model's interpretation. For example, a restaurants menu might contain many items. To reduce the size of the JSON response, you probably want to omit the items that weren't ordered. In this case, you can give an example and a response prefix and let the model complete it:\n\nPrompt:\nValid fields are cheeseburger, hamburger, fries, and drink.\nOrder: Give me a cheeseburger and fries\nOutput:\n```\n{\n\"cheeseburger\": 1,\n\"fries\": 1\n}\n```\nOrder: I want two burgers, a drink, and fries.\nOutput:\n\nResponse:\n```\n{\n\"hamburger\": 2,\n\"drink\": 1,\n\"fries\": 1\n}\n```\n\n(gemini-pro)\n\nNotice how \"cheeseburger\" was excluded from the output because it wasn't a part of the order.\n\nPrompt the model to format its response\n\nThe completion strategy can also help format the response. The following example prompts the model to create an essay outline:\n\nPrompt:\nCreate an outline for an essay about hummingbirds.\n\nResponse:\nI. Introduction\nA. Hook: Begin with an intriguing fact or description of hummingbirds.\nB. Provide some background information on hummingbirds.\n1. Mention their small size and long, thin beaks.\n2. Highlight their unique ability to hover and fly backward.\n\nII. Body\nA. Anatomy and Physiology\n1. Elaborate on their tiny size, making comparisons to other animals.\n2. Describe their wings and how they enable hovering and swift flight.\n3. Discuss their metabolism and energy requirements, emphasizing their caloric needs.\n\nB. Feeding Habits and Diet\n1. Explain their primary food source, nectar, and how they extract it from flowers.\n2. Describe their ability to feed from a wide variety of flowers.\n3. Mention their consumption of insects and the nutritional value they provide.\n\nC. Migration Patterns\n1. Discuss the incredible long-distance migrations of some hummingbird species.\n2. Explain the phenomenon of seasonal migration and the environmental factors driving it.\n3. Describe the routes taken by different species during migration.\n\nD. Conservation and Threats\n1. Highlight the importance of hummingbirds in ecosystems as pollinators.\n2. Discuss the challenges and threats they face, such as habitat loss, nectar scarcity, and climate change.\n3. Mention conservation efforts and ways to support hummingbird populations.\n\nIII. Conclusion\nA. Summarize the main points covered in the essay.\nB. Reinforce the importance of hummingbirds and their ecological role.\nC. Provide a final thought or call to action to protect these fascinating creatures.\n\n(gemini-pro)\n\nThe prompt didn't specify the format for the outline and the model chose a format for you. To get the model to return an outline in a specific format, you can add text that represents the start of the outline and let the model complete it based on the pattern that you initiated.\n\nPrompt:\nCreate an outline for an essay about hummingbirds.\nI. Introduction\n*\n\nResponse:\nI. Introduction\n* Capture the reader's attention with an interesting anecdote or fact about hummingbirds.\n* Provide a brief background on hummingbirds, including their unique characteristics.\n* State the main points that will be covered in the essay.\n\nII. The Unique Characteristics of Hummingbirds\n* Discuss the hummingbird's exceptionally rapid wing-beat, allowing them to hover and fly backward.\n* Highlight their tiny size, making them the smallest birds in the world.\n* Describe their long, slender beaks and tongues, allowing them to reach deep into flowers to extract nectar.\n* Explain their iridescent plumage, which creates brilliant and vibrant colors.\n\nIII. Hummingbird Migration and Distribution\n* Discuss the extensive migration patterns of hummingbirds, covering vast distances across continents.\n* Describe the different habitats where hummingbirds can be found, including tropical rainforests, deserts, and urban areas.\n* Explain the seasonal changes that influence hummingbird migration and habitat selection.\n\nIV. Hummingbird Diet and Feeding Habits\n* Focus on the hummingbird's primary food source, which is nectar from flowers.\n* Describe their ability to consume insects, spiders, and other small invertebrates for protein.\n* Explain how hummingbirds use their long, slender tongues to extract nectar from flowers.\n* Discuss the importance of flowering plants in providing sustenance for hummingbirds.\n\nV. Reproduction and Nesting Behavior\n* Describe the mating rituals and courtship behavior of hummingbirds.\n* Explain the process of nest-building, including the materials used and the unique characteristics of hummingbird nests.\n* Discuss the role of the female hummingbird in laying and incubating eggs.\n* Describe the development of hummingbird chicks and the role of both parents in providing care.\n\nVI. Threats to Hummingbirds and Conservation Efforts\n* Highlight habitat loss, climate change, and deforestation as significant threats to hummingbird populations.\n* Describe the role of habitat conservation initiatives in protecting hummingbird habitats.\n* Explain the importance of creating hummingbird-friendly gardens and landscapes.\n* Discuss the efforts of organizations and individuals working to conserve hummingbird populations.\n\nVII. Conclusion\n* Summarize the main points covered in the essay, emphasizing the unique characteristics, migration patterns, diet, reproduction, and conservation of hummingbirds.\n* Provide a closing statement that leaves a lasting impression on the reader and reinforces the significance of these fascinating creatures.\n\n(gemini-pro)\nSummary\nIf you give the model a partial input, the model completes that input based on any available examples or context in the prompt.\nHaving the model complete an input may sometimes be easier than describing the task in natural language.\nAdding a partial answer to a prompt can guide the model to follow a desired pattern or format.\nBreak down prompts into simple components\n\nFor use cases that require complex prompts, you can help the model manage this complexity by breaking things down into simpler components.\n\nBreak down instructions\n\nInstead of having many instructions in one prompt, create one prompt per instruction. You can choose which prompt to process based on the user's input.\n\nChain prompts\nFor complex tasks that involve multiple sequential steps, make each step a prompt and chain the prompts together in a sequence. In this sequential chain of prompts, the output of one prompt in the sequence becomes the input of the next prompt. The output of the last prompt in the sequence is the final output.\n\nAggregate responses\n\nAggregation is when you want to perform different parallel tasks on different portions of the data and aggregate the results to produce the final output. For example, you can tell the model to perform one operation on the first part of the data, perform another operation on the rest of the data and aggregate the results.\n\nSummary\nBreak down complex instructions into a prompt for each instruction and decide which prompt to apply based on the user's input.\nBreak down multiple sequential steps into separate prompts and chain them such that the output on the preceding prompt becomes the input of the following prompt.\nBreak down parallel tasks and aggregate the responses to produce the final output.\nExperiment with different parameter values\n\nEach call that you send to a model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Experiment with different parameter values to get the best values for the task. The parameters available for different models may differ. The most common parameters are the following:\n\nMax output tokens\nTemperature\nTop-K\nTop-P\nMax output tokens\nMaximum number of tokens that can be generated in the response. A token is approximately four characters. 100 tokens correspond to roughly 20 words.\n\nSpecify a lower value for shorter responses and a higher value for longer responses.\n\nTemperature\nThe temperature is used for sampling during response generation, which occurs when topP and topK are applied. Temperature controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a more deterministic and less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. A temperature of 0 is deterministic, meaning that the highest probability response is always selected.\n\nFor most use cases, try starting with a temperature of 0.2. If the model returns a response that's too generic, too short, or the model gives a fallback response, try increasing the temperature.\n\nTop-K\nTop-K changes how the model selects tokens for output. A top-K of 1 means the next selected token is the most probable among all tokens in the model's vocabulary (also called greedy decoding), while a top-K of 3 means that the next token is selected from among the three most probable tokens by using temperature.\n\nFor each token selection step, the top-K tokens with the highest probabilities are sampled. Then tokens are further filtered based on top-P with the final token selected using temperature sampling.\n\nSpecify a lower value for less random responses and a higher value for more random responses. The default top-K is 40.\n\nTop-P\nTop-P changes how the model selects tokens for output. Tokens are selected from the most (see top-K) to least probable until the sum of their probabilities equals the top-P value. For example, if tokens A, B, and C have a probability of 0.3, 0.2, and 0.1 and the top-P value is 0.5, then the model will select either A or B as the next token by using temperature and excludes C as a candidate.\n\nSpecify a lower value for less random responses and a higher value for more random responses. The default top-P is 0.95.\n\nPrompt iteration strategies\n\nPrompt design is an iterative process that often requires a few iterations before you get the desired response consistently. This section provides guidance on some things you can try when iterating on your prompts.\n\nUse different phrasing\n\nUsing different words or phrasing in your prompts often yields different responses from the model even though they all mean the same thing. If you're not getting the expected results from your prompt, try rephrasing it.\n\nVersion 1:\nHow do I bake a pie?\n\nVersion 2:\nSuggest a recipe for a pie.\n\nVersion 3:\nWhat's a good pie recipe?\n\n\n\nSwitch to an analogous task\n\nIf you can't get the model to follow your instructions for a task, try giving it instructions for an analogous task that achieves the same result.\n\nThis prompt tells the model to categorize a book by using predefined categories.\n\nPrompt:\nWhich category does The Odyssey belong to:\nthriller\nsci-fi\nmythology\nbiography\n\nResponse:\nThe answer: mythology\n\nExplanations:\n\nThe Odyssey is an epic poem in ancient Greek literature. It is one of two major ancient Greek epic\npoems attributed to Homer. The Odyssey is an epic poem that tells the story of Odysseus, a Greek\nhero who fought in the Trojan War and then spent ten years trying to return home to Ithaca. The\nOdyssey is a work of mythology.\n\n(text-bison@001)\n\nThe response is correct, but the model didn't stay within the bounds of the options. You also want to model to just respond with one of the options instead of in a full sentence. In this case, you can rephrase the instructions as a multiple choice question and ask the model to choose an option.\n\nPrompt:\nMultiple choice problem: Which of the following options describes the book The Odyssey?\nOptions:\n- thriller\n- sci-fi\n- mythology\n- biography\n\nResponse:\nThe answer is: mythology\n\n(text-bison@001)\nChange the order of prompt content\n\nThe order of the content in the prompt can sometimes affect the response. Try changing the content order and see how that affects the response.\n\nVersion 1:\n[examples]\n[context]\n[input]\n\nVersion 2:\n[input]\n[examples]\n[context]\n\nVersion 3:\n[examples]\n[input]\n[context]\n\nFallback responses\n\nA fallback response is a response returned by the model when either the prompt or the response triggers a safety filter. An example of a fallback response is \"I'm not able to help with that, as I'm only a language model.\"\n\nIf the model responds with a fallback response, try increasing the temperature.\n\nThings to avoid\nAvoid relying on models to generate factual information.\nUse with care on math and logic problems.\nNext steps\nNow that you have a deeper understanding of prompt design, try writing your own prompts using Google AI Studio.\nTo learn about multimodal prompting, see Prompting with media files.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 4900,
            "filtered_content": "Prompt design strategies \nThis page introduces you to some general prompt design strategies that you can employ when designing prompts. While there's no right or wrong way to design a prompt, there are common strategies that you can use to affect the model's responses. Rigorous testing and evaluation remain crucial for optimizing model performance.\nLarge language models (LLM) are trained on vast amounts of text data to learn the patterns and relationships between units of language. When given some text (the prompt), language models can predict what is likely to come next, like a sophisticated autocompletion tool. Therefore, when designing prompts, consider the different factors that can influence what a model predicts comes next.\nGiving the model instructions on what to do is an effective and efficient way to customize model behavior. Ensure that the instructions you give are clear and specific. Instructions can be as simple as a list of step-by-step instructions or as complex as mapping out a user's experience and mindset.\nDescribe in detail the task that you want the model to perform. The task can be as simple as a step-by-step list of instructions or as complex as mapping out a user's experience and mindset. The following prompt tells the model to summarize a block of text:\nSummarize this text.\nQuantum computers utilize quantum mechanical phenomena to perform computations significantly faster\nthan traditional computers. By exploiting the particle-wave duality of matter at tiny scales,\nquantum computers leverage specialized hardware to solve problems beyond classical physics.\nPotential applications include breaking encryption, developing better weather forecasting, and more.\nHowever, current quantum computers are still largely experimental and impractical.\nSpecify any constraints on reading the prompt or generating a response. You can tell the model what to do and not to do. From the previous example, the summarization is shorter than the original text, but maybe you want the summary to be shorter. In this case, you can specify a constraint in the prompt on how long you want the summary to be:\nSummarize this text in two sentences.\nQuantum computers use quantum mechanical phenomena to perform calculations much faster than\ntraditional computers. They have the potential to revolutionize various fields, but current quantum\ncomputers are still experimental and impractical.\nYou can also give instructions that specify the format of the response. For example, you can ask for the response to be formatted as a table, bulleted list, elevator pitch, keywords, sentence, or paragraph. The following prompt instructs the model to give bullet points of the key information in the text:\nSummarize this text as bullets points of key information.\n- Quantum computers leverage quantum mechanical phenomena for exponentially faster calculations than\ntraditional computers.\n- Quantum devices utilize specialized hardware to exploit tiny-scale matter behavior as both\nparticles and waves.\n- Their operating principles transcend classical physics.\n- Potential applications include cybersecurity, weather forecasting, and more.\n- Current quantum computers are largely experimental and impractical.\nGive the models instructions on what to do.\nMake the instructions clear and specific.\nSpecify any constraints or formatting requirements for the output.\nYou can include examples in the prompt that show the model what getting it right looks like. The model attempts to identify patterns and relationships from the examples and applies them when generating a response. Prompts that contain a few examples are called few-shot prompts, while prompts that provide no examples are called zero-shot prompts. Few-shot prompts are often used to regulate the formatting, phrasing, scoping, or general patterning of model responses. Use specific and varied examples to help the model narrow its focus and generate more accurate results.\nWe recommend to always include few-shot examples in your prompts. Prompts without few-shot examples are likely to be less effective, because they show the model how to apply instructions. In fact, you can remove instructions from your prompt if your examples are clear enough in showing the task at hand.\nThe following zero-shot prompt asks the model to choose the best explanation.\nExplanation1\nIf your use case requires the model to produce concise responses, you can include examples in the prompt that give preference to concise responses.\nThe following prompt provides two examples that show preference to the shorter explanations. In the response, you can see that the examples guided the model to choose the shorter explanation (Explanation2) as opposed to the longer explanation (Explanation1) like it did previously.\nQuestion: Why is sky blue?\nExplanation1: The sky appears blue because of Rayleigh scattering, which causes shorter blue\nwavelengths of light to be scattered more easily than longer red wavelengths, making the sky look\nblue.\nExplanation2: Due to Rayleigh scattering effect.\nAnswer: Explanation2\nQuestion: What is the cause of earthquakes?\nExplanation1: Sudden release of energy in the Earth's crust.\nExplanation2: Earthquakes happen when tectonic plates suddenly slip or break apart, causing a\nrelease of energy that creates seismic waves that can shake the ground and cause damage.\nAnswer: Explanation1\nExplanation2\nYou can experiment with the number of examples to provide in the prompt for the most desired results. Models like PaLM and Gemini can often pick up on patterns using a few examples, though you may need to experiment with what number of examples lead to the desired results. For simpler models like BERT, you may need more examples. At the same time, if you include too many examples, the model may start to overfit the response to the examples.\nUsing examples to show the model a pattern to follow is more effective than using examples to show the model an antipattern to avoid.\n⛔ Negative pattern:\nDon't end haikus with a question:\nDon't you enjoy them?\n✅ Positive pattern:\nAlways end haikus with an assertion:\nA joy to write\nMake sure that the structure and formatting of few-shot examples are the same to avoid responses with undesired formats. One of the primary objectives of adding few-shot examples in prompts is to show the model the response format. Therefore, it is essential to ensure a consistent format across all examples, especially paying attention to XML tags, white spaces, newlines, and example splitters.\nIncluding prompt-response examples in the prompt helps the model learn how to respond.\nGive the model examples of the patterns to follow instead of examples of patterns to avoid.\nExperiment with the number of prompts to include. Depending on the model, too few examples are ineffective at changing model behavior. Too many examples cause the model to overfit.\nYou can include in the prompt instructions and information that the model needs to solve a problem instead of assuming that the model has all of the required information. This contextual information helps the model understand the constraints and details of what you're asking for it to do.\nThe following example asks the model to give troubleshooting guidance for a router:\nWhat should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and\nblinking slowly.\n1. **Check the Cables:**\n- Make sure that all cables are securely connected to your Google Wifi router and modem.\n- Try replacing the cables with new ones to ensure they are not faulty.\n2. **Reboot the Router:**\n- Unplug your Google Wifi router and modem from the power outlet.\n- Wait for at least 30 seconds.\n- Plug the modem and router back in and wait for them to start up.\n3. **Factory Reset the Router:**\n- Resetting the router will restore it to its default settings.\n- Find the small reset button on the back of the router.\n- Press and hold the reset button with a paper clip or similar object for 10 seconds.\n- Release the button and wait for the router to restart.\n4. **Check Your Internet Connection:**\n- Use a wired connection to connect a device directly to your modem.\n- If the internet works, the issue may be with your router.\n- If the internet still doesn't work, contact your Internet Service Provider (ISP).\n5. **Update Router's Firmware:**\n- Check if there is a firmware update available for your Google Wifi router.\n- Download and install the latest firmware update from the Google Wifi app.\n6. **Interference and Obstacles:**\n- Make sure the router is not near electronic devices that can cause interference, like microwaves or cordless phones.\n- Remove any obstacles between the router and your devices, such as furniture or thick walls.\n7. **Change Wi-Fi Channel:**\n- In the Google Wifi app, go to Settings > Network & General > Advanced Networking.\n- Try changing the Wi-Fi channel to a less congested one.\n8. **Contact Google Support:**\n- If you've tried the above steps and the issue persists, contact Google support for further assistance.\nThe response looks like generic troubleshooting information that's not specific to the router or the status of the LED indicator lights.\nTo customize the response for the specific router, you can add to the prompt the router's troubleshooting guide as context for it to refer to when providing a response.\nAnswer the question using the text below. Respond with only the text provided.\nQuestion: What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and blinking slowly.\nText:\nColor: Slowly pulsing yellow\nWhat it means: There is a network error.\nColor: Fast blinking yellow\nWhat it means: You are holding down the reset button and are factory resetting this device.\nIf you keep holding down the reset button, after about 12 seconds, the light will turn solid yellow. Once it is solid yellow, let go of the factory reset button.\nColor: Solid yellow\nWhat it means: Router is factory resetting.\nThis can take up to 10 minutes. When it's done, the device will reset itself and start pulsing white, letting you know it's ready for setup.\nColor: Solid red\nWhat it means: Something is wrong.\nCritical failure. Factory reset the router. If the light stays red, contact Wifi customer support.\nInclude information (context) in the prompt that you want the model to use when generating a response.\nGive the model instructions on how to use the contextual information.\nA prefix is a word or phrase that you add to the prompt content that can serve several purposes, depending on where you put the prefix:\nInput prefix: Adding a prefix to the input signals semantically meaningful parts of the input to the model. For example, the prefixes \"English:\" and \"French:\" demarcate two different languages.\nOutput prefix: Even though the output is generated by the model, you can add a prefix for the output in the prompt. The output prefix gives the model information about what's expected as a response. For example, the output prefix \"JSON:\" signals to the model that the output should be in JSON format.\nExample prefix: In few-shot prompts, adding prefixes to the examples provides labels that the model can use when generating the output, which makes it easier to parse output content.\nIn the following example, \"Text:\" is the input prefix and \"The answer is:\" is the output prefix.\nClassify the text as one of the following categories.\n- large\n- small\nText: Rhino\nThe answer is: large\nText: Mouse\nText: Snail\nText: Elephant\nlarge\nGenerative language models work like an advanced autocompletion tool. When you provide partial content, the model can provide the rest of the content or what it thinks is a continuation of that content as a response. When doing so, if you include any examples or context, the model can take those examples or context into account.\nThe following example provides a prompt with an instruction and an entity input:\nFor the given order, return a JSON object that has the fields cheeseburger, hamburger, fries, or\ndrink, with the value being the quantity.\nOrder: A burger and a drink.\n\"cheeseburger\": 0,\n\"hamburger\": 1,\n\"fries\": 0,\n\"drink\": 1\nWhile the model did as prompted, writing out the instructions in natural language can sometimes be challenging and it leaves a lot to the model's interpretation. For example, a restaurants menu might contain many items. To reduce the size of the JSON response, you probably want to omit the items that weren't ordered. In this case, you can give an example and a response prefix and let the model complete it:\nValid fields are cheeseburger, hamburger, fries, and drink.\nOrder: Give me a cheeseburger and fries\n\"cheeseburger\": 1,\nOrder: I want two burgers, a drink, and fries.\n\"hamburger\": 2,\n\"drink\": 1,\nNotice how \"cheeseburger\" was excluded from the output because it wasn't a part of the order.\nPrompt the model to format its response\nThe completion strategy can also help format the response. The following example prompts the model to create an essay outline:\nA. Hook: Begin with an intriguing fact or description of hummingbirds.\nB. Provide some background information on hummingbirds.\n1. Mention their small size and long, thin beaks.\n2. Highlight their unique ability to hover and fly backward.\nII. Body\nA. Anatomy and Physiology\n1. Elaborate on their tiny size, making comparisons to other animals.\n2. Describe their wings and how they enable hovering and swift flight.\n3. Discuss their metabolism and energy requirements, emphasizing their caloric needs.\nB. Feeding Habits and Diet\n1. Explain their primary food source, nectar, and how they extract it from flowers.\n2. Describe their ability to feed from a wide variety of flowers.\n3. Mention their consumption of insects and the nutritional value they provide.\nC. Migration Patterns\n1. Discuss the incredible long-distance migrations of some hummingbird species.\n2. Explain the phenomenon of seasonal migration and the environmental factors driving it.\n3. Describe the routes taken by different species during migration.\nD. Conservation and Threats\n1. Highlight the importance of hummingbirds in ecosystems as pollinators.\n2. Discuss the challenges and threats they face, such as habitat loss, nectar scarcity, and climate change.\n3. Mention conservation efforts and ways to support hummingbird populations.\nIII. Conclusion\nA. Summarize the main points covered in the essay.\nB. Reinforce the importance of hummingbirds and their ecological role.\nC. Provide a final thought or call to action to protect these fascinating creatures.\nThe prompt didn't specify the format for the outline and the model chose a format for you. To get the model to return an outline in a specific format, you can add text that represents the start of the outline and let the model complete it based on the pattern that you initiated.\n*\n* Capture the reader's attention with an interesting anecdote or fact about hummingbirds.\n* Provide a brief background on hummingbirds, including their unique characteristics.\n* State the main points that will be covered in the essay.\nII. The Unique Characteristics of Hummingbirds\n* Discuss the hummingbird's exceptionally rapid wing-beat, allowing them to hover and fly backward.\n* Highlight their tiny size, making them the smallest birds in the world.\n* Describe their long, slender beaks and tongues, allowing them to reach deep into flowers to extract nectar.\n* Explain their iridescent plumage, which creates brilliant and vibrant colors.\nIII. Hummingbird Migration and Distribution\n* Discuss the extensive migration patterns of hummingbirds, covering vast distances across continents.\n* Describe the different habitats where hummingbirds can be found, including tropical rainforests, deserts, and urban areas.\n* Explain the seasonal changes that influence hummingbird migration and habitat selection.\nIV. Hummingbird Diet and Feeding Habits\n* Focus on the hummingbird's primary food source, which is nectar from flowers.\n* Describe their ability to consume insects, spiders, and other small invertebrates for protein.\n* Explain how hummingbirds use their long, slender tongues to extract nectar from flowers.\n* Discuss the importance of flowering plants in providing sustenance for hummingbirds.\nV. Reproduction and Nesting Behavior\n* Describe the mating rituals and courtship behavior of hummingbirds.\n* Explain the process of nest-building, including the materials used and the unique characteristics of hummingbird nests.\n* Discuss the role of the female hummingbird in laying and incubating eggs.\n* Describe the development of hummingbird chicks and the role of both parents in providing care.\nVI. Threats to Hummingbirds and Conservation Efforts\n* Highlight habitat loss, climate change, and deforestation as significant threats to hummingbird populations.\n* Describe the role of habitat conservation initiatives in protecting hummingbird habitats.\n* Explain the importance of creating hummingbird-friendly gardens and landscapes.\n* Discuss the efforts of organizations and individuals working to conserve hummingbird populations.\nVII. Conclusion\n* Summarize the main points covered in the essay, emphasizing the unique characteristics, migration patterns, diet, reproduction, and conservation of hummingbirds.\n* Provide a closing statement that leaves a lasting impression on the reader and reinforces the significance of these fascinating creatures.\nIf you give the model a partial input, the model completes that input based on any available examples or context in the prompt.\nHaving the model complete an input may sometimes be easier than describing the task in natural language.\nAdding a partial answer to a prompt can guide the model to follow a desired pattern or format.\nFor use cases that require complex prompts, you can help the model manage this complexity by breaking things down into simpler components.\nInstead of having many instructions in one prompt, create one prompt per instruction. You can choose which prompt to process based on the user's input.\nFor complex tasks that involve multiple sequential steps, make each step a prompt and chain the prompts together in a sequence. In this sequential chain of prompts, the output of one prompt in the sequence becomes the input of the next prompt. The output of the last prompt in the sequence is the final output.\nAggregation is when you want to perform different parallel tasks on different portions of the data and aggregate the results to produce the final output. For example, you can tell the model to perform one operation on the first part of the data, perform another operation on the rest of the data and aggregate the results.\nBreak down complex instructions into a prompt for each instruction and decide which prompt to apply based on the user's input.\nBreak down multiple sequential steps into separate prompts and chain them such that the output on the preceding prompt becomes the input of the following prompt.\nBreak down parallel tasks and aggregate the responses to produce the final output.\nEach call that you send to a model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Experiment with different parameter values to get the best values for the task. The parameters available for different models may differ. The most common parameters are the following:\nMaximum number of tokens that can be generated in the response. A token is approximately four characters. 100 tokens correspond to roughly 20 words.\nSpecify a lower value for shorter responses and a higher value for longer responses.\nThe temperature is used for sampling during response generation, which occurs when topP and topK are applied. Temperature controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a more deterministic and less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. A temperature of 0 is deterministic, meaning that the highest probability response is always selected.\nFor most use cases, try starting with a temperature of 0.2. If the model returns a response that's too generic, too short, or the model gives a fallback response, try increasing the temperature.\nTop-K changes how the model selects tokens for output. A top-K of 1 means the next selected token is the most probable among all tokens in the model's vocabulary (also called greedy decoding), while a top-K of 3 means that the next token is selected from among the three most probable tokens by using temperature.\nFor each token selection step, the top-K tokens with the highest probabilities are sampled. Then tokens are further filtered based on top-P with the final token selected using temperature sampling.\nSpecify a lower value for less random responses and a higher value for more random responses. The default top-K is 40.\nTop-P changes how the model selects tokens for output. Tokens are selected from the most (see top-K) to least probable until the sum of their probabilities equals the top-P value. For example, if tokens A, B, and C have a probability of 0.3, 0.2, and 0.1 and the top-P value is 0.5, then the model will select either A or B as the next token by using temperature and excludes C as a candidate.\nSpecify a lower value for less random responses and a higher value for more random responses. The default top-P is 0.95.\nPrompt design is an iterative process that often requires a few iterations before you get the desired response consistently. This section provides guidance on some things you can try when iterating on your prompts.\nUsing different words or phrasing in your prompts often yields different responses from the model even though they all mean the same thing. If you're not getting the expected results from your prompt, try rephrasing it.\nHow do I bake a pie?\nSuggest a recipe for a pie.\nWhat's a good pie recipe?\nIf you can't get the model to follow your instructions for a task, try giving it instructions for an analogous task that achieves the same result.\nThis prompt tells the model to categorize a book by using predefined categories.\nWhich category does The Odyssey belong to:\nthriller\nsci-fi\nmythology\nbiography\nThe answer: mythology\nExplanations:\nThe Odyssey is an epic poem in ancient Greek literature. It is one of two major ancient Greek epic\npoems attributed to Homer. The Odyssey is an epic poem that tells the story of Odysseus, a Greek\nhero who fought in the Trojan War and then spent ten years trying to return home to Ithaca. The\nOdyssey is a work of mythology.\nThe response is correct, but the model didn't stay within the bounds of the options. You also want to model to just respond with one of the options instead of in a full sentence. In this case, you can rephrase the instructions as a multiple choice question and ask the model to choose an option.\nMultiple choice problem: Which of the following options describes the book The Odyssey?\n- thriller\n- sci-fi\n- mythology\n- biography\nThe answer is: mythology\nThe order of the content in the prompt can sometimes affect the response. Try changing the content order and see how that affects the response.\nA fallback response is a response returned by the model when either the prompt or the response triggers a safety filter. An example of a fallback response is \"I'm not able to help with that, as I'm only a language model.\"\nIf the model responds with a fallback response, try increasing the temperature.\nAvoid relying on models to generate factual information.\nUse with care on math and logic problems.\nNow that you have a deeper understanding of prompt design, try writing your own prompts using Google AI Studio.",
            "filtered_word_count": 3829
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nIntro to prompting\nPrompting with media files\nPrompting strategies\nFile prompting strategies\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nUsing media files with prompts\nStrategies for prompting with media\nPrompt design fundamentals\nTroubleshooting your multimodal prompt\nPrompt design fundamentals\nBe specific in your instructions\nAdd a few examples\nBreak it down step-by-step\nTry specifying the output format\nPut your image first for single-image prompts\nTroubleshooting your multimodal prompt\nIf the model is not drawing information from the relevant part of the image\nIf the model output is too generic and not tailored enough to the image input\nTroubleshooting which part of the prompt failed\nTuning the sampling parameters\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nFile prompting strategies \nbookmark_border\n\nThe Gemini family of artificial intelligence (AI) models is built to handle various types of input data, including text, images, and audio. Since these models can handle more more than one type or mode of data, the Gemini models are called multimodal models or explained as having multimodal capabilities.\n\nNote: Prompting with media files is supported by specific Gemini models. For more information about which models support this feature, see Prompting with media files.\n\nThis page provides guidance and best practices for using media files with prompts for the Gemini API. For information on using the Gemini Files API for uploading media files and including them in your prompts, see Prompting with media files.\n\nUsing media files with prompts\n\nBeing able to use various types of data in your prompts gives you more flexibility in terms of what tasks you can tackle with the Gemini API. For example, you can send the model a photo of a delicious meal and ask it to write a short blog about the meal.\n\nPrompt\tResponse\n\n\nWrite a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\n\n\n\t\n\nMeal prepping is a great way to save time and money, and it can also help you to eat healthier. This meal is a great example of a healthy and delicious meal that can be easily prepped ahead of time.\n\nThis meal features brown rice, roasted vegetables, and chicken teriyaki. The brown rice is a healthy and complex carbohydrate that will give you sustained energy. The roasted vegetables are a great way to get your daily dose of vitamins and minerals, and the chicken teriyaki is a delicious and protein-rich option.\n\nThis meal is also very easy to prepare. Simply cook the brown rice, roast the vegetables, and cook the chicken teriyaki. Once everything is cooked, divide it into meal prep containers and store them in the refrigerator. You can then grab a container and go on busy mornings!\n\nIf you're looking for a healthy and delicious meal that can be easily prepped ahead of time, this meal is a great option. It's packed with nutrients and flavor, and it's sure to keep you feeling full and satisfied.\n\nHere's to healthy and delicious meal prepping!\n\nStrategies for prompting with media\n\nIf you are having trouble getting the output you want from prompts that use media files, there are some strategies that can help you get the results you want. The following sections provide design approaches and troubleshooting tips for improving prompts that use multimodal input.\n\nYou can improve your multimodal prompts by following these best practices:\n\nPrompt design fundamentals\nBe specific in your instructions: Craft clear and concise instructions that leave minimal room for misinterpretation.\nAdd a few examples to your prompt: Use realistic few-shot examples to illustrate what you want to achieve.\nBreak it down step-by-step: Divide complex tasks into manageable sub-goals, guiding the model through the process.\nSpecify the output format: In your prompt, ask for the output to be in the format you want, like markdown, JSON, HTML and more.\nPut your image first for single-image prompts: While Gemini can handle image and text inputs in any order, for prompts containing a single image, it might perform better if that image is placed before the text prompt.\nTroubleshooting your multimodal prompt\nIf the model is not drawing information from the relevant part of the image: Drop hints with which aspects of the image you want the prompt to draw information from.\nIf the model output is too generic (not tailored enough to the image): At the start of the prompt, try asking the model to describe the image(s) before providing the task instruction, or try asking the model to refer to what's in the image.\nPrompt design fundamentals\n\nThis section expands on the best practices listed in the previous section.\n\nNote: Model results from the following Gemini examples can vary from run to run.\n\nBe specific in your instructions\n\nPrompts have the most success when they are clear and detailed. If you have a specific output in mind, it's better to include that requirement in the prompt to ensure you get the output you want.\n\nSometimes, a prompt's intent might seem clear to the person who wrote it, but it is actually under-specified. To customize model behavior, consider how your prompt could be (mis)interpreted, and ensure that the instructions you give are specific and clear. Remember to leave minimal room for misinterpretation\n\nFor this image of an airport board, asking the model to just \"describe this image\" could generate a general description. If you need the model to parse the time and city from the image, you can include that request directly in your prompt.\n\nPrompt\tModel response\n\n\nDescribe this image.\n\n\t\n\nThe image shows an airport arrivals and departures board.\n\nUpdated prompt\tImproved response\n\n\nParse the time and city from the airport board shown in this image into a list.\n\n\t\n\n10:50 Moscow\n11:05 Edinburgh\n11:05 London\n11:10 Bucharest\n11:30 Kiev\n11:35 Dublin\n11:45 East Midlands\n12:15 Sofia\n12:30 London\n12:30 Newcastle\n12:40 St Petersburg\n12:40 London\n12:45 Manchester\n\nAdd a few examples\n\nThe Gemini model can accept multiple inputs which it can use as examples to understand the output you want. Adding these examples can help the model identify the patterns and apply the relationship between the given images and responses to the new example. This is also called \"few-shot\" learning.\n\nIn the example below, the initial output is written in sentence form, and also contains the country (Brazil). Suppose you want the output in a different format or style, and you want only the city, not the country. Adding few-shot examples to your prompt can steer the model to respond in the way you want.\n\nPrompt\tModel response\n\n\nDetermine the city along with the landmark.\n\n\t\n\nThe landmark is the Christ the Redeemer statue in Rio de Janeiro, Brazil.\n\nUpdated prompt\tImproved response\n\n\nDetermine the city along with the landmark.\n\n\t\n\ncity: Rome, landmark: the Colosseum.\n\n\n\t\n\ncity: Beijing, landmark: Forbidden City\n\n\n\t\n\ncity: Rio de Janeiro, landmark: Christ the Redeemer statue\n\nBreak it down step-by-step\n\nFor complex tasks like the ones that require both visual understanding and reasoning, it can be helpful to split the task into smaller, more straightforward steps. Alternatively, it could also be effective if you directly ask the model to “think step by step” in your prompt.\n\nPrompt\tModel response\n\n\nWhen will I run out of toilet paper?\n\n\t\n\nSoon, you only have 3 rolls left.\n\nUpdated prompt\tImproved response\n\n\n1. First, count how many toilet paper rolls are in this picture.\n2. Then, determine how much toilet paper a typical person uses per day.\n3. Calculate how long these rolls of toilet paper will last.\n\n\t\n\n1. There are 3 rolls of toilet paper in this picture.\n2. A typical person uses about 20 sheets of toilet paper per day.\n3. If each roll contains 200 sheets, then each roll will last for about 10 days. Therefore, the 3 rolls will last for about a month.\n\nMath problems or other types of word problems are great candidates for asking the model to think step-by-step.\n\nPrompt\tResponse\n\n\nWhat is the 4th term in the sequence?\n\n\t\n\n-135\n\nThe response from the model is incorrect. Some ways to improve this is to ask the model to parse the problem before answering the prompt.\n\nPrompt\tResponse\n\n\nParse the formula in the image first.\n\nThen based on the formula, answer \"what's the 4th term in the sequence?\".\n\n\t\n\nClick to expand the result\n\nThis model response is correct - now to make the response even more streamlined, you can ask the model to to think step-by-step.\n\nUpdated prompt\tImproved response\n\n\nWhat is the 4th term in the sequence? Think step by step.\n\n\t\n\nThe first term is 15.\n\nThe second term is b(1) * (-3) = 15 * (-3) = -45.\n\nThe third term is b(2) * (-3) = -45 * (-3) = 135.\n\nThe fourth term is b(3) * (-3) = 135 * (-3) = -405.\n\nTry specifying the output format\n\nA common problem is the need for model output to be in a certain format (e.g. markdown, JSON, HTML), especially if the model output needs to be ingested by a downstream task. You can try to produce output in that format by instructing the model to do so within the prompt. Below are two examples:\n\nPrompt\tModel response\n\n\nParse the table in this image into markdown format\n\n\t\n\n| Subject | Status | Time | Start date | Due on |\n\n| ------- | ------ | ---- | --------- | ------ |\n\n| Math | Done | 1.5 hrs | 11/29/2023 | 12/1/2023 |\n\n| Geography | Done | 30 min | 12/2/2023 | 12/4/2023 |\n\n| Physics | In progress | 2 hrs | 12/3/2023 | 12/5/2023 |\n\n| Biology | Not started | 6 hrs | 11/2/2016 | 12/6/2023 |\n\nPrompt\tModel response\n\n\nProvide a list of all the following attributes:\n\ningredients, type of cuisine, vegetarian or not, in JSON format\n\n\t\n\n```json```\n\n{\n\n\"ingredients\": [\n\n\"rice\",\n\n\"shrimp\",\n\n\"clams\",\n\n\"mussels\",\n\n\"peas\",\n\n\"tomatoes\",\n\n\"onions\",\n\n\"garlic\",\n\n\"olive oil\",\n\n\"paprika\",\n\n\"salt\",\n\n\"pepper\"\n\n],\n\n\"type of cuisine\": \"Spanish\",\n\n\"vegetarian\": false\n\nPut your image first for single-image prompts\n\nWhile Gemini can interpret image and text in any order within a prompt, placing a single image before the text prompt might lead to better results. In the following samples, you'll notice the image comes first before the text in each prompt.\n\nTroubleshooting your multimodal prompt\n\nYou might need to troubleshoot your prompt if you are not getting a helpful response. Here are a few strategies you could try.\n\nIf the model is not drawing information from the relevant part of the image\n\nTo get a more specific response, you can point out which aspects of the image you want the prompt to draw information from to inform its response.\n\nPrompt\tModel response\n\n\nHow many days will these diapers last a baby?\n\n\t\n\nThe diapers will last for 198 days before they run out.\n\nUpdated prompt\tImproved response\n\n\nHow long will these diapers last before I run out?\n\nUse the weight shown on the box to determine the child's age, and use the total number of diapers in the box.\n\nDivide the total number by how many diapers the child goes through per day.\n\n\t\n\nThe box contains 198 diapers. The box states the diapers are for a child weighing 22-37 lbs.\n\nThe average child in this weight range is likely between 1 and 2 years old.\n\nA 2-year-old typically goes through 6 diapers per day, therefore, the diapers will last around 33 days (198/6).\n\nIf the model output is too generic and not tailored enough to the image input\n\nTo help the model tailor its response to the image(s), try asking it to describe the images before performing its reasoning task.\n\nPrompt\tModel response\n   \n\nWhat is in common between these images?\n\n\t\n\nAll four images are examples of landscape photography.\n\nUpdated prompt\tImproved response\n   \n\nFirst, describe what's in each image in detail. What's in common between these images?\n\n\t\n\nThe first image shows a person packing a suitcase. The second image shows an empty hallway in a shopping mall. The third image shows a roll of toilet paper. The fourth image shows a dark and stormy sea.\n\nThe commonality between these images is that they are all examples of liminal spaces. Liminal spaces are places or situations that are in between two other places or situations. They are often characterized by a sense of uncertainty or ambiguity.\n\nThe first image shows the person in between being at home and being on a trip. The second image shows the hallway in between two stores. The third image is of toilet paper, which can represent a bathroom. A bathroom is a transitional space between private and public realms. It's a place where we prepare ourselves to enter or leave the outside world.\n\nThe fourth image shows the sea in between being calm and being stormy.\n\nLiminal spaces can be both exciting and unsettling. They can be a place of new beginning or a place of endings. They can be a place of reflection or a place of action.\n\nYou can also try explicitly asking the model to refer to what's in the image.\n\nUpdated prompt\tImproved response\n   \n\nWhat is in common between these images? Refer to what's in the images in your response.\n\n\t\n\nAll of the images are related to travel. The first image shows a person packing a suitcase, the second image shows an empty hallway in a shopping mall, the third image shows a stack of toilet paper, and the fourth image shows a dark and stormy sea.\n\nThese images are all related to travel because they are all things that people need or use when they travel. The first image shows a person packing a suitcase, which is something that people do when they are going on a trip. The second image shows an empty hallway in a shopping mall, which is a place where people often go to buy things for their trips. The third image shows a stack of toilet paper, which is something that people often use when they are traveling. The fourth image shows a dark and stormy sea, which is something that people often encounter when they are traveling.\n\nThe same tips work for creative output from images. In the following example with the rabbit, explicitly asking the model to include aspects from the image can improve the output.\n\nPrompt\tModel response\n\n\nCan you write me a poem about this image?\n\n\t\n\nLittle bunny, so soft and brown,\nHopping through the field, up and down.\nYour ears so long, your tail so small,\nYou're the cutest creature of them all.\n\nYou nibble on the grass, so green and sweet,\nAnd hop away when you see me.\nBut I'll always be your friend,\nLittle bunny, until the very end.\n\nUpdated prompt\tImproved response\n\n\nCan you write me a descriptive and dramatic poem about this image and include the location?\n\n\t\n\nLittle bunny on the green,\nEars so long, so keen.\nWhat do you see out there,\nIn the distance, where you stare?\n\nIs it the ocean blue,\nSparkling in the sun's hue?\nOr the waves that crash and roar,\nA rhythm that you adore?\n\nLittle bunny, tell me true,\nWhat captures your attention so?\nIs it the salty breeze,\nOr the seagulls' cries that please?\n\nPerhaps it's the vastness of it all,\nA world so big and small.\nA place where dreams can roam,\nAnd adventures can be sown.\n\nLittle bunny, I wonder what you dream,\nAs you sit on the grass, so serene.\nDo you yearn to explore the deep,\nOr stay on land, where you can leap?\n\nWhatever it may be, little bunny,\nKeep that spark of wonder burning brightly.\nFor in your dreams and aspirations,\nLies a world waiting for your creation.\n\nTroubleshooting which part of the prompt failed\n\nIt can be hard to know whether a prompt failed because the model didn't understand the image to begin with, or if it did understand the image but did not perform the correct reasoning steps afterward.\n\nTo disambiguate between those reasons, ask the model to describe what's in the image.\n\nIn this example below, if the model responds with a snack that seems surprising when paired with tea (e.g. popcorn), you can first troubleshoot to determine whether the model correctly recognized that the image contains tea.\n\nPrompt\tPrompt for troubleshooting\n\n\nWhat's a snack I can make in 1 minute that would go well with this?\n\n\t\n\nDescribe what's in this image.\n\nAnother strategy is to ask the model to explain its reasoning. That can help you narrow down which part of the reasoning broke down, if any.\n\nPrompt\tPrompt for troubleshooting\n\n\nWhat's a snack I can make in 1 minute that would go well with this?\n\n\t\n\nWhat's a snack I can make in 1 minute that would go well with this? Please explain why.\n\nTuning the sampling parameters\n\nIn each request, you send not only the multimodal prompt but a set of sampling parameters to the model. The model can generate different results for different parameter values. Experiment with the different parameters to get the best values for the task. The most commonly adjusted parameters are the following:\n\nTemperature\ntop-P\ntop-K\nTemperature\n\nTemperature is used for sampling during response generation, which occurs when top-P and top-K are applied. Temperature controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a more deterministic and less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. A temperature of 0 is deterministic, meaning that the highest probability response is always selected.\n\n\nFor most use cases, try starting with a temperature of 0.4. If you need more creative results, try increasing the temperature. If you observe clear hallucinations, try reducing the temperature.\n\nTop-K\n\nTop-K changes how the model selects tokens for output. A top-K of 1 means the next selected token is the most probable among all tokens in the model's vocabulary (also called greedy decoding), while a top-K of 3 means that the next token is selected from among the three most probable tokens by using temperature.\n\n\nFor each token selection step, the top-K tokens with the highest probabilities are sampled. Then tokens are further filtered based on top-P with the final token selected using temperature sampling.\n\nSpecify a lower value for less random responses and a higher value for more random responses. The default value of top-K is 32.\n\nTop-P\n\nTop-P changes how the model selects tokens for output. Tokens are selected from the most (see top-K) to least probable until the sum of their probabilities equals the top-P value. For example, if tokens A, B, and C have a probability of 0.6, 0.3, 0.1 and the top-P value is 0.9, then the model will select either A or B as the next token by using temperature and excludes C as a candidate.\n\n\nSpecify a lower value for less random responses and a higher value for more random responses. The default value of top-P is 1.0.\n\nNext steps\nTry writing your own multimodal prompts using Google AI Studio.\nFor more guidance on prompt design, see the Prompt strategies page.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-24 UTC.\n\nTerms\nPrivacy",
            "word_count": 3339,
            "filtered_content": "File prompting strategies \nThe Gemini family of artificial intelligence (AI) models is built to handle various types of input data, including text, images, and audio. Since these models can handle more more than one type or mode of data, the Gemini models are called multimodal models or explained as having multimodal capabilities.\nNote: Prompting with media files is supported by specific Gemini models. For more information about which models support this feature, see Prompting with media files.\nThis page provides guidance and best practices for using media files with prompts for the Gemini API. For information on using the Gemini Files API for uploading media files and including them in your prompts, see Prompting with media files.\nBeing able to use various types of data in your prompts gives you more flexibility in terms of what tasks you can tackle with the Gemini API. For example, you can send the model a photo of a delicious meal and ask it to write a short blog about the meal.\nWrite a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\nThis meal features brown rice, roasted vegetables, and chicken teriyaki. The brown rice is a healthy and complex carbohydrate that will give you sustained energy. The roasted vegetables are a great way to get your daily dose of vitamins and minerals, and the chicken teriyaki is a delicious and protein-rich option.\nThis meal is also very easy to prepare. Simply cook the brown rice, roast the vegetables, and cook the chicken teriyaki. Once everything is cooked, divide it into meal prep containers and store them in the refrigerator. You can then grab a container and go on busy mornings!\nIf you're looking for a healthy and delicious meal that can be easily prepped ahead of time, this meal is a great option. It's packed with nutrients and flavor, and it's sure to keep you feeling full and satisfied.\nHere's to healthy and delicious meal prepping!\nIf you are having trouble getting the output you want from prompts that use media files, there are some strategies that can help you get the results you want. The following sections provide design approaches and troubleshooting tips for improving prompts that use multimodal input.\nYou can improve your multimodal prompts by following these best practices:\nBe specific in your instructions: Craft clear and concise instructions that leave minimal room for misinterpretation.\nAdd a few examples to your prompt: Use realistic few-shot examples to illustrate what you want to achieve.\nBreak it down step-by-step: Divide complex tasks into manageable sub-goals, guiding the model through the process.\nSpecify the output format: In your prompt, ask for the output to be in the format you want, like markdown, JSON, HTML and more.\nPut your image first for single-image prompts: While Gemini can handle image and text inputs in any order, for prompts containing a single image, it might perform better if that image is placed before the text prompt.\nIf the model is not drawing information from the relevant part of the image: Drop hints with which aspects of the image you want the prompt to draw information from.\nIf the model output is too generic (not tailored enough to the image): At the start of the prompt, try asking the model to describe the image(s) before providing the task instruction, or try asking the model to refer to what's in the image.\nThis section expands on the best practices listed in the previous section.\nNote: Model results from the following Gemini examples can vary from run to run.\nPrompts have the most success when they are clear and detailed. If you have a specific output in mind, it's better to include that requirement in the prompt to ensure you get the output you want.\nSometimes, a prompt's intent might seem clear to the person who wrote it, but it is actually under-specified. To customize model behavior, consider how your prompt could be (mis)interpreted, and ensure that the instructions you give are specific and clear. Remember to leave minimal room for misinterpretation\nFor this image of an airport board, asking the model to just \"describe this image\" could generate a general description. If you need the model to parse the time and city from the image, you can include that request directly in your prompt.\nDescribe this image.\nThe image shows an airport arrivals and departures board.\nParse the time and city from the airport board shown in this image into a list.\n10:50 Moscow\n11:05 Edinburgh\n11:05 London\n11:10 Bucharest\n11:30 Kiev\n11:35 Dublin\n11:45 East Midlands\n12:15 Sofia\n12:30 London\n12:30 Newcastle\n12:40 St Petersburg\n12:40 London\n12:45 Manchester\nThe Gemini model can accept multiple inputs which it can use as examples to understand the output you want. Adding these examples can help the model identify the patterns and apply the relationship between the given images and responses to the new example. This is also called \"few-shot\" learning.\nIn the example below, the initial output is written in sentence form, and also contains the country (Brazil). Suppose you want the output in a different format or style, and you want only the city, not the country. Adding few-shot examples to your prompt can steer the model to respond in the way you want.\nThe landmark is the Christ the Redeemer statue in Rio de Janeiro, Brazil.\ncity: Rome, landmark: the Colosseum.\ncity: Beijing, landmark: Forbidden City\ncity: Rio de Janeiro, landmark: Christ the Redeemer statue\nFor complex tasks like the ones that require both visual understanding and reasoning, it can be helpful to split the task into smaller, more straightforward steps. Alternatively, it could also be effective if you directly ask the model to “think step by step” in your prompt.\nWhen will I run out of toilet paper?\nSoon, you only have 3 rolls left.\n1. First, count how many toilet paper rolls are in this picture.\n2. Then, determine how much toilet paper a typical person uses per day.\n3. Calculate how long these rolls of toilet paper will last.\n1. There are 3 rolls of toilet paper in this picture.\n2. A typical person uses about 20 sheets of toilet paper per day.\n3. If each roll contains 200 sheets, then each roll will last for about 10 days. Therefore, the 3 rolls will last for about a month.\nMath problems or other types of word problems are great candidates for asking the model to think step-by-step.\nWhat is the 4th term in the sequence?\n-135\nThe response from the model is incorrect. Some ways to improve this is to ask the model to parse the problem before answering the prompt.\nParse the formula in the image first.\nThen based on the formula, answer \"what's the 4th term in the sequence?\".\nClick to expand the result\nThis model response is correct - now to make the response even more streamlined, you can ask the model to to think step-by-step.\nWhat is the 4th term in the sequence? Think step by step.\nThe first term is 15.\nThe second term is b(1) * (-3) = 15 * (-3) = -45.\nThe third term is b(2) * (-3) = -45 * (-3) = 135.\nThe fourth term is b(3) * (-3) = 135 * (-3) = -405.\nA common problem is the need for model output to be in a certain format (e.g. markdown, JSON, HTML), especially if the model output needs to be ingested by a downstream task. You can try to produce output in that format by instructing the model to do so within the prompt. Below are two examples:\nParse the table in this image into markdown format\n| Subject | Status | Time | Start date | Due on |\n| ------- | ------ | ---- | --------- | ------ |\n| Math | Done | 1.5 hrs | 11/29/2023 | 12/1/2023 |\n| Geography | Done | 30 min | 12/2/2023 | 12/4/2023 |\n| Physics | In progress | 2 hrs | 12/3/2023 | 12/5/2023 |\n| Biology | Not started | 6 hrs | 11/2/2016 | 12/6/2023 |\nProvide a list of all the following attributes:\ningredients, type of cuisine, vegetarian or not, in JSON format\n```json```\n\"ingredients\": [\n\"rice\",\n\"shrimp\",\n\"clams\",\n\"mussels\",\n\"peas\",\n\"tomatoes\",\n\"onions\",\n\"garlic\",\n\"olive oil\",\n\"paprika\",\n\"salt\",\n\"pepper\"\n],\n\"type of cuisine\": \"Spanish\",\n\"vegetarian\": false\nWhile Gemini can interpret image and text in any order within a prompt, placing a single image before the text prompt might lead to better results. In the following samples, you'll notice the image comes first before the text in each prompt.\nYou might need to troubleshoot your prompt if you are not getting a helpful response. Here are a few strategies you could try.\nTo get a more specific response, you can point out which aspects of the image you want the prompt to draw information from to inform its response.\nHow many days will these diapers last a baby?\nThe diapers will last for 198 days before they run out.\nHow long will these diapers last before I run out?\nUse the weight shown on the box to determine the child's age, and use the total number of diapers in the box.\nDivide the total number by how many diapers the child goes through per day.\nThe box contains 198 diapers. The box states the diapers are for a child weighing 22-37 lbs.\nThe average child in this weight range is likely between 1 and 2 years old.\nA 2-year-old typically goes through 6 diapers per day, therefore, the diapers will last around 33 days (198/6).\nTo help the model tailor its response to the image(s), try asking it to describe the images before performing its reasoning task.\nWhat is in common between these images?\nAll four images are examples of landscape photography.\nFirst, describe what's in each image in detail. What's in common between these images?\nThe first image shows a person packing a suitcase. The second image shows an empty hallway in a shopping mall. The third image shows a roll of toilet paper. The fourth image shows a dark and stormy sea.\nThe commonality between these images is that they are all examples of liminal spaces. Liminal spaces are places or situations that are in between two other places or situations. They are often characterized by a sense of uncertainty or ambiguity.\nThe first image shows the person in between being at home and being on a trip. The second image shows the hallway in between two stores. The third image is of toilet paper, which can represent a bathroom. A bathroom is a transitional space between private and public realms. It's a place where we prepare ourselves to enter or leave the outside world.\nThe fourth image shows the sea in between being calm and being stormy.\nLiminal spaces can be both exciting and unsettling. They can be a place of new beginning or a place of endings. They can be a place of reflection or a place of action.\nYou can also try explicitly asking the model to refer to what's in the image.\nWhat is in common between these images? Refer to what's in the images in your response.\nAll of the images are related to travel. The first image shows a person packing a suitcase, the second image shows an empty hallway in a shopping mall, the third image shows a stack of toilet paper, and the fourth image shows a dark and stormy sea.\nThese images are all related to travel because they are all things that people need or use when they travel. The first image shows a person packing a suitcase, which is something that people do when they are going on a trip. The second image shows an empty hallway in a shopping mall, which is a place where people often go to buy things for their trips. The third image shows a stack of toilet paper, which is something that people often use when they are traveling. The fourth image shows a dark and stormy sea, which is something that people often encounter when they are traveling.\nThe same tips work for creative output from images. In the following example with the rabbit, explicitly asking the model to include aspects from the image can improve the output.\nCan you write me a poem about this image?\nLittle bunny, so soft and brown,\nHopping through the field, up and down.\nYour ears so long, your tail so small,\nYou're the cutest creature of them all.\nYou nibble on the grass, so green and sweet,\nAnd hop away when you see me.\nBut I'll always be your friend,\nLittle bunny, until the very end.\nCan you write me a descriptive and dramatic poem about this image and include the location?\nLittle bunny on the green,\nEars so long, so keen.\nWhat do you see out there,\nIn the distance, where you stare?\nIs it the ocean blue,\nSparkling in the sun's hue?\nOr the waves that crash and roar,\nA rhythm that you adore?\nLittle bunny, tell me true,\nWhat captures your attention so?\nIs it the salty breeze,\nOr the seagulls' cries that please?\nPerhaps it's the vastness of it all,\nA world so big and small.\nA place where dreams can roam,\nAnd adventures can be sown.\nLittle bunny, I wonder what you dream,\nAs you sit on the grass, so serene.\nDo you yearn to explore the deep,\nOr stay on land, where you can leap?\nWhatever it may be, little bunny,\nKeep that spark of wonder burning brightly.\nFor in your dreams and aspirations,\nLies a world waiting for your creation.\nIt can be hard to know whether a prompt failed because the model didn't understand the image to begin with, or if it did understand the image but did not perform the correct reasoning steps afterward.\nTo disambiguate between those reasons, ask the model to describe what's in the image.\nIn this example below, if the model responds with a snack that seems surprising when paired with tea (e.g. popcorn), you can first troubleshoot to determine whether the model correctly recognized that the image contains tea.\nDescribe what's in this image.\nAnother strategy is to ask the model to explain its reasoning. That can help you narrow down which part of the reasoning broke down, if any.\nWhat's a snack I can make in 1 minute that would go well with this? Please explain why.\nIn each request, you send not only the multimodal prompt but a set of sampling parameters to the model. The model can generate different results for different parameter values. Experiment with the different parameters to get the best values for the task. The most commonly adjusted parameters are the following:\ntop-P\ntop-K\nTemperature is used for sampling during response generation, which occurs when top-P and top-K are applied. Temperature controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a more deterministic and less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. A temperature of 0 is deterministic, meaning that the highest probability response is always selected.\nFor most use cases, try starting with a temperature of 0.4. If you need more creative results, try increasing the temperature. If you observe clear hallucinations, try reducing the temperature.\nSpecify a lower value for less random responses and a higher value for more random responses. The default value of top-K is 32.\nTop-P changes how the model selects tokens for output. Tokens are selected from the most (see top-K) to least probable until the sum of their probabilities equals the top-P value. For example, if tokens A, B, and C have a probability of 0.6, 0.3, 0.1 and the top-P value is 0.9, then the model will select either A or B as the next token by using temperature and excludes C as a candidate.\nSpecify a lower value for less random responses and a higher value for more random responses. The default value of top-P is 1.0.\nTry writing your own multimodal prompts using Google AI Studio.\nFor more guidance on prompt design, see the Prompt strategies page.\nLast updated 2024-04-24 UTC.",
            "filtered_word_count": 2724
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nExamples\nCode generation\nFormatted data generation\nMusic chatbot\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nSystem instructions \nbookmark_border\n\nBeta: System instructions are available in beta in the Gemini API and Google AI Studio.\n\nSystem instructions enable users to steer the behavior of the model based on their specific needs and use cases. When you set a system instruction, you give the model additional context to understand the task, provide more customized responses, and adhere to specific guidelines over the full user interaction with the model. For developers, product-level behavior can be specified in system instructions, separate from prompts provided by end users.\n\nYou can use system instructions in many ways, including:\n\nDefining a persona or role (for a chatbot, for example)\nDefining output format (Markdown, YAML, etc.)\nDefining output style and tone (for example, verbosity, formality, and target reading level)\nDefining goals or rules for the task (for example, returning a code snippet without further explanations)\nProviding additional context for the prompt (for example, a knowledge cutoff)\n\nWhen a system instruction is set, it applies to the entire request. It works across multiple user and model turns when included in the prompt. System instructions are part of your overall prompts and therefore are subject to standard data use policies.\n\nNote: System instructions can help guide the model to follow instructions, but they don't fully prevent jailbreaks or leaks. We recommend exercising caution around putting any sensitive information in system instructions.\nExamples\n\nHere's a simple example of setting the system instruction using the Python SDK for the Gemini API:\n\nmodel=genai.GenerativeModel(\n    model_name=\"gemini-1.5-pro-latest\",\n    system_instruction=\"You are a cat. Your name is Neko.\")\n\n\nThe following are examples of system prompts that define the expected behavior of the model.\n\nCode generation\nSystem: You are a coding expert that specializes in rendering code for front-end interfaces. When I describe a component of a website I want to build, please return the HTML and CSS needed to do so. Do not give an explanation for this code. Also offer some UI design suggestions.\nUser: Create a box in the middle of the page that contains a rotating selection of images each with a caption. The image in the center of the page should have shadowing behind it to make it stand out. It should also link to another page of the site. Leave the URL blank so that I can fill it in.\nFormatted data generation\n\nSystem: You are an assistant for home cooks. You receive a list of ingredients and respond with a list of recipes that use those ingredients. Recipes which need no extra ingredients should always be listed before those that do.\n\nYour response must be a JSON object containing 3 recipes. A recipe object has the following schema:\n\nname: The name of the recipe\nusedIngredients: Ingredients in the recipe that were provided in the list\notherIngredients: Ingredients in the recipe that were not provided in the list (omitted if there are no other ingredients)\ndescription: A brief description of the recipe, written positively as if to sell it\n\nUser:\n\n1 lb bag frozen broccoli\n1 pint heavy cream\n1 lb pack cheese ends and pieces\nMusic chatbot\nSystem: You will respond as a music historian, demonstrating comprehensive knowledge across diverse musical genres and providing relevant examples. Your tone will be upbeat and enthusiastic, spreading the joy of music. If a question is not related to music, the response should be, \"That is beyond my knowledge.\"\nUser: If a person was born in the sixties, what was the most popular music genre being played? List five songs by bullet point.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 768,
            "filtered_content": "System instructions \nBeta: System instructions are available in beta in the Gemini API and Google AI Studio.\nSystem instructions enable users to steer the behavior of the model based on their specific needs and use cases. When you set a system instruction, you give the model additional context to understand the task, provide more customized responses, and adhere to specific guidelines over the full user interaction with the model. For developers, product-level behavior can be specified in system instructions, separate from prompts provided by end users.\nYou can use system instructions in many ways, including:\nDefining a persona or role (for a chatbot, for example)\nDefining output format (Markdown, YAML, etc.)\nDefining output style and tone (for example, verbosity, formality, and target reading level)\nDefining goals or rules for the task (for example, returning a code snippet without further explanations)\nProviding additional context for the prompt (for example, a knowledge cutoff)\nWhen a system instruction is set, it applies to the entire request. It works across multiple user and model turns when included in the prompt. System instructions are part of your overall prompts and therefore are subject to standard data use policies.\nNote: System instructions can help guide the model to follow instructions, but they don't fully prevent jailbreaks or leaks. We recommend exercising caution around putting any sensitive information in system instructions.\nHere's a simple example of setting the system instruction using the Python SDK for the Gemini API:\nmodel=genai.GenerativeModel(\n    model_name=\"gemini-1.5-pro-latest\",\n    system_instruction=\"You are a cat. Your name is Neko.\")\nThe following are examples of system prompts that define the expected behavior of the model.\nSystem: You are a coding expert that specializes in rendering code for front-end interfaces. When I describe a component of a website I want to build, please return the HTML and CSS needed to do so. Do not give an explanation for this code. Also offer some UI design suggestions.\nUser: Create a box in the middle of the page that contains a rotating selection of images each with a caption. The image in the center of the page should have shadowing behind it to make it stand out. It should also link to another page of the site. Leave the URL blank so that I can fill it in.\nSystem: You are an assistant for home cooks. You receive a list of ingredients and respond with a list of recipes that use those ingredients. Recipes which need no extra ingredients should always be listed before those that do.\nYour response must be a JSON object containing 3 recipes. A recipe object has the following schema:\nname: The name of the recipe\nusedIngredients: Ingredients in the recipe that were provided in the list\notherIngredients: Ingredients in the recipe that were not provided in the list (omitted if there are no other ingredients)\ndescription: A brief description of the recipe, written positively as if to sell it\nUser:\n1 lb bag frozen broccoli\n1 pint heavy cream\n1 lb pack cheese ends and pieces\nSystem: You will respond as a music historian, demonstrating comprehensive knowledge across diverse musical genres and providing relevant examples. Your tone will be upbeat and enthusiastic, spreading the joy of music. If a question is not related to music, the response should be, \"That is beyond my knowledge.\"\nUser: If a person was born in the sixties, what was the most popular music genre being played? List five songs by bullet point.",
            "filtered_word_count": 571
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nOverview\nSetup\nImport the Generative Language API\nAuthenticate\nSetup OAuth using service accounts\nCreate a corpus\nGet the created corpus\nCreate a document\nGet the created document\nIngest & Chunk a Document\nIngest HTML and chunk via HtmlChunker\nBatch create chunks\nList Chunks and get state\nIngest another document\nQuery the corpus\nAttributed Question-Answering\nanswerable_probability and the “I don’t know” problem\nAQA Helpful Tips\nMore Options: AQA Using Inline Passages\nShare the corpus\nDelete the corpus\nSummary and further reading\nAppendix: Setup OAuth with user credentials\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet started with semantic retrieval \nbookmark_border\n\nRun in Google Colab\n\t\nView source on GitHub\nOverview\n\nLarge Language Models (LLMs) can learn new abilities without directly being trained on them. However, LLMs have been known to \"hallucinate\" when tasked with providing responses for questions they have not been trained on. This is partly because LLMs are unaware of events after training. It is also very difficult to trace the sources from which LLMs draw their responses from. For reliable, scalable applications, it is important that an LLM provides responses that are grounded in facts and is able to cite its information sources.\n\nA common approach used to overcome these constraints is called Retrieval Augmented Generation (RAG), which augments the prompt sent to an LLM with relevant data retrieved from an external knowledge base through an Information Retrieval (IR) mechanism. The knowledge base can be your own corpora of documents, databases, or APIs.\n\nThis notebook walks you through a workflow to improve an LLM's response by augmenting its knowledge with external text corpora and performing semantic information retrieval to answer questions using the Semantic Retriever and the Attributed Question & Answering (AQA) APIs of the Generative Language API.\n\nNote: This API is currently in beta and is only available in certain regions.\nSetup\nImport the Generative Language API\n# Install the Client library (Semantic Retriever is only supported for versions >0.4.0)\npip install -U google.ai.generativelanguage\n\nAuthenticate\n\nThe Semantic Retriever API lets you perform semantic search on your own data. Since it's your data, this needs stricter access controls than API keys. Authenticate with OAuth with service accounts or through your user credentials.\n\nThis quickstart uses a simplified authentication approach meant for a testing environment, and service account setups are typically easier to start from. For a production environment, learn about authentication and authorization before choosing the access credentials that are appropriate for your app.\n\nSetup OAuth using service accounts\n\nFollow the steps below to setup OAuth using service accounts:\n\nEnable the Generative Language API.\n\nCreate the Service Account by following the documentation.\n\nAfter creating the service account, generate a service account key.\n\nUpload your service account file by using the file icon on the left sidebar, then the upload icon, as shown in the screenshot below.\n\nRename the uploaded file to service_account_key.json or change the variable service_account_file_name in the code below.\n\npip install -U google-auth-oauthlib\n\nservice_account_file_name = 'service_account_key.json'\n\nfrom google.oauth2 import service_account\n\ncredentials = service_account.Credentials.from_service_account_file(service_account_file_name)\n\nscoped_credentials = credentials.with_scopes(\n    ['https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/generative-language.retriever'])\n\n\nInitialize the client library using the service account credentials.\n\nimport google.ai.generativelanguage as glm\ngenerative_service_client = glm.GenerativeServiceClient(credentials=scoped_credentials)\nretriever_service_client = glm.RetrieverServiceClient(credentials=scoped_credentials)\npermission_service_client = glm.PermissionServiceClient(credentials=scoped_credentials)\n\nCreate a corpus\n\nThe Semantic Retriever API lets you define up to 5 custom text corpora per project. You can specify either of the following fields while defining your corpora:\n\nname: The Corpus resource name (ID). Must contain only a maximum of 40 alphanumeric characters. If the name is empty on creation, a unique name will be generated with a maximum length of 40 characters with a prefix from the display_name and a 12 character random suffix.\ndisplay_name: The human-readable display name for the Corpus. Must contain only a maximum of 512 characters, including alphanumerics, spaces, and dashes.\nexample_corpus = glm.Corpus(display_name=\"Google for Developers Blog\")\ncreate_corpus_request = glm.CreateCorpusRequest(corpus=example_corpus)\n\n# Make the request\ncreate_corpus_response = retriever_service_client.create_corpus(create_corpus_request)\n\n# Set the `corpus_resource_name` for subsequent sections.\ncorpus_resource_name = create_corpus_response.name\nprint(create_corpus_response)\n\nname: \"corpora/google-for-developers-blog-dqrtz8rs0jg\"\ndisplay_name: \"Google for Developers Blog\"\ncreate_time {\n  seconds: 1713497533\n  nanos: 587977000\n}\nupdate_time {\n  seconds: 1713497533\n  nanos: 587977000\n}\n\nGet the created corpus\n\nUse the GetCorpusRequest method to programmatically access the Corpus you created above. The value of the name parameter refers to the full resource name of the Corpus and is set in the cell above as corpus_resource_name. The expected format is corpora/corpus-123.\n\nget_corpus_request = glm.GetCorpusRequest(name=corpus_resource_name)\n\n# Make the request\nget_corpus_response = retriever_service_client.get_corpus(get_corpus_request)\n\n# Print the response\nprint(get_corpus_response)\n\nCreate a document\n\nA Corpus can contain up to 10,000 Documents. You can specify either of the following fields while defining your documents:\n\nname: The Document resource name (ID). Must contain only a maximum of 40 characters (alphanumeric or dashes only). The ID cannot start or end with a dash. If the name is empty on creation, a unique name will be derived from display_name along with a 12 character random suffix.\ndisplay_name: The human-readable display name. Must contain only a maximum of 512 characters, including alphanumerics, spaces, and dashes.\n\nDocuments also support up to 20 user-specified custom_metadata fields, specified as key-value pairs. Custom metadata can be strings, lists of strings, or numeric. Note that lists of strings can support a maximum of 10 values and numeric values are represented as floating-point numbers in the API.\n\n# Create a document with a custom display name.\nexample_document = glm.Document(display_name=\"Introducing Project IDX, An Experiment to Improve Full-stack, Multiplatform App Development\")\n\n# Add metadata.\n# Metadata also supports numeric values not specified here\ndocument_metadata = [\n    glm.CustomMetadata(key=\"url\", string_value=\"https://developers.googleblog.com/2023/08/introducing-project-idx-experiment-to-improve-full-stack-multiplatform-app-development.html\")]\nexample_document.custom_metadata.extend(document_metadata)\n\n# Make the request\n# corpus_resource_name is a variable set in the \"Create a corpus\" section.\ncreate_document_request = glm.CreateDocumentRequest(parent=corpus_resource_name, document=example_document)\ncreate_document_response = retriever_service_client.create_document(create_document_request)\n\n# Set the `document_resource_name` for subsequent sections.\ndocument_resource_name = create_document_response.name\nprint(create_document_response)\n\nGet the created document\n\nUse the GetDocumentRequest method to programmatically access the document you created above. The value of the name parameter refers to the full resource name of the document and is set in the cell above as document_resource_name. The expected format is corpora/corpus-123/documents/document-123.\n\nget_document_request = glm.GetDocumentRequest(name=document_resource_name)\n\n# Make the request\n# document_resource_name is a variable set in the \"Create a document\" section.\nget_document_response = retriever_service_client.get_document(get_document_request)\n\n# Print the response\nprint(get_document_response)\n\nIngest & Chunk a Document\n\nTo improve the relevance of content returned by the vector database during semantic retrieval, break down large documents into smaller pieces or chunks while ingesting the document.\n\nA Chunk is a subpart of a Document that is treated as an independent unit for the purposes of vector representation and storage. A Chunk can have a maximum of 2043 tokens. A Corpus can have a maximum of 1 million Chunks.\n\nSimilar to Documents, Chunks also support up to 20 user-specified custom_metadata fields, specified as key-value pairs. Custom metadata can be strings, lists of strings, or numeric. Note that lists of strings can support a maximum of 10 values and numeric values are represented as floating-point numbers in the API.\n\nThis guide uses Google's Open Source HtmlChunker.\n\nOther chunkers you can use include LangChain or LlamaIndex.\n\nIngest HTML and chunk via HtmlChunker\n!pip install google-labs-html-chunker\n\nfrom google_labs_html_chunker.html_chunker import HtmlChunker\n\nfrom urllib.request import urlopen\n\n\nGet the HTML DOM for a website. Here, the HTML is read directly, but it would be better to get HTML post-rendering to include Javascript-injected HTML such as document.documentElement.innerHTML.\n\nwith(urlopen(\"https://developers.googleblog.com/2023/08/introducing-project-idx-experiment-to-improve-full-stack-multiplatform-app-development.html\")) as f:\n  html = f.read().decode(\"utf-8\")\n\n\nBreak down the text document into passages and create Chunks from these passages. This step creates the Chunk objects themselves and the next section uploads them to the Semantic Retriever API.\n\n# Chunk the file using HtmlChunker\nchunker = HtmlChunker(\n    max_words_per_aggregate_passage=200,\n    greedily_aggregate_sibling_nodes=True,\n    html_tags_to_exclude={\"noscript\", \"script\", \"style\"},\n)\npassages = chunker.chunk(html)\nprint(passages)\n\n\n# Create `Chunk` entities.\nchunks = []\nfor passage in passages:\n    chunk = glm.Chunk(data={'string_value': passage})\n    # Optionally, you can add metadata to a chunk\n    chunk.custom_metadata.append(glm.CustomMetadata(key=\"tags\",\n                                                    string_list_value=glm.StringList(\n                                                        values=[\"Google For Developers\", \"Project IDX\", \"Blog\", \"Announcement\"])))\n    chunk.custom_metadata.append(glm.CustomMetadata(key=\"chunking_strategy\",\n                                                    string_value=\"greedily_aggregate_sibling_nodes\"))\n    chunk.custom_metadata.append(glm.CustomMetadata(key = \"publish_date\",\n                                                    numeric_value = 20230808))\n    chunks.append(chunk)\nprint(chunks)\n\nBatch create chunks\n\nCreate chunks in batches. You can specify a maximum of 100 chunks per batch request.\n\nUse CreateChunk() for single chunk creation.\n\n# Option 1: Use HtmlChunker in the section above.\n# `chunks` is the variable set from the section above.\ncreate_chunk_requests = []\nfor chunk in chunks:\n  create_chunk_requests.append(glm.CreateChunkRequest(parent=document_resource_name, chunk=chunk))\n\n# Make the request\nrequest = glm.BatchCreateChunksRequest(parent=document_resource_name, requests=create_chunk_requests)\nresponse = retriever_service_client.batch_create_chunks(request)\nprint(response)\n\n\nAlternatively, you can make chunks without using the HtmlChunker.\n\n# Add up to 100 CreateChunk requests per batch request.\n# document_resource_name is a variable set in the \"Create a document\" section.\nchunks = []\nchunk_1 = glm.Chunk(data={'string_value': \"Chunks support user specified metadata.\"})\nchunk_1.custom_metadata.append(glm.CustomMetadata(key=\"section\",\n                                                  string_value=\"Custom metadata filters\"))\nchunk_2 = glm.Chunk(data={'string_value': \"The maximum number of metadata supported is 20\"})\nchunk_2.custom_metadata.append(glm.CustomMetadata(key = \"num_keys\",\n                                                  numeric_value = 20))\nchunks = [chunk_1, chunk_2]\ncreate_chunk_requests = []\nfor chunk in chunks:\n  create_chunk_requests.append(glm.CreateChunkRequest(parent=document_resource_name, chunk=chunk))\n\n# Make the request\nrequest = glm.BatchCreateChunksRequest(parent=document_resource_name, requests=create_chunk_requests)\nresponse = retriever_service_client.batch_create_chunks(request)\nprint(response)\n\nList Chunks and get state\n\nUse the ListChunksRequest method to get all available Chunks as a paginated list with a maximum size limit of 100 Chunks per page, sorted in ascending order of Chunk.create_time. If you do not specify a limit, a maximum of 10 Chunks are returned.\n\nProvide the next_page_token returned in the ListChunksRequest response as an argument to the next request to retrieve the next page. Note that when paginating, all other parameters provided to ListChunks must match the call that provided the page token.\n\nAll Chunks return a state. Use this to check the state of the Chunks before querying a Corpus. Chunk states include - UNSPECIFIED, PENDING_PROCESSING, ACTIVE, and FAILED. You can only query ACTIVE Chunks.\n\n# Make the request\nrequest = glm.ListChunksRequest(parent=document_resource_name)\nlist_chunks_response = retriever_service_client.list_chunks(request)\nfor index, chunks in enumerate(list_chunks_response.chunks):\n  print(f'\\nChunk # {index + 1}')\n  print(f'Resource Name: {chunks.name}')\n  # Only ACTIVE chunks can be queried.\n  print(f'State: {glm.Chunk.State(chunks.state).name}')\n\nIngest another document\n\nAdd another Document via HtmlChunker and add filters.\n\n# Create a document with a custom display name.\nexample_document = glm.Document(display_name=\"How it’s Made: Interacting with Gemini through multimodal prompting\")\n\n# Add document metadata.\n# Metadata also supports numeric values not specified here\ndocument_metadata = [\n    glm.CustomMetadata(key=\"url\", string_value=\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html\")]\nexample_document.custom_metadata.extend(document_metadata)\n\n# Make the CreateDocument request\n# corpus_resource_name is a variable set in the \"Create a corpus\" section.\ncreate_document_request = glm.CreateDocumentRequest(parent=corpus_resource_name, document=example_document)\ncreate_document_response = retriever_service_client.create_document(create_document_request)\n\n# Set the `document_resource_name` for subsequent sections.\ndocument_resource_name = create_document_response.name\nprint(create_document_response)\n\n# Chunks - add another webpage from Google for Developers\nwith(urlopen(\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html\")) as f:\n  html = f.read().decode(\"utf-8\")\n\n# Chunk the file using HtmlChunker\nchunker = HtmlChunker(\n    max_words_per_aggregate_passage=100,\n    greedily_aggregate_sibling_nodes=False,\n)\npassages = chunker.chunk(html)\n\n# Create `Chunk` entities.\nchunks = []\nfor passage in passages:\n    chunk = glm.Chunk(data={'string_value': passage})\n    chunk.custom_metadata.append(glm.CustomMetadata(key=\"tags\",\n                                                    string_list_value=glm.StringList(\n                                                        values=[\"Google For Developers\", \"Gemini API\", \"Blog\", \"Announcement\"])))\n    chunk.custom_metadata.append(glm.CustomMetadata(key=\"chunking_strategy\",\n                                                    string_value=\"no_aggregate_sibling_nodes\"))\n    chunk.custom_metadata.append(glm.CustomMetadata(key = \"publish_date\",\n                                                    numeric_value = 20231206))\n    chunks.append(chunk)\n\n# Make the request\ncreate_chunk_requests = []\nfor chunk in chunks:\n  create_chunk_requests.append(glm.CreateChunkRequest(parent=document_resource_name, chunk=chunk))\nrequest = glm.BatchCreateChunksRequest(parent=document_resource_name, requests=create_chunk_requests)\nresponse = retriever_service_client.batch_create_chunks(request)\nprint(response)\n\nQuery the corpus\n\nUse the QueryCorpusRequest method to perform semantic search to get relevant passages.\n\nresults_count: Specify the number of passages to return. Maximum is 100. If unspecified, the API returns a maximum of 10 Chunks.\nmetadata_filters: Filter by chunk_metadata or document_metadata. Each MetadataFilter needs to correspond to a unique key. Multiple MetadataFilter objects are joined by logical ANDs. Similar metadata filter conditions are joined by logical ORs. Some examples:\n(year >= 2020 OR year < 2010) AND (genre = drama OR genre = action)\n\nmetadata_filter = [\n  {\n    key = \"document.custom_metadata.year\"\n    conditions = [\n      {int_value = 2020, operation = GREATER_EQUAL},\n      {int_value = 2010, operation = LESS}]\n  },\n  {\n    key = \"document.custom_metadata.genre\"\n    conditions = [\n      {string_value = \"drama\", operation = EQUAL},\n      {string_value = \"action\", operation = EQUAL} }]\n  }]\n\n\nNote that only numeric values support \"AND\"s for the same key. String values only support \"OR\"s for the same key.\n\n(\"Google for Developers\" in tags) and (20230314 > publish_date)\n\nmetadata_filter = [\n {\n    key = \"chunk.custom_metadata.tags\"\n    conditions = [\n    {string_value = 'Google for Developers', operation = INCLUDES},\n  },\n  {\n    key = \"chunk.custom_metadata.publish_date\"\n    conditions = [\n    {numeric_value = 20230314, operation = GREATER_EQUAL}]\n  }]\n\nuser_query = \"What is the purpose of Project IDX?\"\nresults_count = 5\n\n# Add metadata filters for both chunk and document.\nchunk_metadata_filter = glm.MetadataFilter(key='chunk.custom_metadata.tags',\n                                           conditions=[glm.Condition(\n                                              string_value='Google For Developers',\n                                              operation=glm.Condition.Operator.INCLUDES)])\n\n# Make the request\n# corpus_resource_name is a variable set in the \"Create a corpus\" section.\nrequest = glm.QueryCorpusRequest(name=corpus_resource_name,\n                                 query=user_query,\n                                 results_count=results_count,\n                                 metadata_filters=[chunk_metadata_filter])\nquery_corpus_response = retriever_service_client.query_corpus(request)\nprint(query_corpus_response)\n\nAttributed Question-Answering\n\nUse the GenerateAnswer method to perform Attributed Question-Answering over your document, corpus, or a set of passages.\n\nAttributed Question-Answering (AQA) refers to answering questions grounded to a given context and providing attributions(s), while minimizing hallucination.\n\nGenerateAnswer provides several advantages over using an untuned LLM, in cases where AQA is desired:\n\nThe underlying model has been trained to return only answers that are grounded in the supplied context.\nIt identifies attributions (segments of the supplied context that contributed to the answer). Attributions enable the user to verify the answer.\nIt estimates the answerable_probability for a given (question, context) pair, which further empowers you to divert product behavior depending on how likely the returned answer is to be grounded and correct.\nNote: AQA currently only supports queries in English.\nanswerable_probability and the “I don’t know” problem\n\nIn some instances, the best response to the question is in fact “I don’t know”. For example, if the provided context does not contain the answer to the question, then the question is considered to be “unanswerable”.\n\nThe AQA model is highly adept at recognizing such cases. It can even distinguish between degrees of answerability and unanswerability.\n\nHowever, the GenerateAnswer API puts the final decision-making power in your hands by:\n\nAlways attempting to return a grounded answer - even when that answer is relatively unlikely to be grounded and correct.\nReturning a value answerable_probability - The model's estimate of the probability that the answer is grounded and correct.\n\nA low answerable_probability may be explained by 1 or more of the following factors:\n\nThe model is not confident that its answer is correct.\nThe model is not confident that its answer is grounded in the cited passages; The answer may be derived instead from world knowledge. For example: question=\"1+1=?\", passages=[\"2+2=4”] → answer=2, answerable_probability=0.02\nThe model provided relevant information that did not completely answer the question. Example: question=\"Is it available in my size?, passages=[\"Available in sizes 5-11\"] → answer=\"Yes it is available in sizes 5-11\", answerable_probability=0.03\"\nNo well-formed question was asked in the GenerateAnswerRequest.\n\nSince a low answerable_probability indicates that the GenerateAnswerResponse.answer is likely wrong or ungrounded, it is highly recommended to further process the response by inspecting answerable_probability.\n\nWhen answerable_probability is low, some clients may wish to:\n\nDisplay a message to the effect of \"couldn't answer that question\" to the end user.\nFall back to a general-purpose LLM that answers the question from world knowledge. The threshold and nature of such fallbacks will depend on individual use cases. A value of answerable_probability <= 0.5 is a good starting threshold.\nAQA Helpful Tips\n\nFor full API specifications, refer to the GenerateAnswerRequest API Reference.\n\nPassage length: Up to 300 tokens per passage are recommended.\nPassage sorting:\nIf you provide GenerateAnswerRequest.inline_passages, the passages should be sorted in decreasing order of relevance to the query. If the model's context length limit is exceeded, the last (least-relevant) passages will be omitted.\nIf you provide GenerateAnswerRequest.semantic_retriever, then relevance sorting will be done automatically for you.\nLimitations: The AQA model is specialized for question-answering. For other use cases such as creative writing, summarization, etc., please call a general-purpose model via GenerateContent.\nChat: If the user input is known to be a question that may be answerable from a certain context, then AQA can answer chat queries. But if user input may be any type of entry, then a general-purpose model may be a better choice.\nTemperature:\nGenerally, a relatively low (~0.2) temperature is recommended for accurate AQA.\nIf your use case relies on deterministic outputs, then set temperature=0.\nuser_query = \"What is the purpose of Project IDX?\"\nanswer_style = \"ABSTRACTIVE\" # Or VERBOSE, EXTRACTIVE\nMODEL_NAME = \"models/aqa\"\n\n# Make the request\n# corpus_resource_name is a variable set in the \"Create a corpus\" section.\ncontent = glm.Content(parts=[glm.Part(text=user_query)])\nretriever_config = glm.SemanticRetrieverConfig(source=corpus_resource_name, query=content)\nreq = glm.GenerateAnswerRequest(model=MODEL_NAME,\n                                contents=[content],\n                                semantic_retriever=retriever_config,\n                                answer_style=answer_style)\naqa_response = generative_service_client.generate_answer(req)\nprint(aqa_response)\n\n# Get the metadata from the first attributed passages for the source\nchunk_resource_name = aqa_response.answer.grounding_attributions[0].source_id.semantic_retriever_chunk.chunk\nget_chunk_response = retriever_service_client.get_chunk(name=chunk_resource_name)\nprint(get_chunk_response)\n\nMore Options: AQA Using Inline Passages\n\nAlternatively, you can use the AQA endpoint directly, without using the Semantic Retriever API by passing inline_passages.\n\nuser_query = \"What is AQA from Google?\"\nuser_query_content = glm.Content(parts=[glm.Part(text=user_query)])\nanswer_style = \"VERBOSE\" # or ABSTRACTIVE, EXTRACTIVE\nMODEL_NAME = \"models/aqa\"\n\n# Create the grounding inline passages\ngrounding_passages = glm.GroundingPassages()\npassage_a = glm.Content(parts=[glm.Part(text=\"Attributed Question and Answering (AQA) refers to answering questions grounded to a given corpus and providing citation\")])\ngrounding_passages.passages.append(glm.GroundingPassage(content=passage_a, id=\"001\"))\npassage_b = glm.Content(parts=[glm.Part(text=\"An LLM is not designed to generate content grounded in a set of passages. Although instructing an LLM to answer questions only based on a set of passages reduces hallucination, hallucination still often occurs when LLMs generate responses unsupported by facts provided by passages\")])\ngrounding_passages.passages.append(glm.GroundingPassage(content=passage_b, id=\"002\"))\npassage_c = glm.Content(parts=[glm.Part(text=\"Hallucination is one of the biggest problems in Large Language Models (LLM) development. Large Language Models (LLMs) could produce responses that are fictitious and incorrect, which significantly impacts the usefulness and trustworthiness of applications built with language models.\")])\ngrounding_passages.passages.append(glm.GroundingPassage(content=passage_c, id=\"003\"))\n\n# Create the request\nreq = glm.GenerateAnswerRequest(model=MODEL_NAME,\n                                contents=[user_query_content],\n                                inline_passages=grounding_passages,\n                                answer_style=answer_style)\naqa_response = generative_service_client.generate_answer(req)\nprint(aqa_response)\n\nShare the corpus\n\nYou can choose to share the corpus with others using the CreatePermissionRequest API.\n\nConstraints:\n\nThere are 2 roles for sharing: READER and EDITOR.\nA READER can query the corpus.\nA WRITER has reader's permissions and additionally can edit and share the corpus.\nA corpus can be public by granting EVERYONE as user_type read access.\n# Replace your-email@gmail.com with the email added as a test user in the OAuth Quickstart\nshared_user_email = \"TODO-your-email@gmail.com\" #  @param {type:\"string\"}\nuser_type = \"USER\"\nrole = \"READER\"\n\n# Make the request\n# corpus_resource_name is a variable set in the \"Create a corpus\" section.\nrequest = glm.CreatePermissionRequest(\n    parent=corpus_resource_name,\n    permission=glm.Permission(grantee_type=user_type,\n                              email_address=shared_user_email,\n                              role=role))\ncreate_permission_response = permission_service_client.create_permission(request)\nprint(create_permission_response)\n\nDelete the corpus\n\nUse DeleteCorpusRequest to delete a user corpus and all associated Documents & Chunks.\n\nNote that non-empty corpora will throw an error without specifying an force=True flag. If you set force=True, any Chunks and objects related to this Document will also be deleted.\n\nIf force=False (the default) and the Document contains any Chunks, a FAILED_PRECONDITION error will be returned.\n\n# Set force to False if you don't want to delete non-empty corpora.\nreq = glm.DeleteCorpusRequest(name=corpus_resource_name, force=True)\ndelete_corpus_response = retriever_service_client.delete_corpus(req)\nprint(\"Successfully deleted corpus: \" + corpus_resource_name)\n\nSummary and further reading\n\nThis guide introduced the Semantic Retriever and Attributed Question & Answering (AQA) APIs of the Generative Language API and showed how you can use it to perform semantic information retrieval on your custom text data. Note that this API also works with the LlamaIndex data framework. Refer to the tutorial to learn more.\n\nAlso refer to the API docs to learn more about the other available functionalities.\n\nAppendix: Setup OAuth with user credentials\n\nFollow the steps below from the OAuth Quickstart to setup OAuth authentication.\n\nConfigure the OAuth consent screen.\n\nAuthorize credentials for a desktop application. To run this notebook in Colab, first rename your credential file (usually client_secret_*.json) to just client_secret.json. Then upload the file by using the file icon on the left sidebar, then the upload icon, as shown in the screenshot below.\n\n# Replace TODO-your-project-name with the project used in the OAuth Quickstart\nproject_name = \"TODO-your-project-name\" #  @param {type:\"string\"}\n# Replace TODO-your-email@gmail.com with the email added as a test user in the OAuth Quickstart\nemail = \"TODO-your-email@gmail.com\" #  @param {type:\"string\"}\n# Rename the uploaded file to `client_secret.json` OR\n# Change the variable `client_file_name` in the code below.\nclient_file_name = \"client_secret.json\"\n\n# IMPORTANT: Follow the instructions from the output - you must copy the command\n# to your terminal and copy the output after authentication back here.\n!gcloud config set project $project_name\n!gcloud config set account $email\n\n# NOTE: The simplified project setup in this tutorial triggers a \"Google hasn't verified this app.\" dialog.\n# This is normal, click \"Advanced\" -> \"Go to [app name] (unsafe)\"\n!gcloud auth application-default login --no-browser --client-id-file=$client_file_name --scopes=\"https://www.googleapis.com/auth/generative-language.retriever,https://www.googleapis.com/auth/cloud-platform\"\n\n\nInitialize the client library and re-run the notebook starting from Create a corpus.\n\nimport google.ai.generativelanguage as glm\n\ngenerative_service_client = glm.GenerativeServiceClient()\nretriever_service_client = glm.RetrieverServiceClient()\npermission_service_client = glm.PermissionServiceClient()\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 3515,
            "filtered_content": "Get started with semantic retrieval \nLarge Language Models (LLMs) can learn new abilities without directly being trained on them. However, LLMs have been known to \"hallucinate\" when tasked with providing responses for questions they have not been trained on. This is partly because LLMs are unaware of events after training. It is also very difficult to trace the sources from which LLMs draw their responses from. For reliable, scalable applications, it is important that an LLM provides responses that are grounded in facts and is able to cite its information sources.\nA common approach used to overcome these constraints is called Retrieval Augmented Generation (RAG), which augments the prompt sent to an LLM with relevant data retrieved from an external knowledge base through an Information Retrieval (IR) mechanism. The knowledge base can be your own corpora of documents, databases, or APIs.\nThis notebook walks you through a workflow to improve an LLM's response by augmenting its knowledge with external text corpora and performing semantic information retrieval to answer questions using the Semantic Retriever and the Attributed Question & Answering (AQA) APIs of the Generative Language API.\nNote: This API is currently in beta and is only available in certain regions.\n# Install the Client library (Semantic Retriever is only supported for versions >0.4.0)\npip install -U google.ai.generativelanguage\nThe Semantic Retriever API lets you perform semantic search on your own data. Since it's your data, this needs stricter access controls than API keys. Authenticate with OAuth with service accounts or through your user credentials.\nThis quickstart uses a simplified authentication approach meant for a testing environment, and service account setups are typically easier to start from. For a production environment, learn about authentication and authorization before choosing the access credentials that are appropriate for your app.\nFollow the steps below to setup OAuth using service accounts:\nEnable the Generative Language API.\nCreate the Service Account by following the documentation.\nAfter creating the service account, generate a service account key.\nUpload your service account file by using the file icon on the left sidebar, then the upload icon, as shown in the screenshot below.\nRename the uploaded file to service_account_key.json or change the variable service_account_file_name in the code below.\npip install -U google-auth-oauthlib\nservice_account_file_name = 'service_account_key.json'\nfrom google.oauth2 import service_account\ncredentials = service_account.Credentials.from_service_account_file(service_account_file_name)\nscoped_credentials = credentials.with_scopes(\n    ['https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/generative-language.retriever'])\nInitialize the client library using the service account credentials.\ngenerative_service_client = glm.GenerativeServiceClient(credentials=scoped_credentials)\nretriever_service_client = glm.RetrieverServiceClient(credentials=scoped_credentials)\npermission_service_client = glm.PermissionServiceClient(credentials=scoped_credentials)\nThe Semantic Retriever API lets you define up to 5 custom text corpora per project. You can specify either of the following fields while defining your corpora:\nname: The Corpus resource name (ID). Must contain only a maximum of 40 alphanumeric characters. If the name is empty on creation, a unique name will be generated with a maximum length of 40 characters with a prefix from the display_name and a 12 character random suffix.\ndisplay_name: The human-readable display name for the Corpus. Must contain only a maximum of 512 characters, including alphanumerics, spaces, and dashes.\nexample_corpus = glm.Corpus(display_name=\"Google for Developers Blog\")\ncreate_corpus_request = glm.CreateCorpusRequest(corpus=example_corpus)\ncreate_corpus_response = retriever_service_client.create_corpus(create_corpus_request)\n# Set the `corpus_resource_name` for subsequent sections.\ncorpus_resource_name = create_corpus_response.name\nprint(create_corpus_response)\nname: \"corpora/google-for-developers-blog-dqrtz8rs0jg\"\ndisplay_name: \"Google for Developers Blog\"\ncreate_time {\nupdate_time {\nUse the GetCorpusRequest method to programmatically access the Corpus you created above. The value of the name parameter refers to the full resource name of the Corpus and is set in the cell above as corpus_resource_name. The expected format is corpora/corpus-123.\nget_corpus_request = glm.GetCorpusRequest(name=corpus_resource_name)\nget_corpus_response = retriever_service_client.get_corpus(get_corpus_request)\nprint(get_corpus_response)\nA Corpus can contain up to 10,000 Documents. You can specify either of the following fields while defining your documents:\nname: The Document resource name (ID). Must contain only a maximum of 40 characters (alphanumeric or dashes only). The ID cannot start or end with a dash. If the name is empty on creation, a unique name will be derived from display_name along with a 12 character random suffix.\ndisplay_name: The human-readable display name. Must contain only a maximum of 512 characters, including alphanumerics, spaces, and dashes.\nDocuments also support up to 20 user-specified custom_metadata fields, specified as key-value pairs. Custom metadata can be strings, lists of strings, or numeric. Note that lists of strings can support a maximum of 10 values and numeric values are represented as floating-point numbers in the API.\nexample_document = glm.Document(display_name=\"Introducing Project IDX, An Experiment to Improve Full-stack, Multiplatform App Development\")\n# Add metadata.\n    glm.CustomMetadata(key=\"url\", string_value=\"https://developers.googleblog.com/2023/08/introducing-project-idx-experiment-to-improve-full-stack-multiplatform-app-development.html\")]\nUse the GetDocumentRequest method to programmatically access the document you created above. The value of the name parameter refers to the full resource name of the document and is set in the cell above as document_resource_name. The expected format is corpora/corpus-123/documents/document-123.\nget_document_request = glm.GetDocumentRequest(name=document_resource_name)\nget_document_response = retriever_service_client.get_document(get_document_request)\nprint(get_document_response)\nTo improve the relevance of content returned by the vector database during semantic retrieval, break down large documents into smaller pieces or chunks while ingesting the document.\nA Chunk is a subpart of a Document that is treated as an independent unit for the purposes of vector representation and storage. A Chunk can have a maximum of 2043 tokens. A Corpus can have a maximum of 1 million Chunks.\nSimilar to Documents, Chunks also support up to 20 user-specified custom_metadata fields, specified as key-value pairs. Custom metadata can be strings, lists of strings, or numeric. Note that lists of strings can support a maximum of 10 values and numeric values are represented as floating-point numbers in the API.\nThis guide uses Google's Open Source HtmlChunker.\nOther chunkers you can use include LangChain or LlamaIndex.\n!pip install google-labs-html-chunker\nfrom google_labs_html_chunker.html_chunker import HtmlChunker\nfrom urllib.request import urlopen\nGet the HTML DOM for a website. Here, the HTML is read directly, but it would be better to get HTML post-rendering to include Javascript-injected HTML such as document.documentElement.innerHTML.\nwith(urlopen(\"https://developers.googleblog.com/2023/08/introducing-project-idx-experiment-to-improve-full-stack-multiplatform-app-development.html\")) as f:\nBreak down the text document into passages and create Chunks from these passages. This step creates the Chunk objects themselves and the next section uploads them to the Semantic Retriever API.\n    max_words_per_aggregate_passage=200,\n    greedily_aggregate_sibling_nodes=True,\n    html_tags_to_exclude={\"noscript\", \"script\", \"style\"},\nprint(passages)\n    # Optionally, you can add metadata to a chunk\n                                                        values=[\"Google For Developers\", \"Project IDX\", \"Blog\", \"Announcement\"])))\n                                                    string_value=\"greedily_aggregate_sibling_nodes\"))\n                                                    numeric_value = 20230808))\nprint(chunks)\nCreate chunks in batches. You can specify a maximum of 100 chunks per batch request.\nUse CreateChunk() for single chunk creation.\n# Option 1: Use HtmlChunker in the section above.\n# `chunks` is the variable set from the section above.\nAlternatively, you can make chunks without using the HtmlChunker.\n# Add up to 100 CreateChunk requests per batch request.\nchunk_1 = glm.Chunk(data={'string_value': \"Chunks support user specified metadata.\"})\nchunk_1.custom_metadata.append(glm.CustomMetadata(key=\"section\",\n                                                  string_value=\"Custom metadata filters\"))\nchunk_2 = glm.Chunk(data={'string_value': \"The maximum number of metadata supported is 20\"})\nchunk_2.custom_metadata.append(glm.CustomMetadata(key = \"num_keys\",\n                                                  numeric_value = 20))\nchunks = [chunk_1, chunk_2]\nUse the ListChunksRequest method to get all available Chunks as a paginated list with a maximum size limit of 100 Chunks per page, sorted in ascending order of Chunk.create_time. If you do not specify a limit, a maximum of 10 Chunks are returned.\nProvide the next_page_token returned in the ListChunksRequest response as an argument to the next request to retrieve the next page. Note that when paginating, all other parameters provided to ListChunks must match the call that provided the page token.\nAll Chunks return a state. Use this to check the state of the Chunks before querying a Corpus. Chunk states include - UNSPECIFIED, PENDING_PROCESSING, ACTIVE, and FAILED. You can only query ACTIVE Chunks.\nrequest = glm.ListChunksRequest(parent=document_resource_name)\nlist_chunks_response = retriever_service_client.list_chunks(request)\nfor index, chunks in enumerate(list_chunks_response.chunks):\n  print(f'\\nChunk # {index + 1}')\n  print(f'Resource Name: {chunks.name}')\n  # Only ACTIVE chunks can be queried.\n  print(f'State: {glm.Chunk.State(chunks.state).name}')\nAdd another Document via HtmlChunker and add filters.\nexample_document = glm.Document(display_name=\"How it’s Made: Interacting with Gemini through multimodal prompting\")\n# Add document metadata.\n    glm.CustomMetadata(key=\"url\", string_value=\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html\")]\n# Make the CreateDocument request\n# Chunks - add another webpage from Google for Developers\nwith(urlopen(\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html\")) as f:\n    max_words_per_aggregate_passage=100,\n    greedily_aggregate_sibling_nodes=False,\n                                                        values=[\"Google For Developers\", \"Gemini API\", \"Blog\", \"Announcement\"])))\n                                                    string_value=\"no_aggregate_sibling_nodes\"))\n                                                    numeric_value = 20231206))\nUse the QueryCorpusRequest method to perform semantic search to get relevant passages.\nresults_count: Specify the number of passages to return. Maximum is 100. If unspecified, the API returns a maximum of 10 Chunks.\nmetadata_filters: Filter by chunk_metadata or document_metadata. Each MetadataFilter needs to correspond to a unique key. Multiple MetadataFilter objects are joined by logical ANDs. Similar metadata filter conditions are joined by logical ORs. Some examples:\n(year >= 2020 OR year < 2010) AND (genre = drama OR genre = action)\n    key = \"document.custom_metadata.year\"\n      {int_value = 2020, operation = GREATER_EQUAL},\n      {int_value = 2010, operation = LESS}]\n    key = \"document.custom_metadata.genre\"\n      {string_value = \"drama\", operation = EQUAL},\n      {string_value = \"action\", operation = EQUAL} }]\nNote that only numeric values support \"AND\"s for the same key. String values only support \"OR\"s for the same key.\n(\"Google for Developers\" in tags) and (20230314 > publish_date)\n {\n    key = \"chunk.custom_metadata.tags\"\n    {string_value = 'Google for Developers', operation = INCLUDES},\n    key = \"chunk.custom_metadata.publish_date\"\n    {numeric_value = 20230314, operation = GREATER_EQUAL}]\nresults_count = 5\n# Add metadata filters for both chunk and document.\nchunk_metadata_filter = glm.MetadataFilter(key='chunk.custom_metadata.tags',\n                                           conditions=[glm.Condition(\n                                              string_value='Google For Developers',\n                                              operation=glm.Condition.Operator.INCLUDES)])\nrequest = glm.QueryCorpusRequest(name=corpus_resource_name,\n                                 query=user_query,\n                                 results_count=results_count,\n                                 metadata_filters=[chunk_metadata_filter])\nquery_corpus_response = retriever_service_client.query_corpus(request)\nprint(query_corpus_response)\nUse the GenerateAnswer method to perform Attributed Question-Answering over your document, corpus, or a set of passages.\nAttributed Question-Answering (AQA) refers to answering questions grounded to a given context and providing attributions(s), while minimizing hallucination.\nGenerateAnswer provides several advantages over using an untuned LLM, in cases where AQA is desired:\nThe underlying model has been trained to return only answers that are grounded in the supplied context.\nIt identifies attributions (segments of the supplied context that contributed to the answer). Attributions enable the user to verify the answer.\nIt estimates the answerable_probability for a given (question, context) pair, which further empowers you to divert product behavior depending on how likely the returned answer is to be grounded and correct.\nNote: AQA currently only supports queries in English.\nIn some instances, the best response to the question is in fact “I don’t know”. For example, if the provided context does not contain the answer to the question, then the question is considered to be “unanswerable”.\nThe AQA model is highly adept at recognizing such cases. It can even distinguish between degrees of answerability and unanswerability.\nHowever, the GenerateAnswer API puts the final decision-making power in your hands by:\nAlways attempting to return a grounded answer - even when that answer is relatively unlikely to be grounded and correct.\nReturning a value answerable_probability - The model's estimate of the probability that the answer is grounded and correct.\nA low answerable_probability may be explained by 1 or more of the following factors:\nThe model is not confident that its answer is correct.\nThe model is not confident that its answer is grounded in the cited passages; The answer may be derived instead from world knowledge. For example: question=\"1+1=?\", passages=[\"2+2=4”] → answer=2, answerable_probability=0.02\nThe model provided relevant information that did not completely answer the question. Example: question=\"Is it available in my size?, passages=[\"Available in sizes 5-11\"] → answer=\"Yes it is available in sizes 5-11\", answerable_probability=0.03\"\nNo well-formed question was asked in the GenerateAnswerRequest.\nSince a low answerable_probability indicates that the GenerateAnswerResponse.answer is likely wrong or ungrounded, it is highly recommended to further process the response by inspecting answerable_probability.\nWhen answerable_probability is low, some clients may wish to:\nDisplay a message to the effect of \"couldn't answer that question\" to the end user.\nFall back to a general-purpose LLM that answers the question from world knowledge. The threshold and nature of such fallbacks will depend on individual use cases. A value of answerable_probability <= 0.5 is a good starting threshold.\nFor full API specifications, refer to the GenerateAnswerRequest API Reference.\nPassage length: Up to 300 tokens per passage are recommended.\nPassage sorting:\nIf you provide GenerateAnswerRequest.inline_passages, the passages should be sorted in decreasing order of relevance to the query. If the model's context length limit is exceeded, the last (least-relevant) passages will be omitted.\nIf you provide GenerateAnswerRequest.semantic_retriever, then relevance sorting will be done automatically for you.\nLimitations: The AQA model is specialized for question-answering. For other use cases such as creative writing, summarization, etc., please call a general-purpose model via GenerateContent.\nChat: If the user input is known to be a question that may be answerable from a certain context, then AQA can answer chat queries. But if user input may be any type of entry, then a general-purpose model may be a better choice.\nTemperature:\nGenerally, a relatively low (~0.2) temperature is recommended for accurate AQA.\nIf your use case relies on deterministic outputs, then set temperature=0.\nanswer_style = \"ABSTRACTIVE\" # Or VERBOSE, EXTRACTIVE\ncontent = glm.Content(parts=[glm.Part(text=user_query)])\nretriever_config = glm.SemanticRetrieverConfig(source=corpus_resource_name, query=content)\n                                contents=[content],\n                                semantic_retriever=retriever_config,\n# Get the metadata from the first attributed passages for the source\nchunk_resource_name = aqa_response.answer.grounding_attributions[0].source_id.semantic_retriever_chunk.chunk\nget_chunk_response = retriever_service_client.get_chunk(name=chunk_resource_name)\nprint(get_chunk_response)\nAlternatively, you can use the AQA endpoint directly, without using the Semantic Retriever API by passing inline_passages.\nuser_query = \"What is AQA from Google?\"\nuser_query_content = glm.Content(parts=[glm.Part(text=user_query)])\nanswer_style = \"VERBOSE\" # or ABSTRACTIVE, EXTRACTIVE\n# Create the grounding inline passages\ngrounding_passages = glm.GroundingPassages()\npassage_a = glm.Content(parts=[glm.Part(text=\"Attributed Question and Answering (AQA) refers to answering questions grounded to a given corpus and providing citation\")])\ngrounding_passages.passages.append(glm.GroundingPassage(content=passage_a, id=\"001\"))\npassage_b = glm.Content(parts=[glm.Part(text=\"An LLM is not designed to generate content grounded in a set of passages. Although instructing an LLM to answer questions only based on a set of passages reduces hallucination, hallucination still often occurs when LLMs generate responses unsupported by facts provided by passages\")])\ngrounding_passages.passages.append(glm.GroundingPassage(content=passage_b, id=\"002\"))\npassage_c = glm.Content(parts=[glm.Part(text=\"Hallucination is one of the biggest problems in Large Language Models (LLM) development. Large Language Models (LLMs) could produce responses that are fictitious and incorrect, which significantly impacts the usefulness and trustworthiness of applications built with language models.\")])\ngrounding_passages.passages.append(glm.GroundingPassage(content=passage_c, id=\"003\"))\n# Create the request\n                                contents=[user_query_content],\n                                inline_passages=grounding_passages,\nYou can choose to share the corpus with others using the CreatePermissionRequest API.\nConstraints:\nThere are 2 roles for sharing: READER and EDITOR.\nA READER can query the corpus.\nA WRITER has reader's permissions and additionally can edit and share the corpus.\nA corpus can be public by granting EVERYONE as user_type read access.\n# Replace your-email@gmail.com with the email added as a test user in the OAuth Quickstart\nshared_user_email = \"TODO-your-email@gmail.com\" #  @param {type:\"string\"}\nuser_type = \"USER\"\nrole = \"READER\"\nrequest = glm.CreatePermissionRequest(\n    parent=corpus_resource_name,\n    permission=glm.Permission(grantee_type=user_type,\n                              email_address=shared_user_email,\n                              role=role))\ncreate_permission_response = permission_service_client.create_permission(request)\nprint(create_permission_response)\nUse DeleteCorpusRequest to delete a user corpus and all associated Documents & Chunks.\nNote that non-empty corpora will throw an error without specifying an force=True flag. If you set force=True, any Chunks and objects related to this Document will also be deleted.\nIf force=False (the default) and the Document contains any Chunks, a FAILED_PRECONDITION error will be returned.\n# Set force to False if you don't want to delete non-empty corpora.\nreq = glm.DeleteCorpusRequest(name=corpus_resource_name, force=True)\ndelete_corpus_response = retriever_service_client.delete_corpus(req)\nprint(\"Successfully deleted corpus: \" + corpus_resource_name)\nThis guide introduced the Semantic Retriever and Attributed Question & Answering (AQA) APIs of the Generative Language API and showed how you can use it to perform semantic information retrieval on your custom text data. Note that this API also works with the LlamaIndex data framework. Refer to the tutorial to learn more.\nAlso refer to the API docs to learn more about the other available functionalities.\nFollow the steps below from the OAuth Quickstart to setup OAuth authentication.\nConfigure the OAuth consent screen.\nAuthorize credentials for a desktop application. To run this notebook in Colab, first rename your credential file (usually client_secret_*.json) to just client_secret.json. Then upload the file by using the file icon on the left sidebar, then the upload icon, as shown in the screenshot below.\n# Replace TODO-your-project-name with the project used in the OAuth Quickstart\nproject_name = \"TODO-your-project-name\" #  @param {type:\"string\"}\n# Replace TODO-your-email@gmail.com with the email added as a test user in the OAuth Quickstart\nemail = \"TODO-your-email@gmail.com\" #  @param {type:\"string\"}\n# Rename the uploaded file to `client_secret.json` OR\n# Change the variable `client_file_name` in the code below.\nclient_file_name = \"client_secret.json\"\n# IMPORTANT: Follow the instructions from the output - you must copy the command\n# to your terminal and copy the output after authentication back here.\n!gcloud config set project $project_name\n!gcloud config set account $email\n# NOTE: The simplified project setup in this tutorial triggers a \"Google hasn't verified this app.\" dialog.\n# This is normal, click \"Advanced\" -> \"Go to [app name] (unsafe)\"\n!gcloud auth application-default login --no-browser --client-id-file=$client_file_name --scopes=\"https://www.googleapis.com/auth/generative-language.retriever,https://www.googleapis.com/auth/cloud-platform\"\nInitialize the client library and re-run the notebook starting from Create a corpus.\ngenerative_service_client = glm.GenerativeServiceClient()\nretriever_service_client = glm.RetrieverServiceClient()\npermission_service_client = glm.PermissionServiceClient()",
            "filtered_word_count": 2725
        },
        "https://ai.google.dev/gemini-api/docs/oauth": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nObjectives\nPrerequisites\nSet up your cloud project\n1. Enable the API\n2. Configure the OAuth consent screen\n3. Authorize credentials for a desktop application\nSet up application default credentials\nCurl\nPython\nNode.js\nNext steps\nManage credentials yourself [Python]\n1. Install the necessary libraries\n2. Write the credential manager\n3. Write your program\n4. Run your program\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nAuthentication with OAuth quickstart \nbookmark_border\n\nThe Gemini API lets you perform semantic retrieval on your own data. Since it's your data, this needs stricter access controls than API keys.\n\nThis quickstart uses a simplified authentication approach that is appropriate for a testing environment. For a production environment, learn about authentication and authorization before choosing the access credentials that are appropriate for your app.\n\nObjectives\nSet up your cloud project for OAuth\nSet up application-default-credentials\nManage credentials in your program instead of using gcloud auth\nPrerequisites\n\nTo run this quickstart, you need:\n\nA Google Cloud project\nA local installation of the gcloud CLI\nSet up your cloud project\n\nTo complete this quickstart, you first need to setup your Cloud project.\n\n1. Enable the API\n\nBefore using Google APIs, you need to turn them on in a Google Cloud project.\n\nIn the Google Cloud console, enable the Google Generative Language API.\n\n\nEnable the API\n\n2. Configure the OAuth consent screen\n\nNext configure the project's OAuth consent screen and add yourself as a test user. If you've already completed this step for your Cloud project, skip to the next section.\n\nIn the Google Cloud console, go to Menu > APIs & Services > OAuth consent screen.\n\nGo to OAuth consent screen\n\nSelect the user type External for your app, then click Create.\n\nComplete the app registration form (you can leave most fields blank), then click Save and Continue.\n\nFor now, you can skip adding scopes and click Save and Continue. In the future, when you create an app for use outside of your Google Workspace organization, you must add and verify the authorization scopes that your app requires.\n\nAdd test users:\n\nUnder Test users, click Add users.\nEnter your email address and any other authorized test users, then click Save and Continue.\n\nReview your app registration summary. To make changes, click Edit. If the app registration looks OK, click Back to Dashboard.\n\n3. Authorize credentials for a desktop application\n\nTo authenticate as an end user and access user data in your app, you need to create one or more OAuth 2.0 Client IDs. A client ID is used to identify a single app to Google's OAuth servers. If your app runs on multiple platforms, you must create a separate client ID for each platform.\n\nIn the Google Cloud console, go to Menu > APIs & Services > Credentials.\n\nGo to Credentials\n\nClick Create Credentials > OAuth client ID.\n\nClick Application type > Desktop app.\n\nIn the Name field, type a name for the credential. This name is only shown in the Google Cloud console.\n\nClick Create. The OAuth client created screen appears, showing your new Client ID and Client secret.\n\nClick OK. The newly created credential appears under OAuth 2.0 Client IDs.\n\nClick the download button to save the JSON file. It will be saved as client_secret_<identifier>.json, and rename it to client_secret.json and move it to your working directory.\n\nSet up application default credentials\n\nTo convert the client_secret.json file into usable credentials, pass its location the gcloud auth application-default login command's --client-id-file argument.\n\ngcloud auth application-default login \\\n    --client-id-file=client_secret.json \\\n    --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.retriever'\n\n\nThe simplified project setup in this tutorial triggers a \"Google hasn't verified this app.\" dialog. This is normal, choose \"continue\".\n\nThis places the resulting token in a well known location so it can be accessed by gcloud or the client libraries.\n\nNote: If running on Colab include --no-browser and carefully follow the instructions it prints (don't just click the link). Also make sure your local gcloud --version is the latest to match Colab.\n\ngcloud auth application-default login \n\n    --no-browser\n    --client-id-file=client_secret.json \n\n    --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.retriever'\n\n\nOnce you have the application default credentials (ACD) set, the client libraries in most languages need minimal to no help to find them.\n\nCurl\n\nThe quickest way to test that this is working is to use it to access the REST API using curl:\n\naccess_token=$(gcloud auth application-default print-access-token)\nproject_id=<MY PROJECT ID>\n\ncurl -X GET https://generativelanguage.googleapis.com/v1/models \\\n    -H 'Content-Type: application/json' \\\n    -H \"Authorization: Bearer ${access_token}\" \\\n    -H \"x-goog-user-project: ${project_id}\" | grep '\"name\"'\n\nPython\n\nIn python the client libraries should find them automatically:\n\npip install google-generativeai\n\n\nA minimal script to test it might be:\n\nimport google.generativeai as genai\n\nprint('Available base models:', [m.name for m in genai.list_models()])\n\nNode.js\n\nTo use these credentials with the Node.js client library, set the GOOGLE_APPLICATION_CREDENTIALS environment variable.\n\nexport GOOGLE_APPLICATION_CREDENTIALS='<PATH_TO>/application_default_credentials.json'\n\n\nInstall the client library:\n\nnpm install @google-ai/generativelanguage\n\n\nCreate a minimal script:\n\nconst { ModelServiceClient } =\n  require(\"@google-ai/generativelanguage\").v1;\n\nconst MODEL_NAME = \"models/embedding-001\";\n\nconst client = new ModelServiceClient({});\n\nclient\n  .listModels({})\n  .then((result) => {\n    result = result[0]\n    for (let i = 0; i < result.length; i++) {\n      console.log(result[i].name);\n    }\n  });\n\nNext steps\n\nIf that's working you're ready to try Semantic retrieval on your text data.\n\nManage credentials yourself [Python]\n\nIn many cases you won't have the gcloud command available to create the access token from the Client ID (client_secret.json). Google provides libraries in many languages to let you manage that process within your app. This section demonstrates the process, in python. There are equivalent examples of this sort of procedure, for other languages, available in the Drive API documentation\n\n1. Install the necessary libraries\n\nInstall the Google client library for Python, and the Gemini client library.\n\npip install --upgrade -q google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\npip install google-generativeai\n\n2. Write the credential manager\n\nTo minimize the number of times you have to click through the authorization screens, create a file called load_creds.py in your working directory to caches a token.json file that it can reuse later, or refresh if it expires.\n\nStart with the following code to convert the client_secret.json file to a token usable with genai.configure:\n\nimport os.path\n\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\n\nSCOPES = ['https://www.googleapis.com/auth/generative-language.retriever']\n\ndef load_creds():\n    \"\"\"Converts `client_secret.json` to a credential object.\n\n    This function caches the generated tokens to minimize the use of the\n    consent screen.\n    \"\"\"\n    creds = None\n    # The file token.json stores the user's access and refresh tokens, and is\n    # created automatically when the authorization flow completes for the first\n    # time.\n    if os.path.exists('token.json'):\n        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n    # If there are no (valid) credentials available, let the user log in.\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(\n                'client_secret.json', SCOPES)\n            creds = flow.run_local_server(port=0)\n        # Save the credentials for the next run\n        with open('token.json', 'w') as token:\n            token.write(creds.to_json())\n    return creds\n\n3. Write your program\n\nNow create your script.py:\n\nimport pprint\nimport google.generativeai as genai\nfrom load_creds import load_creds\n\ncreds = load_creds()\n\ngenai.configure(credentials=creds)\n\nprint()\nprint('Available base models:', [m.name for m in genai.list_models()])\n\n4. Run your program\n\nIn your working directory, run the sample:\n\npython script.py\n\n\nThe first time you run the script, it opens a browser window and prompts you to authorize access.\n\nIf you're not already signed in to your Google Account, you're prompted to sign in. If you're signed in to multiple accounts, be sure to select the account you set as a \"Test Account\" when configuring your project.\n\nNote: The simplified project setup in this tutorial triggers a \"Google hasn't verified this app.\" dialog. This is normal, choose \"continue\".\n\nAuthorization information is stored in the file system, so the next time you run the sample code, you aren't prompted for authorization.\n\nYou have successfully setup authentication.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 1441,
            "filtered_content": "Authentication with OAuth quickstart \nThe Gemini API lets you perform semantic retrieval on your own data. Since it's your data, this needs stricter access controls than API keys.\nThis quickstart uses a simplified authentication approach that is appropriate for a testing environment. For a production environment, learn about authentication and authorization before choosing the access credentials that are appropriate for your app.\nSet up your cloud project for OAuth\nSet up application-default-credentials\nManage credentials in your program instead of using gcloud auth\nTo run this quickstart, you need:\nA Google Cloud project\nA local installation of the gcloud CLI\nTo complete this quickstart, you first need to setup your Cloud project.\nBefore using Google APIs, you need to turn them on in a Google Cloud project.\nIn the Google Cloud console, enable the Google Generative Language API.\nEnable the API\nNext configure the project's OAuth consent screen and add yourself as a test user. If you've already completed this step for your Cloud project, skip to the next section.\nIn the Google Cloud console, go to Menu > APIs & Services > OAuth consent screen.\nGo to OAuth consent screen\nSelect the user type External for your app, then click Create.\nComplete the app registration form (you can leave most fields blank), then click Save and Continue.\nFor now, you can skip adding scopes and click Save and Continue. In the future, when you create an app for use outside of your Google Workspace organization, you must add and verify the authorization scopes that your app requires.\nAdd test users:\nUnder Test users, click Add users.\nEnter your email address and any other authorized test users, then click Save and Continue.\nReview your app registration summary. To make changes, click Edit. If the app registration looks OK, click Back to Dashboard.\nTo authenticate as an end user and access user data in your app, you need to create one or more OAuth 2.0 Client IDs. A client ID is used to identify a single app to Google's OAuth servers. If your app runs on multiple platforms, you must create a separate client ID for each platform.\nIn the Google Cloud console, go to Menu > APIs & Services > Credentials.\nGo to Credentials\nClick Create Credentials > OAuth client ID.\nClick Application type > Desktop app.\nIn the Name field, type a name for the credential. This name is only shown in the Google Cloud console.\nClick Create. The OAuth client created screen appears, showing your new Client ID and Client secret.\nClick OK. The newly created credential appears under OAuth 2.0 Client IDs.\nClick the download button to save the JSON file. It will be saved as client_secret_<identifier>.json, and rename it to client_secret.json and move it to your working directory.\nTo convert the client_secret.json file into usable credentials, pass its location the gcloud auth application-default login command's --client-id-file argument.\ngcloud auth application-default login \\\n    --client-id-file=client_secret.json \\\n    --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.retriever'\nThe simplified project setup in this tutorial triggers a \"Google hasn't verified this app.\" dialog. This is normal, choose \"continue\".\nThis places the resulting token in a well known location so it can be accessed by gcloud or the client libraries.\nNote: If running on Colab include --no-browser and carefully follow the instructions it prints (don't just click the link). Also make sure your local gcloud --version is the latest to match Colab.\ngcloud auth application-default login \n    --no-browser\n    --client-id-file=client_secret.json \n    --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.retriever'\nOnce you have the application default credentials (ACD) set, the client libraries in most languages need minimal to no help to find them.\nThe quickest way to test that this is working is to use it to access the REST API using curl:\naccess_token=$(gcloud auth application-default print-access-token)\nproject_id=<MY PROJECT ID>\ncurl -X GET https://generativelanguage.googleapis.com/v1/models \\\n    -H \"x-goog-user-project: ${project_id}\" | grep '\"name\"'\nIn python the client libraries should find them automatically:\nA minimal script to test it might be:\nTo use these credentials with the Node.js client library, set the GOOGLE_APPLICATION_CREDENTIALS environment variable.\nexport GOOGLE_APPLICATION_CREDENTIALS='<PATH_TO>/application_default_credentials.json'\nInstall the client library:\nnpm install @google-ai/generativelanguage\nCreate a minimal script:\nconst { ModelServiceClient } =\n  require(\"@google-ai/generativelanguage\").v1;\nconst MODEL_NAME = \"models/embedding-001\";\nconst client = new ModelServiceClient({});\nclient\n  .listModels({})\n  .then((result) => {\n    result = result[0]\n    for (let i = 0; i < result.length; i++) {\n      console.log(result[i].name);\nIf that's working you're ready to try Semantic retrieval on your text data.\nIn many cases you won't have the gcloud command available to create the access token from the Client ID (client_secret.json). Google provides libraries in many languages to let you manage that process within your app. This section demonstrates the process, in python. There are equivalent examples of this sort of procedure, for other languages, available in the Drive API documentation\nInstall the Google client library for Python, and the Gemini client library.\npip install --upgrade -q google-api-python-client google-auth-httplib2 google-auth-oauthlib\nTo minimize the number of times you have to click through the authorization screens, create a file called load_creds.py in your working directory to caches a token.json file that it can reuse later, or refresh if it expires.\nStart with the following code to convert the client_secret.json file to a token usable with genai.configure:\nimport os.path\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nSCOPES = ['https://www.googleapis.com/auth/generative-language.retriever']\ndef load_creds():\n    \"\"\"Converts `client_secret.json` to a credential object.\n    This function caches the generated tokens to minimize the use of the\n    consent screen.\n    \"\"\"\n    creds = None\n    # The file token.json stores the user's access and refresh tokens, and is\n    # created automatically when the authorization flow completes for the first\n    # time.\n    if os.path.exists('token.json'):\n        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n    # If there are no (valid) credentials available, let the user log in.\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(\n                'client_secret.json', SCOPES)\n            creds = flow.run_local_server(port=0)\n        # Save the credentials for the next run\n        with open('token.json', 'w') as token:\n            token.write(creds.to_json())\n    return creds\nNow create your script.py:\nfrom load_creds import load_creds\ncreds = load_creds()\ngenai.configure(credentials=creds)\nprint()\nIn your working directory, run the sample:\npython script.py\nThe first time you run the script, it opens a browser window and prompts you to authorize access.\nIf you're not already signed in to your Google Account, you're prompted to sign in. If you're signed in to multiple accounts, be sure to select the account you set as a \"Test Account\" when configuring your project.\nNote: The simplified project setup in this tutorial triggers a \"Google hasn't verified this app.\" dialog. This is normal, choose \"continue\".\nAuthorization information is stored in the file system, so the next time you run the sample code, you aren't prompted for authorization.\nYou have successfully setup authentication.",
            "filtered_word_count": 1105
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nBuild Chatbot with the Gemini API\nMultimodal Tasks with the Gemini API\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API Firebase Extensions \nbookmark_border\n\nFirebase is an app development platform backed by Google and trusted by millions of developers around the world. If you're a Firebase developer interested in using the Gemini API to add features to applications, there are several Firebase extensions to help you do so. These are pre-packaged solutions that help you deploy new capabilities to your app quickly.\n\nBuild Chatbot with the Gemini API\n\nThe Build Chatbot with the Gemini API extension lets you establish and manage interactive conversations between your users and large language models through the Gemini API, using Cloud Firestore as the database. A collection in Cloud Firestore represents each chat. The extension monitors the collection of new messages, then queries the Gemini API for a suitable response, considering the chat's previous messages as context.\n\nBy integrating the Build Chatbot with the Gemini API extension, you can efficiently create chatbot applications, enhancing user experience and interaction while saving time and effort on custom code development.\n\nMultimodal Tasks with the Gemini API\n\nThe Multimodal Tasks with the Gemini API extension lets you perform language tasks on data in Firestore, using a text prompt and, optionally, an image.\n\nYou configure each instance of the extension to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\nPredict star ratings on a collection of product reviews.\nClassify customer feedback as positive, negative, or neutral.\nSummarize long articles.\nExtract named entities from text.\nGenerate creative text, such as poems or code.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 449,
            "filtered_content": "Gemini API Firebase Extensions \nFirebase is an app development platform backed by Google and trusted by millions of developers around the world. If you're a Firebase developer interested in using the Gemini API to add features to applications, there are several Firebase extensions to help you do so. These are pre-packaged solutions that help you deploy new capabilities to your app quickly.\nThe Build Chatbot with the Gemini API extension lets you establish and manage interactive conversations between your users and large language models through the Gemini API, using Cloud Firestore as the database. A collection in Cloud Firestore represents each chat. The extension monitors the collection of new messages, then queries the Gemini API for a suitable response, considering the chat's previous messages as context.\nBy integrating the Build Chatbot with the Gemini API extension, you can efficiently create chatbot applications, enhancing user experience and interaction while saving time and effort on custom code development.\nThe Multimodal Tasks with the Gemini API extension lets you perform language tasks on data in Firestore, using a text prompt and, optionally, an image.\nYou configure each instance of the extension to perform one particular task. If you have multiple tasks, you can install multiple instances.\nFor example, you could use this extension to:\nPredict star ratings on a collection of product reviews.\nClassify customer feedback as positive, negative, or neutral.\nSummarize long articles.\nExtract named entities from text.\nGenerate creative text, such as poems or code.",
            "filtered_word_count": 244
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nMigrate from Gemini on Google AI to Vertex AI\nPython: Migrate from Google AI Gemini API to the Vertex AI Gemini API\nDelete unused API Keys\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nBuild with Gemini on Google Cloud \nbookmark_border\n\nIf you are new to Gemini, using the quickstarts is the fastest way to get started.\n\nHowever, as your generative AI solutions mature, you may need a platform for building and deploying generative AI applications and solutions end to end. Google Cloud provides a comprehensive ecosystem of tools to enable developers to harness the power of generative AI, from the initial stages of app development to app deployment, app hosting, and managing complex data at scale.\n\nGoogle Cloud's Vertex AI platform offers a suite of MLOps tools that streamline usage, deployment, and monitoring of AI models for efficiency and reliability. Additionally, integrations with databases, DevOps tools, logging, monitoring, and IAM provide a holistic approach to managing the entire generative AI lifecycle.\n\nThe following table summarizes the main differences between Google AI and Vertex AI to help you decide which option is right for your use case:\n\nFeatures\tGoogle AI Gemini API\tGoogle Cloud Vertex AI Gemini API\nLatest Gemini models\tGemini Pro and Gemini Ultra\tGemini Pro and Gemini Ultra\nSign up\tGoogle account\tGoogle Cloud account (with terms agreement and billing)\nAuthentication\tAPI key\tGoogle Cloud service account\nUser interface playground\tGoogle AI Studio\tVertex AI Studio\nAPI & SDK\tPython, Node.js, Android (Kotlin/Java), Swift, Go\tSDK supports Python, Node.js, Java, Go\nFree tier\tYes\t$300 Google Cloud credit for new users\nQuota (Request per minute)\t60 (can request increase)\tIncrease upon request (default: 60)\nEnterprise support\tNo\tCustomer encryption key\nVirtual private cloud\nData residency\nAccess transparency\nScalable infrastructure for application hosting\nDatabases and data storage\nMLOps\tNo\tFull MLOps on Vertex AI (Examples: model evaluation, Model Monitoring, Model Registry)\n\nTo learn which products, frameworks, and tools are the best match for building your generative AI application on Google Cloud, see Build a generative AI application on Google Cloud.\n\nMigrate from Gemini on Google AI to Vertex AI\n\nIf your application uses Google AI Gemini APIs, you'll need to migrate to Google Cloud's Vertex AI Gemini APIs.\n\nWhen you migrate:\n\nYou can use your existing Google Cloud project (the same one you used to generate your API key) or you can create a new Google Cloud project.\n\nSupported regions may differ between Google AI Studio and Vertex AI. See the list of supported regions for generative AI on Google Cloud.\n\nAny models you created in Google AI Studio need to be retrained in Vertex AI.\n\nPython: Migrate from Google AI Gemini API to the Vertex AI Gemini API\n\nThe following sections show code snippets to help you migrate your Python code to use the Vertex AI Gemini API.\n\nVertex AI Python SDK Setup\n\nOn Vertex AI, you don't need an API key. Instead, Gemini on Vertex AI is managed using IAM access, which controls permission for a user, a group, or a service account to call the Gemini API through the Vertex AI SDK.\n\nWhile there are many ways to authenticate, the easiest method for authenticating in a development environment is to install the Google Cloud CLI then use your user credentials to sign in to the CLI.\n\nTo make inference calls to Vertex AI, you must also make sure that your user or service account has the Vertex AI User role.\n\nCode example to install the client\nGoogle AI\tVertex AI\n\n# To install the Python SDK, use this CLI command:\n# pip install google-generativeai\n\nfrom google.generativeai import GenerativeModel\nfrom google.colab import userdata\n\ngenai.configure(userdata.get('API_KEY'))\n       \n\t\n# To install the Python SDK, use this CLI command:\n# pip install google-cloud-aiplatform\n\nimport vertexai\nfrom vertexai.generative_models\n          import GenerativeModel, Image\n\nPROJECT_ID = \"\"\nREGION = \"\"  # e.g. us-central1\nvertexai.init(project=PROJECT_ID, location=REGION)\n       \nCode example to generate text from text prompt\nGoogle AI\tVertex AI\n\nmodel = GenerativeModel('gemini-1.0-pro')\n\nresponse = model.generate_content('The opposite of hot is')\nprint(response.text) #  The opposite of hot is cold.\n       \n\t\nmodel = GenerativeModel('gemini-1.0-pro')\n\nresponse = model.generate_content('The opposite of hot is')\nprint(response.text) #  The opposite of hot is cold.\n       \nCode example to generate text from text and image\nGoogle AI\tVertex AI\n\nimport PIL.Image\n\nmultimodal_model = GenerativeModel('gemini-1.0-pro-vision')\n\nimage = PIL.Image.open('image.jpg')\n\nresponse = multimodal_model.generate_content(['What is this picture?', image])\nprint(response.text) # A cat is shown in this picture.\n       \n\t\nmultimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")\n\nimage = Image.load_from_file(\"image.jpg\")\n\nresponse = multimodal_model.generate_content([\"What is shown in this image?\", image])\n\nprint(response.text) # A cat is shown in this picture.\n       \nCode example to generate multi-turn chat\nGoogle AI\tVertex AI\n\nmodel = GenerativeModel('gemini-1.0-pro')\n\nchat = model.start_chat()\n\nprint(chat.send_message(\"How are you?\").text)\nprint(chat.send_message(\"What can you do?\").text)\n       \n\t\nmodel = GenerativeModel(\"gemini-1.0-pro\")\n\nchat = model.start_chat()\n\nprint(chat.send_message(\"How are you?\").text)\nprint(chat.send_message(\"What can you do?\").text)\n       \nDelete unused API Keys\n\nIf you no longer need to use your Google AI Gemini API key, follow security best practices and delete it.\n\nNext steps\nSee the Vertex AI overview to learn more about generative AI solutions on Vertex AI.\nDive deeper into the Vertex AI Gemini API.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 1008,
            "filtered_content": "Build with Gemini on Google Cloud \nIf you are new to Gemini, using the quickstarts is the fastest way to get started.\nHowever, as your generative AI solutions mature, you may need a platform for building and deploying generative AI applications and solutions end to end. Google Cloud provides a comprehensive ecosystem of tools to enable developers to harness the power of generative AI, from the initial stages of app development to app deployment, app hosting, and managing complex data at scale.\nGoogle Cloud's Vertex AI platform offers a suite of MLOps tools that streamline usage, deployment, and monitoring of AI models for efficiency and reliability. Additionally, integrations with databases, DevOps tools, logging, monitoring, and IAM provide a holistic approach to managing the entire generative AI lifecycle.\nThe following table summarizes the main differences between Google AI and Vertex AI to help you decide which option is right for your use case:\nFeatures\tGoogle AI Gemini API\tGoogle Cloud Vertex AI Gemini API\nLatest Gemini models\tGemini Pro and Gemini Ultra\tGemini Pro and Gemini Ultra\nSign up\tGoogle account\tGoogle Cloud account (with terms agreement and billing)\nAuthentication\tAPI key\tGoogle Cloud service account\nUser interface playground\tGoogle AI Studio\tVertex AI Studio\nAPI & SDK\tPython, Node.js, Android (Kotlin/Java), Swift, Go\tSDK supports Python, Node.js, Java, Go\nFree tier\tYes\t$300 Google Cloud credit for new users\nQuota (Request per minute)\t60 (can request increase)\tIncrease upon request (default: 60)\nEnterprise support\tNo\tCustomer encryption key\nVirtual private cloud\nData residency\nAccess transparency\nScalable infrastructure for application hosting\nDatabases and data storage\nMLOps\tNo\tFull MLOps on Vertex AI (Examples: model evaluation, Model Monitoring, Model Registry)\nTo learn which products, frameworks, and tools are the best match for building your generative AI application on Google Cloud, see Build a generative AI application on Google Cloud.\nIf your application uses Google AI Gemini APIs, you'll need to migrate to Google Cloud's Vertex AI Gemini APIs.\nWhen you migrate:\nYou can use your existing Google Cloud project (the same one you used to generate your API key) or you can create a new Google Cloud project.\nSupported regions may differ between Google AI Studio and Vertex AI. See the list of supported regions for generative AI on Google Cloud.\nAny models you created in Google AI Studio need to be retrained in Vertex AI.\nThe following sections show code snippets to help you migrate your Python code to use the Vertex AI Gemini API.\nVertex AI Python SDK Setup\nOn Vertex AI, you don't need an API key. Instead, Gemini on Vertex AI is managed using IAM access, which controls permission for a user, a group, or a service account to call the Gemini API through the Vertex AI SDK.\nWhile there are many ways to authenticate, the easiest method for authenticating in a development environment is to install the Google Cloud CLI then use your user credentials to sign in to the CLI.\nTo make inference calls to Vertex AI, you must also make sure that your user or service account has the Vertex AI User role.\nCode example to install the client\n# pip install google-generativeai\nfrom google.generativeai import GenerativeModel\ngenai.configure(userdata.get('API_KEY'))\n# pip install google-cloud-aiplatform\nimport vertexai\nfrom vertexai.generative_models\n          import GenerativeModel, Image\nPROJECT_ID = \"\"\nREGION = \"\"  # e.g. us-central1\nvertexai.init(project=PROJECT_ID, location=REGION)\nCode example to generate text from text prompt\nCode example to generate text from text and image\nmultimodal_model = GenerativeModel('gemini-1.0-pro-vision')\nimage = PIL.Image.open('image.jpg')\nresponse = multimodal_model.generate_content(['What is this picture?', image])\nmultimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")\nimage = Image.load_from_file(\"image.jpg\")\nresponse = multimodal_model.generate_content([\"What is shown in this image?\", image])\nCode example to generate multi-turn chat\nmodel = GenerativeModel(\"gemini-1.0-pro\")\nIf you no longer need to use your Google AI Gemini API key, follow security best practices and delete it.\nSee the Vertex AI overview to learn more about generative AI solutions on Vertex AI.\nDive deeper into the Vertex AI Gemini API.",
            "filtered_word_count": 652
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting": {
            "status": "Looks good",
            "content": "Products\nExamples\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nError codes\nCheck your API calls for model parameter errors\nCheck if you have the right model\nSafety issues\nImprove model output\nUnderstand token limits\nKnown issues\nFile a bug\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nSend feedback\nTroubleshooting guide \nbookmark_border\n\nUse this guide to help you diagnose and resolve common issues that arise when you call the Gemini API. If you encounter API key issues, ensure you have set up your API key correctly per the API key setup guide.\n\nError codes\n\nThe following table lists common error codes you may encounter, along with explanations for their causes and troubleshooting steps:\n\nHTTP Code\tStatus\tDescription\tSolution\n400\tINVALID_ARGUMENT\tThe request body is malformed.\tCheck the API reference for request format, examples, and supported versions. Using features from a newer API version with an older endpoint can cause errors.\n403\tPERMISSION_DENIED\tYour API key doesn't have the required permissions.\tCheck that your API key is set and has the right access.\n404\tNOT_FOUND\tThe requested resource wasn't found.\tCheck if all parameters in your request are valid for your API version.\n429\tRESOURCE_EXHAUSTED\tYou've exceeded the rate limit.\tEnsure you're within the model's rate limit. Request a quota increase if needed.\n500\tINTERNAL\tAn unexpected error occurred on Google's side.\tWait a bit and retry your request. If the issue persists after retrying, please report it using the Send feedback button in Google AI Studio.\n503\tUNAVAILABLE\tThe service may be temporarily overloaded or down.\tWait a bit and retry your request. If the issue persists after retrying, please report it using the Send feedback button in Google AI Studio.\nCheck your API calls for model parameter errors\n\nEnsure your model parameters are within the following values:\n\nModel parameter\tValues (range)\nCandidate count\t1-8 (integer)\nTemperature\t0.0-1.0\nMax output tokens\tUse get_model (Python) to determine the maximum number of tokens for the model you are using.\nTopP\t0.0-1.0\n\nIn addition to checking parameter values, make sure you're using the correct API version (e.g., /v1 or /v1beta) and model that supports the features you need. For example, if a feature is in Beta release, it will only be available in the /v1beta API version.\n\nCheck if you have the right model\n\nEnsure you are using a supported model. Use list_models (Python) to get all models available for use.\n\nSafety issues\n\nIf you see a prompt was blocked because of a safety setting in your API call, review the prompt with respect to the filters you set in the API call.\n\nIf you see BlockedReason.OTHER, the query or response may violate the terms of service or be otherwise unsupported.\n\nImprove model output\n\nFor higher quality model outputs, explore writing more structured prompts. The introduction to prompt design page introduces some basic concepts, strategies, and best practices to get you started.\n\nIf you have hundreds of examples of good input/output pairs, you can also consider model tuning.\n\nUnderstand token limits\n\nUse the ModelService API to get additional metadata about the models, including input and output token limits.\n\nTo get the tokens used by your prompt, use countMessageTokens for chat models and countTextTokens for text models.\n\nKnown issues\nMobile support for Google AI Studio: While you can open the website on mobile, it has not been optimized for small screens.\nThe API supports only English. Submitting prompts in different languages can produce unexpected or even blocked responses. See available languages for updates.\nFile a bug\n\nFile an issue in Github to ask questions or submit feature requests or bugs.\n\nGeneral API usage questions\nPython client library issues\nSwift client library issues\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-19 UTC.\n\nTerms\nPrivacy",
            "word_count": 761,
            "filtered_content": "Troubleshooting guide \nUse this guide to help you diagnose and resolve common issues that arise when you call the Gemini API. If you encounter API key issues, ensure you have set up your API key correctly per the API key setup guide.\nThe following table lists common error codes you may encounter, along with explanations for their causes and troubleshooting steps:\nHTTP Code\tStatus\tDescription\tSolution\n400\tINVALID_ARGUMENT\tThe request body is malformed.\tCheck the API reference for request format, examples, and supported versions. Using features from a newer API version with an older endpoint can cause errors.\n403\tPERMISSION_DENIED\tYour API key doesn't have the required permissions.\tCheck that your API key is set and has the right access.\n404\tNOT_FOUND\tThe requested resource wasn't found.\tCheck if all parameters in your request are valid for your API version.\n429\tRESOURCE_EXHAUSTED\tYou've exceeded the rate limit.\tEnsure you're within the model's rate limit. Request a quota increase if needed.\n500\tINTERNAL\tAn unexpected error occurred on Google's side.\tWait a bit and retry your request. If the issue persists after retrying, please report it using the Send feedback button in Google AI Studio.\n503\tUNAVAILABLE\tThe service may be temporarily overloaded or down.\tWait a bit and retry your request. If the issue persists after retrying, please report it using the Send feedback button in Google AI Studio.\nEnsure your model parameters are within the following values:\nModel parameter\tValues (range)\nCandidate count\t1-8 (integer)\nTemperature\t0.0-1.0\nMax output tokens\tUse get_model (Python) to determine the maximum number of tokens for the model you are using.\nTopP\t0.0-1.0\nIn addition to checking parameter values, make sure you're using the correct API version (e.g., /v1 or /v1beta) and model that supports the features you need. For example, if a feature is in Beta release, it will only be available in the /v1beta API version.\nEnsure you are using a supported model. Use list_models (Python) to get all models available for use.\nIf you see a prompt was blocked because of a safety setting in your API call, review the prompt with respect to the filters you set in the API call.\nIf you see BlockedReason.OTHER, the query or response may violate the terms of service or be otherwise unsupported.\nFor higher quality model outputs, explore writing more structured prompts. The introduction to prompt design page introduces some basic concepts, strategies, and best practices to get you started.\nIf you have hundreds of examples of good input/output pairs, you can also consider model tuning.\nUse the ModelService API to get additional metadata about the models, including input and output token limits.\nTo get the tokens used by your prompt, use countMessageTokens for chat models and countTextTokens for text models.\nMobile support for Google AI Studio: While you can open the website on mobile, it has not been optimized for small screens.\nThe API supports only English. Submitting prompts in different languages can produce unexpected or even blocked responses. See available languages for updates.\nFile an issue in Github to ask questions or submit feature requests or bugs.\nGeneral API usage questions\nPython client library issues\nSwift client library issues",
            "filtered_word_count": 528
        },
        "https://ai.google.dev/gemini-api/docs/workspace": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nTurn on Early Access apps\nTroubleshooting\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nAccess Google AI Studio with your Workspace account \nbookmark_border\n\nThis page explains how to enable Google AI Studio for Google Workspace users in your organization. If you're having trouble accessing Google AI Studio with your Workspace account, see Troubleshooting.\n\nPrerequisites\n\nYour current account might not have permission to do these steps. To continue, make sure you're signed in to an admin account. Learn more\n\nAs an admin, you can control who uses Early Access apps:\n\nEarly Access apps are turned off by default for all editions.\nThe setting lets you turn all Early Access apps on or off. You can't turn on or off individual apps independently.\nGoogle Workspace for Education editions: Users under the age of 18 are restricted from using Early Access apps with their Google Workspace for Education accounts. This is true even when the Early Access Apps setting is on. For details, go to Control access to Google services by age.\nEarly Access apps access to core services is also off by default.\nTurn on Early Access apps\n\nTo apply the setting for certain users, put their accounts in an organizational unit (to set by department) or a configuration group (to set for users across or within departments).\n\nIn the workspace Admin console, go to Menu -> Apps -> Additional Google services.\nIn the list of all services, scroll to and click Early Access Apps. The settings for Early Access Apps page opens.\nOn the Settings for Early Access Apps page, click Service status.\nTo turn a service on or off, select On or Off, and then click Save.\nTo turn on and off a service for an organization or a group within an organization, see the detailed steps in the support article.\nTroubleshooting\n\nIf you get an error similar to the following:\n\nWe are sorry, but you do not have access to Google AI Studio. Please contact your Organization Administrator for access.\n\nwhen trying to access Google AI Studio using your workspace account, you may need to enable Early Access apps in that account.\n\nGoogle AI Studio is an early access app. Early Access apps are services and products developed by Google teams. Learn more about early access apps on the turning on early access apps support page.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-18 UTC.\n\nTerms\nPrivacy",
            "word_count": 560,
            "filtered_content": "Access Google AI Studio with your Workspace account \nThis page explains how to enable Google AI Studio for Google Workspace users in your organization. If you're having trouble accessing Google AI Studio with your Workspace account, see Troubleshooting.\nYour current account might not have permission to do these steps. To continue, make sure you're signed in to an admin account. Learn more\nAs an admin, you can control who uses Early Access apps:\nEarly Access apps are turned off by default for all editions.\nThe setting lets you turn all Early Access apps on or off. You can't turn on or off individual apps independently.\nGoogle Workspace for Education editions: Users under the age of 18 are restricted from using Early Access apps with their Google Workspace for Education accounts. This is true even when the Early Access Apps setting is on. For details, go to Control access to Google services by age.\nEarly Access apps access to core services is also off by default.\nTo apply the setting for certain users, put their accounts in an organizational unit (to set by department) or a configuration group (to set for users across or within departments).\nIn the workspace Admin console, go to Menu -> Apps -> Additional Google services.\nIn the list of all services, scroll to and click Early Access Apps. The settings for Early Access Apps page opens.\nOn the Settings for Early Access Apps page, click Service status.\nTo turn a service on or off, select On or Off, and then click Save.\nTo turn on and off a service for an organization or a group within an organization, see the detailed steps in the support article.\nIf you get an error similar to the following:\nWe are sorry, but you do not have access to Google AI Studio. Please contact your Organization Administrator for access.\nwhen trying to access Google AI Studio using your workspace account, you may need to enable Early Access apps in that account.\nGoogle AI Studio is an early access app. Early Access apps are services and products developed by Google teams. Learn more about early access apps on the turning on early access apps support page.",
            "filtered_word_count": 365
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nUnderstand 403 Access Restricted errors\nResolve No Content responses on Google AI Studio\nCheck token usage and limits\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nTroubleshoot Google AI Studio \nbookmark_border\n\nThis page provides suggestions for troubleshooting Google AI Studio if you encounter issues.\n\nUnderstand 403 Access Restricted errors\n\nIf you see a 403 Access Restricted error, you are using Google AI Studio in a way that does not follow the Terms of Service. One common reason is you are not located in a supported region.\n\nResolve No Content responses on Google AI Studio\n\nA warning No Content message appears on Google AI Studio if the content is blocked for any reason. To see more details, hold the pointer over No Content and click warning Safety.\n\nIf the response was blocked due to safety settings and you considered the safety risks for your use case, you can modify the safety settings to influence the returned response.\n\nIf the response was blocked but not due to the safety settings, the query or response may violate the Terms of Service or be otherwise unsupported.\n\nCheck token usage and limits\n\nWhen you have a prompt open, the Text Preview button at the bottom of the screen shows the current tokens used for the content of your prompt and the maximum token count for the model being used.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-19 UTC.\n\nTerms\nPrivacy",
            "word_count": 396,
            "filtered_content": "Troubleshoot Google AI Studio \nThis page provides suggestions for troubleshooting Google AI Studio if you encounter issues.\nIf you see a 403 Access Restricted error, you are using Google AI Studio in a way that does not follow the Terms of Service. One common reason is you are not located in a supported region.\nA warning No Content message appears on Google AI Studio if the content is blocked for any reason. To see more details, hold the pointer over No Content and click warning Safety.\nIf the response was blocked due to safety settings and you considered the safety risks for your use case, you can modify the safety settings to influence the returned response.\nIf the response was blocked but not due to the safety settings, the query or response may violate the Terms of Service or be otherwise unsupported.\nWhen you have a prompt open, the Text Preview button at the bottom of the screen shows the current tokens used for the content of your prompt and the maximum token count for the model being used.",
            "filtered_word_count": 179
        },
        "https://ai.google.dev/gemini-api/docs/quota": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nOptions for increasing your requests per minute (RPM) limit \nbookmark_border\n\nEach model variation has an associated rate limit (requests per minute, RPM). For details on those rate limits, see Gemini models.\n\nIf you're using the Gemini API with the Google AI SDKs and you'd like a higher rate limit than what we currently offer, you can continue on the no-cost plan and fill out this \"Request rate limit increase\" form with details about your project and use case. We offer no guarantees about increasing your rate limit, but we'll do our best to review your request and reach out to you if we're able to accommodate your capacity needs.\n\nYou can also consider migrating to the Vertex AI platform on Google Cloud which may offer higher limits. With minimal code changes, you can continue using the Gemini API through the Vertex AI SDKs.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-19 UTC.\n\nTerms\nPrivacy",
            "word_count": 320,
            "filtered_content": "Options for increasing your requests per minute (RPM) limit \nEach model variation has an associated rate limit (requests per minute, RPM). For details on those rate limits, see Gemini models.\nIf you're using the Gemini API with the Google AI SDKs and you'd like a higher rate limit than what we currently offer, you can continue on the no-cost plan and fill out this \"Request rate limit increase\" form with details about your project and use case. We offer no guarantees about increasing your rate limit, but we'll do our best to review your request and reach out to you if we're able to accommodate your capacity needs.\nYou can also consider migrating to the Vertex AI platform on Google Cloud which may offer higher limits. With minimal code changes, you can continue using the Gemini API through the Vertex AI SDKs.",
            "filtered_word_count": 142
        },
        "https://ai.google.dev/gemini-api/docs/available-regions": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nAvailable languages\nAvailable regions\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nAvailable languages and regions for Google AI Studio and Gemini API \nbookmark_border\n\nNote: If you reached this page after trying to open Google AI Studio, it may be because Google AI Studio is not available in your region, or you don't meet the age requirements (18+) for access. You can learn more about the available regions below, and other requirements in the terms of service.\nAvailable languages\n\nThe Gemini API supports the following languages:\n\nArabic (ar)\nBengali (bn)\nBulgarian (bg)\nChinese simplified and traditional (zh)\nCroatian (hr)\nCzech (cs)\nDanish (da)\nDutch (nl)\nEnglish (en)\nEstonian (et)\nFinnish (fi)\nFrench (fr)\nGerman (de)\nGreek (el)\nHebrew (iw)\nHindi (hi)\nHungarian (hu)\nIndonesian (id)\nItalian (it)\nJapanese (ja)\nKorean (ko)\nLatvian (lv)\nLithuanian (lt)\nNorwegian (no)\nPolish (pl)\nPortuguese (pt)\nRomanian (ro)\nRussian (ru)\nSerbian (sr)\nSlovak (sk)\nSlovenian (sl)\nSpanish (es)\nSwahili (sw)\nSwedish (sv)\nThai (th)\nTurkish (tr)\nUkrainian (uk)\nVietnamese (vi)\n\nThe PaLM API supports only English. Using other languages may produce unexpected results.\n\nAvailable regions\nNote: For Colab users - Region restrictions are applied based on the region that the Colab instance is in, not the region that the user is in. You can check the location of the Colab instance using !curl ipinfo.io\n\nThe Gemini API and Google AI Studio are available in the following countries and territories. If you're not in one of these countries or territories, try Gemini Pro in Vertex AI:\n\nAlgeria\nAmerican Samoa\nAngola\nAnguilla\nAntarctica\nAntigua and Barbuda\nArgentina\nArmenia\nAruba\nAustralia\nAzerbaijan\nThe Bahamas\nBahrain\nBangladesh\nBarbados\nBelize\nBenin\nBermuda\nBhutan\nBolivia\nBotswana\nBrazil\nBritish Indian Ocean Territory\nBritish Virgin Islands\nBrunei\nBurkina Faso\nBurundi\nCabo Verde\nCambodia\nCameroon\nCanada\nCaribbean Netherlands\nCayman Islands\nCentral African Republic\nChad\nChile\nChristmas Island\nCocos (Keeling) Islands\nColombia\nComoros\nCook Islands\nCôte d'Ivoire\nCosta Rica\nCuraçao\nDemocratic Republic of the Congo\nDjibouti\nDominica\nDominican Republic\nEcuador\nEgypt\nEl Salvador\nEquatorial Guinea\nEritrea\nEswatini\nEthiopia\nFalkland Islands (Islas Malvinas)\nFiji\nGabon\nThe Gambia\nGeorgia\nGhana\nGibraltar\nGrenada\nGuam\nGuatemala\nGuernsey\nGuinea\nGuinea-Bissau\nGuyana\nHaiti\nHeard Island and McDonald Islands\nHonduras\nIndia\nIndonesia\nIraq\nIsle of Man\nIsrael\nJamaica\nJapan\nJersey\nJordan\nKazakhstan\nKenya\nKiribati\nKyrgyzstan\nKuwait\nLaos\nLebanon\nLesotho\nLiberia\nLibya\nMadagascar\nMalawi\nMalaysia\nMaldives\nMali\nMarshall Islands\nMauritania\nMauritius\nMexico\nMicronesia\nMongolia\nMontserrat\nMorocco\nMozambique\nNamibia\nNauru\nNepal\nNew Caledonia\nNew Zealand\nNicaragua\nNiger\nNigeria\nNiue\nNorfolk Island\nNorthern Mariana Islands\nOman\nPakistan\nPalau\nPalestine\nPanama\nPapua New Guinea\nParaguay\nPeru\nPhilippines\nPitcairn Islands\nPuerto Rico\nQatar\nRepublic of the Congo\nRwanda\nSaint Barthélemy\nSaint Kitts and Nevis\nSaint Lucia\nSaint Pierre and Miquelon\nSaint Vincent and the Grenadines\nSaint Helena, Ascension and Tristan da Cunha\nSamoa\nSão Tomé and Príncipe\nSaudi Arabia\nSenegal\nSeychelles\nSierra Leone\nSingapore\nSolomon Islands\nSomalia\nSouth Africa\nSouth Georgia and the South Sandwich Islands\nSouth Korea\nSouth Sudan\nSri Lanka\nSudan\nSuriname\nTaiwan\nTajikistan\nTanzania\nThailand\nTimor-Leste\nTogo\nTokelau\nTonga\nTrinidad and Tobago\nTunisia\nTürkiye\nTurkmenistan\nTurks and Caicos Islands\nTuvalu\nUganda\nUnited Arab Emirates\nUnited States\nUnited States Minor Outlying Islands\nU.S. Virgin Islands\nUruguay\nUzbekistan\nVanuatu\nVenezuela\nVietnam\nWallis and Futuna\nWestern Sahara\nYemen\nZambia\nZimbabwe\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-19 UTC.\n\nTerms\nPrivacy",
            "word_count": 705,
            "filtered_content": "Available languages and regions for Google AI Studio and Gemini API \nNote: If you reached this page after trying to open Google AI Studio, it may be because Google AI Studio is not available in your region, or you don't meet the age requirements (18+) for access. You can learn more about the available regions below, and other requirements in the terms of service.\nThe Gemini API supports the following languages:\nArabic (ar)\nBengali (bn)\nBulgarian (bg)\nChinese simplified and traditional (zh)\nCroatian (hr)\nCzech (cs)\nDanish (da)\nDutch (nl)\nEnglish (en)\nEstonian (et)\nFinnish (fi)\nFrench (fr)\nGerman (de)\nGreek (el)\nHebrew (iw)\nHindi (hi)\nHungarian (hu)\nIndonesian (id)\nItalian (it)\nJapanese (ja)\nKorean (ko)\nLatvian (lv)\nLithuanian (lt)\nNorwegian (no)\nPolish (pl)\nPortuguese (pt)\nRomanian (ro)\nRussian (ru)\nSerbian (sr)\nSlovak (sk)\nSlovenian (sl)\nSpanish (es)\nSwahili (sw)\nSwedish (sv)\nThai (th)\nTurkish (tr)\nUkrainian (uk)\nVietnamese (vi)\nThe PaLM API supports only English. Using other languages may produce unexpected results.\nNote: For Colab users - Region restrictions are applied based on the region that the Colab instance is in, not the region that the user is in. You can check the location of the Colab instance using !curl ipinfo.io\nThe Gemini API and Google AI Studio are available in the following countries and territories. If you're not in one of these countries or territories, try Gemini Pro in Vertex AI:\nAlgeria\nAmerican Samoa\nAngola\nAnguilla\nAntarctica\nAntigua and Barbuda\nArgentina\nArmenia\nAruba\nAustralia\nAzerbaijan\nThe Bahamas\nBahrain\nBangladesh\nBarbados\nBelize\nBenin\nBermuda\nBhutan\nBolivia\nBotswana\nBrazil\nBritish Indian Ocean Territory\nBritish Virgin Islands\nBrunei\nBurkina Faso\nBurundi\nCabo Verde\nCambodia\nCameroon\nCanada\nCaribbean Netherlands\nCayman Islands\nCentral African Republic\nChad\nChile\nChristmas Island\nCocos (Keeling) Islands\nColombia\nComoros\nCook Islands\nCôte d'Ivoire\nCosta Rica\nCuraçao\nDemocratic Republic of the Congo\nDjibouti\nDominica\nDominican Republic\nEcuador\nEgypt\nEl Salvador\nEquatorial Guinea\nEritrea\nEswatini\nEthiopia\nFalkland Islands (Islas Malvinas)\nFiji\nGabon\nThe Gambia\nGeorgia\nGhana\nGibraltar\nGrenada\nGuam\nGuatemala\nGuernsey\nGuinea\nGuinea-Bissau\nGuyana\nHaiti\nHeard Island and McDonald Islands\nHonduras\nIndia\nIndonesia\nIraq\nIsle of Man\nIsrael\nJamaica\nJapan\nJersey\nJordan\nKazakhstan\nKenya\nKiribati\nKyrgyzstan\nKuwait\nLaos\nLebanon\nLesotho\nLiberia\nLibya\nMadagascar\nMalawi\nMalaysia\nMaldives\nMali\nMarshall Islands\nMauritania\nMauritius\nMexico\nMicronesia\nMongolia\nMontserrat\nMorocco\nMozambique\nNamibia\nNauru\nNepal\nNew Caledonia\nNew Zealand\nNicaragua\nNiger\nNigeria\nNiue\nNorfolk Island\nNorthern Mariana Islands\nOman\nPakistan\nPalau\nPalestine\nPanama\nPapua New Guinea\nParaguay\nPeru\nPhilippines\nPitcairn Islands\nPuerto Rico\nQatar\nRepublic of the Congo\nRwanda\nSaint Barthélemy\nSaint Kitts and Nevis\nSaint Lucia\nSaint Pierre and Miquelon\nSaint Vincent and the Grenadines\nSaint Helena, Ascension and Tristan da Cunha\nSamoa\nSão Tomé and Príncipe\nSaudi Arabia\nSenegal\nSeychelles\nSierra Leone\nSingapore\nSolomon Islands\nSomalia\nSouth Africa\nSouth Georgia and the South Sandwich Islands\nSouth Korea\nSouth Sudan\nSri Lanka\nSudan\nSuriname\nTaiwan\nTajikistan\nTanzania\nThailand\nTimor-Leste\nTogo\nTokelau\nTonga\nTrinidad and Tobago\nTunisia\nTürkiye\nTurkmenistan\nTurks and Caicos Islands\nTuvalu\nUganda\nUnited Arab Emirates\nUnited States\nUnited States Minor Outlying Islands\nU.S. Virgin Islands\nUruguay\nUzbekistan\nVanuatu\nVenezuela\nVietnam\nWallis and Futuna\nWestern Sahara\nYemen\nZambia\nZimbabwe",
            "filtered_word_count": 516
        },
        "https://ai.google.dev/gemini-api/docs?hl=de#": {
            "status": "Looks good",
            "content": "Produkte\nBeispiele\nAnmelden\nDokumentation\nAPI-Referenz\nÜberblick\nJetzt starten\nAPI-Schlüssel anfordern\nGemini API – Kurzanleitung\nGoogle AI Studio – Kurzanleitung\nAnleitungen für den Einstieg\nModelle\nInformationen zu generativen Modellen\nGemini\nGemini API\nAPI-Übersicht\nAPI-Referenz\nAPI-Versionen\nVersionshinweise\nLeistungsspektrum\nModellabstimmung\nFunktionsaufruf\nEinbettungen\nSicherheit\nLeitfäden\nAufforderungen\nSystemanleitung\nSemantischer Abruf\nAuthentifizierung mit OAuth\nFirebase-Erweiterungen\nZu Cloud migrieren\nAnleitungen\nFunktionsaufruf\nEinbettungen\nAnwendungen\nProblembehebung\nTipps zur Fehlerbehebung\nÜber Workspace auf AI Studio zugreifen\nFehlerbehebung in AI Studio\nHöheres Kontingent beantragen\nCommunity\nDiskursforum\nPaLM API (alt)\nZu Gemini migrieren\nPaLM-Dokumentation\nRecht\nNutzungsbedingungen\n(Vorschau) Nutzungsbedingungen\nVerfügbare Regionen\nSehen Sie sich das neue Cookbook zur Gemini API und unser Community-Forum an.\n Diese Seite wurde von der Cloud Translation API übersetzt.\nErste Schritte mit der Gemini API \n\nGemini ist eine Familie der leistungsstärksten KI-Modelle von Google. Diese Website enthält alle Informationen, die Sie zum Erstellen von Anwendungen mit der Gemini API benötigen.\n\nGemini 1.5 Pro ist jetzt in der öffentlichen Vorschau in Google AI Studio verfügbar. Hier kannst du die Funktion ausprobieren.\n\nGoogle AI Studio \n\nAm schnellsten können Sie Gemini mit Google AI Studio einsteigen, einem webbasierten Tool, mit dem Sie Prototypen erstellen, Prompts direkt in Ihrem Browser ausführen und mit der Gemini API beginnen können.\n\nGoogle AI Studio starten\nGoogle AI Studio – Kurzanleitung\n\nRufen Sie die Kurzanleitung zur Gemini API auf.\n\nInformationen zur sicheren und verantwortungsvollen Verwendung von LLMs finden Sie in den Sicherheitseinstellungen und den Sicherheitsempfehlungen.\n\nErste Schritte mit Python\nErste Schritte mit der REST API\nErste Schritte im Web\nErste Schritte mit Go\nErste Schritte mit Node\nErste Schritte mit Android\nErste Schritte mit iOS\nErste Schritte mit Dart (Flutter)\nIn Google Cloud erstellen\nWeitere Informationen\nWeitere Informationen zu den Modellen, auf denen die Gemini API basiert, finden Sie auf der Seite Modelle.\nDie Gemini API und Google AI Studio sind derzeit in mehr als 180 Ländern verfügbar. Weitere Informationen finden Sie in der Dokumentation.\n\nSofern nicht anders angegeben, sind die Inhalte dieser Seite unter der Creative Commons Attribution 4.0 License und Codebeispiele unter der Apache 2.0 License lizenziert. Weitere Informationen finden Sie in den Websiterichtlinien von Google Developers. Java ist eine eingetragene Marke von Oracle und/oder seinen Partnern.\n\nZuletzt aktualisiert: 2024-04-23 (UTC).\n\nNutzungsbedingungen\nDatenschutz",
            "word_count": 358,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=es-419#": {
            "status": "Looks good",
            "content": "Productos\nEjemplos\nAcceder\nDocumentos\nReferencia de la API\nResumen\nComenzar\nObtén una clave de API\nGuía de inicio rápido de la API de Gemini\nGuía de inicio rápido de Google AI Studio\nInstructivos de introducción\nModelos\nAcerca de los modelos generativos\nGemini\nGemini API\nDescripción general de la API\nReferencia de la API\nVersiones de API\nNotas de la versión\nFunciones\nAjuste del modelo\nLlamada a función\nIncorporaciones\nSeguridad\nGuías\nMensajes\nInstrucciones del sistema\nRecuperación semántica\nAutenticación de OAuth\nExtensiones de Firebase\nMigra a Cloud\nInstructivos\nLlamada a función\nIncorporaciones\nAplicaciones\nSolución de problemas\nGuía de solución de problemas\nAccede a AI Studio con Workspace\nSolución de problemas de AI Studio\nCómo solicitar una cuota mayor\nComunidad\nForo del discurso\nAPI de PaLM (heredada)\nCómo migrar a Gemini\nDocumentos de PaLM\nLegal\nCondiciones del Servicio\n(vista previa) Condiciones del Servicio\nRegiones disponibles\nConsulta la nueva Guía de soluciones de la API de Gemini y nuestro foro de la comunidad.\n Se usó la API de Cloud Translation para traducir esta página.\nComienza a usar la API de Gemini \n\nGemini es una familia de modelos de IA más capaces de de Google. En este sitio, encontrarás toda la información que necesitas para comenzar a compilar aplicaciones con la API de Gemini.\n\nGemini 1.5 Pro ahora está disponible en versión preliminar pública en Google AI Studio. Pruébala ahora.\n\nGoogle AI Studio \n\nLa forma más rápida de comenzar a usar Gemini es con Google AI Studio, una herramienta basada en la Web que te permite crear prototipos, ejecutar instrucciones en el navegador y comenzar a usar la API de Gemini.\n\nIniciar Google AI Studio\nGuía de inicio rápido de Google AI Studio\n\nPara comenzar, ve a la guía de inicio rápido de la API de Gemini.\n\nPara aprender a usar los LLM de forma segura y responsable, consulta la documentación de la configuración de seguridad y la guía de seguridad.\n\nComienza a usar Python\nComienza a usar la API de REST\nComienza a usar la Web\nComienza a usar Go\nComienza a usar Node\nComienza en Android\nComienza en iOS\nCómo comenzar a usar Dart (Flutter)\nCompila en Google Cloud\nLecturas adicionales\nPara obtener más información sobre los modelos que potencian la API de Gemini, consulta la página de modelos.\nPor el momento, la API de Gemini y Google AI Studio están disponibles en más de 180 países. Consulta la documentación para obtener más información.\n\nSalvo que se indique lo contrario, el contenido de esta página está sujeto a la licencia Atribución 4.0 de Creative Commons, y los ejemplos de código están sujetos a la licencia Apache 2.0. Para obtener más información, consulta las políticas del sitio de Google Developers. Java es una marca registrada de Oracle o sus afiliados.\n\nÚltima actualización: 2024-04-23 (UTC)\n\nCondiciones\nPrivacidad",
            "word_count": 462,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=fr#": {
            "status": "Looks good",
            "content": "Produits\nExemples\nConnexion\nDocumentation\nDocument de référence de l'API\nVue d'ensemble\nPremiers pas\nObtenir une clé d'API\nGuide de démarrage rapide de l'API Gemini\nGuide de démarrage rapide de Google AI Studio\nTutoriels de démarrage\nModèles\nÀ propos des modèles génératifs\nGemini\nGemini API\nPrésentation de l'API\nDocumentation de référence des API\nVersions d'API\nNotes de version\nCapacités\nRéglage du modèle\nAppel de fonction\nReprésentations vectorielles continues\nSécurité\nGuides\nInvites\nInstructions système\nRécupération sémantique\nAuthentification OAuth\nExtensions Firebase\nMigrer vers le cloud\nTutoriels\nAppel de fonction\nReprésentations vectorielles continues\nApplications\nDépannage\nGuide de dépannage\nAccéder à AI Studio à l'aide de Workspace\nRésoudre les problèmes liés à AI Studio\nDemander plus de quotas\nCommunauté\nForum de Discourse\nAPI PaLM (ancienne version)\nMigrer vers Gemini\nDocumentation sur PaLM\nJuridique\nConditions d'utilisation\n(Preview) Conditions d'utilisation\nRégions disponibles\nDécouvrez le livre de recettes avec l'API Gemini et notre forum de la communauté.\n Cette page a été traduite par l'API Cloud Translation.\nPremiers pas avec l'API Gemini \n\nGemini est une famille de modèles d'IA Google les plus performants. Ce site contient toutes les informations dont vous avez besoin pour commencer à créer des applications avec l'API Gemini.\n\nGemini 1.5 Pro est désormais disponible en version Preview publique dans Google AI Studio. Essayer\n\nGoogle AI Studio \n\nLe moyen le plus rapide d'utiliser Gemini est d'utiliser Google AI Studio, un outil Web qui vous permet de créer des prototypes, d'exécuter des requêtes directement dans votre navigateur et de faire vos premiers pas avec l'API Gemini.\n\nLancer Google AI Studio\nGuide de démarrage rapide de Google AI Studio\n\nPour commencer, accédez au guide de démarrage rapide de l'API Gemini.\n\nPour savoir comment utiliser les LLM de manière sécurisée et responsable, consultez la documentation sur les paramètres de sécurité et les conseils de sécurité.\n\nPremiers pas avec Python\nPremiers pas avec l'API REST\nPremiers pas sur le Web\nPremiers pas avec Go\nPremiers pas avec Node\nPremiers pas sur Android\nPremiers pas sur iOS\nPremiers pas avec Dart (Flutter)\nCréer sur Google Cloud\nComplément d'informations\nPour en savoir plus sur les modèles qui alimentent l'API Gemini, consultez la page Modèles.\nL'API Gemini et Google AI Studio sont actuellement disponibles dans plus de 180 pays. Consultez la documentation pour en savoir plus.\n\nSauf indication contraire, le contenu de cette page est régi par une licence Creative Commons Attribution 4.0, et les échantillons de code sont régis par une licence Apache 2.0. Pour en savoir plus, consultez les Règles du site Google Developers. Java est une marque déposée d'Oracle et/ou de ses sociétés affiliées.\n\nDernière mise à jour le 2024/04/23 (UTC).\n\nConditions d'utilisation\nRègles de confidentialité",
            "word_count": 436,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=id#": {
            "status": "Looks good",
            "content": "Produk\nContoh\nMasuk\nDokumen\nReferensi API\nRingkasan\nMulai\nMendapatkan kunci API\nPanduan memulai Gemini API\nPanduan memulai Google AI Studio\nTutorial memulai\nModel\nTentang model generatif\nGemini\nGemini API\nRingkasan API\nReferensi API\nVersi API\nCatatan rilis\nKemampuan\nPenyesuaian model\nPanggilan fungsi\nEmbedding\nKeamanan\nPanduan\nMeminta\nPetunjuk sistem\nPengambilan semantik\nAutentikasi OAuth\nEkstensi Firebase\nBermigrasi ke Cloud\nTutorial\nPanggilan fungsi\nEmbedding\nAplikasi\nPemecahan masalah\nPanduan pemecahan masalah\nMengakses AI Studio menggunakan Workspace\nMemecahkan masalah AI Studio\nMeminta lebih banyak kuota\nKomunitas\nForum wacana\nPaLM API (lama)\nBermigrasi ke Gemini\nDokumen PaLM\nHukum\nPersyaratan layanan\nPersyaratan layanan (Pratinjau)\nRegion yang tersedia\nLihat Cookbook Gemini API baru dan forum komunitas kami.\n Halaman ini diterjemahkan oleh Cloud Translation API.\nMulai menggunakan Gemini API \n\nGemini adalah kelompok model AI Google yang paling mumpuni. Situs ini berisi semua informasi yang Anda perlukan untuk mulai membangun aplikasi dengan Gemini API.\n\nGemini 1.5 Pro kini tersedia dalam Pratinjau Publik di Google AI Studio. Coba sekarang.\n\nGoogle AI Studio \n\nCara tercepat untuk mulai menggunakan Gemini adalah dengan Google AI Studio, yakni alat berbasis web yang memungkinkan Anda membuat prototipe, menjalankan perintah langsung di browser, dan mulai menggunakan Gemini API.\n\nLuncurkan Google AI Studio\nPanduan memulai Google AI Studio\n\nUntuk memulai, buka panduan memulai Gemini API.\n\nUntuk mempelajari cara menggunakan LLM dengan aman dan bertanggung jawab, lihat dokumentasi setelan keamanan dan panduan keamanan.\n\nMulai menggunakan Python\nMulai menggunakan REST API\nMemulai di Web\nMulai menggunakan Go\nMulai menggunakan Node\nMemulai di Android\nMemulai di iOS\nMulai menggunakan Dart (Flutter)\nMembangun aplikasi di Google Cloud\nBacaan lebih lanjut\nUntuk mempelajari lebih lanjut model yang mendukung Gemini API, lihat halaman model.\nGemini API dan Google AI Studio saat ini tersedia di lebih dari 180 negara. Lihat dokumentasinya untuk mempelajari lebih lanjut.\n\nKecuali dinyatakan lain, konten di halaman ini dilisensikan berdasarkan Lisensi Creative Commons Attribution 4.0, sedangkan contoh kode dilisensikan berdasarkan Lisensi Apache 2.0. Untuk mengetahui informasi selengkapnya, lihat Kebijakan Situs Google Developers. Java adalah merek dagang terdaftar dari Oracle dan/atau afiliasinya.\n\nTerakhir diperbarui pada 2024-04-23 UTC.\n\nPersyaratan\nPrivasi",
            "word_count": 337,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=it#": {
            "status": "Looks good",
            "content": "Prodotti\nEsempi\nAccedi\nDocumenti\nRiferimento API\nPanoramica\nInizia\nOttieni una chiave API\nGuida rapida dell'API Gemini\nGuida rapida di Google AI Studio\nTutorial introduttivi\nModelli\nInformazioni sui modelli generativi\nGemini\nGemini API\nPanoramica dell'API\nRiferimento API\nVersioni API\nNote di rilascio\nFunzionalità\nOttimizzazione del modello\nChiamata di funzione\nIncorporamenti\nSicurezza\nGuide\nPrompt\nIstruzioni di sistema\nRecupero semantico\nAutenticazione OAuth\nEstensioni Firebase\nEsegui la migrazione a Cloud\nTutorial\nChiamata di funzione\nIncorporamenti\nApplicazioni\nRisoluzione dei problemi\nRisoluzione dei problemi\nAccedere ad AI Studio utilizzando Workspace\nRisoluzione dei problemi relativi ad AI Studio\nRichiedere una quota maggiore\ncommunity\nForum del discorso\nAPI PaLM (legacy)\nEsegui la migrazione a Gemini\nDocumenti PaLM\nLegale\nTermini di servizio\n(Anteprima) Termini di servizio\nAree geografiche disponibili\nDai un'occhiata al nuovo Cookbook dell'API Gemini e al nostro forum della community.\n Questa pagina è stata tradotta dall'API Cloud Translation.\nInizia a utilizzare l'API Gemini \n\nGemini è una famiglia dei modelli di IA più avanzati di Google. Questo sito contiene tutte le informazioni necessarie per iniziare a creare applicazioni con l'API Gemini.\n\nGemini 1.5 Pro è ora disponibile in Anteprima pubblica in Google AI Studio. Prova subito.\n\nGoogle AI Studio \n\nIl modo più rapido per iniziare a utilizzare Gemini è con Google AI Studio, uno strumento basato sul web che ti consente di prototipare, eseguire prompt direttamente nel browser e iniziare a utilizzare l'API Gemini.\n\nAvvia Google AI Studio\nGuida rapida di Google AI Studio\n\nPer iniziare, vai alla guida rapida dell'API Gemini.\n\nPer scoprire come utilizzare gli LLM in modo sicuro e responsabile, consulta la documentazione sulle impostazioni di sicurezza e sulle indicazioni di sicurezza.\n\nInizia a utilizzare Python\nInizia a utilizzare l'API REST\nIniziare a navigare sul web\nInizia a utilizzare Go\nInizia a utilizzare Node\nInizia su Android\nInizia su iOS\nInizia a utilizzare Dart (Flutter)\nCrea su Google Cloud\nPer approfondire\nPer saperne di più sui modelli alla base dell'API Gemini, consulta la pagina relativa ai modelli.\nL'API Gemini e Google AI Studio sono attualmente disponibili in oltre 180 paesi. Consulta la documentazione per saperne di più.\n\nSalvo quando diversamente specificato, i contenuti di questa pagina sono concessi in base alla licenza Creative Commons Attribution 4.0, mentre gli esempi di codice sono concessi in base alla licenza Apache 2.0. Per ulteriori dettagli, consulta le norme del sito di Google Developers. Java è un marchio registrato di Oracle e/o delle sue consociate.\n\nUltimo aggiornamento 2024-04-23 UTC.\n\nTermini\nPrivacy",
            "word_count": 402,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=pl#": {
            "status": "Looks good",
            "content": "Produkty\nPrzykłady\nZaloguj się\nDokumenty\nDokumentacja API\nPrzegląd\nRozpocznij\nUzyskiwanie klucza interfejsu API\nKrótkie wprowadzenie do interfejsu Gemini API\nKrótkie wprowadzenie do Google AI Studio\nSamouczki na początek\nModele\nInformacje o modelach generatywnych\nGemini\nGemini API\nPrzegląd interfejsów API\nDokumentacja API\nWersje interfejsu API\nInformacje o wersjach\nMożliwości\nDostrajanie modeli\nWywoływanie funkcji\nOsadzone elementy\nBezpieczeństwo\nPrzewodniki\nPrompt\nInstrukcje systemowe\nPobieranie semantyczne\nUwierzytelnianie OAuth\nRozszerzenia Firebase\nMigracja do Cloud\nSamouczki\nWywoływanie funkcji\nOsadzone elementy\nAplikacje\nRozwiązywanie problemów\nPrzewodnik rozwiązywania problemów\nDostęp do AI Studio za pomocą Workspace\nRozwiązywanie problemów z AI Studio\nZgłaszanie prośby o dodatkowy limit\nSpołeczność\nForum dyskusyjne\nPaLM API (starsza wersja)\nMigracja do Gemini\nDokumentacja PaLM\nLegal\nWarunki korzystania z usługi\n(Wersja testowa) Warunki korzystania z usługi\nRegiony, w których działa ta usługa\nZapoznaj się z nową książką kucharską na temat interfejsu Gemini API i poznaj nasze forum społeczności.\n Ta strona została przetłumaczona przez Cloud Translation API.\nPierwsze kroki z interfejsem Gemini API \n\nGemini to rodzina najbardziej wydajnych modeli AI Google. Ta witryna zawiera wszystkie informacje potrzebne do rozpoczęcia tworzenia aplikacji za pomocą interfejsu Gemini API.\n\nGemini 1.5 Pro jest teraz dostępny w publicznej wersji przedpremierowej w Google AI Studio. Wypróbuj teraz\n\nGoogle AI Studio \n\nNajszybszym sposobem na rozpoczęcie korzystania z Gemini jest Google AI Studio, narzędzie internetowe, które umożliwia tworzenie prototypów, uruchamianie promptów bezpośrednio w przeglądarce i rozpoczęcie korzystania z interfejsu Gemini API.\n\nUruchom Google AI Studio\nKrótkie wprowadzenie do Google AI Studio\n\nNa początek zapoznaj się z krótkim wprowadzeniem do interfejsu API Gemini.\n\nAby dowiedzieć się, jak bezpiecznie i odpowiedzialnie korzystać z LLM, zapoznaj się z ustawieniami bezpieczeństwa i dokumentacją dotyczącą wskazówek dotyczących bezpieczeństwa.\n\nPierwsze kroki z Pythonem\nPierwsze kroki z interfejsem API typu REST\nPierwsze kroki w internecie\nPierwsze kroki w Go\nWprowadzenie do węzła\nPierwsze kroki na Androidzie\nWypróbuj na iOS\nWprowadzenie do gry Dart (Flutter)\nWykorzystaj Google Cloud\nWięcej informacji\nWięcej informacji o modelach, które obsługują interfejs Gemini API, znajdziesz na stronie z modelami.\nInterfejs Gemini API i Google AI Studio są obecnie dostępne w ponad 180 krajach. Więcej informacji znajdziesz w dokumentacji.\n\nO ile nie stwierdzono inaczej, treść tej strony jest objęta licencją Creative Commons – uznanie autorstwa 4.0, a fragmenty kodu są dostępne na licencji Apache 2.0. Szczegółowe informacje na ten temat zawierają zasady dotyczące witryny Google Developers. Java jest zastrzeżonym znakiem towarowym firmy Oracle i jej podmiotów stowarzyszonych.\n\nOstatnia aktualizacja: 2024-04-23 UTC.\n\nWarunki\nPrywatność",
            "word_count": 394,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=pt-br#": {
            "status": "Looks good",
            "content": "Produtos\nExemplos\nFazer login\nDocs\nReferência da API\nVisão geral\nComeçar\nObter uma chave de API\nGuia de início rápido da API Gemini\nGuia de início rápido do Google AI Studio\nTutoriais com os primeiros passos\nModelos\nSobre modelos generativos\nGemini\nGemini API\nVisão geral da API\nReferência da API\nVersões da API\nNotas da versão\nRecursos\nAjuste do modelo\nChamadas de funções\nEmbeddings\nSegurança\nGuias\nSolicitações de prompt\nInstruções do sistema\nRecuperação semântica\nAutenticação OAuth\nExtensões do Firebase\nMigrar para o Cloud\nTutoriais\nChamadas de funções\nEmbeddings\nAplicativos\nSolução de problemas\nGuia de solução de problemas\nAcessar o AI Studio usando o Workspace\nComo solucionar problemas no AI Studio\nSolicitar mais cotas\nComunidade\nFórum do Discourse\nAPI PaLM (legada)\nMigrar para o Gêmeos\nDocumentos do PaLM\nJurídico\nTermos de Serviço\n(Prévia) Termos de Serviço\nRegiões disponíveis\nConfira o Cookbook da nova API Gemini e nosso fórum da comunidade.\n Esta página foi traduzida pela API Cloud Translation.\nComeçar a usar a API Gemini \n\nO Gemini é uma família de modelos de IA mais qualificados do Google. Este site contém todas as informações que você precisa para começar a criar aplicativos com a API Gemini.\n\nO Gemini 1.5 Pro já está disponível em Acesso antecipado no Google AI Studio. Faça um teste agora.\n\nGoogle AI Studio \n\nA maneira mais rápida de começar a usar o Gemini é com o Google AI Studio, uma ferramenta baseada na Web que permite criar protótipos, executar comandos diretamente no navegador e começar a usar a API Gemini.\n\nInicie o Google AI Studio\nGuia de início rápido do Google AI Studio\n\nPara começar, acesse o guia de início rápido da API Genmini.\n\nPara aprender a usar LLMs com segurança e responsabilidade, consulte a documentação sobre configurações de segurança e orientações de segurança.\n\nIntrodução ao Python\nPrimeiros passos com a API REST\nComeçar na Web\nComeçar a usar Go\nComeçar a usar o Node\nPrimeiros passos no Android\nPrimeiros passos no iOS\nComeçar a usar o Dart (Flutter)\nCrie no Google Cloud\nLeia mais\nPara saber mais sobre os modelos usados na API Gemini, consulte a página Modelos.\nAtualmente, a API Gemini e o Google AI Studio estão disponíveis em mais de 180 países. Confira a documentação para saber mais.\n\nExceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.\n\nÚltima atualização 2024-04-23 UTC.\n\nTermos de Serviço\nPrivacidade",
            "word_count": 438,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=vi#": {
            "status": "Looks good",
            "content": "Sản phẩm\nVí dụ\nĐăng nhập\nTài liệu\nTài liệu tham khảo API\nTổng quan\nBắt đầu\nNhận khoá API\nBắt đầu nhanh API Gemini\nHướng dẫn nhanh về Google AI Studio\nHướng dẫn bắt đầu sử dụng\nMô hình\nGiới thiệu về các mô hình tạo sinh\nGemini\nGemini API\nTổng quan về API\nTài liệu tham khảo API\nPhiên bản API\nGhi chú phát hành\nChức năng\nĐiều chỉnh mô hình\nGọi hàm\nNhúng\nAn toàn\nHướng dẫn\nNhắc nhở\nHướng dẫn hệ thống\nTruy xuất ngữ nghĩa\nXác thực OAuth\nTiện ích Firebase\nDi chuyển sang nền tảng đám mây\nHướng dẫn\nGọi hàm\nNhúng\nỨng dụng\nKhắc phục sự cố\nHướng dẫn khắc phục sự cố\nTruy cập vào AI Studio bằng Workspace\nKhắc phục sự cố với AI Studio\nYêu cầu tăng hạn mức\nCộng đồng\nDiễn đàn Discourse\nAPI PaLM (cũ)\nDi chuyển sang Gemini\nTài liệu PaLM\nPháp lý\nĐiều khoản dịch vụ\n(Bản xem trước) Điều khoản dịch vụ\nKhu vực khả dụng\nHãy khám phá Cookbook API mới và diễn đàn cộng đồng của chúng tôi.\n Trang này được dịch bởi Cloud Translation API.\nLàm quen với API Gemini \n\nGemini là một dòng mô hình AI có hiệu suất cao nhất của Google. Trang web này chứa tất cả thông tin bạn cần để bắt đầu xây dựng ứng dụng bằng API Gemini.\n\nGemini 1.5 Pro hiện đã có Bản dùng trước công khai trong Google AI Studio. Thử ngay.\n\nGoogle AI Studio \n\nCách nhanh nhất để bắt đầu sử dụng Gemini là sử dụng Google AI Studio, một công cụ dựa trên nền tảng web, cho phép bạn tạo nguyên mẫu, chạy câu lệnh ngay trong trình duyệt và bắt đầu sử dụng API Gemini.\n\nMở Google AI Studio\nHướng dẫn nhanh về Google AI Studio\n\nĐể bắt đầu, hãy chuyển đến phần hướng dẫn bắt đầu nhanh về API Gemini.\n\nĐể tìm hiểu cách sử dụng các LLM một cách an toàn và có trách nhiệm, hãy tham khảo chế độ cài đặt an toàn và hướng dẫn về an toàn.\n\nLàm quen với Python\nLàm quen với API REST\nBắt đầu trên web\nLàm quen với Go\nLàm quen với Nút\nBắt đầu trên Android\nBắt đầu trên iOS\nBắt đầu với Dart (Flutter)\nXây dựng trên Google Cloud\nTài liệu đọc thêm\nĐể tìm hiểu thêm về các mô hình hỗ trợ API Gemini, hãy tham khảo trang mô hình.\nAPI Gemini và Google AI Studio hiện có tại hơn 180 quốc gia, hãy xem tài liệu để tìm hiểu thêm.\n\nTrừ khi có lưu ý khác, nội dung của trang này được cấp phép theo Giấy phép ghi nhận tác giả 4.0 của Creative Commons và các mẫu mã lập trình được cấp phép theo Giấy phép Apache 2.0. Để biết thông tin chi tiết, vui lòng tham khảo Chính sách trang web của Google Developers. Java là nhãn hiệu đã đăng ký của Oracle và/hoặc các đơn vị liên kết với Oracle.\n\nCập nhật lần gần đây nhất: 2024-04-23 UTC.\n\nĐiều khoản\nQuyền riêng tư",
            "word_count": 520,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=tr#": {
            "status": "Looks good",
            "content": "Ürünler\nÖrnekler\nOturum aç\nDokümanlar\nAPI Referansı\nGenel bakış\nBaşlama\nAPI anahtarı alma\nGemini API hızlı başlangıç kılavuzu\nGoogle AI Studio hızlı başlangıç kılavuzu\nBaşlangıç eğiticileri\nModeller\nÜretken modeller hakkında\nGemini\nGemini API\nAPI'ye genel bakış\nAPI referansı\nAPI sürümleri\nSürüm notları\nÖzellikler\nModel ince ayarı\nİşlev çağrısı\nYerleştirmeler\nGüvenlik\nRehberler\nİstemde bulunma\nSistem talimatları\nAnlamsal alma\nOAuth kimlik doğrulaması\nFirebase uzantıları\nCloud'a taşı\nEğitimler\nİşlev çağrısı\nYerleştirmeler\nUygulamalar\nSorun giderme\nSorun giderme kılavuzu\nWorkspace'i kullanarak AI Studio'ya erişme\nAI Studio ile ilgili sorunları giderme\nDaha fazla kota isteme\nTopluluk\nTartışma forumu\nPaLM API (eski)\nGemini'a taşıyın\nPaLM belgeleri\nHukuk\nHizmet şartları\n(Önizleme) Hizmet şartları\nKullanılabildiği bölgeler\nYeni Gemini API Cookbook'una ve topluluk forumumuza göz atın.\n Bu sayfa, Cloud Translation API ile çevrilmiştir.\nGemini API'yi kullanmaya başlama \n\nGemini, Google'ın en yetenekli yapay zeka modellerinden oluşan bir ailedir. Gemini API ile uygulama derlemeye başlamak için ihtiyacınız olan tüm bilgileri bu sitede bulabilirsiniz.\n\nGemini 1.5 Pro, artık Google AI Studio'daki Genel Önizleme sürümünde kullanılabilir. Hemen deneyin.\n\nGoogle AI Studio \n\nGemini'ı kullanmaya başlamanın en hızlı yolu, prototip oluşturmanıza, doğrudan tarayıcınızda istemleri çalıştırmanıza ve Gemini API'yi kullanmaya başlamanıza olanak tanıyan web tabanlı Google AI Studio aracından yararlanmaktır.\n\nGoogle AI Studio'yu başlat\nGoogle AI Studio hızlı başlangıç kılavuzu\n\nBaşlamak için Gemini API hızlı başlangıç kılavuzu sayfasına gidin.\n\nLLM'lerin güvenli ve sorumlu bir şekilde nasıl kullanılacağını öğrenmek için güvenlik ayarları ve güvenlik kılavuzu belgelerini inceleyin.\n\nPython'u kullanmaya başlayın\nREST API'yi kullanmaya başlama\nWeb'i kullanmaya başlayın\nGo'yu kullanmaya başlama\nDüğüm kullanmaya başlayın\nAndroid'i kullanmaya başlama\niOS kullanmaya başlayın\nDart'ı (Flutter) kullanmaya başlama\nGoogle Cloud'da geliştirin\nDaha fazla bilgi\nGemini API'yi destekleyen modeller hakkında daha fazla bilgi edinmek için modeller sayfasına bakın.\nGemini API ve Google AI Studio şu anda 180'den fazla ülkede kullanılabilir. Daha fazla bilgi için belgelere göz atın.\n\nAksi belirtilmediği sürece bu sayfanın içeriği Creative Commons Atıf 4.0 Lisansı altında ve kod örnekleri Apache 2.0 Lisansı altında lisanslanmıştır. Ayrıntılı bilgi için Google Developers Site Politikaları'na göz atın. Java, Oracle ve/veya satış ortaklarının tescilli ticari markasıdır.\n\nSon güncelleme tarihi: 2024-04-23 UTC.\n\nŞartlar\nGizlilik",
            "word_count": 337,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=ru#": {
            "status": "Looks good",
            "content": "Продукты\nПримеры\nВойти\nДокументы\nДокументация по API\nОбзор\nНачало работы\nПолучить ключ API\nКраткое руководство по API Gemini\nКраткое руководство по Google AI Studio\nУчебники по началу работы\nМодели\nО генеративных моделях\nGemini\nGemini API\nОбзор API\nСправочник по API\nВерсии API\nПримечания к выпускам\nВозможности, Возможности\nТюнинг модели\nВызов функции\nВложения\nБезопасность\nПутеводители\nПодсказка\nСистемные инструкции\nСемантический поиск\nOAuth-аутентификация\nРасширения Firebase\nМиграция в облако\nРуководства\nВызов функции\nВложения\nПриложения\nУстранение неполадок\nРуководство по устранению неполадок\nДоступ к AI Studio с помощью Workspace\nУстранение неполадок AI Studio\nКак увеличить квоту\nСообщество\nДискурс-форум\nPaLM API (устаревший)\nПерейти на Близнецы\nДокументы ПалМ\nЮридический\nУсловия использования\n(Предварительная версия) Условия использования\nДоступные регионы\nОзнакомьтесь с новой кулинарной книгой Gemini API и форумом нашего сообщества .\n Эта страница переведена с помощью Cloud Translation API.\nНачните работу с API Gemini \n\nGemini — это семейство самых эффективных моделей искусственного интеллекта от Google. Этот сайт содержит всю информацию, необходимую для начала создания приложений с помощью Gemini API.\n\nGemini 1.5 Pro теперь доступен в общедоступной предварительной версии в Google AI Studio. Попробуй это сейчас .\n\nGoogle AI Studio \n\nСамый быстрый способ начать использовать Gemini — использовать Google AI Studio , веб-инструмент, который позволяет создавать прототипы, запускать подсказки прямо в браузере и начинать работу с Gemini API.\n\nЗапустите Google AI Studio.\nКраткое руководство по Google AI Studio\n\nЧтобы начать, перейдите к краткому руководству Gemini API .\n\nЧтобы узнать, как безопасно и ответственно использовать LLM, обратитесь к настройкам безопасности и документации по безопасности .\n\nНачать работу с Python\nНачало работы с REST API\nНачало работы в Интернете\nНачните работу с Go\nНачало работы с Node\nНачать работу на Android\nНачать работу на iOS\nНачните работу с Dart (Flutter)\nИспользуйте Google Cloud\nдальнейшее чтение\nЧтобы узнать больше о моделях, на которых работает Gemini API, посетите страницу моделей .\nGemini API и Google AI Studio в настоящее время доступны более чем в 180 странах. Чтобы узнать больше, ознакомьтесь с документацией.\n\nЕсли не указано иное, контент на этой странице предоставляется по лицензии Creative Commons \"С указанием авторства 4.0\", а примеры кода – по лицензии Apache 2.0. Подробнее об этом написано в правилах сайта. Java – это зарегистрированный товарный знак корпорации Oracle и ее аффилированных лиц.\n\nПоследнее обновление: 2024-04-23 UTC.\n\nУсловия использования\nКонфиденциальность",
            "word_count": 368,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=he#": {
            "status": "Looks good",
            "content": "מוצרים\nדוגמאות\nהיכנס\nמסמכים\nהפניית API\nסקירה כללית\nשנתחיל?\nקבלת מפתח API\nהמדריך למתחילים של Gemini API\nהמדריך למתחילים של Google AI Studio\nמדריכים לתחילת העבודה\nדגמים\nמידע על מודלים גנרטיביים\nGemini\nGemini API\nסקירה כללית בנושא API\nהפניית API\nגרסאות API\nהערות מוצר\nיכולות\nכוונון של מודל\nהפעלת פונקציה\nהטמעות\nסייפטי\nמדריכים\nהנחיות\nהוראות המערכת\nאחזור סמנטי\nאימות OAuth\nתוספי Firebase\nהעברה לענן\nמדריכים\nהפעלת פונקציה\nהטמעות\nאפליקציות\nפתרון בעיות\nמדריך לפתרון בעיות\nגישה ל-AI Studio באמצעות Workspace\nפתרון בעיות ב-AI Studio\nבקשה למכסה נוספת\nקהילה\nפורום דיונים\nPaLM API (קודם)\nמעבר ל-Gemini\nמסמכי PaLM\nמשפטי\nתנאים והגבלות\n(תצוגה מקדימה) תנאים והגבלות\nאזורים זמינים\nכדאי לעיין בספר הבישול החדש של Gemini API ובפורום הקהילה שלנו.\n דף זה תורגם על ידי Cloud Translation API.\nתחילת השימוש ב-Gemini API \n\nGemini הם משפחה של דגמי ה-AI המתקדמים ביותר של Google. אתר זה מכיל את כל המידע הדרוש כדי להתחיל לפתח אפליקציות באמצעות Gemini API.\n\nGemini 1.5 Pro זמין עכשיו בתוכנית Public Preview ב-Google AI Studio. כדאי לנסות עכשיו.\n\nGoogle AI Studio \n\nהדרך המהירה ביותר להתחיל להשתמש ב-Gemini היא באמצעות Google AI Studio, כלי מבוסס-אינטרנט שמאפשר ליצור אב-טיפוס, להריץ הנחיות ישירות בדפדפן ולהתחיל להשתמש ב-Gemini API.\n\nהפעלת Google AI Studio\nהמדריך למתחילים של Google AI Studio\n\nכדי להתחיל, כדאי להיכנס אל המדריך למתחילים של Gemini API.\n\nכדי להבין איך להשתמש ב-LLM בצורה בטוחה ואחראית, אפשר לעיין בהגדרות הבטיחות ובהנחיות הבטיחות.\n\nתחילת העבודה עם Python\nתחילת השימוש ב-API ל-REST\nתחילת העבודה באינטרנט\nתחילת העבודה עם Go\nתחילת העבודה עם Node\nתחילת העבודה ב-Android\nתחילת העבודה ב-iOS\nתחילת העבודה עם Dut (Flutter)\nפיתוח ב-Google Cloud\nקריאה נוספת\nמידע נוסף על המודלים שמפעילים את Gemini API זמין בדף מודלים.\nGemini API ו-Google AI Studio זמינים כרגע ביותר מ-180 מדינות. אפשר לקרוא מידע נוסף במסמכי התיעוד.\n\nאלא אם צוין אחרת, התוכן של דף זה הוא ברישיון Creative Commons Attribution 4.0 ודוגמאות הקוד הן ברישיון Apache 2.0. לפרטים, ניתן לעיין במדיניות האתר Google Developers‏.‏ Java הוא סימן מסחרי רשום של חברת Oracle ו/או של השותפים העצמאיים שלה.\n\nעדכון אחרון: 2024-04-23 (שעון UTC).\n\nתנאים\nפרטיות",
            "word_count": 336,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=ar#": {
            "status": "Looks good",
            "content": "المنتجات\nأمثلة\nتسجيل الدخول\nالمستندات\nمرجع واجهة برمجة تطبيقات\nنظرة عامة\nالبدء\nالحصول على مفتاح واجهة برمجة التطبيقات\nالبدء السريع لواجهة برمجة تطبيقات Gemini\nدليل البدء السريع لاستخدام Google AI Studio\nالبرامج التعليمية للبدء\nالنماذج\nلمحة عن النماذج التوليدية\nGemini\nGemini API\nنظرة عامة على واجهة برمجة التطبيقات\nمرجع واجهة برمجة التطبيقات\nإصدارات واجهة برمجة التطبيقات\nملاحظات الإصدار\nالإمكانيات\nضبط النموذج\nاستدعاء الدوالّ\nعمليات التضمين\nدفاع\nالأدلة\nجارٍ الطلب\nتعليمات النظام\nالاسترجاع الدلالي\nمصادقة OAuth\nإضافات Firebase\nنقل البيانات إلى السحابة الإلكترونية\nالبرامج التعليمية\nاستدعاء الدوالّ\nعمليات التضمين\nالتطبيقات\nتحديد المشاكل وحلّها\nدليل تحديد المشاكل وحلّها\nالوصول إلى AI Studio باستخدام Workspace\nتحديد المشاكل في AI Studio وحلّها\nطلب المزيد من الحصص\nفعالية مجتمعية\nمنتدى الحوار\nPaLM API (الإصدار القديم)\nالانتقال إلى حساب Gemini\nمستندات PaLM\nشؤون قانونية\nبنود الخدمة\n(معاينة) بنود الخدمة\nالمناطق المتاحة\nاطّلِع على دليل Gemini API الجديد والمنتدى الخاص بنا.\n تمت ترجمة هذه الصفحة بواسطة Cloud Translation API‏.\nبدء استخدام Gemini API \n\nGemini هي مجموعة من طُرز الذكاء الاصطناعي الأكثر تطوّرًا من Google. يحتوي هذا الموقع الإلكتروني على جميع المعلومات التي تحتاج إليها لبدء إنشاء التطبيقات باستخدام Gemini API.\n\nيتوفر Gemini 1.5 Pro الآن في برنامج \"الميزات التجريبية المتاحة للجميع\" في \"استوديو Google AI Studio\". التجربة الآن\n\nGoogle AI Studio \n\nإنّ أسرع طريقة لبدء استخدام Gemini هي من خلال استوديو Google AI Studio، وهي أداة مستندة إلى الويب تتيح لك إنشاء نماذج أولية وتشغيل الطلبات مباشرةً من متصفحك وبدء استخدام Gemini API.\n\nفتح Google AI Studio\nدليل البدء السريع لاستخدام Google AI Studio\n\nللبدء، انتقِل إلى البدء السريع لواجهة برمجة تطبيقات Gemini API.\n\nللتعرّف على كيفية استخدام النماذج اللغوية الكبيرة بأمان ومسؤولية، يمكنك الاطّلاع على مستندات إعدادات الأمان وإرشادات السلامة.\n\nبدء استخدام بايثون\nبدء استخدام REST API\nالبدء على الويب\nبدء استخدام Go\nبدء استخدام Node\nالبدء على Android\nالبدء على نظام التشغيل iOS\nبدء استخدام Dart (Flutter)\nإنشاء التطبيقات باستخدام Google Cloud\nمحتوى إضافي للقراءة\nللاطّلاع على مزيد من المعلومات حول التصاميم التي تستند إليها واجهة Gemini API، يمكنك مراجعة صفحة النماذج.\nتتوفر واجهة Gemini API وGoogle AI Studio حاليًا في أكثر من 180 بلدًا، ويمكنك الاطّلاع على المستندات للحصول على مزيد من المعلومات.\n\nإنّ محتوى هذه الصفحة مرخّص بموجب ترخيص Creative Commons Attribution 4.0‏ ما لم يُنصّ على خلاف ذلك، ونماذج الرموز مرخّصة بموجب ترخيص Apache 2.0‏. للاطّلاع على التفاصيل، يُرجى مراجعة سياسات موقع Google Developers‏. إنّ Java هي علامة تجارية مسجَّلة لشركة Oracle و/أو شركائها التابعين.\n\nتاريخ التعديل الأخير: 2024-04-23 (حسب التوقيت العالمي المتفَّق عليه)\n\nالبنود\nالخصوصية",
            "word_count": 404,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=fa#": {
            "status": "Looks good",
            "content": "محصولات\nمثال ها\nورود به برنامه\nاسناد\nمرجع API\nبررسی اجمالی\nشروع کنید\nیک کلید API دریافت کنید\nGemini API شروع سریع\nشروع سریع استودیوی هوش مصنوعی گوگل\nآموزش های شروع\nمدل ها\nدرباره مدل های مولد\nGemini\nGemini API\nنمای کلی API\nمرجع API\nنسخه های API\nیادداشت های انتشار\nقابلیت ها، قابلیت ها\nتیونینگ مدل\nفراخوانی تابع\nجاسازی ها\nایمنی\nراهنماها\nتحریک کردن\nدستورالعمل های سیستم\nبازیابی معنایی\nاحراز هویت OAuth\nافزونه های Firebase\nمهاجرت به ابر\nآموزش ها\nفراخوانی تابع\nجاسازی ها\nبرنامه های کاربردی\nعیب یابی\nراهنمای عیب یابی\nبا استفاده از Workspace به AI Studio دسترسی پیدا کنید\nعیب یابی AI Studio\nدرخواست سهمیه بیشتر\nانجمن\nانجمن گفتمان\nPalm API (میراث)\nبه جمینی مهاجرت کنید\nاسناد PalM\nمجاز\nشرایط استفاده از خدمات\n(پیش نمایش) شرایط خدمات\nمناطق در دسترس\nکتاب آشپزی جدید Gemini API و انجمن انجمن ما را بررسی کنید.\n این صفحه به‌وسیله ‏Cloud Translation API‏ ترجمه شده است.\nبا Gemini API شروع کنید \n\nجمینی خانواده ای از توانمندترین مدل های هوش مصنوعی گوگل است. این سایت حاوی تمام اطلاعاتی است که برای شروع ساختن اپلیکیشن با Gemini API نیاز دارید.\n\nGemini 1.5 Pro اکنون در پیش نمایش عمومی در Google AI Studio در دسترس است. الآن امتحانش کن .\n\nGoogle AI Studio \n\nسریع‌ترین راه برای شروع استفاده از Gemini، استفاده از Google AI Studio است، ابزاری مبتنی بر وب که به شما امکان می‌دهد نمونه‌سازی اولیه کنید، درخواست‌ها را مستقیماً در مرورگر خود اجرا کنید و با Gemini API شروع کنید.\n\nGoogle AI Studio را راه اندازی کنید\nشروع سریع استودیوی هوش مصنوعی گوگل\n\nبرای شروع، به Gemini API Quickstart بروید.\n\nبرای یادگیری نحوه استفاده ایمن و مسئولانه از LLM، به تنظیمات ایمنی و مستندات راهنمای ایمنی مراجعه کنید.\n\nبا پایتون شروع کنید\nبا REST API شروع کنید\nدر وب شروع کنید\nبا Go شروع کنید\nبا Node شروع کنید\nدر اندروید شروع کنید\nدر iOS شروع کنید\nبا دارت (فلاتر) شروع کنید\nساخت بر روی Google Cloud\nبیشتر خواندن\nبرای کسب اطلاعات بیشتر در مورد مدل هایی که API Gemini را تامین می کنند، به صفحه مدل ها مراجعه کنید.\nGemini API و Google AI Studio در حال حاضر در بیش از 180 کشور در دسترس هستند، برای کسب اطلاعات بیشتر، مستندات را بررسی کنید.\n\nجز در مواردی که غیر از این ذکر شده باشد،‌محتوای این صفحه تحت مجوز Creative Commons Attribution 4.0 License است. نمونه کدها نیز دارای مجوز Apache 2.0 License است. برای اطلاع از جزئیات، به خطمشی‌های سایت Google Developers‏ مراجعه کنید. جاوا علامت تجاری ثبت‌شده Oracle و/یا شرکت‌های وابسته به آن است.\n\nتاریخ آخرین به‌روزرسانی 2024-04-23 به‌وقت ساعت هماهنگ جهانی.\n\nشرایط\nحریم خصوصی",
            "word_count": 435,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=hi#": {
            "status": "Looks good",
            "content": "प्रॉडक्ट\nउदाहरण\nप्रवेश करें\nDocs\nएपीआई का संदर्भ\nखास जानकारी\nशुरू करें\nएपीआई पासकोड पाएं\nGemini API क्विकस्टार्ट\nGoogle AI Studio क्विकस्टार्ट\nट्यूटोरियल शुरू करना\nमॉडल\nजनरेटिव मॉडल के बारे में जानकारी\nGemini\nGemini API\nएपीआई के बारे में खास जानकारी\nएपीआई का संदर्भ\nएपीआई वर्शन\nप्रॉडक्ट की जानकारी\nमिलने वाली अनुमतियां\nमॉडल ट्यूनिंग\nफ़ंक्शन कॉल करने की सुविधा\nएम्बेड करना\nसुरक्षा\nगाइड\nप्रॉम्प्ट करना\nसिस्टम से जुड़े निर्देश\nसिमैंटिक रिकवरी\nOAuth प्रमाणीकरण\nFirebase एक्सटेंशन\nCloud पर माइग्रेट करें\nट्यूटोरियल\nफ़ंक्शन कॉल करने की सुविधा\nएम्बेड करना\nऐप्लिकेशन\nसमस्या का हल\nसमस्या हल करने के लिए गाइड\nWorkspace की मदद से एआई स्टूडियो को ऐक्सेस करना\nAI Studio से जुड़ी समस्याएं हल करना\nअनुरोध भेजने की सीमा बढ़ाने का अनुरोध करना\nकम्यूनिटी\nबातचीत के लिए फ़ोरम\nPaLM API (लेगसी)\nGemini में माइग्रेट करें\nPaLM के दस्तावेज़\nकानूनी\nसेवा की शर्तें\n(झलक) सेवा की शर्तें\nउपलब्ध क्षेत्र\nनया Gemini API कुकबुक और हमारा कम्यूनिटी फ़ोरम देखें.\n इस पेज का अनुवाद Cloud Translation API से किया गया है.\nGemini API का इस्तेमाल शुरू करना \n\nGemini, Google के सबसे ज़्यादा कारगर एआई मॉडल का फ़ैमिली ग्रुप है. इस साइट में वह सारी जानकारी मौजूद है जो Gemini API की मदद से ऐप्लिकेशन बनाने के लिए ज़रूरी है.\n\nGoogle AI Studio में, Gemini 1.5 Pro अब Public Preview में उपलब्ध है. इसे अभी आज़माएं.\n\nGoogle AI Studio \n\nGemini का इस्तेमाल तेज़ी से शुरू करने के लिए, Google AI Studio का इस्तेमाल करें. यह वेब पर आधारित टूल है. इसकी मदद से प्रोटोटाइप बनाया जा सकता है, सीधे अपने ब्राउज़र में प्रॉम्प्ट चलाए जा सकते हैं, और Gemini API का इस्तेमाल किया जा सकता है.\n\nGoogle AI Studio लॉन्च करें\nGoogle AI Studio क्विकस्टार्ट\n\nशुरू करने के लिए, Gemini API क्विकस्टार्ट पर जाएं.\n\nएलएलएम का सुरक्षित और ज़िम्मेदारी के साथ इस्तेमाल करने के बारे में जानने के लिए, सुरक्षा सेटिंग और सुरक्षा से जुड़े दिशा-निर्देश वाले दस्तावेज़ देखें.\n\nPython का इस्तेमाल शुरू करना\nREST API का इस्तेमाल शुरू करना\nवेब पर इस्तेमाल शुरू करना\nGo के साथ शुरू करें\nNode का इस्तेमाल शुरू करें\nAndroid पर इस्तेमाल शुरू करना\niOS पर इस्तेमाल करना शुरू करें\nDart (Flutter) के साथ शुरू करना\nGoogle Cloud पर बनाएं\nइसके बारे में और पढ़ें\nGemini API को बेहतर बनाने वाले मॉडल के बारे में ज़्यादा जानने के लिए, मॉडल पेज देखें.\nफ़िलहाल, Gemini API और Google AI Studio 180 से ज़्यादा देशों में उपलब्ध हैं. ज़्यादा जानने के लिए दस्तावेज़ देखें.\n\nजब तक कुछ अलग से न बताया जाए, तब तक इस पेज की सामग्री को Creative Commons Attribution 4.0 License के तहत और कोड के नमूनों को Apache 2.0 License के तहत लाइसेंस मिला है. ज़्यादा जानकारी के लिए, Google Developers साइट नीतियां देखें. Oracle और/या इससे जुड़ी हुई कंपनियों का, Java एक रजिस्टर किया हुआ ट्रेडमार्क है.\n\nआखिरी बार 2024-04-23 (UTC) को अपडेट किया गया.\n\nशर्तें\nनिजता",
            "word_count": 470,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=bn#": {
            "status": "Looks good",
            "content": "পণ্য\nউদাহরণ\nসাইন-ইন করুন\nডক্স\nAPI রেফারেন্স\nওভারভিউ\nএবার শুরু করা যাক\nএকটি API কী পান\nজেমিনি API কুইকস্টার্ট\nগুগল এআই স্টুডিও দ্রুত শুরু\nটিউটোরিয়াল শুরু করা হচ্ছে\nমডেল\nজেনারেটিভ মডেল সম্পর্কে\nGemini\nGemini API\nAPI ওভারভিউ\nAPI রেফারেন্স\nAPI সংস্করণ\nঅব্যাহতি পত্র\nক্ষমতা, ক্ষমতা\nমডেল টিউনিং\nফাংশন কলিং\nএমবেডিং\nনিরাপত্তা\nগাইড\nপ্রম্পটিং\nসিস্টেম নির্দেশাবলী\nশব্দার্থিক পুনরুদ্ধার\nOAuth প্রমাণীকরণ\nফায়ারবেস এক্সটেনশন\nক্লাউডে মাইগ্রেট করুন\nটিউটোরিয়াল\nফাংশন কলিং\nএমবেডিং\nঅ্যাপ্লিকেশন\nসমস্যা সমাধান\nসমস্যা সমাধানের গাইড\nওয়ার্কস্পেস ব্যবহার করে এআই স্টুডিও অ্যাক্সেস করুন\nএআই স্টুডিওর সমস্যা সমাধান করা হচ্ছে\nআরো কোটা অনুরোধ\nসম্প্রদায়\nডিসকোর্স ফোরাম\nPaLM API (উত্তরাধিকার)\nমিথুন রাশিতে চলে যান\nPaLM ডক্স\nআইনি\nসেবা পাবার শর্ত\n(প্রিভিউ) পরিষেবার শর্তাবলী\nউপলব্ধ অঞ্চল\nনতুন জেমিনি API কুকবুক এবং আমাদের কমিউনিটি ফোরাম দেখুন।\n এই পৃষ্ঠাটি Cloud Translation API অনুবাদ করেছে।\nGemini API দিয়ে শুরু করুন \n\nGemini হল Google এর সবচেয়ে সক্ষম AI মডেলের একটি পরিবার। জেমিনি এপিআই-এর সাহায্যে অ্যাপ্লিকেশান তৈরি করা শুরু করার জন্য আপনার প্রয়োজনীয় সমস্ত তথ্য এই সাইটে রয়েছে৷\n\nGemini 1.5 Pro এখন Google AI স্টুডিওতে পাবলিক প্রিভিউতে পাওয়া যাচ্ছে। এটা এখন চেষ্টা কর .\n\nGoogle AI Studio \n\nGemini ব্যবহার শুরু করার দ্রুততম উপায় হল Google AI Studio , একটি ওয়েব-ভিত্তিক টুল যা আপনাকে প্রোটোটাইপ করতে দেয়, সরাসরি আপনার ব্রাউজারে প্রম্পট চালাতে এবং Gemini API দিয়ে শুরু করতে দেয়।\n\nগুগল এআই স্টুডিও চালু করুন\nগুগল এআই স্টুডিও দ্রুত শুরু\n\nশুরু করতে, Gemini API quickstart- এ যান।\n\nকীভাবে নিরাপদে এবং দায়িত্বের সাথে LLM ব্যবহার করবেন তা শিখতে, নিরাপত্তা সেটিংস এবং নিরাপত্তা নির্দেশিকা ডকুমেন্টেশন পড়ুন।\n\nপাইথন দিয়ে শুরু করুন\nREST API দিয়ে শুরু করুন\nওয়েবে শুরু করুন\nGo দিয়ে শুরু করুন\nনোড দিয়ে শুরু করুন\nAndroid এ শুরু করুন\niOS এ শুরু করুন\nডার্ট দিয়ে শুরু করুন (ফ্লাটার)\nGoogle ক্লাউডে তৈরি করুন\nআরও পড়া\nজেমিনি APIকে শক্তি দেয় এমন মডেলগুলি সম্পর্কে আরও জানতে, মডেল পৃষ্ঠাটি পড়ুন৷\nGemini API এবং Google AI স্টুডিও বর্তমানে 180+ দেশে উপলব্ধ, আরও জানতে ডকুমেন্টেশন দেখুন।\n\nঅন্য কিছু উল্লেখ না করা থাকলে, এই পৃষ্ঠার কন্টেন্ট Creative Commons Attribution 4.0 License-এর অধীনে এবং কোডের নমুনাগুলি Apache 2.0 License-এর অধীনে লাইসেন্স প্রাপ্ত। আরও জানতে, Google Developers সাইট নীতি দেখুন। Java হল Oracle এবং/অথবা তার অ্যাফিলিয়েট সংস্থার রেজিস্টার্ড ট্রেডমার্ক।\n\n2024-04-23 UTC-তে শেষবার আপডেট করা হয়েছে।\n\nশর্তাবলী\nগোপনীয়তা",
            "word_count": 355,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=th#": {
            "status": "Looks good",
            "content": "ผลิตภัณฑ์\nตัวอย่าง\nลงชื่อเข้าใช้\nเอกสาร\nเอกสารอ้างอิง API\nภาพรวม\nเริ่มต้น\nรับคีย์ API\nการเริ่มต้นใช้งาน Gemini API อย่างรวดเร็ว\nคู่มือเริ่มใช้งาน Google AI Studio อย่างรวดเร็ว\nบทแนะนําสําหรับเริ่มต้นใช้งาน\nรูปแบบ\nเกี่ยวกับโมเดล Generative\nGemini\nGemini API\nภาพรวม API\nเอกสารอ้างอิง API\nเวอร์ชัน API\nบันทึกประจำรุ่น\nความสามารถ\nการปรับแต่งโมเดล\nการเรียกใช้ฟังก์ชัน\nการฝัง\nความปลอดภัย\nคำแนะนำ\nข้อความแจ้ง\nวิธีการสำหรับระบบ\nการดึงข้อมูลความหมาย\nการตรวจสอบสิทธิ์ OAuth\nส่วนขยาย Firebase\nย้ายข้อมูลไปยังระบบคลาวด์\nบทแนะนำ\nการเรียกใช้ฟังก์ชัน\nการฝัง\nแอปพลิเคชัน\nการแก้ปัญหา\nคู่มือการแก้ปัญหา\nเข้าถึง AI Studio โดยใช้ Workspace\nการแก้ปัญหาเกี่ยวกับ AI Studio\nขอเพิ่มโควต้า\nชุมชน\nฟอรัมสนทนา\nPaLM API (เดิม)\nย้ายข้อมูลไปยัง Gemini\nเอกสาร PaLM\nกฎหมาย\nข้อกำหนดในการให้บริการ\n(ตัวอย่าง) ข้อกำหนดในการให้บริการ\nภูมิภาคที่สามารถใช้บริการได้\nดูตำราอาหาร Gemini API และฟอรัมชุมชนของเรา\n หน้านี้ได้รับการแปลโดย Cloud Translation API\nเริ่มต้นใช้งาน Gemini API \n\nGemini เป็นกลุ่มโมเดล AI ที่มีความสามารถมากที่สุดของ Google เว็บไซต์นี้มีข้อมูลทั้งหมดที่จำเป็นต่อการสร้างแอปพลิเคชันด้วย Gemini API\n\nGemini 1.5 Pro พร้อมให้ใช้งานในเวอร์ชันตัวอย่างแบบสาธารณะใน Google AI Studio แล้ว ลองใช้เลย\n\nGoogle AI Studio \n\nวิธีที่เร็วที่สุดในการเริ่มใช้ Gemini คือ Google AI Studio ซึ่งเป็นเครื่องมือบนเว็บที่ช่วยให้คุณสร้างต้นแบบ เรียกใช้พรอมต์ในเบราว์เซอร์ได้โดยตรง และเริ่มต้นใช้งาน Gemini API\n\nเปิด Google AI Studio\nคู่มือเริ่มใช้งาน Google AI Studio อย่างรวดเร็ว\n\nหากต้องการเริ่มต้นใช้งาน ให้ไปที่การเริ่มต้นอย่างรวดเร็วสำหรับ Gemini API\n\nหากต้องการดูวิธีใช้ LLM อย่างปลอดภัยและมีความรับผิดชอบ โปรดอ่านเอกสารการตั้งค่าความปลอดภัยและคำแนะนำด้านความปลอดภัย\n\nเริ่มต้นใช้งาน Python\nเริ่มต้นใช้งาน REST API\nเริ่มต้นใช้งานบนเว็บ\nเริ่มต้นใช้งาน Go\nเริ่มต้นใช้งานโหนด\nเริ่มต้นใช้งานบน Android\nเริ่มต้นใช้งานบน iOS\nเริ่มต้นใช้งาน Dart (Flutter)\nสร้างบน Google Cloud\nอ่านเพิ่มเติม\nดูข้อมูลเพิ่มเติมเกี่ยวกับโมเดลที่ขับเคลื่อน Gemini API ได้ที่หน้ารุ่น\nขณะนี้ Gemini API และ Google AI Studio มีให้บริการในกว่า 180 ประเทศ โปรดอ่านเอกสารประกอบเพื่อดูข้อมูลเพิ่มเติม\n\nเนื้อหาของหน้าเว็บนี้ได้รับอนุญาตภายใต้ใบอนุญาตที่ต้องระบุที่มาของครีเอทีฟคอมมอนส์ 4.0 และตัวอย่างโค้ดได้รับอนุญาตภายใต้ใบอนุญาต Apache 2.0 เว้นแต่จะระบุไว้เป็นอย่างอื่น โปรดดูรายละเอียดที่นโยบายเว็บไซต์ Google Developers Java เป็นเครื่องหมายการค้าจดทะเบียนของ Oracle และ/หรือบริษัทในเครือ\n\nอัปเดตล่าสุด 2024-04-23 UTC\n\nข้อกำหนด\nความเป็นส่วนตัว",
            "word_count": 188,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=zh-cn#": {
            "status": "Looks good",
            "content": "产品\n示例\n登录\n文档\nAPI 参考文档\n概览\n开始使用\n获取 API 密钥\nGemini API 快速入门\nGoogle AI Studio 快速入门\n入门教程\n模型\n生成模型简介\nGemini\nGemini API\nAPI 概览\nAPI 参考\nAPI 版本\n版本说明\n功能\n模型调整\n函数调用\nEmbeddings\n安全\n指南\n提示\n系统说明\n语义检索\nOAuth 身份验证\nFirebase Extensions\n迁移到云端\n教程\n函数调用\nEmbeddings\n应用\n问题排查\n问题排查指南\n使用 Workspace 访问 AI Studio\n排查 AI Studio 问题\n申请增加配额\n社区\n对话论坛\nPaLM API（旧版）\n迁移到 Gemini\nPaLM 文档\n法律\n服务条款\n（预览版）服务条款\n可用区域\n查看全新 Gemini API 实战宝典和我们的社区论坛。\n 此页面由 Cloud Translation API 翻译。\nGemini API 使用入门 \n\nGemini 是 Google 功能最强大的 AI 模型系列。此网站包含您开始使用 Gemini API 构建应用所需的全部信息。\n\nGemini 1.5 Pro 现已在 Google AI Studio 中提供公开预览版。立即试用。\n\nGoogle AI Studio \n\n最快速开始使用 Gemini 的方法是 Google AI Studio，这是一款基于网络的工具，可让您直接在浏览器中设计原型、运行提示并开始使用 Gemini API。\n\n启动 Google AI Studio\nGoogle AI Studio 快速入门\n\n要开始使用，请转到 Gemini API 快速入门。\n\n如需了解如何安全、负责任地使用 LLM，请参阅安全设置和安全指南文档。\n\nPython 使用入门\n开始使用 REST API\n开始网页版\nGo 使用入门\nNode 使用入门\n适用于 Android 的使用入门\n适用于 iOS 的使用入门\nDart 使用入门 (Flutter)\n在 Google Cloud 上构建\n深入阅读\n如需详细了解为 Gemini API 提供支持的模型，请参阅模型页面。\nGemini API 和 Google AI Studio 目前可在 180 多个国家/地区使用，请查看相关文档了解详情。\n\n如未另行说明，那么本页面中的内容已根据知识共享署名 4.0 许可获得了许可，并且代码示例已根据 Apache 2.0 许可获得了许可。有关详情，请参阅 Google 开发者网站政策。Java 是 Oracle 和/或其关联公司的注册商标。\n\n最后更新时间 (UTC)：2024-04-23。\n\n条款\n隐私权政策",
            "word_count": 179,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=zh-tw#": {
            "status": "Looks good",
            "content": "產品\n範例\n登入\n文件\nAPI 參考資料\n總覽\n開始轉接\n取得 API 金鑰\nGemini API 快速入門導覽課程\nGoogle AI Studio 快速入門導覽課程\n入門教學課程\n模型\n關於生成式模型\nGemini\nGemini API\nAPI 總覽\nAPI 參考資料\nAPI 版本\n版本資訊\n功能\n模型調整\n函式呼叫\n嵌入\n安全分\n指南\n提示\n系統操作說明\n語意擷取\nOAuth 驗證\nFirebase 擴充功能\n遷移至 Cloud\n教學課程\n函式呼叫\n嵌入\n應用程式\n疑難排解\n疑難排解指南\n使用 Workspace 存取 AI Studio\nAI Studio 疑難排解\n要求提高配額\n社群\n討論論壇\nPaLM API (舊版)\n遷移至 Gemini\nPaLM 文件\nLegal\n服務條款\n(預先發布版) 服務條款\n可用地區\n有興趣看看全新的 Gemini API 教戰手冊和我們的社群論壇。\n 本頁面由 Cloud Translation API 翻譯而成。\n開始使用 Gemini API \n\nGemini 是 Google 功能最強大的 AI 模型系列，這個網站提供了開始使用 Gemini API 建構應用程式所需的一切資訊。\n\nGoogle AI Studio 的公開測試版現已支援 Gemini 1.5 Pro。立即試用。\n\nGoogle AI Studio \n\n如要開始使用 Gemini，最快的方法是透過 Google AI Studio 這項網頁式工具。這項工具可讓您設計原型、直接在瀏覽器中執行提示，並開始使用 Gemini API。\n\n啟動 Google AI Studio\nGoogle AI Studio 快速入門導覽課程\n\n如要開始使用，請前往 Gemini API 快速入門導覽課程。\n\n如要瞭解如何以負責任的方式使用 LLM，請參閱安全性設定和安全指南說明文件。\n\n開始使用 Python\n開始使用 REST API\n開始使用網頁版\n開始使用 Go\n開始使用節點\n開始使用 Android\n開始使用 iOS 裝置\n開始使用 Dart (Flutter)\n在 Google Cloud 中建構\n其他資訊\n如要進一步瞭解採用 Gemini API 的模型，請參閱模型頁面。\nGemini API 和 Google AI Studio 目前已在 180 多個國家/地區提供服務，詳情請參閱說明文件。\n\n除非另有註明，否則本頁面中的內容是採用創用 CC 姓名標示 4.0 授權，程式碼範例則為阿帕契 2.0 授權。詳情請參閱《Google Developers 網站政策》。Java 是 Oracle 和/或其關聯企業的註冊商標。\n\n上次更新時間：2024-04-23 (世界標準時間)。\n\n條款\n隱私權",
            "word_count": 179,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=ja#": {
            "status": "Looks good",
            "content": "プロダクト\n例\nログイン\nドキュメント\nAPI リファレンス\n概要\n使ってみる\nAPI キーを取得する\nGemini API クイックスタート\nGoogle AI Studio のクイックスタート\nスタートガイドのチュートリアル\nモデル\n生成モデルについて\nGemini\nGemini API\nAPI の概要\nAPI リファレンス\nAPI バージョン\nリリースノート\n機能\nモデルのチューニング\n関数呼び出し\nEmbeddings\n安全性\nガイド\nプロンプト\nシステムの説明\nセマンティック取得\nOAuth 認証\nFirebase Extensions\nクラウドに移行する\nチュートリアル\n関数呼び出し\nEmbeddings\nアプリケーション\nトラブルシューティング\nトラブルシューティング ガイド\nWorkspace を使用して AI Studio にアクセスする\nAI Studio のトラブルシューティング\n割り当ての増加をリクエストする\nコミュニティ\n対話フォーラム\nPaLM API（レガシー）\ngen に移行する\nPaLM ドキュメント\n法務\n利用規約\n（プレビュー）利用規約\n利用可能なリージョン\n新しい Gemini API クックブックとコミュニティ フォーラムをご覧ください。\n このページは Cloud Translation API によって翻訳されました。\nGemini API のスタートガイド \n\nGemini は、Google の最も高性能な AI モデルのファミリーです。このサイトには、Gemini API を使用してアプリケーションを構築するために必要な情報がすべて記載されています。\n\nGemini 1.5 Pro が Google AI Studio の公開プレビュー版で利用可能になりました。こちらから今すぐお試しください。\n\nGoogle AI Studio \n\nGemini の使用を開始する際は、ウェブベースのツールである Google AI Studio を使用することが最速です。これを使用すると、プロトタイプを作成し、ブラウザでプロンプトを実行し、Gemini API を開始できます。\n\nGoogle AI Studio を起動する\nGoogle AI Studio のクイックスタート\n\n開始するには、Gemini API クイックスタートをご覧ください。\n\n安全かつ責任を持って LLM を使用する方法については、安全性設定と安全性に関するガイダンスのドキュメントをご覧ください。\n\nPython のスタートガイド\nREST API を使ってみる\nウェブで使ってみる\nGo スタート ガイド\nNode を使ってみる\nAndroid で使ってみる\niOS で使ってみる\nDart（Flutter）を使ってみる\nGoogle Cloud 上に構築\n関連情報\nGemini API で使用されているモデルの詳細については、モデルのページをご覧ください。\nGemini API と Google AI Studio は現在、180 か国以上で利用できます。詳しくは、ドキュメントをご覧ください。\n\n特に記載のない限り、このページのコンテンツはクリエイティブ・コモンズの表示 4.0 ライセンスにより使用許諾されます。コードサンプルは Apache 2.0 ライセンスにより使用許諾されます。詳しくは、Google Developers サイトのポリシーをご覧ください。Java は Oracle および関連会社の登録商標です。\n\n最終更新日 2024-04-23 UTC。\n\n利用規約\nプライバシー",
            "word_count": 172,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs?hl=ko#": {
            "status": "Looks good",
            "content": "제품\n예\n로그인\nDocs\nAPI 참조\n개요\n시작하기\nAPI 키 가져오기\nGemini API 빠른 시작\nGoogle AI 스튜디오 빠른 시작\n시작 가이드\n모델\n생성 모델 정보\nGemini\nGemini API\nAPI 개요\nAPI 참조 문서\nAPI 버전\n출시 노트\n기능\n모델 조정\n함수 호출\n임베딩\n안전\n가이드\n메시지 표시\n시스템 안내\n시맨틱 검색\nOAuth 인증\nFirebase Extensions\n클라우드로 마이그레이션\n튜토리얼\n함수 호출\n임베딩\n애플리케이션\n문제해결\n문제 해결 가이드\nWorkspace를 사용하여 AI Studio에 액세스\nAI Studio 문제 해결\n할당량 추가 요청\n커뮤니티\n담화 포럼\nPaLM API (기존)\nGemini로 이전\nPaLM 문서\n법률\n서비스 약관\n(미리보기) 서비스 약관\n사용 가능한 리전\n새로운 Gemini API 설명서와 커뮤니티 포럼을 확인하세요.\n 이 페이지는 Cloud Translation API를 통해 번역되었습니다.\nGemini API 시작하기 \n\nGemini는 Google에서 가장 성능이 뛰어난 AI 모델 제품군입니다. 이 사이트에는 Gemini API로 애플리케이션 빌드를 시작하는 데 필요한 모든 정보가 포함되어 있습니다.\n\n이제 Gemini 1.5 Pro가 Google AI 스튜디오의 공개 미리보기로 제공됩니다. 지금 사용해보기\n\nGoogle AI Studio \n\nGemini를 사용하는 가장 빠른 방법은 웹 기반 도구인 Google AI 스튜디오를 사용하는 것입니다. 이 도구를 사용하면 프로토타입을 제작하고 브라우저에서 바로 프롬프트를 실행하고 Gemini API를 시작할 수 있습니다.\n\nGoogle AI 스튜디오 실행\nGoogle AI 스튜디오 빠른 시작\n\n시작하려면 Gemini API 빠른 시작으로 이동하세요.\n\nLLM을 안전하고 책임감 있게 사용하는 방법을 알아보려면 안전 설정 및 안전 안내 문서를 참조하세요.\n\nPython 시작하기\nREST API 시작하기\n웹에서 시작하기\nGo 시작하기\nNode 시작하기\nAndroid에서 시작하기\niOS에서 시작하기\nDart (Flutter) 시작하기\nGoogle Cloud에서 빌드\n추가 자료\nGemini API를 구동하는 모델에 대해 자세히 알아보려면 모델 페이지를 참조하세요.\nGemini API 및 Google AI 스튜디오는 현재 180개 이상의 국가에서 사용할 수 있습니다. 자세한 내용은 문서를 확인하세요.\n\n달리 명시되지 않는 한 이 페이지의 콘텐츠에는 Creative Commons Attribution 4.0 라이선스에 따라 라이선스가 부여되며, 코드 샘플에는 Apache 2.0 라이선스에 따라 라이선스가 부여됩니다. 자세한 내용은 Google Developers 사이트 정책을 참조하세요. 자바는 Oracle 및/또는 Oracle 계열사의 등록 상표입니다.\n\n최종 업데이트: 2024-04-23(UTC)\n\n약관\n개인정보처리방침",
            "word_count": 299,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/api-key#": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nVerify your API key with a curl command\nKeep your API key secure\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet an API key \nbookmark_border\n\nTo use the Gemini API, you need an API key. You can create a key with one click in Google AI Studio.\n\nGet an API key\n\nImportant: Remember to use your API keys securely. Review Keep your API key secure and then check out the API quickstarts to learn language-specific best practices for securing your API key.\nVerify your API key with a curl command\n\nYou can use a curl command to verify your setup. You can pass the API key either in the URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOr in the x-goog-api-key header:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nKeep your API key secure\n\nIt's important to keep your Gemini API key secure. Here are a few things to keep in mind when using your Gemini API key:\n\nThe Google AI Gemini API uses API keys for authorization. If others get access to your Gemini API key, they can make calls using your project's quota, which could result in lost quota or additional billing charges (if billing is enabled). API keys also guard access to tuned models and files.\n\nWhen you click Get API key in Google AI Studio, you choose whether to provision a Gemini API key in a new or existing Google Cloud project. The API keys list in Google AI Studio shows all the API keys that AI Studio has provisioned for use with the Google AI Gemini API (along with all their associated Google Cloud projects).\n\nHowever, any API keys within the Google Cloud project can potentially be used to call the Google AI Gemini API. You can view and manage all your project's API keys in the APIs & Services > Credentials panel in the Google Cloud console.\n\nAdding API key restrictions can help limit the surface area usable through each API key. By default, the Gemini API key generated by Google AI Studio can only be used with the Google AI Gemini API (officially called the \"Generative Language API\" or generativelanguage.googleapis.com).\n\nIf there are any API keys within your Google Cloud project that lack API restrictions or any API keys that have allowlisted the Generative Language API, then those keys can be used with the Google AI Gemini API. It's best practice to restrict each API key to only the APIs that you call using that key.\nNote that even with API key restrictions, if a malicious actor obtains your API key, they can use it to make calls using your project's quota for all the APIs allowlisted for that API key.\n\nYou're responsible for keeping your Gemini API key secure.\n\nDo NOT check Gemini API keys into source control.\nClient-side applications (Android, Swift, web, and Dart/Flutter) risk exposing API keys, so we do not recommend using the Google AI client SDKs in production apps to call the Google AI Gemini API directly from your mobile and web apps. Check out the SDK quickstarts to learn language-specific best practices for securing your API key.\n\nFor some general best practices, you can also review this support article.\n\nNext steps\nCheck out the API quickstarts to learn best practices for securing your API key and using it.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 754,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=de": {
            "status": "Looks good",
            "content": "Produkte\nBeispiele\nAnmelden\nDokumentation\nAPI-Referenz\nÜberblick\nJetzt starten\nAPI-Schlüssel anfordern\nGemini API – Kurzanleitung\nGoogle AI Studio – Kurzanleitung\nAnleitungen für den Einstieg\nModelle\nInformationen zu generativen Modellen\nGemini\nGemini API\nAPI-Übersicht\nAPI-Referenz\nAPI-Versionen\nVersionshinweise\nLeistungsspektrum\nModellabstimmung\nFunktionsaufruf\nEinbettungen\nSicherheit\nLeitfäden\nAufforderungen\nSystemanleitung\nSemantischer Abruf\nAuthentifizierung mit OAuth\nFirebase-Erweiterungen\nZu Cloud migrieren\nAnleitungen\nFunktionsaufruf\nEinbettungen\nAnwendungen\nProblembehebung\nTipps zur Fehlerbehebung\nÜber Workspace auf AI Studio zugreifen\nFehlerbehebung in AI Studio\nHöheres Kontingent beantragen\nCommunity\nDiskursforum\nPaLM API (alt)\nZu Gemini migrieren\nPaLM-Dokumentation\nRecht\nNutzungsbedingungen\n(Vorschau) Nutzungsbedingungen\nVerfügbare Regionen\nAuf dieser Seite\nAPI-Schlüssel mit einem curl-Befehl prüfen\nAPI-Schlüssel sicher aufbewahren\nNächste Schritte\nSehen Sie sich das neue Cookbook zur Gemini API und unser Community-Forum an.\n Diese Seite wurde von der Cloud Translation API übersetzt.\nGoogle AI for Developers\nProdukte\nWar das hilfreich?\nFeedback geben\nAPI-Schlüssel anfordern \nbookmark_border\n\nWenn Sie die Gemini API verwenden möchten, benötigen Sie einen API-Schlüssel. In Google AI Studio können Sie mit einem Klick einen Schlüssel erstellen.\n\nAPI-Schlüssel anfordern\n\nWichtig :Verwenden Sie Ihre API-Schlüssel auf sichere Weise. Lesen Sie den Abschnitt API-Schlüssel sicher halten und anschließend die API-Kurzanleitungen, um sprachspezifische Best Practices zum Sichern Ihres API-Schlüssels kennenzulernen.\nAPI-Schlüssel mit einem curl-Befehl prüfen\n\nSie können die Einrichtung mit einem curl-Befehl überprüfen. Sie können den API-Schlüssel entweder in der URL übergeben:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOder im x-goog-api-key-Header:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nAPI-Schlüssel sicher aufbewahren\n\nEs ist wichtig, dass Ihr Gemini API-Schlüssel sicher ist. Bei der Verwendung Ihres Gemini-API-Schlüssels sollten Sie Folgendes beachten:\n\nDie Google AI Gemini API verwendet API-Schlüssel für die Autorisierung. Wenn andere Zugriff auf Ihren Gemini API-Schlüssel erhalten, können sie Aufrufe über das Kontingent Ihres Projekts tätigen. Das kann zum Verlust von Kontingenten oder zu zusätzlichen Abrechnungsgebühren führen (falls die Abrechnung aktiviert ist). API-Schlüssel schützen auch den Zugriff auf abgestimmte Modelle und Dateien.\n\nWenn Sie in Google AI Studio auf API-Schlüssel abrufen klicken, wählen Sie aus, ob ein Gemini API-Schlüssel in einem neuen oder vorhandenen Google Cloud-Projekt bereitgestellt werden soll. Die Liste der API-Schlüssel in Google AI Studio enthält alle API-Schlüssel, die AI Studio für die Verwendung mit der Google AI Gemini API bereitgestellt hat (einschließlich aller zugehörigen Google Cloud-Projekte).\n\nAllerdings können alle API-Schlüssel innerhalb des Google Cloud-Projekts zum Aufrufen der Google AI Gemini API verwendet werden. Sie können alle API-Schlüssel Ihres Projekts in der Google Cloud Console im Bereich APIs und Dienste > Anmeldedaten ansehen und verwalten.\n\nWenn Sie Einschränkungen für API-Schlüssel festlegen, lässt sich die mit jedem API-Schlüssel nutzbare Oberfläche einschränken. Standardmäßig kann der von Google AI Studio generierte Gemini API-Schlüssel nur mit der Google AI Gemini API (offiziell als „Generative Language API“ oder generativelanguage.googleapis.com bezeichnet) verwendet werden.\n\nWenn in Ihrem Google Cloud-Projekt API-Schlüssel ohne API-Einschränkungen vorhanden sind oder API-Schlüssel auf der Zulassungsliste für die Generative Language API stehen, können diese Schlüssel mit der Google AI Gemini API verwendet werden. Es empfiehlt sich, einen API-Schlüssel auf die APIs zu beschränken, die Sie mit diesem Schlüssel aufrufen.\nHinweis: Auch bei Einschränkungen für API-Schlüssel können böswillige Akteure damit Aufrufe ausführen und dabei das Kontingent Ihres Projekts für alle APIs auf der Zulassungsliste für diesen API-Schlüssel nutzen.\n\nSie sind für die Sicherheit Ihres Gemini API-Schlüssels verantwortlich.\n\nGeben Sie Gemini API-Schlüssel NICHT in die Versionsverwaltung ein.\nBei clientseitigen Anwendungen (Android, Swift, Web und Dart/Flutter) besteht die Gefahr, dass API-Schlüssel offengelegt werden. Daher raten wir davon ab, die Google AI-Client-SDKs in Produktionsanwendungen zu verwenden, um die Google AI Gemini API direkt über Ihre mobilen Apps und Webanwendungen aufzurufen. In den SDK-Kurzanleitungen finden Sie sprachspezifische Best Practices zum Sichern Ihres API-Schlüssels.\n\nEinige allgemeine Best Practices finden Sie auch in diesem Hilfeartikel.\n\nNächste Schritte\nIn den API-Kurzanleitungen finden Sie Best Practices zum Sichern und Verwenden Ihres API-Schlüssels.\nWar das hilfreich?\nFeedback geben\n\nSofern nicht anders angegeben, sind die Inhalte dieser Seite unter der Creative Commons Attribution 4.0 License und Codebeispiele unter der Apache 2.0 License lizenziert. Weitere Informationen finden Sie in den Websiterichtlinien von Google Developers. Java ist eine eingetragene Marke von Oracle und/oder seinen Partnern.\n\nZuletzt aktualisiert: 2024-04-24 (UTC).\n\nNutzungsbedingungen\nDatenschutz",
            "word_count": 694,
            "filtered_content": "Auf dieser Seite\nAPI-Schlüssel anfordern \nWenn Sie die Gemini API verwenden möchten, benötigen Sie einen API-Schlüssel. In Google AI Studio können Sie mit einem Klick einen Schlüssel erstellen.\nWichtig :Verwenden Sie Ihre API-Schlüssel auf sichere Weise. Lesen Sie den Abschnitt API-Schlüssel sicher halten und anschließend die API-Kurzanleitungen, um sprachspezifische Best Practices zum Sichern Ihres API-Schlüssels kennenzulernen.\nSie können die Einrichtung mit einem curl-Befehl überprüfen. Sie können den API-Schlüssel entweder in der URL übergeben:\nOder im x-goog-api-key-Header:\nEs ist wichtig, dass Ihr Gemini API-Schlüssel sicher ist. Bei der Verwendung Ihres Gemini-API-Schlüssels sollten Sie Folgendes beachten:\nDie Google AI Gemini API verwendet API-Schlüssel für die Autorisierung. Wenn andere Zugriff auf Ihren Gemini API-Schlüssel erhalten, können sie Aufrufe über das Kontingent Ihres Projekts tätigen. Das kann zum Verlust von Kontingenten oder zu zusätzlichen Abrechnungsgebühren führen (falls die Abrechnung aktiviert ist). API-Schlüssel schützen auch den Zugriff auf abgestimmte Modelle und Dateien.\nWenn Sie in Google AI Studio auf API-Schlüssel abrufen klicken, wählen Sie aus, ob ein Gemini API-Schlüssel in einem neuen oder vorhandenen Google Cloud-Projekt bereitgestellt werden soll. Die Liste der API-Schlüssel in Google AI Studio enthält alle API-Schlüssel, die AI Studio für die Verwendung mit der Google AI Gemini API bereitgestellt hat (einschließlich aller zugehörigen Google Cloud-Projekte).\nAllerdings können alle API-Schlüssel innerhalb des Google Cloud-Projekts zum Aufrufen der Google AI Gemini API verwendet werden. Sie können alle API-Schlüssel Ihres Projekts in der Google Cloud Console im Bereich APIs und Dienste > Anmeldedaten ansehen und verwalten.\nWenn Sie Einschränkungen für API-Schlüssel festlegen, lässt sich die mit jedem API-Schlüssel nutzbare Oberfläche einschränken. Standardmäßig kann der von Google AI Studio generierte Gemini API-Schlüssel nur mit der Google AI Gemini API (offiziell als „Generative Language API“ oder generativelanguage.googleapis.com bezeichnet) verwendet werden.\nWenn in Ihrem Google Cloud-Projekt API-Schlüssel ohne API-Einschränkungen vorhanden sind oder API-Schlüssel auf der Zulassungsliste für die Generative Language API stehen, können diese Schlüssel mit der Google AI Gemini API verwendet werden. Es empfiehlt sich, einen API-Schlüssel auf die APIs zu beschränken, die Sie mit diesem Schlüssel aufrufen.\nHinweis: Auch bei Einschränkungen für API-Schlüssel können böswillige Akteure damit Aufrufe ausführen und dabei das Kontingent Ihres Projekts für alle APIs auf der Zulassungsliste für diesen API-Schlüssel nutzen.\nSie sind für die Sicherheit Ihres Gemini API-Schlüssels verantwortlich.\nGeben Sie Gemini API-Schlüssel NICHT in die Versionsverwaltung ein.\nBei clientseitigen Anwendungen (Android, Swift, Web und Dart/Flutter) besteht die Gefahr, dass API-Schlüssel offengelegt werden. Daher raten wir davon ab, die Google AI-Client-SDKs in Produktionsanwendungen zu verwenden, um die Google AI Gemini API direkt über Ihre mobilen Apps und Webanwendungen aufzurufen. In den SDK-Kurzanleitungen finden Sie sprachspezifische Best Practices zum Sichern Ihres API-Schlüssels.\nEinige allgemeine Best Practices finden Sie auch in diesem Hilfeartikel.\nIn den API-Kurzanleitungen finden Sie Best Practices zum Sichern und Verwenden Ihres API-Schlüssels.\nZuletzt aktualisiert: 2024-04-24 (UTC).",
            "filtered_word_count": 458
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=es-419": {
            "status": "Looks good",
            "content": "Productos\nEjemplos\nAcceder\nDocumentos\nReferencia de la API\nResumen\nComenzar\nObtén una clave de API\nGuía de inicio rápido de la API de Gemini\nGuía de inicio rápido de Google AI Studio\nInstructivos de introducción\nModelos\nAcerca de los modelos generativos\nGemini\nGemini API\nDescripción general de la API\nReferencia de la API\nVersiones de API\nNotas de la versión\nFunciones\nAjuste del modelo\nLlamada a función\nIncorporaciones\nSeguridad\nGuías\nMensajes\nInstrucciones del sistema\nRecuperación semántica\nAutenticación de OAuth\nExtensiones de Firebase\nMigra a Cloud\nInstructivos\nLlamada a función\nIncorporaciones\nAplicaciones\nSolución de problemas\nGuía de solución de problemas\nAccede a AI Studio con Workspace\nSolución de problemas de AI Studio\nCómo solicitar una cuota mayor\nComunidad\nForo del discurso\nAPI de PaLM (heredada)\nCómo migrar a Gemini\nDocumentos de PaLM\nLegal\nCondiciones del Servicio\n(vista previa) Condiciones del Servicio\nRegiones disponibles\nEn esta página\nVerifica tu clave de API con un comando curl\nProtege tu clave de API\nPróximos pasos\nConsulta la nueva Guía de soluciones de la API de Gemini y nuestro foro de la comunidad.\n Se usó la API de Cloud Translation para traducir esta página.\nGoogle AI for Developers\nProductos\n¿Te resultó útil?\nEnviar comentarios\nObtén una clave de API \nbookmark_border\n\nPara usar la API de Gemini, necesitas una clave de API. Puedes crear una clave con un clic en Google AI Studio.\n\nObtén una clave de API.\n\nImportante: Recuerda usar tus claves de API de forma segura. Consulta Mantén segura tu clave de API y, luego, revisa las guías de inicio rápido de la API para conocer prácticas recomendadas específicas del lenguaje para proteger tu clave de API.\nVerifica tu clave de API con un comando curl\n\nPuedes usar un comando curl para verificar la configuración. Puedes pasar la clave de API en la URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nTambién puedes hacerlo en el encabezado x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nProtege tu clave de API\n\nEs importante mantener segura tu clave de API de Gemini. A continuación, se incluyen algunos aspectos que debes tener en cuenta cuando uses tu clave de API de Gemini:\n\nLa API de Google AI Gemini usa claves de API para la autorización. Si otras personas acceden a tu clave de API de Gemini, podrán realizar llamadas con la cuota de tu proyecto, lo que podría generar la pérdida de cuota o cargos de facturación adicionales (si la facturación está habilitada). Las claves de API también protegen el acceso a modelos y archivos ajustados.\n\nCuando haces clic en Obtener clave de API en Google AI Studio, eliges si deseas aprovisionar una clave de API de Gemini en un proyecto de Google Cloud nuevo o existente. En la lista de claves de API en Google AI Studio, se muestran todas las claves de API que AI Studio aprovisionó para usar con la API de Google AI Gemini (junto con todos sus proyectos de Google Cloud asociados).\n\nSin embargo, es posible que se use cualquier clave de API dentro del proyecto de Google Cloud para llamar a la API de Google AI Gemini. Puedes ver y administrar todas las claves de API de tu proyecto en el panel APIs y servicios > Credenciales en la consola de Google Cloud.\n\nAgregar restricciones de clave de API puede ayudar a limitar el área de superficie que se puede usar a través de cada clave de API. De forma predeterminada, la clave de API de Gemini generada por Google AI Studio solo se puede usar con la API de Gemini de la IA de Google (oficialmente denominada \"API de Generative Language\" o generativelanguage.googleapis.com).\n\nSi hay claves de API en tu proyecto de Google Cloud que carecen de restricciones de API o alguna clave de API que incluyó la API de Generative Language en la lista de entidades permitidas, esas claves se pueden usar con la API de Gemini de Google AI. La práctica recomendada es restringir cada clave de API solo a las APIs a las que llamas con ella.\nTen en cuenta que, incluso con las restricciones de la clave de API, si un actor malicioso obtiene tu clave de API, podrá usarla para realizar llamadas con la cuota de tu proyecto para todas las APIs incluidas en la lista de entidades permitidas de esa clave.\n\nEres responsable de mantener segura tu clave de API de Gemini.\n\nNO registres las claves de API de Gemini en el control de código fuente.\nLas aplicaciones del cliente (Android, Swift, la Web y Dart/Flutter) corren el riesgo de exponer las claves de API, por lo que no recomendamos usar los SDK cliente de la IA de Google en apps de producción para llamar a la API de Google AI Gemini directamente desde tus apps web y para dispositivos móviles. Consulta las guías de inicio rápido del SDK y conoce las prácticas recomendadas específicas del lenguaje para proteger tu clave de API.\n\nSi quieres conocer algunas prácticas recomendadas generales, también puedes consultar este artículo de asistencia.\n\nPróximos pasos\nRevisa las guías de inicio rápido de la API a fin de conocer las prácticas recomendadas para proteger tu clave de API y usarla.\n¿Te resultó útil?\nEnviar comentarios\n\nSalvo que se indique lo contrario, el contenido de esta página está sujeto a la licencia Atribución 4.0 de Creative Commons, y los ejemplos de código están sujetos a la licencia Apache 2.0. Para obtener más información, consulta las políticas del sitio de Google Developers. Java es una marca registrada de Oracle o sus afiliados.\n\nÚltima actualización: 2024-04-24 (UTC)\n\nCondiciones\nPrivacidad",
            "word_count": 953,
            "filtered_content": "En esta página\nObtén una clave de API \nPara usar la API de Gemini, necesitas una clave de API. Puedes crear una clave con un clic en Google AI Studio.\nObtén una clave de API.\nImportante: Recuerda usar tus claves de API de forma segura. Consulta Mantén segura tu clave de API y, luego, revisa las guías de inicio rápido de la API para conocer prácticas recomendadas específicas del lenguaje para proteger tu clave de API.\nPuedes usar un comando curl para verificar la configuración. Puedes pasar la clave de API en la URL:\nTambién puedes hacerlo en el encabezado x-goog-api-key:\nEs importante mantener segura tu clave de API de Gemini. A continuación, se incluyen algunos aspectos que debes tener en cuenta cuando uses tu clave de API de Gemini:\nLa API de Google AI Gemini usa claves de API para la autorización. Si otras personas acceden a tu clave de API de Gemini, podrán realizar llamadas con la cuota de tu proyecto, lo que podría generar la pérdida de cuota o cargos de facturación adicionales (si la facturación está habilitada). Las claves de API también protegen el acceso a modelos y archivos ajustados.\nCuando haces clic en Obtener clave de API en Google AI Studio, eliges si deseas aprovisionar una clave de API de Gemini en un proyecto de Google Cloud nuevo o existente. En la lista de claves de API en Google AI Studio, se muestran todas las claves de API que AI Studio aprovisionó para usar con la API de Google AI Gemini (junto con todos sus proyectos de Google Cloud asociados).\nSin embargo, es posible que se use cualquier clave de API dentro del proyecto de Google Cloud para llamar a la API de Google AI Gemini. Puedes ver y administrar todas las claves de API de tu proyecto en el panel APIs y servicios > Credenciales en la consola de Google Cloud.\nAgregar restricciones de clave de API puede ayudar a limitar el área de superficie que se puede usar a través de cada clave de API. De forma predeterminada, la clave de API de Gemini generada por Google AI Studio solo se puede usar con la API de Gemini de la IA de Google (oficialmente denominada \"API de Generative Language\" o generativelanguage.googleapis.com).\nSi hay claves de API en tu proyecto de Google Cloud que carecen de restricciones de API o alguna clave de API que incluyó la API de Generative Language en la lista de entidades permitidas, esas claves se pueden usar con la API de Gemini de Google AI. La práctica recomendada es restringir cada clave de API solo a las APIs a las que llamas con ella.\nTen en cuenta que, incluso con las restricciones de la clave de API, si un actor malicioso obtiene tu clave de API, podrá usarla para realizar llamadas con la cuota de tu proyecto para todas las APIs incluidas en la lista de entidades permitidas de esa clave.\nEres responsable de mantener segura tu clave de API de Gemini.\nNO registres las claves de API de Gemini en el control de código fuente.\nLas aplicaciones del cliente (Android, Swift, la Web y Dart/Flutter) corren el riesgo de exponer las claves de API, por lo que no recomendamos usar los SDK cliente de la IA de Google en apps de producción para llamar a la API de Google AI Gemini directamente desde tus apps web y para dispositivos móviles. Consulta las guías de inicio rápido del SDK y conoce las prácticas recomendadas específicas del lenguaje para proteger tu clave de API.\nSi quieres conocer algunas prácticas recomendadas generales, también puedes consultar este artículo de asistencia.\nRevisa las guías de inicio rápido de la API a fin de conocer las prácticas recomendadas para proteger tu clave de API y usarla.\nÚltima actualización: 2024-04-24 (UTC)",
            "filtered_word_count": 636
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fr": {
            "status": "Looks good",
            "content": "Produits\nExemples\nConnexion\nDocumentation\nDocument de référence de l'API\nVue d'ensemble\nPremiers pas\nObtenir une clé d'API\nGuide de démarrage rapide de l'API Gemini\nGuide de démarrage rapide de Google AI Studio\nTutoriels de démarrage\nModèles\nÀ propos des modèles génératifs\nGemini\nGemini API\nPrésentation de l'API\nDocumentation de référence des API\nVersions d'API\nNotes de version\nCapacités\nRéglage du modèle\nAppel de fonction\nReprésentations vectorielles continues\nSécurité\nGuides\nInvites\nInstructions système\nRécupération sémantique\nAuthentification OAuth\nExtensions Firebase\nMigrer vers le cloud\nTutoriels\nAppel de fonction\nReprésentations vectorielles continues\nApplications\nDépannage\nGuide de dépannage\nAccéder à AI Studio à l'aide de Workspace\nRésoudre les problèmes liés à AI Studio\nDemander plus de quotas\nCommunauté\nForum de Discourse\nAPI PaLM (ancienne version)\nMigrer vers Gemini\nDocumentation sur PaLM\nJuridique\nConditions d'utilisation\n(Preview) Conditions d'utilisation\nRégions disponibles\nSur cette page\nValider votre clé API à l'aide d'une commande curl\nSécuriser votre clé API\nÉtapes suivantes\nDécouvrez le livre de recettes avec l'API Gemini et notre forum de la communauté.\n Cette page a été traduite par l'API Cloud Translation.\nGoogle AI for Developers\nProduits\nCe contenu vous a-t-il été utile ?\nEnvoyer des commentaires\nObtenir une clé d'API \nbookmark_border\n\nPour utiliser l'API Gemini, vous avez besoin d'une clé API. Vous pouvez créer une clé en un clic dans Google AI Studio.\n\nObtenir une clé API\n\nImportant :N'oubliez pas d'utiliser vos clés API de manière sécurisée. Consultez la section Sécuriser votre clé API, puis les guides de démarrage rapide de l'API pour découvrir les bonnes pratiques spécifiques aux langages de sécurisation de votre clé API.\nValider votre clé API à l'aide d'une commande curl\n\nVous pouvez utiliser une commande curl pour vérifier votre configuration. Vous pouvez transmettre la clé API via l'URL suivante:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOu dans l'en-tête x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nSécuriser votre clé API\n\nIl est important de sécuriser votre clé API Gemini. Voici quelques points à garder à l'esprit lorsque vous utilisez votre clé API Gemini:\n\nL'API Google AI Gemini utilise des clés API pour les autorisations. Si d'autres utilisateurs obtiennent l'accès à votre clé API Gemini, ils peuvent effectuer des appels en utilisant le quota de votre projet, ce qui peut entraîner une perte de quota ou des frais supplémentaires (si la facturation est activée). Les clés API sécurisent également l'accès aux modèles et aux fichiers réglés.\n\nLorsque vous cliquez sur Obtenir une clé API dans Google AI Studio, vous choisissez de provisionner une clé API Gemini dans un projet Google Cloud nouveau ou existant. La liste des clés API dans Google AI Studio indique toutes les clés API qu'AI Studio a provisionnées pour une utilisation avec l'API Google AI Gemini (ainsi que tous les projets Google Cloud associés).\n\nCependant, n'importe quelle clé API du projet Google Cloud peut être utilisée pour appeler l'API Google AI Gemini. Vous pouvez afficher et gérer toutes les clés API de votre projet dans le panneau API et services > Identifiants de la console Google Cloud.\n\nL'ajout de restrictions de clé API peut vous aider à limiter la surface utilisable avec chaque clé API. Par défaut, la clé API Gemini générée par Google AI Studio ne peut être utilisée qu'avec l'API Generative AI de Google (officiellement appelée \"API Generative Language\" ou generativelanguage.googleapis.com).\n\nSi des clés API de votre projet Google Cloud ne disposent pas de restrictions d'API, ou si des clés API ont été ajoutées à la liste d'autorisation de l'API de langage génératif, elles peuvent être utilisées avec l'API Google AI Gemini. Il est recommandé de limiter chaque clé API aux seules API que vous appelez à l'aide de cette clé.\nNotez que même avec les restrictions de clé API, si un acteur malveillant obtient votre clé API, il peut l'utiliser pour effectuer des appels en utilisant le quota de votre projet pour toutes les API ajoutées à la liste d'autorisation pour cette clé API.\n\nVous êtes responsable de la sécurité de votre clé API Gemini.\n\nNE activez PAS les clés API Gemini dans le contrôle du code source.\nLes applications côté client (Android, Swift, Web et Dart/Flutter) risquent d'exposer des clés API. Nous vous déconseillons donc d'utiliser les SDK clients Google AI dans les applications de production pour appeler l'API Google AI Gemini directement à partir de vos applications mobiles et Web. Consultez les guides de démarrage rapide des SDK pour connaître les bonnes pratiques propres à chaque langage afin de sécuriser votre clé API.\n\nPour connaître les bonnes pratiques générales, vous pouvez également consulter cet article d'aide.\n\nÉtapes suivantes\nConsultez les guides de démarrage rapide de l'API pour connaître les bonnes pratiques permettant de sécuriser votre clé API et de l'utiliser.\nCe contenu vous a-t-il été utile ?\nEnvoyer des commentaires\n\nSauf indication contraire, le contenu de cette page est régi par une licence Creative Commons Attribution 4.0, et les échantillons de code sont régis par une licence Apache 2.0. Pour en savoir plus, consultez les Règles du site Google Developers. Java est une marque déposée d'Oracle et/ou de ses sociétés affiliées.\n\nDernière mise à jour le 2024/04/24 (UTC).\n\nConditions d'utilisation\nRègles de confidentialité",
            "word_count": 880,
            "filtered_content": "Sur cette page\nObtenir une clé d'API \nPour utiliser l'API Gemini, vous avez besoin d'une clé API. Vous pouvez créer une clé en un clic dans Google AI Studio.\nObtenir une clé API\nImportant :N'oubliez pas d'utiliser vos clés API de manière sécurisée. Consultez la section Sécuriser votre clé API, puis les guides de démarrage rapide de l'API pour découvrir les bonnes pratiques spécifiques aux langages de sécurisation de votre clé API.\nVous pouvez utiliser une commande curl pour vérifier votre configuration. Vous pouvez transmettre la clé API via l'URL suivante:\nOu dans l'en-tête x-goog-api-key:\nIl est important de sécuriser votre clé API Gemini. Voici quelques points à garder à l'esprit lorsque vous utilisez votre clé API Gemini:\nL'API Google AI Gemini utilise des clés API pour les autorisations. Si d'autres utilisateurs obtiennent l'accès à votre clé API Gemini, ils peuvent effectuer des appels en utilisant le quota de votre projet, ce qui peut entraîner une perte de quota ou des frais supplémentaires (si la facturation est activée). Les clés API sécurisent également l'accès aux modèles et aux fichiers réglés.\nLorsque vous cliquez sur Obtenir une clé API dans Google AI Studio, vous choisissez de provisionner une clé API Gemini dans un projet Google Cloud nouveau ou existant. La liste des clés API dans Google AI Studio indique toutes les clés API qu'AI Studio a provisionnées pour une utilisation avec l'API Google AI Gemini (ainsi que tous les projets Google Cloud associés).\nCependant, n'importe quelle clé API du projet Google Cloud peut être utilisée pour appeler l'API Google AI Gemini. Vous pouvez afficher et gérer toutes les clés API de votre projet dans le panneau API et services > Identifiants de la console Google Cloud.\nL'ajout de restrictions de clé API peut vous aider à limiter la surface utilisable avec chaque clé API. Par défaut, la clé API Gemini générée par Google AI Studio ne peut être utilisée qu'avec l'API Generative AI de Google (officiellement appelée \"API Generative Language\" ou generativelanguage.googleapis.com).\nSi des clés API de votre projet Google Cloud ne disposent pas de restrictions d'API, ou si des clés API ont été ajoutées à la liste d'autorisation de l'API de langage génératif, elles peuvent être utilisées avec l'API Google AI Gemini. Il est recommandé de limiter chaque clé API aux seules API que vous appelez à l'aide de cette clé.\nNotez que même avec les restrictions de clé API, si un acteur malveillant obtient votre clé API, il peut l'utiliser pour effectuer des appels en utilisant le quota de votre projet pour toutes les API ajoutées à la liste d'autorisation pour cette clé API.\nVous êtes responsable de la sécurité de votre clé API Gemini.\nNE activez PAS les clés API Gemini dans le contrôle du code source.\nLes applications côté client (Android, Swift, Web et Dart/Flutter) risquent d'exposer des clés API. Nous vous déconseillons donc d'utiliser les SDK clients Google AI dans les applications de production pour appeler l'API Google AI Gemini directement à partir de vos applications mobiles et Web. Consultez les guides de démarrage rapide des SDK pour connaître les bonnes pratiques propres à chaque langage afin de sécuriser votre clé API.\nPour connaître les bonnes pratiques générales, vous pouvez également consulter cet article d'aide.\nConsultez les guides de démarrage rapide de l'API pour connaître les bonnes pratiques permettant de sécuriser votre clé API et de l'utiliser.\nDernière mise à jour le 2024/04/24 (UTC).",
            "filtered_word_count": 568
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=id": {
            "status": "Looks good",
            "content": "Produk\nContoh\nMasuk\nDokumen\nReferensi API\nRingkasan\nMulai\nMendapatkan kunci API\nPanduan memulai Gemini API\nPanduan memulai Google AI Studio\nTutorial memulai\nModel\nTentang model generatif\nGemini\nGemini API\nRingkasan API\nReferensi API\nVersi API\nCatatan rilis\nKemampuan\nPenyesuaian model\nPanggilan fungsi\nEmbedding\nKeamanan\nPanduan\nMeminta\nPetunjuk sistem\nPengambilan semantik\nAutentikasi OAuth\nEkstensi Firebase\nBermigrasi ke Cloud\nTutorial\nPanggilan fungsi\nEmbedding\nAplikasi\nPemecahan masalah\nPanduan pemecahan masalah\nMengakses AI Studio menggunakan Workspace\nMemecahkan masalah AI Studio\nMeminta lebih banyak kuota\nKomunitas\nForum wacana\nPaLM API (lama)\nBermigrasi ke Gemini\nDokumen PaLM\nHukum\nPersyaratan layanan\nPersyaratan layanan (Pratinjau)\nRegion yang tersedia\nPada halaman ini\nMemverifikasi kunci API dengan perintah curl\nMenjaga keamanan kunci API\nLangkah berikutnya\nLihat Cookbook Gemini API baru dan forum komunitas kami.\n Halaman ini diterjemahkan oleh Cloud Translation API.\nGoogle AI for Developers\nProduk\nApakah informasi ini membantu?\nKirim masukan\nMendapatkan kunci API \nbookmark_border\n\nUntuk menggunakan Gemini API, Anda memerlukan kunci API. Anda dapat membuat kunci dengan sekali klik di Google AI Studio.\n\nMendapatkan kunci API\n\nPenting: Ingatlah untuk menggunakan kunci API Anda dengan aman. Tinjau Menjaga keamanan kunci API Anda, lalu lihat panduan memulai API untuk mempelajari praktik terbaik spesifik per bahasa guna mengamankan kunci API Anda.\nMemverifikasi kunci API dengan perintah curl\n\nAnda dapat menggunakan perintah curl untuk memverifikasi penyiapan. Anda dapat meneruskan kunci API di URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nAtau di header x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nMenjaga keamanan kunci API\n\nAnda harus menjaga keamanan kunci API Gemini. Berikut adalah beberapa hal yang perlu diingat saat menggunakan kunci Gemini API:\n\nGoogle AI Gemini API menggunakan kunci API untuk otorisasi. Jika orang lain mendapatkan akses ke kunci Gemini API Anda, mereka dapat melakukan panggilan menggunakan kuota project Anda, yang dapat mengakibatkan hilangnya kuota atau biaya penagihan tambahan (jika penagihan diaktifkan). Kunci API juga menjaga akses ke model dan file yang telah disesuaikan.\n\nSaat mengklik Get API key di Google AI Studio, Anda dapat memilih apakah akan menyediakan kunci Gemini API di project Google Cloud yang baru atau yang sudah ada. Daftar kunci API di Google AI Studio menampilkan semua kunci API yang telah disediakan AI Studio untuk digunakan dengan Google AI Gemini API (beserta semua project Google Cloud terkait).\n\nNamun, kunci API apa pun dalam project Google Cloud dapat berpotensi digunakan untuk memanggil Google AI Gemini API. Anda dapat melihat dan mengelola semua kunci API project di panel API & Layanan > Credentials di Konsol Google Cloud.\n\nMenambahkan pembatasan kunci API dapat membantu membatasi area platform yang dapat digunakan melalui setiap kunci API. Secara default, kunci Gemini API yang dihasilkan oleh Google AI Studio hanya dapat digunakan dengan Google AI Gemini API (secara resmi disebut \"Generative Language API\" atau generativelanguage.googleapis.com).\n\nJika ada kunci API dalam project Google Cloud Anda yang tidak memiliki pembatasan API atau kunci API yang telah mengizinkan Generative Language API, maka kunci tersebut dapat digunakan dengan Google AI Gemini API. Praktik terbaiknya adalah membatasi setiap kunci API hanya ke API yang Anda panggil menggunakan kunci tersebut.\nPerlu diperhatikan bahwa meskipun dengan pembatasan kunci API, jika pelaku kejahatan memperoleh kunci API Anda, mereka dapat menggunakannya untuk melakukan panggilan menggunakan kuota project Anda untuk semua API yang diizinkan untuk kunci API tersebut.\n\nAnda bertanggung jawab untuk menjaga keamanan kunci API Gemini.\n\nJANGAN memasukkan kunci API Gemini ke dalam kontrol sumber.\nAplikasi sisi klien (Android, Swift, web, dan Dart/Flutter) berisiko mengekspos kunci API. Oleh karena itu, sebaiknya jangan gunakan SDK klien Google AI dalam aplikasi produksi untuk memanggil Google AI Gemini API langsung dari aplikasi seluler dan web Anda. Lihat panduan memulai SDK guna mempelajari praktik terbaik khusus bahasa untuk mengamankan kunci API.\n\nUntuk beberapa praktik terbaik umum, Anda juga dapat meninjau artikel dukungan ini.\n\nLangkah berikutnya\nLihat panduan memulai API guna mempelajari praktik terbaik untuk mengamankan kunci API dan menggunakannya.\nApakah informasi ini membantu?\nKirim masukan\n\nKecuali dinyatakan lain, konten di halaman ini dilisensikan berdasarkan Lisensi Creative Commons Attribution 4.0, sedangkan contoh kode dilisensikan berdasarkan Lisensi Apache 2.0. Untuk mengetahui informasi selengkapnya, lihat Kebijakan Situs Google Developers. Java adalah merek dagang terdaftar dari Oracle dan/atau afiliasinya.\n\nTerakhir diperbarui pada 2024-04-24 UTC.\n\nPersyaratan\nPrivasi",
            "word_count": 713,
            "filtered_content": "Pada halaman ini\nMendapatkan kunci API \nUntuk menggunakan Gemini API, Anda memerlukan kunci API. Anda dapat membuat kunci dengan sekali klik di Google AI Studio.\nPenting: Ingatlah untuk menggunakan kunci API Anda dengan aman. Tinjau Menjaga keamanan kunci API Anda, lalu lihat panduan memulai API untuk mempelajari praktik terbaik spesifik per bahasa guna mengamankan kunci API Anda.\nAnda dapat menggunakan perintah curl untuk memverifikasi penyiapan. Anda dapat meneruskan kunci API di URL:\nAtau di header x-goog-api-key:\nAnda harus menjaga keamanan kunci API Gemini. Berikut adalah beberapa hal yang perlu diingat saat menggunakan kunci Gemini API:\nGoogle AI Gemini API menggunakan kunci API untuk otorisasi. Jika orang lain mendapatkan akses ke kunci Gemini API Anda, mereka dapat melakukan panggilan menggunakan kuota project Anda, yang dapat mengakibatkan hilangnya kuota atau biaya penagihan tambahan (jika penagihan diaktifkan). Kunci API juga menjaga akses ke model dan file yang telah disesuaikan.\nSaat mengklik Get API key di Google AI Studio, Anda dapat memilih apakah akan menyediakan kunci Gemini API di project Google Cloud yang baru atau yang sudah ada. Daftar kunci API di Google AI Studio menampilkan semua kunci API yang telah disediakan AI Studio untuk digunakan dengan Google AI Gemini API (beserta semua project Google Cloud terkait).\nNamun, kunci API apa pun dalam project Google Cloud dapat berpotensi digunakan untuk memanggil Google AI Gemini API. Anda dapat melihat dan mengelola semua kunci API project di panel API & Layanan > Credentials di Konsol Google Cloud.\nMenambahkan pembatasan kunci API dapat membantu membatasi area platform yang dapat digunakan melalui setiap kunci API. Secara default, kunci Gemini API yang dihasilkan oleh Google AI Studio hanya dapat digunakan dengan Google AI Gemini API (secara resmi disebut \"Generative Language API\" atau generativelanguage.googleapis.com).\nJika ada kunci API dalam project Google Cloud Anda yang tidak memiliki pembatasan API atau kunci API yang telah mengizinkan Generative Language API, maka kunci tersebut dapat digunakan dengan Google AI Gemini API. Praktik terbaiknya adalah membatasi setiap kunci API hanya ke API yang Anda panggil menggunakan kunci tersebut.\nPerlu diperhatikan bahwa meskipun dengan pembatasan kunci API, jika pelaku kejahatan memperoleh kunci API Anda, mereka dapat menggunakannya untuk melakukan panggilan menggunakan kuota project Anda untuk semua API yang diizinkan untuk kunci API tersebut.\nAnda bertanggung jawab untuk menjaga keamanan kunci API Gemini.\nJANGAN memasukkan kunci API Gemini ke dalam kontrol sumber.\nAplikasi sisi klien (Android, Swift, web, dan Dart/Flutter) berisiko mengekspos kunci API. Oleh karena itu, sebaiknya jangan gunakan SDK klien Google AI dalam aplikasi produksi untuk memanggil Google AI Gemini API langsung dari aplikasi seluler dan web Anda. Lihat panduan memulai SDK guna mempelajari praktik terbaik khusus bahasa untuk mengamankan kunci API.\nUntuk beberapa praktik terbaik umum, Anda juga dapat meninjau artikel dukungan ini.\nLihat panduan memulai API guna mempelajari praktik terbaik untuk mengamankan kunci API dan menggunakannya.\nTerakhir diperbarui pada 2024-04-24 UTC.",
            "filtered_word_count": 468
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=it": {
            "status": "Looks good",
            "content": "Prodotti\nEsempi\nAccedi\nDocumenti\nRiferimento API\nPanoramica\nInizia\nOttieni una chiave API\nGuida rapida dell'API Gemini\nGuida rapida di Google AI Studio\nTutorial introduttivi\nModelli\nInformazioni sui modelli generativi\nGemini\nGemini API\nPanoramica dell'API\nRiferimento API\nVersioni API\nNote di rilascio\nFunzionalità\nOttimizzazione del modello\nChiamata di funzione\nIncorporamenti\nSicurezza\nGuide\nPrompt\nIstruzioni di sistema\nRecupero semantico\nAutenticazione OAuth\nEstensioni Firebase\nEsegui la migrazione a Cloud\nTutorial\nChiamata di funzione\nIncorporamenti\nApplicazioni\nRisoluzione dei problemi\nRisoluzione dei problemi\nAccedere ad AI Studio utilizzando Workspace\nRisoluzione dei problemi relativi ad AI Studio\nRichiedere una quota maggiore\ncommunity\nForum del discorso\nAPI PaLM (legacy)\nEsegui la migrazione a Gemini\nDocumenti PaLM\nLegale\nTermini di servizio\n(Anteprima) Termini di servizio\nAree geografiche disponibili\nSu questa pagina\nVerificare la chiave API con un comando curl\nProteggere la chiave API\nPassaggi successivi\nDai un'occhiata al nuovo Cookbook dell'API Gemini e al nostro forum della community.\n Questa pagina è stata tradotta dall'API Cloud Translation.\nGoogle AI for Developers\nProdotti\nQuesta pagina è stata utile?\nInvia feedback\nOttieni una chiave API \nbookmark_border\n\nPer utilizzare l'API Gemini, è necessaria una chiave API. Puoi creare una chiave con un clic in Google AI Studio.\n\nOttenere una chiave API\n\nImportante: ricorda di utilizzare le chiavi API in modo sicuro. Consulta la pagina Mantieni sicura la chiave API e consulta le guide rapide alle API per conoscere le best practice specifiche per i vari linguaggi per proteggere la chiave API.\nVerificare la chiave API con un comando curl\n\nPuoi utilizzare un comando curl per verificare la configurazione. Puoi passare la chiave API nell'URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOppure nell'intestazione x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nProteggere la chiave API\n\nÈ importante proteggere la chiave API Gemini. Ecco alcuni aspetti da tenere presente quando utilizzi la chiave API Gemini:\n\nL'API Google AI Gemini utilizza chiavi API per l'autorizzazione. Se altri utenti hanno accesso alla tua chiave API Gemini, possono effettuare chiamate utilizzando la quota del progetto, il che potrebbe comportare la perdita di quota o costi aggiuntivi (se la fatturazione è abilitata). Le chiavi API proteggono anche l'accesso ai modelli e ai file ottimizzati.\n\nQuando fai clic su Ottieni chiave API in Google AI Studio, scegli se eseguire il provisioning di una chiave API Gemini in un progetto Google Cloud nuovo o esistente. L'elenco delle chiavi API in Google AI Studio mostra tutte le chiavi API di cui AI Studio ha eseguito il provisioning per l'utilizzo con l'API Google AI Gemini (insieme a tutti i progetti Google Cloud associati).\n\nTuttavia, qualsiasi chiave API all'interno del progetto Google Cloud può essere potenzialmente utilizzata per chiamare l'API Google AI Gemini. Puoi visualizzare e gestire tutte le chiavi API del tuo progetto nel riquadro API e servizi > Credenziali nella console Google Cloud.\n\nL'aggiunta di restrizioni delle chiavi API può aiutare a limitare l'area della superficie utilizzabile tramite ciascuna chiave API. Per impostazione predefinita, la chiave API Gemini generata da Google AI Studio può essere utilizzata solo con l'API Gemini AI di Google (denominata ufficialmente \"API Generative Language\" o generativelanguage.googleapis.com).\n\nSe all'interno del tuo progetto Google Cloud sono presenti chiavi API prive di restrizioni API o chiavi API che hanno inserito l'API Generative Language nella lista consentita, queste possono essere utilizzate con l'API Google AI Gemini. La best practice prevede di limitare ogni chiave API solo alle API che chiami utilizzando quella chiave.\nTieni presente che, anche con le limitazioni relative alle chiavi API, se un utente malintenzionato ottiene la tua chiave API, può utilizzarla per effettuare chiamate utilizzando la quota del tuo progetto per tutte le API incluse nella lista consentita per quella chiave API.\n\nSei responsabile di mantenere sicura la chiave API Gemini.\n\nNON controllare le chiavi API Gemini nel controllo del codice sorgente.\nLe applicazioni lato client (Android, Swift, web e Dart/Flutter) rischiano di esporre le chiavi API, perciò sconsigliamo di utilizzare gli SDK client dell'IA di Google nelle app di produzione per chiamare l'API Google AI Gemini direttamente dalle app web e mobile. Consulta le guide rapide degli SDK per scoprire le best practice specifiche per ogni lingua per la protezione della tua chiave API.\n\nPer alcune best practice generali, puoi anche consultare questo articolo del Centro assistenza.\n\nPassaggi successivi\nConsulta le guide rapide sulle API per apprendere le best practice per la protezione e l'utilizzo della chiave API.\nQuesta pagina è stata utile?\nInvia feedback\n\nSalvo quando diversamente specificato, i contenuti di questa pagina sono concessi in base alla licenza Creative Commons Attribution 4.0, mentre gli esempi di codice sono concessi in base alla licenza Apache 2.0. Per ulteriori dettagli, consulta le norme del sito di Google Developers. Java è un marchio registrato di Oracle e/o delle sue consociate.\n\nUltimo aggiornamento 2024-04-24 UTC.\n\nTermini\nPrivacy",
            "word_count": 818,
            "filtered_content": "Su questa pagina\nOttieni una chiave API \nPer utilizzare l'API Gemini, è necessaria una chiave API. Puoi creare una chiave con un clic in Google AI Studio.\nOttenere una chiave API\nImportante: ricorda di utilizzare le chiavi API in modo sicuro. Consulta la pagina Mantieni sicura la chiave API e consulta le guide rapide alle API per conoscere le best practice specifiche per i vari linguaggi per proteggere la chiave API.\nPuoi utilizzare un comando curl per verificare la configurazione. Puoi passare la chiave API nell'URL:\nOppure nell'intestazione x-goog-api-key:\nÈ importante proteggere la chiave API Gemini. Ecco alcuni aspetti da tenere presente quando utilizzi la chiave API Gemini:\nL'API Google AI Gemini utilizza chiavi API per l'autorizzazione. Se altri utenti hanno accesso alla tua chiave API Gemini, possono effettuare chiamate utilizzando la quota del progetto, il che potrebbe comportare la perdita di quota o costi aggiuntivi (se la fatturazione è abilitata). Le chiavi API proteggono anche l'accesso ai modelli e ai file ottimizzati.\nQuando fai clic su Ottieni chiave API in Google AI Studio, scegli se eseguire il provisioning di una chiave API Gemini in un progetto Google Cloud nuovo o esistente. L'elenco delle chiavi API in Google AI Studio mostra tutte le chiavi API di cui AI Studio ha eseguito il provisioning per l'utilizzo con l'API Google AI Gemini (insieme a tutti i progetti Google Cloud associati).\nTuttavia, qualsiasi chiave API all'interno del progetto Google Cloud può essere potenzialmente utilizzata per chiamare l'API Google AI Gemini. Puoi visualizzare e gestire tutte le chiavi API del tuo progetto nel riquadro API e servizi > Credenziali nella console Google Cloud.\nL'aggiunta di restrizioni delle chiavi API può aiutare a limitare l'area della superficie utilizzabile tramite ciascuna chiave API. Per impostazione predefinita, la chiave API Gemini generata da Google AI Studio può essere utilizzata solo con l'API Gemini AI di Google (denominata ufficialmente \"API Generative Language\" o generativelanguage.googleapis.com).\nSe all'interno del tuo progetto Google Cloud sono presenti chiavi API prive di restrizioni API o chiavi API che hanno inserito l'API Generative Language nella lista consentita, queste possono essere utilizzate con l'API Google AI Gemini. La best practice prevede di limitare ogni chiave API solo alle API che chiami utilizzando quella chiave.\nTieni presente che, anche con le limitazioni relative alle chiavi API, se un utente malintenzionato ottiene la tua chiave API, può utilizzarla per effettuare chiamate utilizzando la quota del tuo progetto per tutte le API incluse nella lista consentita per quella chiave API.\nSei responsabile di mantenere sicura la chiave API Gemini.\nNON controllare le chiavi API Gemini nel controllo del codice sorgente.\nLe applicazioni lato client (Android, Swift, web e Dart/Flutter) rischiano di esporre le chiavi API, perciò sconsigliamo di utilizzare gli SDK client dell'IA di Google nelle app di produzione per chiamare l'API Google AI Gemini direttamente dalle app web e mobile. Consulta le guide rapide degli SDK per scoprire le best practice specifiche per ogni lingua per la protezione della tua chiave API.\nPer alcune best practice generali, puoi anche consultare questo articolo del Centro assistenza.\nConsulta le guide rapide sulle API per apprendere le best practice per la protezione e l'utilizzo della chiave API.\nUltimo aggiornamento 2024-04-24 UTC.",
            "filtered_word_count": 531
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pl": {
            "status": "Looks good",
            "content": "Produkty\nPrzykłady\nZaloguj się\nDokumenty\nDokumentacja API\nPrzegląd\nRozpocznij\nUzyskiwanie klucza interfejsu API\nKrótkie wprowadzenie do interfejsu Gemini API\nKrótkie wprowadzenie do Google AI Studio\nSamouczki na początek\nModele\nInformacje o modelach generatywnych\nGemini\nGemini API\nPrzegląd interfejsów API\nDokumentacja API\nWersje interfejsu API\nInformacje o wersjach\nMożliwości\nDostrajanie modeli\nWywoływanie funkcji\nOsadzone elementy\nBezpieczeństwo\nPrzewodniki\nPrompt\nInstrukcje systemowe\nPobieranie semantyczne\nUwierzytelnianie OAuth\nRozszerzenia Firebase\nMigracja do Cloud\nSamouczki\nWywoływanie funkcji\nOsadzone elementy\nAplikacje\nRozwiązywanie problemów\nPrzewodnik rozwiązywania problemów\nDostęp do AI Studio za pomocą Workspace\nRozwiązywanie problemów z AI Studio\nZgłaszanie prośby o dodatkowy limit\nSpołeczność\nForum dyskusyjne\nPaLM API (starsza wersja)\nMigracja do Gemini\nDokumentacja PaLM\nLegal\nWarunki korzystania z usługi\n(Wersja testowa) Warunki korzystania z usługi\nRegiony, w których działa ta usługa\nNa tej stronie\nZweryfikuj klucz interfejsu API za pomocą polecenia curl\nZabezpiecz swój klucz interfejsu API\nDalsze kroki\nZapoznaj się z nową książką kucharską na temat interfejsu Gemini API i poznaj nasze forum społeczności.\n Ta strona została przetłumaczona przez Cloud Translation API.\nGoogle AI for Developers\nProdukty\nCzy te wskazówki były pomocne?\nPrześlij opinię\nUzyskiwanie klucza interfejsu API \nbookmark_border\n\nAby używać interfejsu Gemini API, potrzebujesz klucza interfejsu API. Możesz utworzyć klucz jednym kliknięciem w Google AI Studio.\n\nUzyskiwanie klucza interfejsu API\n\nWażne: pamiętaj, aby bezpiecznie używać kluczy interfejsu API. Przeczytaj artykuł Zabezpieczanie klucza interfejsu API, a potem przeczytaj krótkie wprowadzenia do interfejsu API, aby poznać sprawdzone metody zabezpieczania klucza interfejsu API w poszczególnych językach.\nZweryfikuj klucz interfejsu API za pomocą polecenia curl\n\nAby sprawdzić konfigurację, możesz użyć polecenia curl. Klucz interfejsu API możesz przekazać w adresie URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nLub w nagłówku x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nZabezpiecz swój klucz interfejsu API\n\nKlucz interfejsu Gemini API musi być bezpieczny. Oto kilka kwestii, o których należy pamiętać, używając klucza interfejsu Gemini API:\n\nInterfejs Google AI Gemini API do autoryzacji używa kluczy interfejsu API. Jeśli inne osoby uzyskają dostęp do Twojego klucza interfejsu Gemini API, będą mogły wykonywać wywołania, korzystając z limitu projektu, co może spowodować utratę limitu lub dodatkowe opłaty (jeśli płatności są włączone). Klucze interfejsu API chronią też dostęp do dostrojonych modeli i plików.\n\nGdy klikniesz Pobierz klucz interfejsu API w Google AI Studio, wybierzesz, czy chcesz udostępnić klucz interfejsu Gemini API w nowym czy istniejącym projekcie Google Cloud. Lista kluczy interfejsów API w Google AI Studio zawiera wszystkie klucze interfejsu API udostępnione przez AI Studio do użycia z interfejsem Google AI Gemini API (wraz ze wszystkimi powiązanymi projektami Google Cloud).\n\nJednak dowolne klucze interfejsu API w projekcie Google Cloud mogą zostać użyte do wywołania interfejsu Google AI Gemini API. W konsoli Google Cloud możesz przeglądać wszystkie klucze interfejsu API swojego projektu i zarządzać nimi w panelu Interfejsy API i usługi > Dane logowania.\n\nDodanie ograniczeń dotyczących kluczy interfejsu API pomaga ograniczyć obszar wykorzystywanych przez poszczególne klucze interfejsu API. Domyślnie klucza interfejsu API Gemini wygenerowanego przez Google AI Studio można używać tylko razem z interfejsem Google AI AI Gemini API (oficjalnie nazywanym „Generative Language API” lub generativelanguage.googleapis.com).\n\nJeśli w Twoim projekcie Google Cloud są klucze interfejsu API, które nie mają ograniczeń interfejsu API ani żadnych kluczy, które zostały dodane do listy dozwolonych interfejsu API języka generatywnego, możesz ich używać z interfejsem Google AI Gemini API. Sprawdzoną metodą jest ograniczenie każdego klucza API tylko do tych, które są wywoływane za jego pomocą.\nPamiętaj, że nawet w przypadku ograniczeń klucza interfejsu API, jeśli złośliwy użytkownik zdobędzie klucz interfejsu API, może go używać do wykonywania wywołań z wykorzystaniem limitu projektu dla wszystkich interfejsów API dodanych do listy dozwolonych dla danego klucza interfejsu API.\n\nOdpowiadasz za bezpieczeństwo klucza interfejsu Gemini API.\n\nNIE sprawdzaj kluczy interfejsu Gemini API pod kątem kontroli źródła.\nAplikacje po stronie klienta (Android, Swift, web i Dart/Flutter) ryzykują ujawnienie kluczy interfejsu API, dlatego nie zalecamy używania pakietów SDK klienta AI od Google w aplikacjach produkcyjnych do wywoływania interfejsu Google AI Gemini API bezpośrednio z aplikacji mobilnych i internetowych. Zapoznaj się z krótkimi wprowadzeniami do pakietu SDK, aby poznać sprawdzone metody zabezpieczania klucza interfejsu API w danym języku.\n\nOgólne sprawdzone metody znajdziesz w tym artykule pomocy.\n\nDalsze kroki\nPrzeczytaj krótkie wprowadzenia do interfejsu API, aby poznać sprawdzone metody zabezpieczania klucza interfejsu API i jego używania.\nCzy te wskazówki były pomocne?\nPrześlij opinię\n\nO ile nie stwierdzono inaczej, treść tej strony jest objęta licencją Creative Commons – uznanie autorstwa 4.0, a fragmenty kodu są dostępne na licencji Apache 2.0. Szczegółowe informacje na ten temat zawierają zasady dotyczące witryny Google Developers. Java jest zastrzeżonym znakiem towarowym firmy Oracle i jej podmiotów stowarzyszonych.\n\nOstatnia aktualizacja: 2024-04-24 UTC.\n\nWarunki\nPrywatność",
            "word_count": 785,
            "filtered_content": "Na tej stronie\nUzyskiwanie klucza interfejsu API \nAby używać interfejsu Gemini API, potrzebujesz klucza interfejsu API. Możesz utworzyć klucz jednym kliknięciem w Google AI Studio.\nWażne: pamiętaj, aby bezpiecznie używać kluczy interfejsu API. Przeczytaj artykuł Zabezpieczanie klucza interfejsu API, a potem przeczytaj krótkie wprowadzenia do interfejsu API, aby poznać sprawdzone metody zabezpieczania klucza interfejsu API w poszczególnych językach.\nAby sprawdzić konfigurację, możesz użyć polecenia curl. Klucz interfejsu API możesz przekazać w adresie URL:\nLub w nagłówku x-goog-api-key:\nKlucz interfejsu Gemini API musi być bezpieczny. Oto kilka kwestii, o których należy pamiętać, używając klucza interfejsu Gemini API:\nInterfejs Google AI Gemini API do autoryzacji używa kluczy interfejsu API. Jeśli inne osoby uzyskają dostęp do Twojego klucza interfejsu Gemini API, będą mogły wykonywać wywołania, korzystając z limitu projektu, co może spowodować utratę limitu lub dodatkowe opłaty (jeśli płatności są włączone). Klucze interfejsu API chronią też dostęp do dostrojonych modeli i plików.\nGdy klikniesz Pobierz klucz interfejsu API w Google AI Studio, wybierzesz, czy chcesz udostępnić klucz interfejsu Gemini API w nowym czy istniejącym projekcie Google Cloud. Lista kluczy interfejsów API w Google AI Studio zawiera wszystkie klucze interfejsu API udostępnione przez AI Studio do użycia z interfejsem Google AI Gemini API (wraz ze wszystkimi powiązanymi projektami Google Cloud).\nJednak dowolne klucze interfejsu API w projekcie Google Cloud mogą zostać użyte do wywołania interfejsu Google AI Gemini API. W konsoli Google Cloud możesz przeglądać wszystkie klucze interfejsu API swojego projektu i zarządzać nimi w panelu Interfejsy API i usługi > Dane logowania.\nDodanie ograniczeń dotyczących kluczy interfejsu API pomaga ograniczyć obszar wykorzystywanych przez poszczególne klucze interfejsu API. Domyślnie klucza interfejsu API Gemini wygenerowanego przez Google AI Studio można używać tylko razem z interfejsem Google AI AI Gemini API (oficjalnie nazywanym „Generative Language API” lub generativelanguage.googleapis.com).\nJeśli w Twoim projekcie Google Cloud są klucze interfejsu API, które nie mają ograniczeń interfejsu API ani żadnych kluczy, które zostały dodane do listy dozwolonych interfejsu API języka generatywnego, możesz ich używać z interfejsem Google AI Gemini API. Sprawdzoną metodą jest ograniczenie każdego klucza API tylko do tych, które są wywoływane za jego pomocą.\nPamiętaj, że nawet w przypadku ograniczeń klucza interfejsu API, jeśli złośliwy użytkownik zdobędzie klucz interfejsu API, może go używać do wykonywania wywołań z wykorzystaniem limitu projektu dla wszystkich interfejsów API dodanych do listy dozwolonych dla danego klucza interfejsu API.\nOdpowiadasz za bezpieczeństwo klucza interfejsu Gemini API.\nNIE sprawdzaj kluczy interfejsu Gemini API pod kątem kontroli źródła.\nAplikacje po stronie klienta (Android, Swift, web i Dart/Flutter) ryzykują ujawnienie kluczy interfejsu API, dlatego nie zalecamy używania pakietów SDK klienta AI od Google w aplikacjach produkcyjnych do wywoływania interfejsu Google AI Gemini API bezpośrednio z aplikacji mobilnych i internetowych. Zapoznaj się z krótkimi wprowadzeniami do pakietu SDK, aby poznać sprawdzone metody zabezpieczania klucza interfejsu API w danym języku.\nOgólne sprawdzone metody znajdziesz w tym artykule pomocy.\nPrzeczytaj krótkie wprowadzenia do interfejsu API, aby poznać sprawdzone metody zabezpieczania klucza interfejsu API i jego używania.\nOstatnia aktualizacja: 2024-04-24 UTC.",
            "filtered_word_count": 490
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pt-br": {
            "status": "Looks good",
            "content": "Produtos\nExemplos\nFazer login\nDocs\nReferência da API\nVisão geral\nComeçar\nObter uma chave de API\nGuia de início rápido da API Gemini\nGuia de início rápido do Google AI Studio\nTutoriais com os primeiros passos\nModelos\nSobre modelos generativos\nGemini\nGemini API\nVisão geral da API\nReferência da API\nVersões da API\nNotas da versão\nRecursos\nAjuste do modelo\nChamadas de funções\nEmbeddings\nSegurança\nGuias\nSolicitações de prompt\nInstruções do sistema\nRecuperação semântica\nAutenticação OAuth\nExtensões do Firebase\nMigrar para o Cloud\nTutoriais\nChamadas de funções\nEmbeddings\nAplicativos\nSolução de problemas\nGuia de solução de problemas\nAcessar o AI Studio usando o Workspace\nComo solucionar problemas no AI Studio\nSolicitar mais cotas\nComunidade\nFórum do Discourse\nAPI PaLM (legada)\nMigrar para o Gêmeos\nDocumentos do PaLM\nJurídico\nTermos de Serviço\n(Prévia) Termos de Serviço\nRegiões disponíveis\nNesta página\nVerificar sua chave de API com um comando curl\nProteja sua chave de API\nPróximas etapas\nConfira o Cookbook da nova API Gemini e nosso fórum da comunidade.\n Esta página foi traduzida pela API Cloud Translation.\nGoogle AI for Developers\nProdutos\nIsso foi útil?\nEnvie comentários\nObter uma chave de API \nbookmark_border\n\nPara usar a API Gemini, você precisa de uma chave de API. É possível criar uma chave com um clique no Google AI Studio.\n\nGerar uma chave de API\n\nImportante :não se esqueça de usar suas chaves de API com segurança. Consulte Proteger sua chave de API e confira os Guias de início rápido da API para conhecer as práticas recomendadas específicas da linguagem e proteger sua chave de API.\nVerificar sua chave de API com um comando curl\n\nUse um comando curl para verificar a configuração. É possível transmitir a chave de API no URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOu no cabeçalho x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nProteja sua chave de API\n\nÉ importante manter sua chave de API do Gemini segura. Veja alguns pontos a serem considerados ao usar a chave de API do Gemini:\n\nA API Google AI Gemini usa chaves de API para autorização. Se outras pessoas tiverem acesso à sua chave de API do Gemini, elas poderão fazer chamadas usando a cota do seu projeto, o que pode resultar na perda de cota ou em outras cobranças de faturamento (se o faturamento estiver ativado). As chaves de API também protegem o acesso a modelos e arquivos ajustados.\n\nAo clicar em Receber chave de API no Google AI Studio, você escolhe se quer provisionar uma chave de API do Gemini em um projeto novo ou atual do Google Cloud. A lista de chaves de API no Google AI Studio mostra todas as chaves de API que o AI Studio provisionou para uso com a API Google AI Gemini, além de todos os projetos associados do Google Cloud.\n\nNo entanto, qualquer chave de API no projeto do Google Cloud pode ser usada para chamar a API Google AI Gemini. É possível ver e gerenciar todas as chaves de API do projeto no painel \"APIs e serviços > Credenciais \" no console do Google Cloud.\n\nAdicionar restrições de chave de API pode ajudar a limitar a área de superfície utilizável por meio de cada chave de API. Por padrão, a chave da API Genmini gerada pelo Google AI Studio só pode ser usada com a API Generative Language do Google (chamada oficialmente de \"API Generative Language\" ou generativelanguage.googleapis.com).\n\nSe houver alguma chave de API no projeto do Google Cloud que não tenha restrições de API ou que tenha a API Generative Language na lista de permissões, essas chaves poderão ser usadas com a API Google AI Gemini. Recomendamos restringir cada chave apenas às APIs que você chama usando essa chave.\nMesmo com restrições de chave de API, se uma pessoa mal-intencionada conseguir sua chave de API, ela poderá usá-la para fazer chamadas usando a cota do seu projeto para todas as APIs permitidas para essa chave.\n\nVocê é responsável por manter sua chave de API do Gemini protegida.\n\nNÃO verifique as chaves de API do Gemini no controle de origem.\nAplicativos do lado do cliente (Android, Swift, Web e Dart/Flutter) correm o risco de expor chaves de API. Por isso, não recomendamos o uso de SDKs do cliente de IA do Google em aplicativos de produção para chamar a API Google AI Gemini diretamente dos apps da Web e para dispositivos móveis. Confira os guias de início rápido do SDK para conhecer as práticas recomendadas específicas para cada linguagem e proteger sua chave de API.\n\nPara conferir algumas práticas recomendadas gerais, consulte também este artigo de suporte.\n\nPróximas etapas\nConfira os guias de início rápido da API e conheça as práticas recomendadas para proteger e usar sua chave de API.\nIsso foi útil?\nEnvie comentários\n\nExceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.\n\nÚltima atualização 2024-04-24 UTC.\n\nTermos de Serviço\nPrivacidade",
            "word_count": 887,
            "filtered_content": "Nesta página\nObter uma chave de API \nPara usar a API Gemini, você precisa de uma chave de API. É possível criar uma chave com um clique no Google AI Studio.\nGerar uma chave de API\nImportante :não se esqueça de usar suas chaves de API com segurança. Consulte Proteger sua chave de API e confira os Guias de início rápido da API para conhecer as práticas recomendadas específicas da linguagem e proteger sua chave de API.\nUse um comando curl para verificar a configuração. É possível transmitir a chave de API no URL:\nOu no cabeçalho x-goog-api-key:\nÉ importante manter sua chave de API do Gemini segura. Veja alguns pontos a serem considerados ao usar a chave de API do Gemini:\nA API Google AI Gemini usa chaves de API para autorização. Se outras pessoas tiverem acesso à sua chave de API do Gemini, elas poderão fazer chamadas usando a cota do seu projeto, o que pode resultar na perda de cota ou em outras cobranças de faturamento (se o faturamento estiver ativado). As chaves de API também protegem o acesso a modelos e arquivos ajustados.\nAo clicar em Receber chave de API no Google AI Studio, você escolhe se quer provisionar uma chave de API do Gemini em um projeto novo ou atual do Google Cloud. A lista de chaves de API no Google AI Studio mostra todas as chaves de API que o AI Studio provisionou para uso com a API Google AI Gemini, além de todos os projetos associados do Google Cloud.\nNo entanto, qualquer chave de API no projeto do Google Cloud pode ser usada para chamar a API Google AI Gemini. É possível ver e gerenciar todas as chaves de API do projeto no painel \"APIs e serviços > Credenciais \" no console do Google Cloud.\nAdicionar restrições de chave de API pode ajudar a limitar a área de superfície utilizável por meio de cada chave de API. Por padrão, a chave da API Genmini gerada pelo Google AI Studio só pode ser usada com a API Generative Language do Google (chamada oficialmente de \"API Generative Language\" ou generativelanguage.googleapis.com).\nSe houver alguma chave de API no projeto do Google Cloud que não tenha restrições de API ou que tenha a API Generative Language na lista de permissões, essas chaves poderão ser usadas com a API Google AI Gemini. Recomendamos restringir cada chave apenas às APIs que você chama usando essa chave.\nMesmo com restrições de chave de API, se uma pessoa mal-intencionada conseguir sua chave de API, ela poderá usá-la para fazer chamadas usando a cota do seu projeto para todas as APIs permitidas para essa chave.\nVocê é responsável por manter sua chave de API do Gemini protegida.\nNÃO verifique as chaves de API do Gemini no controle de origem.\nAplicativos do lado do cliente (Android, Swift, Web e Dart/Flutter) correm o risco de expor chaves de API. Por isso, não recomendamos o uso de SDKs do cliente de IA do Google em aplicativos de produção para chamar a API Google AI Gemini diretamente dos apps da Web e para dispositivos móveis. Confira os guias de início rápido do SDK para conhecer as práticas recomendadas específicas para cada linguagem e proteger sua chave de API.\nPara conferir algumas práticas recomendadas gerais, consulte também este artigo de suporte.\nConfira os guias de início rápido da API e conheça as práticas recomendadas para proteger e usar sua chave de API.\nÚltima atualização 2024-04-24 UTC.",
            "filtered_word_count": 579
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=vi": {
            "status": "Looks good",
            "content": "Sản phẩm\nVí dụ\nĐăng nhập\nTài liệu\nTài liệu tham khảo API\nTổng quan\nBắt đầu\nNhận khoá API\nBắt đầu nhanh API Gemini\nHướng dẫn nhanh về Google AI Studio\nHướng dẫn bắt đầu sử dụng\nMô hình\nGiới thiệu về các mô hình tạo sinh\nGemini\nGemini API\nTổng quan về API\nTài liệu tham khảo API\nPhiên bản API\nGhi chú phát hành\nChức năng\nĐiều chỉnh mô hình\nGọi hàm\nNhúng\nAn toàn\nHướng dẫn\nNhắc nhở\nHướng dẫn hệ thống\nTruy xuất ngữ nghĩa\nXác thực OAuth\nTiện ích Firebase\nDi chuyển sang nền tảng đám mây\nHướng dẫn\nGọi hàm\nNhúng\nỨng dụng\nKhắc phục sự cố\nHướng dẫn khắc phục sự cố\nTruy cập vào AI Studio bằng Workspace\nKhắc phục sự cố với AI Studio\nYêu cầu tăng hạn mức\nCộng đồng\nDiễn đàn Discourse\nAPI PaLM (cũ)\nDi chuyển sang Gemini\nTài liệu PaLM\nPháp lý\nĐiều khoản dịch vụ\n(Bản xem trước) Điều khoản dịch vụ\nKhu vực khả dụng\nTrên trang này\nXác minh khoá API bằng lệnh curl\nBảo mật khoá API\nCác bước tiếp theo\nHãy khám phá Cookbook API mới và diễn đàn cộng đồng của chúng tôi.\n Trang này được dịch bởi Cloud Translation API.\nGoogle AI for Developers\nSản phẩm\nThông tin này có hữu ích không cho bạn không?\nGửi ý kiến phản hồi\nNhận khoá API \nbookmark_border\n\nĐể sử dụng API Gemini, bạn cần có khoá API. Bạn có thể tạo khoá chỉ bằng một lần nhấp trong Google AI Studio.\n\nLấy khoá API\n\nLưu ý quan trọng: Hãy nhớ sử dụng khoá API một cách an toàn. Hãy xem phần Bảo mật khoá API rồi xem hướng dẫn bắt đầu nhanh về API để tìm hiểu các phương pháp hay nhất theo ngôn ngữ cụ thể nhằm bảo mật khoá API.\nXác minh khoá API bằng lệnh curl\n\nBạn có thể sử dụng lệnh curl để xác minh chế độ thiết lập của mình. Bạn có thể chuyển khoá API trong URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nHoặc trong tiêu đề x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nBảo mật khoá API\n\nĐiều quan trọng là bạn phải bảo mật khoá API Gemini. Dưới đây là một vài điều cần lưu ý khi sử dụng khoá API Gemini:\n\nAPI AI Gemini của Google sử dụng khoá API để uỷ quyền. Nếu những người khác có quyền truy cập vào khoá API Gemini của bạn, họ có thể thực hiện lệnh gọi bằng hạn mức dự án của bạn. Điều này có thể dẫn đến việc mất hạn mức hoặc bị tính thêm phí thanh toán (nếu bạn bật tính năng thanh toán). Khoá API cũng bảo vệ quyền truy cập vào các mô hình và tệp đã được điều chỉnh.\n\nKhi nhấp vào Get API key (Lấy khoá API) trong Google AI Studio, bạn có thể chọn cung cấp khoá API Gemini trong một dự án mới hoặc hiện có trên Google Cloud. Danh sách khoá API trong Google AI Studio cho thấy tất cả các khoá API mà AI Studio đã cấp phép để sử dụng với API Google AI Gemini (cùng với tất cả các dự án Google Cloud có liên quan).\n\nTuy nhiên, bạn có thể dùng bất kỳ khoá API nào trong dự án Google Cloud để gọi API Gemini của Google AI. Bạn có thể xem và quản lý tất cả khoá API của dự án tại API và dịch vụ > Bảng thông tin xác thực trong bảng điều khiển Google Cloud.\n\nViệc thêm các hạn chế về khoá API có thể giúp giới hạn diện tích bề mặt có thể sử dụng thông qua mỗi khoá API. Theo mặc định, bạn chỉ có thể sử dụng khoá APIGemini do Google AI Studio tạo với API Genmini của Google AI (gọi chính thức là \"API ngôn ngữ tạo sinh\" hay generativelanguage.googleapis.com).\n\nNếu có bất kỳ khoá API nào trong dự án Google Cloud của bạn thiếu quy định hạn chế đối với API hoặc bất kỳ khoá API nào đã đưa API Ngôn ngữ tạo sinh vào danh sách cho phép, thì bạn có thể sử dụng các khoá đó với API của Google AI Gemini. Tốt nhất là bạn chỉ nên hạn chế mỗi khoá API ở các API mà bạn gọi bằng khoá đó.\nLưu ý rằng ngay cả với các hạn chế về khoá API, nếu một đối tượng xấu lấy được khoá API của bạn, thì họ vẫn có thể sử dụng khoá đó để thực hiện lệnh gọi bằng hạn mức dự án của bạn cho mọi API được cho phép đối với khoá API đó.\n\nBạn có trách nhiệm bảo mật khoá API Gemini.\n\nKHÔNG kiểm tra khoá API Gemini trong chế độ kiểm soát nguồn.\nCác ứng dụng phía máy khách (Android, Swift, web và Dart/Flutter) có nguy cơ để lộ khoá API. Vì vậy, bạn không nên sử dụng SDK ứng dụng AI của Google trong ứng dụng chính thức để gọi API Gemini của Google AI trực tiếp từ ứng dụng web và ứng dụng di động. Xem hướng dẫn bắt đầu nhanh về SDK để tìm hiểu các phương pháp hay nhất dành riêng cho từng ngôn ngữ nhằm bảo mật khoá API.\n\nĐể tìm hiểu một số phương pháp chung hay nhất, bạn cũng có thể xem bài viết hỗ trợ này.\n\nCác bước tiếp theo\nXem hướng dẫn bắt đầu nhanh về API để tìm hiểu các phương pháp hay nhất giúp bảo mật và sử dụng khoá API.\nThông tin này có hữu ích không cho bạn không?\nGửi ý kiến phản hồi\n\nTrừ khi có lưu ý khác, nội dung của trang này được cấp phép theo Giấy phép ghi nhận tác giả 4.0 của Creative Commons và các mẫu mã lập trình được cấp phép theo Giấy phép Apache 2.0. Để biết thông tin chi tiết, vui lòng tham khảo Chính sách trang web của Google Developers. Java là nhãn hiệu đã đăng ký của Oracle và/hoặc các đơn vị liên kết với Oracle.\n\nCập nhật lần gần đây nhất: 2024-04-24 UTC.\n\nĐiều khoản\nQuyền riêng tư",
            "word_count": 1069,
            "filtered_content": "Trên trang này\nNhận khoá API \nĐể sử dụng API Gemini, bạn cần có khoá API. Bạn có thể tạo khoá chỉ bằng một lần nhấp trong Google AI Studio.\nLấy khoá API\nLưu ý quan trọng: Hãy nhớ sử dụng khoá API một cách an toàn. Hãy xem phần Bảo mật khoá API rồi xem hướng dẫn bắt đầu nhanh về API để tìm hiểu các phương pháp hay nhất theo ngôn ngữ cụ thể nhằm bảo mật khoá API.\nBạn có thể sử dụng lệnh curl để xác minh chế độ thiết lập của mình. Bạn có thể chuyển khoá API trong URL:\nHoặc trong tiêu đề x-goog-api-key:\nĐiều quan trọng là bạn phải bảo mật khoá API Gemini. Dưới đây là một vài điều cần lưu ý khi sử dụng khoá API Gemini:\nAPI AI Gemini của Google sử dụng khoá API để uỷ quyền. Nếu những người khác có quyền truy cập vào khoá API Gemini của bạn, họ có thể thực hiện lệnh gọi bằng hạn mức dự án của bạn. Điều này có thể dẫn đến việc mất hạn mức hoặc bị tính thêm phí thanh toán (nếu bạn bật tính năng thanh toán). Khoá API cũng bảo vệ quyền truy cập vào các mô hình và tệp đã được điều chỉnh.\nKhi nhấp vào Get API key (Lấy khoá API) trong Google AI Studio, bạn có thể chọn cung cấp khoá API Gemini trong một dự án mới hoặc hiện có trên Google Cloud. Danh sách khoá API trong Google AI Studio cho thấy tất cả các khoá API mà AI Studio đã cấp phép để sử dụng với API Google AI Gemini (cùng với tất cả các dự án Google Cloud có liên quan).\nTuy nhiên, bạn có thể dùng bất kỳ khoá API nào trong dự án Google Cloud để gọi API Gemini của Google AI. Bạn có thể xem và quản lý tất cả khoá API của dự án tại API và dịch vụ > Bảng thông tin xác thực trong bảng điều khiển Google Cloud.\nViệc thêm các hạn chế về khoá API có thể giúp giới hạn diện tích bề mặt có thể sử dụng thông qua mỗi khoá API. Theo mặc định, bạn chỉ có thể sử dụng khoá APIGemini do Google AI Studio tạo với API Genmini của Google AI (gọi chính thức là \"API ngôn ngữ tạo sinh\" hay generativelanguage.googleapis.com).\nNếu có bất kỳ khoá API nào trong dự án Google Cloud của bạn thiếu quy định hạn chế đối với API hoặc bất kỳ khoá API nào đã đưa API Ngôn ngữ tạo sinh vào danh sách cho phép, thì bạn có thể sử dụng các khoá đó với API của Google AI Gemini. Tốt nhất là bạn chỉ nên hạn chế mỗi khoá API ở các API mà bạn gọi bằng khoá đó.\nLưu ý rằng ngay cả với các hạn chế về khoá API, nếu một đối tượng xấu lấy được khoá API của bạn, thì họ vẫn có thể sử dụng khoá đó để thực hiện lệnh gọi bằng hạn mức dự án của bạn cho mọi API được cho phép đối với khoá API đó.\nBạn có trách nhiệm bảo mật khoá API Gemini.\nKHÔNG kiểm tra khoá API Gemini trong chế độ kiểm soát nguồn.\nCác ứng dụng phía máy khách (Android, Swift, web và Dart/Flutter) có nguy cơ để lộ khoá API. Vì vậy, bạn không nên sử dụng SDK ứng dụng AI của Google trong ứng dụng chính thức để gọi API Gemini của Google AI trực tiếp từ ứng dụng web và ứng dụng di động. Xem hướng dẫn bắt đầu nhanh về SDK để tìm hiểu các phương pháp hay nhất dành riêng cho từng ngôn ngữ nhằm bảo mật khoá API.\nĐể tìm hiểu một số phương pháp chung hay nhất, bạn cũng có thể xem bài viết hỗ trợ này.\nXem hướng dẫn bắt đầu nhanh về API để tìm hiểu các phương pháp hay nhất giúp bảo mật và sử dụng khoá API.\nCập nhật lần gần đây nhất: 2024-04-24 UTC.",
            "filtered_word_count": 689
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=tr": {
            "status": "Looks good",
            "content": "Ürünler\nÖrnekler\nOturum aç\nDokümanlar\nAPI Referansı\nGenel bakış\nBaşlama\nAPI anahtarı alma\nGemini API hızlı başlangıç kılavuzu\nGoogle AI Studio hızlı başlangıç kılavuzu\nBaşlangıç eğiticileri\nModeller\nÜretken modeller hakkında\nGemini\nGemini API\nAPI'ye genel bakış\nAPI referansı\nAPI sürümleri\nSürüm notları\nÖzellikler\nModel ince ayarı\nİşlev çağrısı\nYerleştirmeler\nGüvenlik\nRehberler\nİstemde bulunma\nSistem talimatları\nAnlamsal alma\nOAuth kimlik doğrulaması\nFirebase uzantıları\nCloud'a taşı\nEğitimler\nİşlev çağrısı\nYerleştirmeler\nUygulamalar\nSorun giderme\nSorun giderme kılavuzu\nWorkspace'i kullanarak AI Studio'ya erişme\nAI Studio ile ilgili sorunları giderme\nDaha fazla kota isteme\nTopluluk\nTartışma forumu\nPaLM API (eski)\nGemini'a taşıyın\nPaLM belgeleri\nHukuk\nHizmet şartları\n(Önizleme) Hizmet şartları\nKullanılabildiği bölgeler\nBu sayfada\nAPI anahtarınızı curl komutuyla doğrulama\nAPI anahtarınızı güvende tutun\nSonraki adımlar\nYeni Gemini API Cookbook'una ve topluluk forumumuza göz atın.\n Bu sayfa, Cloud Translation API ile çevrilmiştir.\nGoogle AI for Developers\nÜrünler\nBu size yardımcı oldu mu?\nGeri bildirim gönderin\nAPI anahtarı alma \nbookmark_border\n\nGemini API'yi kullanmak için API anahtarı gerekir. Google AI Studio'da tek tıklamayla anahtar oluşturabilirsiniz.\n\nAPI anahtarı alma\n\nÖnemli: API anahtarlarınızı güvenli bir şekilde kullanmayı unutmayın. API anahtarınızı güvende tutma konusunu inceleyin ve ardından API hızlı başlangıç kılavuzlarını inceleyerek API anahtarınızı güvenceye almayla ilgili dile özgü en iyi uygulamaları öğrenin.\nAPI anahtarınızı curl komutuyla doğrulama\n\nKurulumunuzu doğrulamak için curl komutu kullanabilirsiniz. API anahtarını URL'de aktarabilirsiniz:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nVeya x-goog-api-key başlığında:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nAPI anahtarınızı güvende tutun\n\nGemini API anahtarınızı güvende tutmak önemlidir. Gemini API anahtarınızı kullanırken göz önünde bulundurmanız gereken birkaç nokta aşağıda belirtilmiştir:\n\nGoogle AI Gemini API, yetkilendirme için API anahtarlarını kullanır. Gemini API anahtarınıza başka kullanıcıların erişimi olursa projenizin kotasını kullanarak çağrı yapabilirler. Bu durum, kota kaybına veya ek faturalandırma ücretlerine (faturalandırma etkinse) neden olabilir. API anahtarları, hassaslaştırılmış modellere ve dosyalara erişimi de korur.\n\nGoogle AI Studio'da API anahtarı al'ı tıkladığınızda, yeni veya mevcut bir Google Cloud projesinde Gemini API anahtarı sağlayıp sağlamayacağınızı seçersiniz. Google AI Studio'daki API anahtarları listesinde, AI Studio'nun Google AI Gemini API ile kullanılmak üzere sağladığı tüm API anahtarları (ilişkili tüm Google Cloud projeleriyle birlikte) gösterilir.\n\nBununla birlikte, Google Cloud projesindeki tüm API anahtarları, Google AI Gemini API'yi çağırmak için kullanılabilir. Projenizin tüm API anahtarlarını Google Cloud Console'daki API'ler ve Hizmetler > Kimlik Bilgileri panelinde görüntüleyebilir ve yönetebilirsiniz.\n\nAPI anahtarı kısıtlamaları eklemek, her API anahtarı aracılığıyla kullanılabilecek yüzey alanını sınırlandırmaya yardımcı olabilir. Google AI Studio tarafından oluşturulan Gemini API anahtarı, varsayılan olarak yalnızca Google AI Gemini API (resmi adıyla \"Generative Language API\" veya generativelanguage.googleapis.com) ile kullanılabilir.\n\nGoogle Cloud projenizde API kısıtlamaları olmayan API anahtarları veya Generative Language API'yi izin verilenler listesine eklenmiş API anahtarları varsa bu anahtarlar Google AI Gemini API ile kullanılabilir. En iyi uygulama, her API anahtarını yalnızca bu anahtarı kullanarak çağırdığınız API'lerle kısıtlamaktır.\nAPI anahtarı kısıtlamaları olsa bile API anahtarınızı ele geçiren kötü amaçlı kişiler, projenizin söz konusu API anahtarı için izin verilenler listesine eklenmiş tüm API'lerin kotasını kullanarak çağrı yapmak amacıyla bu anahtarı kullanabilir.\n\nGemini API anahtarınızı güvende tutmak sizin sorumluluğunuzdadır.\n\nGemini API anahtarlarını kaynak kontrolüne İŞARETLEMEYİN.\nİstemci tarafı uygulamalar (Android, Swift, web ve Dart/Flutter) API anahtarlarının açığa çıkma riskini taşır. Bu nedenle, Google AI Gemini API'yi doğrudan mobil ve web uygulamalarınızdan çağırmak için üretim uygulamalarında Google AI istemci SDK'larını kullanmanızı önermeyiz. API anahtarınızı güvenceye almayla ilgili dile özgü en iyi uygulamaları öğrenmek için SDK hızlı başlangıç kılavuzlarına göz atın.\n\nBazı genel en iyi uygulamalar için bu destek makalesini de inceleyebilirsiniz.\n\nSonraki adımlar\nAPI anahtarınızı güvence altına alma ve kullanma ile ilgili en iyi uygulamaları öğrenmek için API hızlı başlangıç kılavuzlarına göz atın.\nBu size yardımcı oldu mu?\nGeri bildirim gönderin\n\nAksi belirtilmediği sürece bu sayfanın içeriği Creative Commons Atıf 4.0 Lisansı altında ve kod örnekleri Apache 2.0 Lisansı altında lisanslanmıştır. Ayrıntılı bilgi için Google Developers Site Politikaları'na göz atın. Java, Oracle ve/veya satış ortaklarının tescilli ticari markasıdır.\n\nSon güncelleme tarihi: 2024-04-24 UTC.\n\nŞartlar\nGizlilik",
            "word_count": 665,
            "filtered_content": "Bu sayfada\nAPI anahtarı alma \nGemini API'yi kullanmak için API anahtarı gerekir. Google AI Studio'da tek tıklamayla anahtar oluşturabilirsiniz.\nÖnemli: API anahtarlarınızı güvenli bir şekilde kullanmayı unutmayın. API anahtarınızı güvende tutma konusunu inceleyin ve ardından API hızlı başlangıç kılavuzlarını inceleyerek API anahtarınızı güvenceye almayla ilgili dile özgü en iyi uygulamaları öğrenin.\nKurulumunuzu doğrulamak için curl komutu kullanabilirsiniz. API anahtarını URL'de aktarabilirsiniz:\nVeya x-goog-api-key başlığında:\nGemini API anahtarınızı güvende tutmak önemlidir. Gemini API anahtarınızı kullanırken göz önünde bulundurmanız gereken birkaç nokta aşağıda belirtilmiştir:\nGoogle AI Gemini API, yetkilendirme için API anahtarlarını kullanır. Gemini API anahtarınıza başka kullanıcıların erişimi olursa projenizin kotasını kullanarak çağrı yapabilirler. Bu durum, kota kaybına veya ek faturalandırma ücretlerine (faturalandırma etkinse) neden olabilir. API anahtarları, hassaslaştırılmış modellere ve dosyalara erişimi de korur.\nGoogle AI Studio'da API anahtarı al'ı tıkladığınızda, yeni veya mevcut bir Google Cloud projesinde Gemini API anahtarı sağlayıp sağlamayacağınızı seçersiniz. Google AI Studio'daki API anahtarları listesinde, AI Studio'nun Google AI Gemini API ile kullanılmak üzere sağladığı tüm API anahtarları (ilişkili tüm Google Cloud projeleriyle birlikte) gösterilir.\nBununla birlikte, Google Cloud projesindeki tüm API anahtarları, Google AI Gemini API'yi çağırmak için kullanılabilir. Projenizin tüm API anahtarlarını Google Cloud Console'daki API'ler ve Hizmetler > Kimlik Bilgileri panelinde görüntüleyebilir ve yönetebilirsiniz.\nAPI anahtarı kısıtlamaları eklemek, her API anahtarı aracılığıyla kullanılabilecek yüzey alanını sınırlandırmaya yardımcı olabilir. Google AI Studio tarafından oluşturulan Gemini API anahtarı, varsayılan olarak yalnızca Google AI Gemini API (resmi adıyla \"Generative Language API\" veya generativelanguage.googleapis.com) ile kullanılabilir.\nGoogle Cloud projenizde API kısıtlamaları olmayan API anahtarları veya Generative Language API'yi izin verilenler listesine eklenmiş API anahtarları varsa bu anahtarlar Google AI Gemini API ile kullanılabilir. En iyi uygulama, her API anahtarını yalnızca bu anahtarı kullanarak çağırdığınız API'lerle kısıtlamaktır.\nAPI anahtarı kısıtlamaları olsa bile API anahtarınızı ele geçiren kötü amaçlı kişiler, projenizin söz konusu API anahtarı için izin verilenler listesine eklenmiş tüm API'lerin kotasını kullanarak çağrı yapmak amacıyla bu anahtarı kullanabilir.\nGemini API anahtarınızı güvende tutmak sizin sorumluluğunuzdadır.\nGemini API anahtarlarını kaynak kontrolüne İŞARETLEMEYİN.\nİstemci tarafı uygulamalar (Android, Swift, web ve Dart/Flutter) API anahtarlarının açığa çıkma riskini taşır. Bu nedenle, Google AI Gemini API'yi doğrudan mobil ve web uygulamalarınızdan çağırmak için üretim uygulamalarında Google AI istemci SDK'larını kullanmanızı önermeyiz. API anahtarınızı güvenceye almayla ilgili dile özgü en iyi uygulamaları öğrenmek için SDK hızlı başlangıç kılavuzlarına göz atın.\nBazı genel en iyi uygulamalar için bu destek makalesini de inceleyebilirsiniz.\nAPI anahtarınızı güvence altına alma ve kullanma ile ilgili en iyi uygulamaları öğrenmek için API hızlı başlangıç kılavuzlarına göz atın.\nSon güncelleme tarihi: 2024-04-24 UTC.",
            "filtered_word_count": 414
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ru": {
            "status": "Looks good",
            "content": "Продукты\nПримеры\nВойти\nДокументы\nДокументация по API\nОбзор\nНачало работы\nПолучить ключ API\nКраткое руководство по API Gemini\nКраткое руководство по Google AI Studio\nУчебники по началу работы\nМодели\nО генеративных моделях\nGemini\nGemini API\nОбзор API\nСправочник по API\nВерсии API\nПримечания к выпускам\nВозможности, Возможности\nТюнинг модели\nВызов функции\nВложения\nБезопасность\nПутеводители\nПодсказка\nСистемные инструкции\nСемантический поиск\nOAuth-аутентификация\nРасширения Firebase\nМиграция в облако\nРуководства\nВызов функции\nВложения\nПриложения\nУстранение неполадок\nРуководство по устранению неполадок\nДоступ к AI Studio с помощью Workspace\nУстранение неполадок AI Studio\nКак увеличить квоту\nСообщество\nДискурс-форум\nPaLM API (устаревший)\nПерейти на Близнецы\nДокументы ПалМ\nЮридический\nУсловия использования\n(Предварительная версия) Условия использования\nДоступные регионы\nСодержание\nПодтвердите свой ключ API с помощью команды Curl.\nХраните свой ключ API в безопасности\nСледующие шаги\nОзнакомьтесь с новой кулинарной книгой Gemini API и форумом нашего сообщества .\n Эта страница переведена с помощью Cloud Translation API.\nGoogle AI for Developers\nПродукты\nЭта информация оказалась полезной?\nОтправить отзыв\nПолучить ключ API \nbookmark_border\n\nЧтобы использовать API Gemini, вам понадобится ключ API. Создать ключ можно одним кликом в Google AI Studio.\n\nПолучить ключ API\n\nВажно! Не забывайте безопасно использовать ключи API. Просмотрите раздел «Защитите свой ключ API» , а затем ознакомьтесь с краткими руководствами по API , чтобы изучить лучшие практики защиты вашего ключа API для конкретного языка.\nПодтвердите свой ключ API с помощью команды Curl.\n\nВы можете использовать команду Curl для проверки вашей настройки. Вы можете передать ключ API либо в URL-адресе:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nИли в заголовке x-goog-api-key :\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nХраните свой ключ API в безопасности\n\nВажно обеспечить безопасность вашего ключа Gemini API. Вот несколько вещей, которые следует учитывать при использовании ключа Gemini API:\n\nAPI Google AI Gemini использует ключи API для авторизации. Если другие люди получат доступ к вашему ключу API Gemini, они смогут совершать вызовы, используя квоту вашего проекта, что может привести к потере квоты или дополнительным расходам по счетам (если выставление счетов включено). Ключи API также защищают доступ к настроенным моделям и файлам.\n\nНажимая «Получить ключ API» в Google AI Studio, вы выбираете, предоставлять ли ключ Gemini API в новом или существующем проекте Google Cloud. Список ключей API в Google AI Studio показывает все ключи API, которые AI Studio предоставила для использования с API Google AI Gemini (вместе со всеми связанными с ними проектами Google Cloud).\n\nОднако любые ключи API в проекте Google Cloud потенциально могут использоваться для вызова API Google AI Gemini. Вы можете просматривать все ключи API вашего проекта и управлять ими на панели API и сервисы > Учетные данные в консоли Google Cloud.\n\nДобавление ограничений на ключи API может помочь ограничить площадь поверхности, которую можно использовать с помощью каждого ключа API. По умолчанию ключ Gemini API, созданный Google AI Studio, можно использовать только с Google AI Gemini API (официально называемым «Generative Language API» или generativelanguage.googleapis.com ).\n\nЕсли в вашем проекте Google Cloud есть какие-либо ключи API, для которых отсутствуют ограничения API, или какие-либо ключи API, внесенные в разрешенный список API генеративного языка, то эти ключи можно использовать с API Google AI Gemini. Рекомендуется ограничить каждый ключ API только теми API, которые вы вызываете с помощью этого ключа.\nОбратите внимание, что даже при наличии ограничений на ключи API, если злоумышленник получит ваш ключ API, он сможет использовать его для выполнения вызовов с использованием квоты вашего проекта для всех API, включенных в разрешенный список для этого ключа API.\n\nВы несете ответственность за безопасность своего ключа API Gemini.\n\nНЕ проверяйте ключи API Gemini в системе контроля версий.\nКлиентские приложения (Android, Swift, веб-приложения и Dart/Flutter) рискуют раскрыть ключи API, поэтому мы не рекомендуем использовать клиентские SDK Google AI в рабочих приложениях для вызова API Google AI Gemini непосредственно из мобильных и веб-приложений. Ознакомьтесь с краткими руководствами по SDK , чтобы узнать лучшие практики защиты вашего ключа API для конкретного языка.\n\nЧтобы ознакомиться с некоторыми общими рекомендациями, вы также можете просмотреть эту статью поддержки .\n\nСледующие шаги\nОзнакомьтесь с краткими руководствами по API , чтобы узнать передовые методы защиты ключа API и его использования.\nЭта информация оказалась полезной?\nОтправить отзыв\n\nЕсли не указано иное, контент на этой странице предоставляется по лицензии Creative Commons \"С указанием авторства 4.0\", а примеры кода – по лицензии Apache 2.0. Подробнее об этом написано в правилах сайта. Java – это зарегистрированный товарный знак корпорации Oracle и ее аффилированных лиц.\n\nПоследнее обновление: 2024-04-23 UTC.\n\nУсловия использования\nКонфиденциальность",
            "word_count": 749,
            "filtered_content": "Содержание\nПолучить ключ API \nЧтобы использовать API Gemini, вам понадобится ключ API. Создать ключ можно одним кликом в Google AI Studio.\nВажно! Не забывайте безопасно использовать ключи API. Просмотрите раздел «Защитите свой ключ API» , а затем ознакомьтесь с краткими руководствами по API , чтобы изучить лучшие практики защиты вашего ключа API для конкретного языка.\nВы можете использовать команду Curl для проверки вашей настройки. Вы можете передать ключ API либо в URL-адресе:\nИли в заголовке x-goog-api-key :\nВажно обеспечить безопасность вашего ключа Gemini API. Вот несколько вещей, которые следует учитывать при использовании ключа Gemini API:\nAPI Google AI Gemini использует ключи API для авторизации. Если другие люди получат доступ к вашему ключу API Gemini, они смогут совершать вызовы, используя квоту вашего проекта, что может привести к потере квоты или дополнительным расходам по счетам (если выставление счетов включено). Ключи API также защищают доступ к настроенным моделям и файлам.\nНажимая «Получить ключ API» в Google AI Studio, вы выбираете, предоставлять ли ключ Gemini API в новом или существующем проекте Google Cloud. Список ключей API в Google AI Studio показывает все ключи API, которые AI Studio предоставила для использования с API Google AI Gemini (вместе со всеми связанными с ними проектами Google Cloud).\nОднако любые ключи API в проекте Google Cloud потенциально могут использоваться для вызова API Google AI Gemini. Вы можете просматривать все ключи API вашего проекта и управлять ими на панели API и сервисы > Учетные данные в консоли Google Cloud.\nДобавление ограничений на ключи API может помочь ограничить площадь поверхности, которую можно использовать с помощью каждого ключа API. По умолчанию ключ Gemini API, созданный Google AI Studio, можно использовать только с Google AI Gemini API (официально называемым «Generative Language API» или generativelanguage.googleapis.com ).\nЕсли в вашем проекте Google Cloud есть какие-либо ключи API, для которых отсутствуют ограничения API, или какие-либо ключи API, внесенные в разрешенный список API генеративного языка, то эти ключи можно использовать с API Google AI Gemini. Рекомендуется ограничить каждый ключ API только теми API, которые вы вызываете с помощью этого ключа.\nОбратите внимание, что даже при наличии ограничений на ключи API, если злоумышленник получит ваш ключ API, он сможет использовать его для выполнения вызовов с использованием квоты вашего проекта для всех API, включенных в разрешенный список для этого ключа API.\nВы несете ответственность за безопасность своего ключа API Gemini.\nНЕ проверяйте ключи API Gemini в системе контроля версий.\nКлиентские приложения (Android, Swift, веб-приложения и Dart/Flutter) рискуют раскрыть ключи API, поэтому мы не рекомендуем использовать клиентские SDK Google AI в рабочих приложениях для вызова API Google AI Gemini непосредственно из мобильных и веб-приложений. Ознакомьтесь с краткими руководствами по SDK , чтобы узнать лучшие практики защиты вашего ключа API для конкретного языка.\nЧтобы ознакомиться с некоторыми общими рекомендациями, вы также можете просмотреть эту статью поддержки .\nОзнакомьтесь с краткими руководствами по API , чтобы узнать передовые методы защиты ключа API и его использования.",
            "filtered_word_count": 474
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=he": {
            "status": "Looks good",
            "content": "מוצרים\nדוגמאות\nהיכנס\nמסמכים\nהפניית API\nסקירה כללית\nשנתחיל?\nקבלת מפתח API\nהמדריך למתחילים של Gemini API\nהמדריך למתחילים של Google AI Studio\nמדריכים לתחילת העבודה\nדגמים\nמידע על מודלים גנרטיביים\nGemini\nGemini API\nסקירה כללית בנושא API\nהפניית API\nגרסאות API\nהערות מוצר\nיכולות\nכוונון של מודל\nהפעלת פונקציה\nהטמעות\nסייפטי\nמדריכים\nהנחיות\nהוראות המערכת\nאחזור סמנטי\nאימות OAuth\nתוספי Firebase\nהעברה לענן\nמדריכים\nהפעלת פונקציה\nהטמעות\nאפליקציות\nפתרון בעיות\nמדריך לפתרון בעיות\nגישה ל-AI Studio באמצעות Workspace\nפתרון בעיות ב-AI Studio\nבקשה למכסה נוספת\nקהילה\nפורום דיונים\nPaLM API (קודם)\nמעבר ל-Gemini\nמסמכי PaLM\nמשפטי\nתנאים והגבלות\n(תצוגה מקדימה) תנאים והגבלות\nאזורים זמינים\nבדף הזה\nאימות מפתח ה-API באמצעות פקודת curl\nשמירה על אבטחת מפתח ה-API\nהשלבים הבאים\nכדאי לעיין בספר הבישול החדש של Gemini API ובפורום הקהילה שלנו.\n דף זה תורגם על ידי Cloud Translation API.\nGoogle AI for Developers\nמוצרים\nהמידע עזר לך?\nשליחת משוב\nקבלת מפתח API \nbookmark_border\n\nכדי להשתמש ב-Gemini API, יש צורך במפתח API. אפשר ליצור מפתח בלחיצה אחת ב-Google AI Studio.\n\nקבלת מפתח API\n\nחשוב: חשוב להשתמש במפתחות ה-API באופן מאובטח. מומלץ לקרוא את המאמר שמירה על אבטחת מפתח ה-API ולאחר מכן לעיין במדריכים למתחילים של ה-API כדי לקבל מידע על שיטות מומלצות וספציפיות לשפה, בנוגע לאבטחת מפתח ה-API.\nאימות מפתח ה-API באמצעות פקודת curl\n\nאתם יכולים להשתמש בפקודת curl כדי לאמת את ההגדרה. אפשר להעביר את מפתח ה-API בכתובת ה-URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nאו בכותרת x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nשמירה על אבטחת מפתח ה-API\n\nחשוב לשמור על האבטחה של מפתח Gemini API. כמה דברים שכדאי לזכור כשמשתמשים במפתח API של Gemini:\n\nב-Google AI Gemini API נעשה שימוש במפתחות API לצורך אימות. אם לאנשים אחרים תהיה גישה למפתח Gemini API, הם יוכלו לבצע שיחות תוך ניצול המכסה של הפרויקט שלכם. כתוצאה מכך, יכול להיות שתאבדו את המכסה או תחויבו בחיובים נוספים (אם הפעלתם את החיוב). מפתחות ה-API מגינים גם על הגישה למודלים ולקבצים מכווננים.\n\nכשלוחצים על קבלת מפתח API ב-Google AI Studio, אפשר לבחור אם להקצות מפתח Gemini API בפרויקט חדש או קיים ב-Google Cloud. ברשימת מפתחות ה-API ב-Google AI Studio מוצגים כל מפתחות ה-API שהוקצו לשימוש ב-Google AI Gemini API (יחד עם כל הפרויקטים המשויכים ב-Google Cloud).\n\nעם זאת, אפשר להשתמש בכל מפתח ה-API בפרויקט ב-Google Cloud כדי לקרוא ל-Google AI Gemini API. אפשר לראות ולנהל את כל מפתחות ה-API של הפרויקט בחלונית APIs & Services > Credentials במסוף Google Cloud.\n\nהוספה של הגבלות על מפתחות API יכולה לעזור להגביל את שטח הפנים שאפשר להשתמש בו דרך כל מפתח API. כברירת מחדל, ניתן להשתמש במפתח ה-API של Gemini שנוצר על ידי Google AI Studio רק בשילוב עם Google AI Gemini API (שנקרא באופן רשמי 'Generative Language API' או 'generativelanguage.googleapis.com').\n\nאם בפרויקט שלכם ב-Google Cloud יש מפתחות API שאין בהם הגבלות על API או מפתחות API שנכללו ברשימת ההיתרים של ה-API לשפה גנרטיבית, תוכלו להשתמש במפתחות האלה ב-Google AI Gemini API. מומלץ להגביל כל מפתח API רק לממשקי ה-API שאתם קוראים להם באמצעות המפתח הזה.\nשימו לב שגם במסגרת ההגבלות על מפתחות API, אם גורם זדוני ישיג את מפתח ה-API שלכם, הוא יוכל להשתמש בו כדי לבצע קריאות באמצעות המכסה של הפרויקט לכל ממשקי ה-API שנמצאים ברשימת ההיתרים של מפתח ה-API הזה.\n\nאתם אחראים לשמור על האבטחה של מפתח Gemini API.\n\nאין לבדוק את מפתחות ה-API של Gemini לבקרת המקור.\nאפליקציות בצד הלקוח (Android, Swift, אינטרנט ו-Dart/Flutter) עלולות לחשוף מפתחות API, לכן אנחנו לא ממליצים להשתמש בערכות ה-SDK של לקוחות ה-AI מבית Google באפליקציות ייצור כדי לקרוא ל-Google AI Gemini API ישירות מהאפליקציות לנייד ולאינטרנט. במדריך למתחילים של SDK תוכלו לקרוא שיטות מומלצות לפי שפה ספציפית לאבטחת מפתח ה-API.\n\nלמידע על שיטות מומלצות כלליות, מומלץ לעיין גם במאמר העזרה הזה.\n\nהשלבים הבאים\nבמדריכים למתחילים של API מפורטות השיטות המומלצות לאבטחת מפתח ה-API ולשימוש בו.\nהמידע עזר לך?\nשליחת משוב\n\nאלא אם צוין אחרת, התוכן של דף זה הוא ברישיון Creative Commons Attribution 4.0 ודוגמאות הקוד הן ברישיון Apache 2.0. לפרטים, ניתן לעיין במדיניות האתר Google Developers‏.‏ Java הוא סימן מסחרי רשום של חברת Oracle ו/או של השותפים העצמאיים שלה.\n\nעדכון אחרון: 2024-04-24 (שעון UTC).\n\nתנאים\nפרטיות",
            "word_count": 700,
            "filtered_content": "בדף הזה\nקבלת מפתח API \nכדי להשתמש ב-Gemini API, יש צורך במפתח API. אפשר ליצור מפתח בלחיצה אחת ב-Google AI Studio.\nחשוב: חשוב להשתמש במפתחות ה-API באופן מאובטח. מומלץ לקרוא את המאמר שמירה על אבטחת מפתח ה-API ולאחר מכן לעיין במדריכים למתחילים של ה-API כדי לקבל מידע על שיטות מומלצות וספציפיות לשפה, בנוגע לאבטחת מפתח ה-API.\nאתם יכולים להשתמש בפקודת curl כדי לאמת את ההגדרה. אפשר להעביר את מפתח ה-API בכתובת ה-URL:\nאו בכותרת x-goog-api-key:\nחשוב לשמור על האבטחה של מפתח Gemini API. כמה דברים שכדאי לזכור כשמשתמשים במפתח API של Gemini:\nב-Google AI Gemini API נעשה שימוש במפתחות API לצורך אימות. אם לאנשים אחרים תהיה גישה למפתח Gemini API, הם יוכלו לבצע שיחות תוך ניצול המכסה של הפרויקט שלכם. כתוצאה מכך, יכול להיות שתאבדו את המכסה או תחויבו בחיובים נוספים (אם הפעלתם את החיוב). מפתחות ה-API מגינים גם על הגישה למודלים ולקבצים מכווננים.\nכשלוחצים על קבלת מפתח API ב-Google AI Studio, אפשר לבחור אם להקצות מפתח Gemini API בפרויקט חדש או קיים ב-Google Cloud. ברשימת מפתחות ה-API ב-Google AI Studio מוצגים כל מפתחות ה-API שהוקצו לשימוש ב-Google AI Gemini API (יחד עם כל הפרויקטים המשויכים ב-Google Cloud).\nעם זאת, אפשר להשתמש בכל מפתח ה-API בפרויקט ב-Google Cloud כדי לקרוא ל-Google AI Gemini API. אפשר לראות ולנהל את כל מפתחות ה-API של הפרויקט בחלונית APIs & Services > Credentials במסוף Google Cloud.\nהוספה של הגבלות על מפתחות API יכולה לעזור להגביל את שטח הפנים שאפשר להשתמש בו דרך כל מפתח API. כברירת מחדל, ניתן להשתמש במפתח ה-API של Gemini שנוצר על ידי Google AI Studio רק בשילוב עם Google AI Gemini API (שנקרא באופן רשמי 'Generative Language API' או 'generativelanguage.googleapis.com').\nאם בפרויקט שלכם ב-Google Cloud יש מפתחות API שאין בהם הגבלות על API או מפתחות API שנכללו ברשימת ההיתרים של ה-API לשפה גנרטיבית, תוכלו להשתמש במפתחות האלה ב-Google AI Gemini API. מומלץ להגביל כל מפתח API רק לממשקי ה-API שאתם קוראים להם באמצעות המפתח הזה.\nשימו לב שגם במסגרת ההגבלות על מפתחות API, אם גורם זדוני ישיג את מפתח ה-API שלכם, הוא יוכל להשתמש בו כדי לבצע קריאות באמצעות המכסה של הפרויקט לכל ממשקי ה-API שנמצאים ברשימת ההיתרים של מפתח ה-API הזה.\nאתם אחראים לשמור על האבטחה של מפתח Gemini API.\nאין לבדוק את מפתחות ה-API של Gemini לבקרת המקור.\nאפליקציות בצד הלקוח (Android, Swift, אינטרנט ו-Dart/Flutter) עלולות לחשוף מפתחות API, לכן אנחנו לא ממליצים להשתמש בערכות ה-SDK של לקוחות ה-AI מבית Google באפליקציות ייצור כדי לקרוא ל-Google AI Gemini API ישירות מהאפליקציות לנייד ולאינטרנט. במדריך למתחילים של SDK תוכלו לקרוא שיטות מומלצות לפי שפה ספציפית לאבטחת מפתח ה-API.\nלמידע על שיטות מומלצות כלליות, מומלץ לעיין גם במאמר העזרה הזה.\nבמדריכים למתחילים של API מפורטות השיטות המומלצות לאבטחת מפתח ה-API ולשימוש בו.\nעדכון אחרון: 2024-04-24 (שעון UTC).",
            "filtered_word_count": 447
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ar": {
            "status": "Looks good",
            "content": "المنتجات\nأمثلة\nتسجيل الدخول\nالمستندات\nمرجع واجهة برمجة تطبيقات\nنظرة عامة\nالبدء\nالحصول على مفتاح واجهة برمجة التطبيقات\nالبدء السريع لواجهة برمجة تطبيقات Gemini\nدليل البدء السريع لاستخدام Google AI Studio\nالبرامج التعليمية للبدء\nالنماذج\nلمحة عن النماذج التوليدية\nGemini\nGemini API\nنظرة عامة على واجهة برمجة التطبيقات\nمرجع واجهة برمجة التطبيقات\nإصدارات واجهة برمجة التطبيقات\nملاحظات الإصدار\nالإمكانيات\nضبط النموذج\nاستدعاء الدوالّ\nعمليات التضمين\nدفاع\nالأدلة\nجارٍ الطلب\nتعليمات النظام\nالاسترجاع الدلالي\nمصادقة OAuth\nإضافات Firebase\nنقل البيانات إلى السحابة الإلكترونية\nالبرامج التعليمية\nاستدعاء الدوالّ\nعمليات التضمين\nالتطبيقات\nتحديد المشاكل وحلّها\nدليل تحديد المشاكل وحلّها\nالوصول إلى AI Studio باستخدام Workspace\nتحديد المشاكل في AI Studio وحلّها\nطلب المزيد من الحصص\nفعالية مجتمعية\nمنتدى الحوار\nPaLM API (الإصدار القديم)\nالانتقال إلى حساب Gemini\nمستندات PaLM\nشؤون قانونية\nبنود الخدمة\n(معاينة) بنود الخدمة\nالمناطق المتاحة\nعلى هذه الصفحة\nالتحقّق من مفتاح واجهة برمجة التطبيقات باستخدام أمر curl\nالحفاظ على أمان مفتاح واجهة برمجة التطبيقات\nالخطوات التالية\nاطّلِع على دليل Gemini API الجديد والمنتدى الخاص بنا.\n تمت ترجمة هذه الصفحة بواسطة Cloud Translation API‏.\nGoogle AI for Developers\nالمنتجات\nهل كان المحتوى مفيدًا؟\nإرسال ملاحظات\nالحصول على مفتاح واجهة برمجة التطبيقات \nbookmark_border\n\nلاستخدام Gemini API، تحتاج إلى مفتاح واجهة برمجة التطبيقات. يمكنك إنشاء مفتاح بنقرة واحدة في \"استوديو Google AI Studio\".\n\nالحصول على مفتاح واجهة برمجة التطبيقات\n\nملاحظة مهمة: لا تنسَ استخدام مفاتيح واجهة برمجة التطبيقات بأمان. راجِع المقالة الحفاظ على أمان مفتاح واجهة برمجة التطبيقات، ثم اطّلِع على البدء السريع لواجهة برمجة التطبيقات للتعرّف على أفضل الممارسات المتعلقة بلغة معيّنة لتأمين مفتاح واجهة برمجة التطبيقات.\nالتحقّق من مفتاح واجهة برمجة التطبيقات باستخدام أمر curl\n\nيمكنك استخدام أمر curl للتحقّق من الإعداد. يمكنك تمرير مفتاح واجهة برمجة التطبيقات إما في عنوان URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nأو في عنوان x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nالحفاظ على أمان مفتاح واجهة برمجة التطبيقات\n\nمن المهم الحفاظ على أمان مفتاح واجهة برمجة تطبيقات Gemini. إليك بعض النقاط التي يجب أخذها في الاعتبار عند استخدام مفتاح واجهة برمجة تطبيقات Gemini:\n\nتستخدم واجهة برمجة التطبيقات Google AI Gemini API مفاتيح واجهة برمجة التطبيقات للمصادقة. إذا حصل المستخدمون الآخرون على إمكانية الوصول إلى مفتاح واجهة برمجة تطبيقات Gemini، بإمكانهم إجراء مكالمات باستخدام حصة مشروعك، مما قد يؤدي إلى فقدان الحصة أو تحصيل رسوم فوترة إضافية (في حال كانت الفوترة مفعّلة). وتعمل مفاتيح واجهة برمجة التطبيقات أيضًا على حماية إمكانية الوصول إلى النماذج والملفات التي تم ضبطها.\n\nعند النقر على الحصول على مفتاح واجهة برمجة التطبيقات في \"استوديو Google AI\"، يمكنك اختيار ما إذا كنت تريد توفير مفتاح واجهة برمجة تطبيقات Gemini في مشروع جديد أو حالي على Google Cloud. تعرض قائمة مفاتيح واجهة برمجة التطبيقات في استوديو Google AI Studio جميع مفاتيح واجهة برمجة التطبيقات التي وفّرتها أداة AI Studio لاستخدامها مع Google AI Gemini API (بالإضافة إلى جميع مشاريع Google Cloud المرتبطة بها).\n\nومع ذلك، من المحتمل استخدام أي مفاتيح واجهة برمجة تطبيقات ضمن مشروع Google Cloud لطلب بيانات من Google AI Gemini API. يمكنك عرض جميع مفاتيح واجهة برمجة التطبيقات الخاصة بالمشروع وإدارتها من خلال واجهات برمجة التطبيقات والخدمات > لوحة بيانات الاعتماد في Google Cloud Console.\n\nيمكن أن تساعد إضافة قيود واجهة برمجة التطبيقات في الحد من مساحة السطح القابلة للاستخدام من خلال كل مفتاح من مفاتيح واجهة برمجة التطبيقات. حسب الإعدادات التلقائية، لا يمكن استخدام مفتاح واجهة برمجة تطبيقات Gemini الذي أنشأه استوديو Google AI Studio إلا مع واجهة برمجة تطبيقات Google AI Gemini (المعروفة رسميًا باسم \"واجهة برمجة تطبيقات اللغة التوليدية\" أو generativelanguage.googleapis.com).\n\nإذا كانت هناك أي مفاتيح واجهة برمجة تطبيقات في مشروعك على Google Cloud تفتقر إلى قيود واجهة برمجة التطبيقات أو أي مفاتيح واجهة برمجة تطبيقات تمت إضافتها إلى القائمة المسموح بها لواجهة برمجة تطبيقات اللغة التوليدية، يمكن استخدام هذه المفاتيح مع واجهة برمجة تطبيقات Google AI Gemini. ومن أفضل الممارسات حصر كل مفتاح واجهة برمجة تطبيقات بواجهات برمجة التطبيقات التي تطلبها باستخدام هذا المفتاح فقط.\nيُرجى العِلم بأنّه حتى في حال حصل مستخدم ضار على مفتاح واجهة برمجة التطبيقات الخاص بك، حتى في حال فرض قيود على مفتاح واجهة برمجة التطبيقات، يمكنه استخدامه لإجراء الطلبات باستخدام حصة مشروعك على جميع واجهات برمجة التطبيقات المدرَجة في القائمة المسموح بها لمفتاح واجهة برمجة التطبيقات هذا.\n\nأنت مسؤول عن الحفاظ على أمان مفتاح واجهة برمجة تطبيقات Gemini.\n\nلا تتحقّق من مفاتيح واجهة برمجة تطبيقات Gemini في التحكّم بالمصدر.\nقد تكشف التطبيقات من جهة العميل (Android وSwift والويب وDart/Flutter) عن مفاتيح واجهة برمجة التطبيقات، لذلك لا ننصح باستخدام حِزم تطوير البرامج (SDK) لعملاء تكنولوجيات الذكاء الاصطناعي من Google في تطبيقات الإنتاج لطلب واجهة برمجة تطبيقات Google AI Gemini مباشرةً من تطبيقات الويب والأجهزة الجوّالة. يمكنك الاطّلاع على البدءات السريعة لحزمة تطوير البرامج (SDK) لمعرفة أفضل الممارسات الخاصة باللغات، ما يتيح لك تأمين مفتاح واجهة برمجة التطبيقات.\n\nللحصول على بعض أفضل الممارسات العامة، يمكنك أيضًا مراجعة مقالة الدعم هذه.\n\nالخطوات التالية\nيمكنك الاطّلاع على البدء السريع لواجهة برمجة التطبيقات للتعرّف على أفضل الممارسات لتأمين مفتاح واجهة برمجة التطبيقات واستخدامه.\nهل كان المحتوى مفيدًا؟\nإرسال ملاحظات\n\nإنّ محتوى هذه الصفحة مرخّص بموجب ترخيص Creative Commons Attribution 4.0‏ ما لم يُنصّ على خلاف ذلك، ونماذج الرموز مرخّصة بموجب ترخيص Apache 2.0‏. للاطّلاع على التفاصيل، يُرجى مراجعة سياسات موقع Google Developers‏. إنّ Java هي علامة تجارية مسجَّلة لشركة Oracle و/أو شركائها التابعين.\n\nتاريخ التعديل الأخير: 2024-04-24 (حسب التوقيت العالمي المتفَّق عليه)\n\nالبنود\nالخصوصية",
            "word_count": 890,
            "filtered_content": "على هذه الصفحة\nالحصول على مفتاح واجهة برمجة التطبيقات \nلاستخدام Gemini API، تحتاج إلى مفتاح واجهة برمجة التطبيقات. يمكنك إنشاء مفتاح بنقرة واحدة في \"استوديو Google AI Studio\".\nملاحظة مهمة: لا تنسَ استخدام مفاتيح واجهة برمجة التطبيقات بأمان. راجِع المقالة الحفاظ على أمان مفتاح واجهة برمجة التطبيقات، ثم اطّلِع على البدء السريع لواجهة برمجة التطبيقات للتعرّف على أفضل الممارسات المتعلقة بلغة معيّنة لتأمين مفتاح واجهة برمجة التطبيقات.\nيمكنك استخدام أمر curl للتحقّق من الإعداد. يمكنك تمرير مفتاح واجهة برمجة التطبيقات إما في عنوان URL:\nأو في عنوان x-goog-api-key:\nمن المهم الحفاظ على أمان مفتاح واجهة برمجة تطبيقات Gemini. إليك بعض النقاط التي يجب أخذها في الاعتبار عند استخدام مفتاح واجهة برمجة تطبيقات Gemini:\nتستخدم واجهة برمجة التطبيقات Google AI Gemini API مفاتيح واجهة برمجة التطبيقات للمصادقة. إذا حصل المستخدمون الآخرون على إمكانية الوصول إلى مفتاح واجهة برمجة تطبيقات Gemini، بإمكانهم إجراء مكالمات باستخدام حصة مشروعك، مما قد يؤدي إلى فقدان الحصة أو تحصيل رسوم فوترة إضافية (في حال كانت الفوترة مفعّلة). وتعمل مفاتيح واجهة برمجة التطبيقات أيضًا على حماية إمكانية الوصول إلى النماذج والملفات التي تم ضبطها.\nعند النقر على الحصول على مفتاح واجهة برمجة التطبيقات في \"استوديو Google AI\"، يمكنك اختيار ما إذا كنت تريد توفير مفتاح واجهة برمجة تطبيقات Gemini في مشروع جديد أو حالي على Google Cloud. تعرض قائمة مفاتيح واجهة برمجة التطبيقات في استوديو Google AI Studio جميع مفاتيح واجهة برمجة التطبيقات التي وفّرتها أداة AI Studio لاستخدامها مع Google AI Gemini API (بالإضافة إلى جميع مشاريع Google Cloud المرتبطة بها).\nومع ذلك، من المحتمل استخدام أي مفاتيح واجهة برمجة تطبيقات ضمن مشروع Google Cloud لطلب بيانات من Google AI Gemini API. يمكنك عرض جميع مفاتيح واجهة برمجة التطبيقات الخاصة بالمشروع وإدارتها من خلال واجهات برمجة التطبيقات والخدمات > لوحة بيانات الاعتماد في Google Cloud Console.\nيمكن أن تساعد إضافة قيود واجهة برمجة التطبيقات في الحد من مساحة السطح القابلة للاستخدام من خلال كل مفتاح من مفاتيح واجهة برمجة التطبيقات. حسب الإعدادات التلقائية، لا يمكن استخدام مفتاح واجهة برمجة تطبيقات Gemini الذي أنشأه استوديو Google AI Studio إلا مع واجهة برمجة تطبيقات Google AI Gemini (المعروفة رسميًا باسم \"واجهة برمجة تطبيقات اللغة التوليدية\" أو generativelanguage.googleapis.com).\nإذا كانت هناك أي مفاتيح واجهة برمجة تطبيقات في مشروعك على Google Cloud تفتقر إلى قيود واجهة برمجة التطبيقات أو أي مفاتيح واجهة برمجة تطبيقات تمت إضافتها إلى القائمة المسموح بها لواجهة برمجة تطبيقات اللغة التوليدية، يمكن استخدام هذه المفاتيح مع واجهة برمجة تطبيقات Google AI Gemini. ومن أفضل الممارسات حصر كل مفتاح واجهة برمجة تطبيقات بواجهات برمجة التطبيقات التي تطلبها باستخدام هذا المفتاح فقط.\nيُرجى العِلم بأنّه حتى في حال حصل مستخدم ضار على مفتاح واجهة برمجة التطبيقات الخاص بك، حتى في حال فرض قيود على مفتاح واجهة برمجة التطبيقات، يمكنه استخدامه لإجراء الطلبات باستخدام حصة مشروعك على جميع واجهات برمجة التطبيقات المدرَجة في القائمة المسموح بها لمفتاح واجهة برمجة التطبيقات هذا.\nأنت مسؤول عن الحفاظ على أمان مفتاح واجهة برمجة تطبيقات Gemini.\nلا تتحقّق من مفاتيح واجهة برمجة تطبيقات Gemini في التحكّم بالمصدر.\nقد تكشف التطبيقات من جهة العميل (Android وSwift والويب وDart/Flutter) عن مفاتيح واجهة برمجة التطبيقات، لذلك لا ننصح باستخدام حِزم تطوير البرامج (SDK) لعملاء تكنولوجيات الذكاء الاصطناعي من Google في تطبيقات الإنتاج لطلب واجهة برمجة تطبيقات Google AI Gemini مباشرةً من تطبيقات الويب والأجهزة الجوّالة. يمكنك الاطّلاع على البدءات السريعة لحزمة تطوير البرامج (SDK) لمعرفة أفضل الممارسات الخاصة باللغات، ما يتيح لك تأمين مفتاح واجهة برمجة التطبيقات.\nللحصول على بعض أفضل الممارسات العامة، يمكنك أيضًا مراجعة مقالة الدعم هذه.\nيمكنك الاطّلاع على البدء السريع لواجهة برمجة التطبيقات للتعرّف على أفضل الممارسات لتأمين مفتاح واجهة برمجة التطبيقات واستخدامه.\nتاريخ التعديل الأخير: 2024-04-24 (حسب التوقيت العالمي المتفَّق عليه)",
            "filtered_word_count": 590
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fa": {
            "status": "Looks good",
            "content": "محصولات\nمثال ها\nورود به برنامه\nاسناد\nمرجع API\nبررسی اجمالی\nشروع کنید\nیک کلید API دریافت کنید\nGemini API شروع سریع\nشروع سریع استودیوی هوش مصنوعی گوگل\nآموزش های شروع\nمدل ها\nدرباره مدل های مولد\nGemini\nGemini API\nنمای کلی API\nمرجع API\nنسخه های API\nیادداشت های انتشار\nقابلیت ها، قابلیت ها\nتیونینگ مدل\nفراخوانی تابع\nجاسازی ها\nایمنی\nراهنماها\nتحریک کردن\nدستورالعمل های سیستم\nبازیابی معنایی\nاحراز هویت OAuth\nافزونه های Firebase\nمهاجرت به ابر\nآموزش ها\nفراخوانی تابع\nجاسازی ها\nبرنامه های کاربردی\nعیب یابی\nراهنمای عیب یابی\nبا استفاده از Workspace به AI Studio دسترسی پیدا کنید\nعیب یابی AI Studio\nدرخواست سهمیه بیشتر\nانجمن\nانجمن گفتمان\nPalm API (میراث)\nبه جمینی مهاجرت کنید\nاسناد PalM\nمجاز\nشرایط استفاده از خدمات\n(پیش نمایش) شرایط خدمات\nمناطق در دسترس\nدر این صفحه\nکلید API خود را با دستور curl تأیید کنید\nکلید API خود را ایمن نگه دارید\nمراحل بعدی\nکتاب آشپزی جدید Gemini API و انجمن انجمن ما را بررسی کنید.\n این صفحه به‌وسیله ‏Cloud Translation API‏ ترجمه شده است.\nGoogle AI for Developers\nمحصولات\nاین مرور مفید بود؟\nارسال بازخورد\nیک کلید API دریافت کنید \nbookmark_border\n\nبرای استفاده از Gemini API، به یک کلید API نیاز دارید. می توانید با یک کلیک در Google AI Studio یک کلید ایجاد کنید.\n\nیک کلید API دریافت کنید\n\nمهم: فراموش نکنید که از کلیدهای API خود به طور ایمن استفاده کنید. مرور کنید کلید API خود را ایمن نگه دارید و سپس شروع سریع API را بررسی کنید تا بهترین شیوه های خاص زبان برای ایمن سازی کلید API خود را بیاموزید.\nکلید API خود را با دستور curl تأیید کنید\n\nمی توانید از دستور curl برای تأیید تنظیمات خود استفاده کنید. می‌توانید کلید API را در URL ارسال کنید:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nیا در هدر x-goog-api-key :\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nکلید API خود را ایمن نگه دارید\n\nمهم است که کلید Gemini API خود را ایمن نگه دارید. در اینجا چند نکته وجود دارد که باید هنگام استفاده از کلید Gemini API خود در نظر داشته باشید:\n\nGoogle AI Gemini API از کلیدهای API برای مجوز استفاده می کند. اگر دیگران به کلید Gemini API شما دسترسی پیدا کنند، می‌توانند با استفاده از سهمیه پروژه شما تماس برقرار کنند، که می‌تواند منجر به از دست رفتن سهمیه یا هزینه‌های اضافی صورت‌حساب شود (در صورت فعال بودن صورت‌حساب). کلیدهای API همچنین از دسترسی به مدل ها و فایل های تنظیم شده محافظت می کنند.\n\nهنگامی که روی دریافت کلید API در استودیوی Google AI کلیک می‌کنید، انتخاب می‌کنید که آیا یک کلید API Gemini در پروژه Google Cloud جدید یا موجود ارائه شود. فهرست کلیدهای API در Google AI Studio همه کلیدهای API را نشان می‌دهد که AI Studio برای استفاده با Google AI Gemini API (همراه با تمام پروژه‌های Google Cloud مرتبط با آنها) ارائه کرده است.\n\nبا این حال، هر کلید API در پروژه Google Cloud به طور بالقوه می تواند برای فراخوانی Google AI Gemini API استفاده شود. می‌توانید تمام کلیدهای API پروژه خود را در APIs & Services > پنل اعتبارنامه‌ها در کنسول Google Cloud مشاهده و مدیریت کنید.\n\nافزودن محدودیت‌های کلید API می‌تواند به محدود کردن سطح قابل استفاده از طریق هر کلید API کمک کند. به‌طور پیش‌فرض، کلید Gemini API تولید شده توسط Google AI Studio تنها می‌تواند با Google AI Gemini API (که به طور رسمی «API زبان تولیدی» یا generativelanguage.googleapis.com نامیده می‌شود) استفاده شود.\n\nاگر کلیدهای API در پروژه Google Cloud شما فاقد محدودیت‌های API هستند یا کلیدهای API که API زبان مولد را در لیست مجاز قرار داده‌اند، می‌توان از آن کلیدها با Google AI Gemini API استفاده کرد. بهترین کار این است که هر کلید API را فقط به APIهایی که با استفاده از آن کلید فرا می‌خوانید محدود کنید.\nتوجه داشته باشید که حتی با محدودیت‌های کلید API، اگر یک عامل مخرب کلید API شما را بدست آورد، می‌تواند از آن برای برقراری تماس با استفاده از سهمیه پروژه شما برای همه APIهای مجاز برای آن کلید API استفاده کند.\n\nشما مسئول حفظ امنیت کلید Gemini API خود هستید.\n\nکلیدهای Gemini API را در کنترل منبع بررسی نکنید.\nبرنامه‌های سمت کلاینت (Android، Swift، وب، و Dart/Flutter) در معرض خطر قرار گرفتن کلیدهای API هستند، بنابراین توصیه نمی‌کنیم از SDKهای سرویس گیرنده Google AI در برنامه‌های تولیدی برای تماس مستقیم با Google AI Gemini API از برنامه‌های تلفن همراه و وب خود استفاده کنید. شروع سریع SDK را بررسی کنید تا بهترین شیوه های خاص زبان را برای ایمن سازی کلید API خود بیاموزید.\n\nبرای برخی از بهترین شیوه های عمومی، می توانید این مقاله پشتیبانی را نیز مرور کنید.\n\nمراحل بعدی\nشروع سریع API را بررسی کنید تا بهترین روش ها را برای ایمن کردن کلید API خود و استفاده از آن بیاموزید.\nاین مرور مفید بود؟\nارسال بازخورد\n\nجز در مواردی که غیر از این ذکر شده باشد،‌محتوای این صفحه تحت مجوز Creative Commons Attribution 4.0 License است. نمونه کدها نیز دارای مجوز Apache 2.0 License است. برای اطلاع از جزئیات، به خطمشی‌های سایت Google Developers‏ مراجعه کنید. جاوا علامت تجاری ثبت‌شده Oracle و/یا شرکت‌های وابسته به آن است.\n\nتاریخ آخرین به‌روزرسانی 2024-04-23 به‌وقت ساعت هماهنگ جهانی.\n\nشرایط\nحریم خصوصی",
            "word_count": 892,
            "filtered_content": "در این صفحه\nیک کلید API دریافت کنید \nبرای استفاده از Gemini API، به یک کلید API نیاز دارید. می توانید با یک کلیک در Google AI Studio یک کلید ایجاد کنید.\nمهم: فراموش نکنید که از کلیدهای API خود به طور ایمن استفاده کنید. مرور کنید کلید API خود را ایمن نگه دارید و سپس شروع سریع API را بررسی کنید تا بهترین شیوه های خاص زبان برای ایمن سازی کلید API خود را بیاموزید.\nمی توانید از دستور curl برای تأیید تنظیمات خود استفاده کنید. می‌توانید کلید API را در URL ارسال کنید:\nیا در هدر x-goog-api-key :\nمهم است که کلید Gemini API خود را ایمن نگه دارید. در اینجا چند نکته وجود دارد که باید هنگام استفاده از کلید Gemini API خود در نظر داشته باشید:\nGoogle AI Gemini API از کلیدهای API برای مجوز استفاده می کند. اگر دیگران به کلید Gemini API شما دسترسی پیدا کنند، می‌توانند با استفاده از سهمیه پروژه شما تماس برقرار کنند، که می‌تواند منجر به از دست رفتن سهمیه یا هزینه‌های اضافی صورت‌حساب شود (در صورت فعال بودن صورت‌حساب). کلیدهای API همچنین از دسترسی به مدل ها و فایل های تنظیم شده محافظت می کنند.\nهنگامی که روی دریافت کلید API در استودیوی Google AI کلیک می‌کنید، انتخاب می‌کنید که آیا یک کلید API Gemini در پروژه Google Cloud جدید یا موجود ارائه شود. فهرست کلیدهای API در Google AI Studio همه کلیدهای API را نشان می‌دهد که AI Studio برای استفاده با Google AI Gemini API (همراه با تمام پروژه‌های Google Cloud مرتبط با آنها) ارائه کرده است.\nبا این حال، هر کلید API در پروژه Google Cloud به طور بالقوه می تواند برای فراخوانی Google AI Gemini API استفاده شود. می‌توانید تمام کلیدهای API پروژه خود را در APIs & Services > پنل اعتبارنامه‌ها در کنسول Google Cloud مشاهده و مدیریت کنید.\nافزودن محدودیت‌های کلید API می‌تواند به محدود کردن سطح قابل استفاده از طریق هر کلید API کمک کند. به‌طور پیش‌فرض، کلید Gemini API تولید شده توسط Google AI Studio تنها می‌تواند با Google AI Gemini API (که به طور رسمی «API زبان تولیدی» یا generativelanguage.googleapis.com نامیده می‌شود) استفاده شود.\nاگر کلیدهای API در پروژه Google Cloud شما فاقد محدودیت‌های API هستند یا کلیدهای API که API زبان مولد را در لیست مجاز قرار داده‌اند، می‌توان از آن کلیدها با Google AI Gemini API استفاده کرد. بهترین کار این است که هر کلید API را فقط به APIهایی که با استفاده از آن کلید فرا می‌خوانید محدود کنید.\nتوجه داشته باشید که حتی با محدودیت‌های کلید API، اگر یک عامل مخرب کلید API شما را بدست آورد، می‌تواند از آن برای برقراری تماس با استفاده از سهمیه پروژه شما برای همه APIهای مجاز برای آن کلید API استفاده کند.\nشما مسئول حفظ امنیت کلید Gemini API خود هستید.\nکلیدهای Gemini API را در کنترل منبع بررسی نکنید.\nبرنامه‌های سمت کلاینت (Android، Swift، وب، و Dart/Flutter) در معرض خطر قرار گرفتن کلیدهای API هستند، بنابراین توصیه نمی‌کنیم از SDKهای سرویس گیرنده Google AI در برنامه‌های تولیدی برای تماس مستقیم با Google AI Gemini API از برنامه‌های تلفن همراه و وب خود استفاده کنید. شروع سریع SDK را بررسی کنید تا بهترین شیوه های خاص زبان را برای ایمن سازی کلید API خود بیاموزید.\nبرای برخی از بهترین شیوه های عمومی، می توانید این مقاله پشتیبانی را نیز مرور کنید.\nشروع سریع API را بررسی کنید تا بهترین روش ها را برای ایمن کردن کلید API خود و استفاده از آن بیاموزید.",
            "filtered_word_count": 574
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=hi": {
            "status": "Looks good",
            "content": "प्रॉडक्ट\nउदाहरण\nप्रवेश करें\nDocs\nएपीआई का संदर्भ\nखास जानकारी\nशुरू करें\nएपीआई पासकोड पाएं\nGemini API क्विकस्टार्ट\nGoogle AI Studio क्विकस्टार्ट\nट्यूटोरियल शुरू करना\nमॉडल\nजनरेटिव मॉडल के बारे में जानकारी\nGemini\nGemini API\nएपीआई के बारे में खास जानकारी\nएपीआई का संदर्भ\nएपीआई वर्शन\nप्रॉडक्ट की जानकारी\nमिलने वाली अनुमतियां\nमॉडल ट्यूनिंग\nफ़ंक्शन कॉल करने की सुविधा\nएम्बेड करना\nसुरक्षा\nगाइड\nप्रॉम्प्ट करना\nसिस्टम से जुड़े निर्देश\nसिमैंटिक रिकवरी\nOAuth प्रमाणीकरण\nFirebase एक्सटेंशन\nCloud पर माइग्रेट करें\nट्यूटोरियल\nफ़ंक्शन कॉल करने की सुविधा\nएम्बेड करना\nऐप्लिकेशन\nसमस्या का हल\nसमस्या हल करने के लिए गाइड\nWorkspace की मदद से एआई स्टूडियो को ऐक्सेस करना\nAI Studio से जुड़ी समस्याएं हल करना\nअनुरोध भेजने की सीमा बढ़ाने का अनुरोध करना\nकम्यूनिटी\nबातचीत के लिए फ़ोरम\nPaLM API (लेगसी)\nGemini में माइग्रेट करें\nPaLM के दस्तावेज़\nकानूनी\nसेवा की शर्तें\n(झलक) सेवा की शर्तें\nउपलब्ध क्षेत्र\nइस पेज पर, यह जानकारी उपलब्ध है\nकर्ल कमांड की मदद से, अपने एपीआई पासकोड की पुष्टि करें\nअपनी एपीआई कुंजी को सुरक्षित रखें\nअगले चरण\nनया Gemini API कुकबुक और हमारा कम्यूनिटी फ़ोरम देखें.\n इस पेज का अनुवाद Cloud Translation API से किया गया है.\nGoogle AI for Developers\nप्रॉडक्ट\nक्या इस कॉन्टेंट से आपको मदद मिली?\nसुझाव भेजें\nएपीआई पासकोड पाएं \nbookmark_border\n\nGemini API का इस्तेमाल करने के लिए, आपको एपीआई पासकोड की ज़रूरत होगी. Google AI Studio में, सिर्फ़ एक क्लिक से कुंजी बनाई जा सकती है.\n\nएपीआई पासकोड पाएं\n\nअहम जानकारी: अपनी एपीआई कुंजियों का सुरक्षित तरीके से इस्तेमाल करना न भूलें. अपनी एपीआई पासकोड को सुरक्षित रखने की समीक्षा करें. इसके बाद, एपीआई पासकोड को सुरक्षित करने के सबसे सही तरीकों के बारे में जानने के लिए, एपीआई क्विकस्टार्ट सेक्शन देखें.\nकर्ल कमांड की मदद से, अपने एपीआई पासकोड की पुष्टि करें\n\nअपने सेटअप की पुष्टि करने के लिए, कर्ल कमांड का इस्तेमाल किया जा सकता है. एपीआई पासकोड को यूआरएल से भी पास किया जा सकता है:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nइसके अलावा, x-goog-api-key हेडर में:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nअपनी एपीआई कुंजी को सुरक्षित रखें\n\nGemini API पासकोड को सुरक्षित रखना ज़रूरी है. Gemini API पासकोड का इस्तेमाल करते समय इन बातों का ध्यान रखें:\n\nअनुमति देने के लिए, Google AI Gemini API, एपीआई कुंजियों का इस्तेमाल करता है. अगर दूसरे लोगों को आपकी Gemini API कुंजी का ऐक्सेस मिल जाता है, तो वे आपके प्रोजेक्ट के कोटा का इस्तेमाल करके कॉल कर सकते हैं. इससे आपका कोटा खत्म हो सकता है या अतिरिक्त बिलिंग शुल्क (अगर बिलिंग की सुविधा चालू है) हो सकती है. एपीआई कुंजियां, ट्यून किए गए मॉडल और फ़ाइलों के ऐक्सेस को भी सुरक्षित रखती हैं.\n\nGoogle AI Studio में एपीआई पासकोड पाएं पर क्लिक करके, यह चुना जा सकता है कि Google Cloud के नए प्रोजेक्ट में Gemini API पासकोड को सेट अप करना है या मौजूदा प्रोजेक्ट में. Google AI Studio में एपीआई कुंजियों की सूची में वे सभी एपीआई कुंजियां दिखती हैं जिन्हें AI Studio ने Google AI Gemini API (इससे जुड़े उनके सभी Google Cloud प्रोजेक्ट) के साथ इस्तेमाल करने के लिए चुना है.\n\nहालांकि, Google Cloud प्रोजेक्ट में मौजूद किसी भी एपीआई कुंजी का इस्तेमाल, Google AI Gemini API को कॉल करने के लिए किया जा सकता है. Google Cloud Console में, एपीआई और सेवाएं > क्रेडेंशियल पैनल में जाकर, अपने प्रोजेक्ट की सभी एपीआई कुंजियां देखी और मैनेज की जा सकती हैं.\n\nएपीआई पासकोड से जुड़ी पाबंदियां जोड़ने से, हर एपीआई पासकोड के लिए इस्तेमाल किए जा सकने वाले सरफ़ेस एरिया को सीमित करने में मदद मिल सकती है. डिफ़ॉल्ट रूप से, Google AI Studio से जनरेट की गई Gemini API कुंजी का इस्तेमाल सिर्फ़ Google AI Gemini API (आधिकारिक तौर पर \"जनरेटिव लैंग्वेज एपीआई\" या generativelanguage.googleapis.com) के साथ किया जा सकता है.\n\nअगर आपके Google Cloud प्रोजेक्ट में ऐसी कोई एपीआई कुंजी है जिसमें एपीआई से जुड़ी पाबंदियों की जानकारी नहीं है या कोई ऐसी एपीआई कुंजी है जिसे Generative Language API की अनुमति मिली है, तो उन कुंजियों का इस्तेमाल Google AI Gemini API के साथ किया जा सकता है. सबसे सही तरीका यह है कि हर एपीआई पासकोड को सिर्फ़ उन एपीआई तक सीमित रखा जाए जिन्हें आपने उस कुंजी का इस्तेमाल करके कॉल किया है.\nध्यान रखें कि एपीआई पासकोड से जुड़ी पाबंदियों के बावजूद, अगर नुकसान पहुंचाने वाले किसी व्यक्ति को आपका एपीआई पासकोड मिल जाता है, तो वह उसका इस्तेमाल आपके प्रोजेक्ट के कोटा का इस्तेमाल करके, उस एपीआई पासकोड के लिए अनुमति वाली सूची में शामिल सभी एपीआई के लिए, कॉल करने के लिए कर सकता है.\n\nअपने Gemini API पासकोड को सुरक्षित रखने की ज़िम्मेदारी आपकी है.\n\nसोर्स कंट्रोल में, Gemini API (एपीआई) कुंजियों को न चुनें.\nक्लाइंट-साइड ऐप्लिकेशन (Android, Swift, web, और Dart/Flutter) में एपीआई पासकोड हो सकते हैं. इसलिए, हमारा सुझाव है कि प्रोडक्शन ऐप्लिकेशन में Google AI क्लाइंट SDK का इस्तेमाल करके, सीधे आपके मोबाइल और वेब ऐप्लिकेशन से Google AI Gemini API को कॉल न करें. एपीआई पासकोड को सुरक्षित करने के सबसे सही तरीकों के बारे में जानने के लिए, SDK टूल के लिए क्विकस्टार्ट सेक्शन देखें.\n\nकुछ सामान्य सबसे सही तरीकों के बारे में जानने के लिए, इस सहायता लेख को भी पढ़ें.\n\nअगले चरण\nएपीआई पासकोड को सुरक्षित करने और उसे इस्तेमाल करने के सबसे सही तरीके जानने के लिए, एपीआई क्विकस्टार्ट देखें.\nक्या इस कॉन्टेंट से आपको मदद मिली?\nसुझाव भेजें\n\nजब तक कुछ अलग से न बताया जाए, तब तक इस पेज की सामग्री को Creative Commons Attribution 4.0 License के तहत और कोड के नमूनों को Apache 2.0 License के तहत लाइसेंस मिला है. ज़्यादा जानकारी के लिए, Google Developers साइट नीतियां देखें. Oracle और/या इससे जुड़ी हुई कंपनियों का, Java एक रजिस्टर किया हुआ ट्रेडमार्क है.\n\nआखिरी बार 2024-04-24 (UTC) को अपडेट किया गया.\n\nशर्तें\nनिजता",
            "word_count": 982,
            "filtered_content": "इस पेज पर, यह जानकारी उपलब्ध है\nएपीआई पासकोड पाएं \nGemini API का इस्तेमाल करने के लिए, आपको एपीआई पासकोड की ज़रूरत होगी. Google AI Studio में, सिर्फ़ एक क्लिक से कुंजी बनाई जा सकती है.\nअहम जानकारी: अपनी एपीआई कुंजियों का सुरक्षित तरीके से इस्तेमाल करना न भूलें. अपनी एपीआई पासकोड को सुरक्षित रखने की समीक्षा करें. इसके बाद, एपीआई पासकोड को सुरक्षित करने के सबसे सही तरीकों के बारे में जानने के लिए, एपीआई क्विकस्टार्ट सेक्शन देखें.\nअपने सेटअप की पुष्टि करने के लिए, कर्ल कमांड का इस्तेमाल किया जा सकता है. एपीआई पासकोड को यूआरएल से भी पास किया जा सकता है:\nइसके अलावा, x-goog-api-key हेडर में:\nGemini API पासकोड को सुरक्षित रखना ज़रूरी है. Gemini API पासकोड का इस्तेमाल करते समय इन बातों का ध्यान रखें:\nअनुमति देने के लिए, Google AI Gemini API, एपीआई कुंजियों का इस्तेमाल करता है. अगर दूसरे लोगों को आपकी Gemini API कुंजी का ऐक्सेस मिल जाता है, तो वे आपके प्रोजेक्ट के कोटा का इस्तेमाल करके कॉल कर सकते हैं. इससे आपका कोटा खत्म हो सकता है या अतिरिक्त बिलिंग शुल्क (अगर बिलिंग की सुविधा चालू है) हो सकती है. एपीआई कुंजियां, ट्यून किए गए मॉडल और फ़ाइलों के ऐक्सेस को भी सुरक्षित रखती हैं.\nGoogle AI Studio में एपीआई पासकोड पाएं पर क्लिक करके, यह चुना जा सकता है कि Google Cloud के नए प्रोजेक्ट में Gemini API पासकोड को सेट अप करना है या मौजूदा प्रोजेक्ट में. Google AI Studio में एपीआई कुंजियों की सूची में वे सभी एपीआई कुंजियां दिखती हैं जिन्हें AI Studio ने Google AI Gemini API (इससे जुड़े उनके सभी Google Cloud प्रोजेक्ट) के साथ इस्तेमाल करने के लिए चुना है.\nहालांकि, Google Cloud प्रोजेक्ट में मौजूद किसी भी एपीआई कुंजी का इस्तेमाल, Google AI Gemini API को कॉल करने के लिए किया जा सकता है. Google Cloud Console में, एपीआई और सेवाएं > क्रेडेंशियल पैनल में जाकर, अपने प्रोजेक्ट की सभी एपीआई कुंजियां देखी और मैनेज की जा सकती हैं.\nएपीआई पासकोड से जुड़ी पाबंदियां जोड़ने से, हर एपीआई पासकोड के लिए इस्तेमाल किए जा सकने वाले सरफ़ेस एरिया को सीमित करने में मदद मिल सकती है. डिफ़ॉल्ट रूप से, Google AI Studio से जनरेट की गई Gemini API कुंजी का इस्तेमाल सिर्फ़ Google AI Gemini API (आधिकारिक तौर पर \"जनरेटिव लैंग्वेज एपीआई\" या generativelanguage.googleapis.com) के साथ किया जा सकता है.\nअगर आपके Google Cloud प्रोजेक्ट में ऐसी कोई एपीआई कुंजी है जिसमें एपीआई से जुड़ी पाबंदियों की जानकारी नहीं है या कोई ऐसी एपीआई कुंजी है जिसे Generative Language API की अनुमति मिली है, तो उन कुंजियों का इस्तेमाल Google AI Gemini API के साथ किया जा सकता है. सबसे सही तरीका यह है कि हर एपीआई पासकोड को सिर्फ़ उन एपीआई तक सीमित रखा जाए जिन्हें आपने उस कुंजी का इस्तेमाल करके कॉल किया है.\nध्यान रखें कि एपीआई पासकोड से जुड़ी पाबंदियों के बावजूद, अगर नुकसान पहुंचाने वाले किसी व्यक्ति को आपका एपीआई पासकोड मिल जाता है, तो वह उसका इस्तेमाल आपके प्रोजेक्ट के कोटा का इस्तेमाल करके, उस एपीआई पासकोड के लिए अनुमति वाली सूची में शामिल सभी एपीआई के लिए, कॉल करने के लिए कर सकता है.\nअपने Gemini API पासकोड को सुरक्षित रखने की ज़िम्मेदारी आपकी है.\nसोर्स कंट्रोल में, Gemini API (एपीआई) कुंजियों को न चुनें.\nक्लाइंट-साइड ऐप्लिकेशन (Android, Swift, web, और Dart/Flutter) में एपीआई पासकोड हो सकते हैं. इसलिए, हमारा सुझाव है कि प्रोडक्शन ऐप्लिकेशन में Google AI क्लाइंट SDK का इस्तेमाल करके, सीधे आपके मोबाइल और वेब ऐप्लिकेशन से Google AI Gemini API को कॉल न करें. एपीआई पासकोड को सुरक्षित करने के सबसे सही तरीकों के बारे में जानने के लिए, SDK टूल के लिए क्विकस्टार्ट सेक्शन देखें.\nकुछ सामान्य सबसे सही तरीकों के बारे में जानने के लिए, इस सहायता लेख को भी पढ़ें.\nएपीआई पासकोड को सुरक्षित करने और उसे इस्तेमाल करने के सबसे सही तरीके जानने के लिए, एपीआई क्विकस्टार्ट देखें.\nआखिरी बार 2024-04-24 (UTC) को अपडेट किया गया.",
            "filtered_word_count": 649
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=bn": {
            "status": "Looks good",
            "content": "পণ্য\nউদাহরণ\nসাইন-ইন করুন\nডক্স\nAPI রেফারেন্স\nওভারভিউ\nএবার শুরু করা যাক\nএকটি API কী পান\nজেমিনি API কুইকস্টার্ট\nগুগল এআই স্টুডিও দ্রুত শুরু\nটিউটোরিয়াল শুরু করা হচ্ছে\nমডেল\nজেনারেটিভ মডেল সম্পর্কে\nGemini\nGemini API\nAPI ওভারভিউ\nAPI রেফারেন্স\nAPI সংস্করণ\nঅব্যাহতি পত্র\nক্ষমতা, ক্ষমতা\nমডেল টিউনিং\nফাংশন কলিং\nএমবেডিং\nনিরাপত্তা\nগাইড\nপ্রম্পটিং\nসিস্টেম নির্দেশাবলী\nশব্দার্থিক পুনরুদ্ধার\nOAuth প্রমাণীকরণ\nফায়ারবেস এক্সটেনশন\nক্লাউডে মাইগ্রেট করুন\nটিউটোরিয়াল\nফাংশন কলিং\nএমবেডিং\nঅ্যাপ্লিকেশন\nসমস্যা সমাধান\nসমস্যা সমাধানের গাইড\nওয়ার্কস্পেস ব্যবহার করে এআই স্টুডিও অ্যাক্সেস করুন\nএআই স্টুডিওর সমস্যা সমাধান করা হচ্ছে\nআরো কোটা অনুরোধ\nসম্প্রদায়\nডিসকোর্স ফোরাম\nPaLM API (উত্তরাধিকার)\nমিথুন রাশিতে চলে যান\nPaLM ডক্স\nআইনি\nসেবা পাবার শর্ত\n(প্রিভিউ) পরিষেবার শর্তাবলী\nউপলব্ধ অঞ্চল\nএই পৃষ্ঠায় যা যা আছে\nএকটি কার্ল কমান্ড দিয়ে আপনার API কী যাচাই করুন\nআপনার API কী সুরক্ষিত রাখুন\nপরবর্তী পদক্ষেপ\nনতুন জেমিনি API কুকবুক এবং আমাদের কমিউনিটি ফোরাম দেখুন।\n এই পৃষ্ঠাটি Cloud Translation API অনুবাদ করেছে।\nGoogle AI for Developers\nপণ্য\nএটি কাজে লেগেছে?\nমতামত জানান\nএকটি API কী পান \nbookmark_border\n\nGemini API ব্যবহার করতে, আপনার একটি API কী প্রয়োজন। আপনি গুগল এআই স্টুডিওতে এক ক্লিকে একটি কী তৈরি করতে পারেন।\n\nএকটি API কী পান\n\nগুরুত্বপূর্ণ: আপনার API কীগুলি নিরাপদে ব্যবহার করতে ভুলবেন না। পর্যালোচনা করুন আপনার API কী সুরক্ষিত রাখুন এবং তারপরে আপনার API কী সুরক্ষিত করার জন্য ভাষা-নির্দিষ্ট সর্বোত্তম অনুশীলনগুলি শিখতে API কুইকস্টার্টগুলি দেখুন।\nএকটি কার্ল কমান্ড দিয়ে আপনার API কী যাচাই করুন\n\nআপনি আপনার সেটআপ যাচাই করতে একটি কার্ল কমান্ড ব্যবহার করতে পারেন। আপনি URL এ API কী পাস করতে পারেন:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nঅথবা x-goog-api-key হেডারে:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nআপনার API কী সুরক্ষিত রাখুন\n\nআপনার Gemini API কী সুরক্ষিত রাখা গুরুত্বপূর্ণ। আপনার জেমিনি এপিআই কী ব্যবহার করার সময় এখানে কয়েকটি বিষয় মনে রাখতে হবে:\n\nGoogle AI Gemini API অনুমোদনের জন্য API কী ব্যবহার করে। অন্যরা যদি আপনার Gemini API কী-তে অ্যাক্সেস পায়, তাহলে তারা আপনার প্রোজেক্টের কোটা ব্যবহার করে কল করতে পারে, যার ফলে কোটা হারানো বা অতিরিক্ত বিলিং চার্জ হতে পারে (যদি বিলিং সক্ষম করা থাকে)। এপিআই কীগুলি টিউন করা মডেল এবং ফাইলগুলিতে অ্যাক্সেস রক্ষা করে।\n\nআপনি যখন Google AI স্টুডিওতে API কী পান ক্লিক করেন, তখন আপনি একটি নতুন বা বিদ্যমান Google ক্লাউড প্রকল্পে একটি Gemini API কী প্রভিশন করবেন কিনা তা বেছে নেন। Google AI স্টুডিওতে API কী তালিকাটি সমস্ত API কীগুলি দেখায় যা AI স্টুডিও Google AI Gemini API (তাদের সমস্ত সম্পর্কিত Google ক্লাউড প্রকল্পগুলির সাথে) ব্যবহারের জন্য বিধান করেছে৷\n\nযাইহোক, Google ক্লাউড প্রজেক্টের মধ্যে থাকা যেকোন API কীগুলিকে Google AI Gemini API কল করার জন্য সম্ভাব্যভাবে ব্যবহার করা যেতে পারে। আপনি Google ক্লাউড কনসোলে API এবং পরিষেবা > শংসাপত্র প্যানেলে আপনার সমস্ত প্রকল্পের API কীগুলি দেখতে এবং পরিচালনা করতে পারেন৷\n\nAPI কী সীমাবদ্ধতা যুক্ত করা প্রতিটি API কী এর মাধ্যমে ব্যবহারযোগ্য পৃষ্ঠের ক্ষেত্রফলকে সীমাবদ্ধ করতে সহায়তা করতে পারে। ডিফল্টরূপে, Google AI স্টুডিও দ্বারা তৈরি Gemini API কী শুধুমাত্র Google AI Gemini API (আধিকারিকভাবে \"জেনারেটিভ ল্যাঙ্গুয়েজ API\" বা generativelanguage.googleapis.com বলা হয়) এর সাথে ব্যবহার করা যেতে পারে।\n\nআপনার Google ক্লাউড প্রজেক্টের মধ্যে যদি এমন কোনো API কী থাকে যেগুলিতে API সীমাবদ্ধতা নেই বা জেনারেটিভ ল্যাঙ্গুয়েজ API-কে অনুমোদিত করে এমন কোনো API কী নেই, তাহলে সেই কীগুলি Google AI Gemini API-এর সাথে ব্যবহার করা যেতে পারে। প্রতিটি API কী শুধুমাত্র সেই API-এর মধ্যে সীমাবদ্ধ রাখা সর্বোত্তম অনুশীলন যা আপনি সেই কী ব্যবহার করে কল করেন।\nমনে রাখবেন যে API কী বিধিনিষেধ থাকা সত্ত্বেও, যদি কোনও দূষিত অভিনেতা আপনার API কী পায়, তবে তারা সেই API কী-এর জন্য অনুমোদিত সমস্ত API-এর জন্য আপনার প্রকল্পের কোটা ব্যবহার করে কল করতে এটি ব্যবহার করতে পারে।\n\nআপনার Gemini API কী সুরক্ষিত রাখার জন্য আপনি দায়ী।\n\nউৎস নিয়ন্ত্রণে Gemini API কী চেক করবেন না।\nক্লায়েন্ট-সাইড অ্যাপ্লিকেশনগুলি (অ্যান্ড্রয়েড, সুইফট, ওয়েব, এবং ডার্ট/ফ্লাটার) API কীগুলিকে প্রকাশ করার ঝুঁকি, তাই আমরা আপনার মোবাইল এবং ওয়েব অ্যাপ থেকে সরাসরি Google AI Gemini API কল করার জন্য প্রোডাকশন অ্যাপে Google AI ক্লায়েন্ট SDK ব্যবহার করার পরামর্শ দিই না। আপনার API কী সুরক্ষিত করার জন্য ভাষা-নির্দিষ্ট সেরা অনুশীলনগুলি শিখতে SDK কুইকস্টার্টগুলি দেখুন৷\n\nকিছু সাধারণ সর্বোত্তম অনুশীলনের জন্য, আপনি এই সমর্থন নিবন্ধটি পর্যালোচনা করতে পারেন।\n\nপরবর্তী পদক্ষেপ\nআপনার API কী সুরক্ষিত করার জন্য এবং এটি ব্যবহার করার জন্য সর্বোত্তম অনুশীলনগুলি শিখতে API দ্রুতস্টার্টগুলি দেখুন।\nএটি কাজে লেগেছে?\nমতামত জানান\n\nঅন্য কিছু উল্লেখ না করা থাকলে, এই পৃষ্ঠার কন্টেন্ট Creative Commons Attribution 4.0 License-এর অধীনে এবং কোডের নমুনাগুলি Apache 2.0 License-এর অধীনে লাইসেন্স প্রাপ্ত। আরও জানতে, Google Developers সাইট নীতি দেখুন। Java হল Oracle এবং/অথবা তার অ্যাফিলিয়েট সংস্থার রেজিস্টার্ড ট্রেডমার্ক।\n\n2024-04-23 UTC-তে শেষবার আপডেট করা হয়েছে।\n\nশর্তাবলী\nগোপনীয়তা",
            "word_count": 760,
            "filtered_content": "এই পৃষ্ঠায় যা যা আছে\nএকটি API কী পান \nGemini API ব্যবহার করতে, আপনার একটি API কী প্রয়োজন। আপনি গুগল এআই স্টুডিওতে এক ক্লিকে একটি কী তৈরি করতে পারেন।\nগুরুত্বপূর্ণ: আপনার API কীগুলি নিরাপদে ব্যবহার করতে ভুলবেন না। পর্যালোচনা করুন আপনার API কী সুরক্ষিত রাখুন এবং তারপরে আপনার API কী সুরক্ষিত করার জন্য ভাষা-নির্দিষ্ট সর্বোত্তম অনুশীলনগুলি শিখতে API কুইকস্টার্টগুলি দেখুন।\nআপনি আপনার সেটআপ যাচাই করতে একটি কার্ল কমান্ড ব্যবহার করতে পারেন। আপনি URL এ API কী পাস করতে পারেন:\nঅথবা x-goog-api-key হেডারে:\nআপনার Gemini API কী সুরক্ষিত রাখা গুরুত্বপূর্ণ। আপনার জেমিনি এপিআই কী ব্যবহার করার সময় এখানে কয়েকটি বিষয় মনে রাখতে হবে:\nGoogle AI Gemini API অনুমোদনের জন্য API কী ব্যবহার করে। অন্যরা যদি আপনার Gemini API কী-তে অ্যাক্সেস পায়, তাহলে তারা আপনার প্রোজেক্টের কোটা ব্যবহার করে কল করতে পারে, যার ফলে কোটা হারানো বা অতিরিক্ত বিলিং চার্জ হতে পারে (যদি বিলিং সক্ষম করা থাকে)। এপিআই কীগুলি টিউন করা মডেল এবং ফাইলগুলিতে অ্যাক্সেস রক্ষা করে।\nআপনি যখন Google AI স্টুডিওতে API কী পান ক্লিক করেন, তখন আপনি একটি নতুন বা বিদ্যমান Google ক্লাউড প্রকল্পে একটি Gemini API কী প্রভিশন করবেন কিনা তা বেছে নেন। Google AI স্টুডিওতে API কী তালিকাটি সমস্ত API কীগুলি দেখায় যা AI স্টুডিও Google AI Gemini API (তাদের সমস্ত সম্পর্কিত Google ক্লাউড প্রকল্পগুলির সাথে) ব্যবহারের জন্য বিধান করেছে৷\nযাইহোক, Google ক্লাউড প্রজেক্টের মধ্যে থাকা যেকোন API কীগুলিকে Google AI Gemini API কল করার জন্য সম্ভাব্যভাবে ব্যবহার করা যেতে পারে। আপনি Google ক্লাউড কনসোলে API এবং পরিষেবা > শংসাপত্র প্যানেলে আপনার সমস্ত প্রকল্পের API কীগুলি দেখতে এবং পরিচালনা করতে পারেন৷\nAPI কী সীমাবদ্ধতা যুক্ত করা প্রতিটি API কী এর মাধ্যমে ব্যবহারযোগ্য পৃষ্ঠের ক্ষেত্রফলকে সীমাবদ্ধ করতে সহায়তা করতে পারে। ডিফল্টরূপে, Google AI স্টুডিও দ্বারা তৈরি Gemini API কী শুধুমাত্র Google AI Gemini API (আধিকারিকভাবে \"জেনারেটিভ ল্যাঙ্গুয়েজ API\" বা generativelanguage.googleapis.com বলা হয়) এর সাথে ব্যবহার করা যেতে পারে।\nআপনার Google ক্লাউড প্রজেক্টের মধ্যে যদি এমন কোনো API কী থাকে যেগুলিতে API সীমাবদ্ধতা নেই বা জেনারেটিভ ল্যাঙ্গুয়েজ API-কে অনুমোদিত করে এমন কোনো API কী নেই, তাহলে সেই কীগুলি Google AI Gemini API-এর সাথে ব্যবহার করা যেতে পারে। প্রতিটি API কী শুধুমাত্র সেই API-এর মধ্যে সীমাবদ্ধ রাখা সর্বোত্তম অনুশীলন যা আপনি সেই কী ব্যবহার করে কল করেন।\nমনে রাখবেন যে API কী বিধিনিষেধ থাকা সত্ত্বেও, যদি কোনও দূষিত অভিনেতা আপনার API কী পায়, তবে তারা সেই API কী-এর জন্য অনুমোদিত সমস্ত API-এর জন্য আপনার প্রকল্পের কোটা ব্যবহার করে কল করতে এটি ব্যবহার করতে পারে।\nআপনার Gemini API কী সুরক্ষিত রাখার জন্য আপনি দায়ী।\nউৎস নিয়ন্ত্রণে Gemini API কী চেক করবেন না।\nক্লায়েন্ট-সাইড অ্যাপ্লিকেশনগুলি (অ্যান্ড্রয়েড, সুইফট, ওয়েব, এবং ডার্ট/ফ্লাটার) API কীগুলিকে প্রকাশ করার ঝুঁকি, তাই আমরা আপনার মোবাইল এবং ওয়েব অ্যাপ থেকে সরাসরি Google AI Gemini API কল করার জন্য প্রোডাকশন অ্যাপে Google AI ক্লায়েন্ট SDK ব্যবহার করার পরামর্শ দিই না। আপনার API কী সুরক্ষিত করার জন্য ভাষা-নির্দিষ্ট সেরা অনুশীলনগুলি শিখতে SDK কুইকস্টার্টগুলি দেখুন৷\nকিছু সাধারণ সর্বোত্তম অনুশীলনের জন্য, আপনি এই সমর্থন নিবন্ধটি পর্যালোচনা করতে পারেন।\nআপনার API কী সুরক্ষিত করার জন্য এবং এটি ব্যবহার করার জন্য সর্বোত্তম অনুশীলনগুলি শিখতে API দ্রুতস্টার্টগুলি দেখুন।",
            "filtered_word_count": 491
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=th": {
            "status": "Looks good",
            "content": "ผลิตภัณฑ์\nตัวอย่าง\nลงชื่อเข้าใช้\nเอกสาร\nเอกสารอ้างอิง API\nภาพรวม\nเริ่มต้น\nรับคีย์ API\nการเริ่มต้นใช้งาน Gemini API อย่างรวดเร็ว\nคู่มือเริ่มใช้งาน Google AI Studio อย่างรวดเร็ว\nบทแนะนําสําหรับเริ่มต้นใช้งาน\nรูปแบบ\nเกี่ยวกับโมเดล Generative\nGemini\nGemini API\nภาพรวม API\nเอกสารอ้างอิง API\nเวอร์ชัน API\nบันทึกประจำรุ่น\nความสามารถ\nการปรับแต่งโมเดล\nการเรียกใช้ฟังก์ชัน\nการฝัง\nความปลอดภัย\nคำแนะนำ\nข้อความแจ้ง\nวิธีการสำหรับระบบ\nการดึงข้อมูลความหมาย\nการตรวจสอบสิทธิ์ OAuth\nส่วนขยาย Firebase\nย้ายข้อมูลไปยังระบบคลาวด์\nบทแนะนำ\nการเรียกใช้ฟังก์ชัน\nการฝัง\nแอปพลิเคชัน\nการแก้ปัญหา\nคู่มือการแก้ปัญหา\nเข้าถึง AI Studio โดยใช้ Workspace\nการแก้ปัญหาเกี่ยวกับ AI Studio\nขอเพิ่มโควต้า\nชุมชน\nฟอรัมสนทนา\nPaLM API (เดิม)\nย้ายข้อมูลไปยัง Gemini\nเอกสาร PaLM\nกฎหมาย\nข้อกำหนดในการให้บริการ\n(ตัวอย่าง) ข้อกำหนดในการให้บริการ\nภูมิภาคที่สามารถใช้บริการได้\nในหน้านี้\nยืนยันคีย์ API ด้วยคำสั่ง curl\nรักษาคีย์ API ให้ปลอดภัย\nขั้นตอนถัดไป\nดูตำราอาหาร Gemini API และฟอรัมชุมชนของเรา\n หน้านี้ได้รับการแปลโดย Cloud Translation API\nGoogle AI for Developers\nผลิตภัณฑ์\nข้อมูลนี้มีประโยชน์ไหม\nส่งความคิดเห็น\nรับคีย์ API \nbookmark_border\n\nหากต้องการใช้ Gemini API คุณต้องมีคีย์ API คุณสร้างคีย์ได้ด้วยคลิกเดียวใน Google AI Studio\n\nรับคีย์ API\n\nสำคัญ: อย่าลืมใช้คีย์ API อย่างปลอดภัย โปรดอ่านรักษาคีย์ API ให้ปลอดภัย จากนั้นดูการเริ่มต้นใช้งาน API อย่างรวดเร็วเพื่อดูแนวทางปฏิบัติแนะนำสำหรับแต่ละภาษาในการรักษาความปลอดภัยคีย์ API\nยืนยันคีย์ API ด้วยคำสั่ง curl\n\nคุณใช้คำสั่ง curl เพื่อยืนยันการตั้งค่าได้ คุณส่งคีย์ API ใน URL ได้โดยทำดังนี้\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nหรือในส่วนหัว x-goog-api-key:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nรักษาคีย์ API ให้ปลอดภัย\n\nคุณควรเก็บรักษาคีย์ Gemini API ให้ปลอดภัย สิ่งที่ควรคำนึงถึงเมื่อใช้คีย์ Gemini API\n\nGoogle AI Gemini API ใช้คีย์ API สำหรับการให้สิทธิ์ หากผู้อื่นมีสิทธิ์เข้าถึงคีย์ Gemini API ของคุณ บุคคลดังกล่าวจะเรียกใช้โดยใช้โควต้าของโปรเจ็กต์ได้ ซึ่งอาจส่งผลให้โควต้าสูญหายหรือการเรียกเก็บเงินเพิ่มเติม (หากเปิดใช้การเรียกเก็บเงิน) คีย์ API ยังป้องกันสิทธิ์เข้าถึงโมเดลและไฟล์ที่มีการปรับแต่งด้วย\n\nเมื่อคลิกรับคีย์ API ใน Google AI Studio คุณเลือกได้ว่าจะจัดสรรคีย์ Gemini API ในโปรเจ็กต์ Google Cloud ใหม่หรือที่มีอยู่ รายการคีย์ API ใน Google AI Studio จะแสดงคีย์ API ทั้งหมดที่ AI Studio จัดสรรไว้ให้ใช้งานกับ Google AI Gemini API (พร้อมกับโปรเจ็กต์ Google Cloud ที่เกี่ยวข้องทั้งหมด)\n\nอย่างไรก็ตาม คีย์ API ทั้งหมดภายในโปรเจ็กต์ Google Cloud อาจใช้เพื่อเรียกใช้ Google AI Gemini API ได้ คุณสามารถดูและจัดการคีย์ API ทั้งหมดของโปรเจ็กต์ได้ใน API และบริการ > แผงข้อมูลเข้าสู่ระบบในคอนโซล Google Cloud\n\nการเพิ่มข้อจำกัดของคีย์ API จะช่วยจำกัดพื้นที่ผิวที่ใช้ได้ผ่านคีย์ API แต่ละรายการ โดยค่าเริ่มต้น คีย์ Gemini API ที่ Google AI Studio สร้างขึ้นจะใช้ได้กับ Google AI Gemini API เท่านั้น (ชื่ออย่างเป็นทางการว่า \"Generative Language API\" หรือ generativelanguage.googleapis.com)\n\nหากมีคีย์ API ภายในโปรเจ็กต์ Google Cloud ที่ไม่มีข้อจํากัดของ API หรือคีย์ API ที่ได้เพิ่ม Generative Language API ไว้ในรายการที่อนุญาตแล้ว คุณจะใช้คีย์เหล่านั้นกับ Google AI Gemini API ได้ แนวทางปฏิบัติแนะนำคือการจำกัดคีย์ API แต่ละรายการให้มีเฉพาะ API ที่คุณเรียกใช้โดยใช้คีย์นั้นเท่านั้น\nโปรดทราบว่าแม้จะมีข้อจำกัดเกี่ยวกับคีย์ API หากผู้ไม่ประสงค์ดีได้รับคีย์ API ของคุณ ผู้ไม่ประสงค์ดีก็อาจใช้คีย์นี้ทำการเรียกโดยใช้โควต้าของโปรเจ็กต์สำหรับ API ทั้งหมดที่อยู่ในรายการที่อนุญาตสำหรับคีย์ API นั้นได้\n\nคุณมีหน้าที่รักษาคีย์ Gemini API ให้ปลอดภัย\n\nอย่าตรวจสอบคีย์ Gemini API ในการควบคุมแหล่งที่มา\nแอปพลิเคชันฝั่งไคลเอ็นต์ (Android, Swift, เว็บ และ Dart/Flutter) มีความเสี่ยงที่จะเปิดเผยคีย์ API เราจึงไม่แนะนำให้ใช้ SDK ไคลเอ็นต์ AI ของ Google ในแอปเวอร์ชันที่ใช้งานจริงเพื่อเรียกใช้ Google AI Gemini API โดยตรงจากแอปบนอุปกรณ์เคลื่อนที่และเว็บแอป ดูการเริ่มต้นใช้งาน SDK อย่างรวดเร็วเพื่อเรียนรู้แนวทางปฏิบัติแนะนำสำหรับแต่ละภาษาในการรักษาความปลอดภัยของคีย์ API\n\nสำหรับแนวทางปฏิบัติแนะนำทั่วไป คุณยังอ่านบทความสนับสนุนนี้ได้อีกด้วย\n\nขั้นตอนถัดไป\nดูการเริ่มต้นใช้งาน API อย่างรวดเร็วเพื่อดูแนวทางปฏิบัติแนะนำในการรักษาความปลอดภัยของคีย์ API และการใช้งาน\nข้อมูลนี้มีประโยชน์ไหม\nส่งความคิดเห็น\n\nเนื้อหาของหน้าเว็บนี้ได้รับอนุญาตภายใต้ใบอนุญาตที่ต้องระบุที่มาของครีเอทีฟคอมมอนส์ 4.0 และตัวอย่างโค้ดได้รับอนุญาตภายใต้ใบอนุญาต Apache 2.0 เว้นแต่จะระบุไว้เป็นอย่างอื่น โปรดดูรายละเอียดที่นโยบายเว็บไซต์ Google Developers Java เป็นเครื่องหมายการค้าจดทะเบียนของ Oracle และ/หรือบริษัทในเครือ\n\nอัปเดตล่าสุด 2024-04-24 UTC\n\nข้อกำหนด\nความเป็นส่วนตัว",
            "word_count": 382,
            "filtered_content": "ในหน้านี้\nรับคีย์ API \nหากต้องการใช้ Gemini API คุณต้องมีคีย์ API คุณสร้างคีย์ได้ด้วยคลิกเดียวใน Google AI Studio\nสำคัญ: อย่าลืมใช้คีย์ API อย่างปลอดภัย โปรดอ่านรักษาคีย์ API ให้ปลอดภัย จากนั้นดูการเริ่มต้นใช้งาน API อย่างรวดเร็วเพื่อดูแนวทางปฏิบัติแนะนำสำหรับแต่ละภาษาในการรักษาความปลอดภัยคีย์ API\nคุณใช้คำสั่ง curl เพื่อยืนยันการตั้งค่าได้ คุณส่งคีย์ API ใน URL ได้โดยทำดังนี้\nหรือในส่วนหัว x-goog-api-key:\nคุณควรเก็บรักษาคีย์ Gemini API ให้ปลอดภัย สิ่งที่ควรคำนึงถึงเมื่อใช้คีย์ Gemini API\nGoogle AI Gemini API ใช้คีย์ API สำหรับการให้สิทธิ์ หากผู้อื่นมีสิทธิ์เข้าถึงคีย์ Gemini API ของคุณ บุคคลดังกล่าวจะเรียกใช้โดยใช้โควต้าของโปรเจ็กต์ได้ ซึ่งอาจส่งผลให้โควต้าสูญหายหรือการเรียกเก็บเงินเพิ่มเติม (หากเปิดใช้การเรียกเก็บเงิน) คีย์ API ยังป้องกันสิทธิ์เข้าถึงโมเดลและไฟล์ที่มีการปรับแต่งด้วย\nเมื่อคลิกรับคีย์ API ใน Google AI Studio คุณเลือกได้ว่าจะจัดสรรคีย์ Gemini API ในโปรเจ็กต์ Google Cloud ใหม่หรือที่มีอยู่ รายการคีย์ API ใน Google AI Studio จะแสดงคีย์ API ทั้งหมดที่ AI Studio จัดสรรไว้ให้ใช้งานกับ Google AI Gemini API (พร้อมกับโปรเจ็กต์ Google Cloud ที่เกี่ยวข้องทั้งหมด)\nอย่างไรก็ตาม คีย์ API ทั้งหมดภายในโปรเจ็กต์ Google Cloud อาจใช้เพื่อเรียกใช้ Google AI Gemini API ได้ คุณสามารถดูและจัดการคีย์ API ทั้งหมดของโปรเจ็กต์ได้ใน API และบริการ > แผงข้อมูลเข้าสู่ระบบในคอนโซล Google Cloud\nการเพิ่มข้อจำกัดของคีย์ API จะช่วยจำกัดพื้นที่ผิวที่ใช้ได้ผ่านคีย์ API แต่ละรายการ โดยค่าเริ่มต้น คีย์ Gemini API ที่ Google AI Studio สร้างขึ้นจะใช้ได้กับ Google AI Gemini API เท่านั้น (ชื่ออย่างเป็นทางการว่า \"Generative Language API\" หรือ generativelanguage.googleapis.com)\nหากมีคีย์ API ภายในโปรเจ็กต์ Google Cloud ที่ไม่มีข้อจํากัดของ API หรือคีย์ API ที่ได้เพิ่ม Generative Language API ไว้ในรายการที่อนุญาตแล้ว คุณจะใช้คีย์เหล่านั้นกับ Google AI Gemini API ได้ แนวทางปฏิบัติแนะนำคือการจำกัดคีย์ API แต่ละรายการให้มีเฉพาะ API ที่คุณเรียกใช้โดยใช้คีย์นั้นเท่านั้น\nโปรดทราบว่าแม้จะมีข้อจำกัดเกี่ยวกับคีย์ API หากผู้ไม่ประสงค์ดีได้รับคีย์ API ของคุณ ผู้ไม่ประสงค์ดีก็อาจใช้คีย์นี้ทำการเรียกโดยใช้โควต้าของโปรเจ็กต์สำหรับ API ทั้งหมดที่อยู่ในรายการที่อนุญาตสำหรับคีย์ API นั้นได้\nคุณมีหน้าที่รักษาคีย์ Gemini API ให้ปลอดภัย\nอย่าตรวจสอบคีย์ Gemini API ในการควบคุมแหล่งที่มา\nแอปพลิเคชันฝั่งไคลเอ็นต์ (Android, Swift, เว็บ และ Dart/Flutter) มีความเสี่ยงที่จะเปิดเผยคีย์ API เราจึงไม่แนะนำให้ใช้ SDK ไคลเอ็นต์ AI ของ Google ในแอปเวอร์ชันที่ใช้งานจริงเพื่อเรียกใช้ Google AI Gemini API โดยตรงจากแอปบนอุปกรณ์เคลื่อนที่และเว็บแอป ดูการเริ่มต้นใช้งาน SDK อย่างรวดเร็วเพื่อเรียนรู้แนวทางปฏิบัติแนะนำสำหรับแต่ละภาษาในการรักษาความปลอดภัยของคีย์ API\nสำหรับแนวทางปฏิบัติแนะนำทั่วไป คุณยังอ่านบทความสนับสนุนนี้ได้อีกด้วย\nดูการเริ่มต้นใช้งาน API อย่างรวดเร็วเพื่อดูแนวทางปฏิบัติแนะนำในการรักษาความปลอดภัยของคีย์ API และการใช้งาน\nอัปเดตล่าสุด 2024-04-24 UTC",
            "filtered_word_count": 213
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-cn": {
            "status": "Looks good",
            "content": "产品\n示例\n登录\n文档\nAPI 参考文档\n概览\n开始使用\n获取 API 密钥\nGemini API 快速入门\nGoogle AI Studio 快速入门\n入门教程\n模型\n生成模型简介\nGemini\nGemini API\nAPI 概览\nAPI 参考\nAPI 版本\n版本说明\n功能\n模型调整\n函数调用\nEmbeddings\n安全\n指南\n提示\n系统说明\n语义检索\nOAuth 身份验证\nFirebase Extensions\n迁移到云端\n教程\n函数调用\nEmbeddings\n应用\n问题排查\n问题排查指南\n使用 Workspace 访问 AI Studio\n排查 AI Studio 问题\n申请增加配额\n社区\n对话论坛\nPaLM API（旧版）\n迁移到 Gemini\nPaLM 文档\n法律\n服务条款\n（预览版）服务条款\n可用区域\n本页内容\n使用 curl 命令验证您的 API 密钥\n保障 API 密钥的安全\n后续步骤\n查看全新 Gemini API 实战宝典和我们的社区论坛。\n 此页面由 Cloud Translation API 翻译。\nGoogle AI for Developers\n产品\n该内容对您有帮助吗？\n发送反馈\n获取 API 密钥 \nbookmark_border\n\n您需要拥有 API 密钥才能使用 Gemini API。 您可以在 Google AI Studio 中一键创建密钥。\n\n获取 API 密钥\n\n重要提示 ：请务必安全地使用您的 API 密钥。请查看保障 API 密钥的安全，然后查看 API 快速入门，了解特定语言来保护 API 密钥的最佳做法。\n使用 curl 命令验证您的 API 密钥\n\n您可以使用 curl 命令来验证设置。 您可以通过以下任一网址传递 API 密钥：\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\n或者在 x-goog-api-key 标头中：\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\n保障 API 密钥的安全\n\n确保您的 Gemini API 密钥安全无虞非常重要。在使用 Gemini API 密钥时，请谨记以下几点：\n\nGoogle AI Gemini API 使用 API 密钥进行授权。如果其他人可以访问您的 Gemini API 密钥，他们就可以使用您的项目配额进行调用，这可能会导致配额丢失或额外费用（如果启用了结算功能）。API 密钥还可保护对调整后的模型和文件的访问。\n\n当您在 Google AI Studio 中点击获取 API 密钥时，您可以选择是在新的或现有的 Google Cloud 项目中配置 Gemini API 密钥。Google AI Studio 中的 API 密钥列表显示了 AI Studio 已配置用于 Google AI Gemini API 的所有 API 密钥（及其所有关联的 Google Cloud 项目）。\n\n不过，Google Cloud 项目中的任何 API 密钥都有可能用于调用 Google AI Gemini API。您可以在 Google Cloud 控制台中的“API 和服务”>“凭据”面板中查看和管理项目的所有 API 密钥。\n\n添加 API 密钥限制有助于限制可通过每个 API 密钥使用的界面区域。默认情况下，Google AI Studio 生成的 Genmini API 密钥只能与 Google AI Genmini API（正式称为“Generative Language API”或 generativelanguage.googleapis.com）搭配使用。\n\n如果您的 Google Cloud 项目中有任何 API 限制缺少 API 限制，或任何 API 密钥已将 Generative Language API 列入许可名单，则这些密钥可以与 Google AI Gemini API 搭配使用。最佳做法是，仅限每个 API 密钥使用您使用该密钥调用的 API。\n请注意，即使设置了 API 密钥限制，如果恶意操作者获取了您的 API 密钥，他们也可以使用该 API 密钥，使用您的项目针对该 API 密钥列入许可名单的所有 API 的配额进行调用。\n\n您有责任确保您的 Gemini API 密钥安全无虞。\n\n请勿将 Gemini API 密钥签入源代码控制系统。\n客户端应用（Android、Swift、Web 和 Dart/Flutter）存在泄露 API 密钥的风险，因此我们不建议在正式版应用中使用 Google AI 客户端 SDK 直接从移动应用和 Web 应用调用 Google AI Gemini API。请参阅 SDK 快速入门，了解针对特定语言保护 API 密钥的最佳做法。\n\n如需了解一些常规的最佳做法，您还可以查看这篇支持文章。\n\n后续步骤\n请参阅 API 快速入门，了解保护 API 密钥的安全和使用 API 密钥的最佳实践。\n该内容对您有帮助吗？\n发送反馈\n\n如未另行说明，那么本页面中的内容已根据知识共享署名 4.0 许可获得了许可，并且代码示例已根据 Apache 2.0 许可获得了许可。有关详情，请参阅 Google 开发者网站政策。Java 是 Oracle 和/或其关联公司的注册商标。\n\n最后更新时间 (UTC)：2024-04-24。\n\n条款\n隐私权政策",
            "word_count": 354,
            "filtered_content": "本页内容\n获取 API 密钥 \n您需要拥有 API 密钥才能使用 Gemini API。 您可以在 Google AI Studio 中一键创建密钥。\n重要提示 ：请务必安全地使用您的 API 密钥。请查看保障 API 密钥的安全，然后查看 API 快速入门，了解特定语言来保护 API 密钥的最佳做法。\n您可以使用 curl 命令来验证设置。 您可以通过以下任一网址传递 API 密钥：\n或者在 x-goog-api-key 标头中：\n确保您的 Gemini API 密钥安全无虞非常重要。在使用 Gemini API 密钥时，请谨记以下几点：\nGoogle AI Gemini API 使用 API 密钥进行授权。如果其他人可以访问您的 Gemini API 密钥，他们就可以使用您的项目配额进行调用，这可能会导致配额丢失或额外费用（如果启用了结算功能）。API 密钥还可保护对调整后的模型和文件的访问。\n当您在 Google AI Studio 中点击获取 API 密钥时，您可以选择是在新的或现有的 Google Cloud 项目中配置 Gemini API 密钥。Google AI Studio 中的 API 密钥列表显示了 AI Studio 已配置用于 Google AI Gemini API 的所有 API 密钥（及其所有关联的 Google Cloud 项目）。\n不过，Google Cloud 项目中的任何 API 密钥都有可能用于调用 Google AI Gemini API。您可以在 Google Cloud 控制台中的“API 和服务”>“凭据”面板中查看和管理项目的所有 API 密钥。\n添加 API 密钥限制有助于限制可通过每个 API 密钥使用的界面区域。默认情况下，Google AI Studio 生成的 Genmini API 密钥只能与 Google AI Genmini API（正式称为“Generative Language API”或 generativelanguage.googleapis.com）搭配使用。\n如果您的 Google Cloud 项目中有任何 API 限制缺少 API 限制，或任何 API 密钥已将 Generative Language API 列入许可名单，则这些密钥可以与 Google AI Gemini API 搭配使用。最佳做法是，仅限每个 API 密钥使用您使用该密钥调用的 API。\n请注意，即使设置了 API 密钥限制，如果恶意操作者获取了您的 API 密钥，他们也可以使用该 API 密钥，使用您的项目针对该 API 密钥列入许可名单的所有 API 的配额进行调用。\n您有责任确保您的 Gemini API 密钥安全无虞。\n请勿将 Gemini API 密钥签入源代码控制系统。\n客户端应用（Android、Swift、Web 和 Dart/Flutter）存在泄露 API 密钥的风险，因此我们不建议在正式版应用中使用 Google AI 客户端 SDK 直接从移动应用和 Web 应用调用 Google AI Gemini API。请参阅 SDK 快速入门，了解针对特定语言保护 API 密钥的最佳做法。\n如需了解一些常规的最佳做法，您还可以查看这篇支持文章。\n请参阅 API 快速入门，了解保护 API 密钥的安全和使用 API 密钥的最佳实践。\n最后更新时间 (UTC)：2024-04-24。",
            "filtered_word_count": 186
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-tw": {
            "status": "Looks good",
            "content": "產品\n範例\n登入\n文件\nAPI 參考資料\n總覽\n開始轉接\n取得 API 金鑰\nGemini API 快速入門導覽課程\nGoogle AI Studio 快速入門導覽課程\n入門教學課程\n模型\n關於生成式模型\nGemini\nGemini API\nAPI 總覽\nAPI 參考資料\nAPI 版本\n版本資訊\n功能\n模型調整\n函式呼叫\n嵌入\n安全分\n指南\n提示\n系統操作說明\n語意擷取\nOAuth 驗證\nFirebase 擴充功能\n遷移至 Cloud\n教學課程\n函式呼叫\n嵌入\n應用程式\n疑難排解\n疑難排解指南\n使用 Workspace 存取 AI Studio\nAI Studio 疑難排解\n要求提高配額\n社群\n討論論壇\nPaLM API (舊版)\n遷移至 Gemini\nPaLM 文件\nLegal\n服務條款\n(預先發布版) 服務條款\n可用地區\n這個頁面中的內容\n使用 curl 指令驗證 API 金鑰\n保護 API 金鑰安全\n後續步驟\n有興趣看看全新的 Gemini API 教戰手冊和我們的社群論壇。\n 本頁面由 Cloud Translation API 翻譯而成。\nGoogle AI for Developers\n產品\n這對你有幫助嗎？\n提供意見\n取得 API 金鑰 \nbookmark_border\n\n您需要 API 金鑰才能使用 Gemini API。 只要在 Google AI Studio 中按一下即可建立金鑰。\n\n取得 API 金鑰\n\n重要事項： 請務必安全地使用 API 金鑰。請參閱保護 API 金鑰安全一文，然後查看 API 快速入門導覽課程，瞭解確保 API 金鑰安全的特定語言最佳做法。\n使用 curl 指令驗證 API 金鑰\n\n您可以使用 curl 指令來驗證設定。您可以在網址中加入 API 金鑰：\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\n或是在 x-goog-api-key 標頭中：\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\n保護 API 金鑰安全\n\n請務必妥善保管 Gemini API 金鑰。使用 Gemini API 金鑰時，請注意下列事項：\n\nGoogle AI Gemini API 會使用 API 金鑰進行授權。如果其他人能存取您的 Gemini API 金鑰，他們可以透過您專案的配額發出呼叫，導致配額遺失或產生額外費用 (如已啟用計費功能)。此外，API 金鑰也能保護經過調整的模型和檔案的存取權限。\n\n在 Google AI Studio 中按一下「取得 API 金鑰」時，您可以選擇要在新的或現有的 Google Cloud 專案中佈建 Gemini API 金鑰。Google AI Studio 中的 API 金鑰清單會顯示 AI Studio 佈建的所有 API 金鑰，可與 Google AI Gemini API 搭配使用 (以及所有相關聯的 Google Cloud 專案)。\n\n不過，Google Cloud 專案內的任何 API 金鑰都可用來呼叫 Google AI Gemini API。您可以在 Google Cloud 控制台的「API 和服務」>「憑證」面板中，查看及管理所有專案的 API 金鑰。\n\n新增 API 金鑰限制，有助於限制透過每個 API 金鑰可使用的途徑區域。根據預設，Google AI Studio 產生的 Genmini API 金鑰只能與 Google AI Genmini API (官方稱為「生成式語言 API」或 generativelanguage.googleapis.com) 搭配使用。\n\n如果 Google Cloud 專案中有任何 API 金鑰沒有 API 限制，或是已將生成式語言 API 加入許可清單的任何 API 金鑰，這些金鑰就能搭配 Google AI Gemini API 使用。最佳做法是將每個 API 金鑰限制為只能使用該金鑰呼叫的 API。\n請注意，即使 API 金鑰限制有所限制，如果惡意人士取得您的 API 金鑰，他們仍可使用專案的配額，針對該 API 金鑰允許的所有 API 進行呼叫。\n\n您必須負責維護 Gemini API 金鑰的安全。\n\n「請勿」將 Gemini API 金鑰納入原始碼控管機制中。\n用戶端應用程式 (Android、Swift、網頁和 Dart/Flutter) 可能洩露 API 金鑰，因此不建議您在正式版應用程式中使用 Google AI 用戶端 SDK，直接從行動裝置和網頁應用程式呼叫 Google AI Gemini API。請參閱 SDK 快速入門導覽課程，瞭解確保 API 金鑰安全的特定語言最佳做法。\n\n如需一些一般最佳做法，也可以參閱這篇支援文章。\n\n後續步驟\n請參閱 API 快速入門導覽課程，瞭解保護 API 金鑰及使用的最佳做法。\n這對你有幫助嗎？\n提供意見\n\n除非另有註明，否則本頁面中的內容是採用創用 CC 姓名標示 4.0 授權，程式碼範例則為阿帕契 2.0 授權。詳情請參閱《Google Developers 網站政策》。Java 是 Oracle 和/或其關聯企業的註冊商標。\n\n上次更新時間：2024-04-24 (世界標準時間)。\n\n條款\n隱私權",
            "word_count": 351,
            "filtered_content": "這個頁面中的內容\n取得 API 金鑰 \n您需要 API 金鑰才能使用 Gemini API。 只要在 Google AI Studio 中按一下即可建立金鑰。\n重要事項： 請務必安全地使用 API 金鑰。請參閱保護 API 金鑰安全一文，然後查看 API 快速入門導覽課程，瞭解確保 API 金鑰安全的特定語言最佳做法。\n您可以使用 curl 指令來驗證設定。您可以在網址中加入 API 金鑰：\n或是在 x-goog-api-key 標頭中：\n請務必妥善保管 Gemini API 金鑰。使用 Gemini API 金鑰時，請注意下列事項：\nGoogle AI Gemini API 會使用 API 金鑰進行授權。如果其他人能存取您的 Gemini API 金鑰，他們可以透過您專案的配額發出呼叫，導致配額遺失或產生額外費用 (如已啟用計費功能)。此外，API 金鑰也能保護經過調整的模型和檔案的存取權限。\n在 Google AI Studio 中按一下「取得 API 金鑰」時，您可以選擇要在新的或現有的 Google Cloud 專案中佈建 Gemini API 金鑰。Google AI Studio 中的 API 金鑰清單會顯示 AI Studio 佈建的所有 API 金鑰，可與 Google AI Gemini API 搭配使用 (以及所有相關聯的 Google Cloud 專案)。\n不過，Google Cloud 專案內的任何 API 金鑰都可用來呼叫 Google AI Gemini API。您可以在 Google Cloud 控制台的「API 和服務」>「憑證」面板中，查看及管理所有專案的 API 金鑰。\n新增 API 金鑰限制，有助於限制透過每個 API 金鑰可使用的途徑區域。根據預設，Google AI Studio 產生的 Genmini API 金鑰只能與 Google AI Genmini API (官方稱為「生成式語言 API」或 generativelanguage.googleapis.com) 搭配使用。\n如果 Google Cloud 專案中有任何 API 金鑰沒有 API 限制，或是已將生成式語言 API 加入許可清單的任何 API 金鑰，這些金鑰就能搭配 Google AI Gemini API 使用。最佳做法是將每個 API 金鑰限制為只能使用該金鑰呼叫的 API。\n請注意，即使 API 金鑰限制有所限制，如果惡意人士取得您的 API 金鑰，他們仍可使用專案的配額，針對該 API 金鑰允許的所有 API 進行呼叫。\n您必須負責維護 Gemini API 金鑰的安全。\n「請勿」將 Gemini API 金鑰納入原始碼控管機制中。\n用戶端應用程式 (Android、Swift、網頁和 Dart/Flutter) 可能洩露 API 金鑰，因此不建議您在正式版應用程式中使用 Google AI 用戶端 SDK，直接從行動裝置和網頁應用程式呼叫 Google AI Gemini API。請參閱 SDK 快速入門導覽課程，瞭解確保 API 金鑰安全的特定語言最佳做法。\n如需一些一般最佳做法，也可以參閱這篇支援文章。\n請參閱 API 快速入門導覽課程，瞭解保護 API 金鑰及使用的最佳做法。\n上次更新時間：2024-04-24 (世界標準時間)。",
            "filtered_word_count": 180
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ja": {
            "status": "Looks good",
            "content": "プロダクト\n例\nログイン\nドキュメント\nAPI リファレンス\n概要\n使ってみる\nAPI キーを取得する\nGemini API クイックスタート\nGoogle AI Studio のクイックスタート\nスタートガイドのチュートリアル\nモデル\n生成モデルについて\nGemini\nGemini API\nAPI の概要\nAPI リファレンス\nAPI バージョン\nリリースノート\n機能\nモデルのチューニング\n関数呼び出し\nEmbeddings\n安全性\nガイド\nプロンプト\nシステムの説明\nセマンティック取得\nOAuth 認証\nFirebase Extensions\nクラウドに移行する\nチュートリアル\n関数呼び出し\nEmbeddings\nアプリケーション\nトラブルシューティング\nトラブルシューティング ガイド\nWorkspace を使用して AI Studio にアクセスする\nAI Studio のトラブルシューティング\n割り当ての増加をリクエストする\nコミュニティ\n対話フォーラム\nPaLM API（レガシー）\ngen に移行する\nPaLM ドキュメント\n法務\n利用規約\n（プレビュー）利用規約\n利用可能なリージョン\nこのページの内容\ncurl コマンドを使用して API キーを確認する\nAPI キーのセキュリティ確保\n次のステップ\n新しい Gemini API クックブックとコミュニティ フォーラムをご覧ください。\n このページは Cloud Translation API によって翻訳されました。\nGoogle AI for Developers\nプロダクト\nこの情報は役に立ちましたか？\nフィードバックを送信\nAPI キーを取得する \nbookmark_border\n\nGemini API を使用するには、API キーが必要です。Google AI Studio ではワンクリックでキーを作成できます。\n\nAPI キーを取得する\n\n重要: API キーは安全に使用することを忘れないでください。API キーを安全に保護するを確認した後、API クイックスタートを確認し、API キーを保護するための言語別のベスト プラクティスを確認してください。\ncurl コマンドを使用して API キーを確認する\n\n設定の確認には curl コマンドを使用します。API キーは、次のいずれかの URL で渡すことができます。\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nまたは x-goog-api-key ヘッダーで次のようにします。\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nAPI キーのセキュリティ確保\n\nGemini API キーは安全に保管することが重要です。Gemini API キーを使用する際は、以下の点にご注意ください。\n\nGoogle AI Gemini API は、認証に API キーを使用します。他のユーザーが Gemini API キーにアクセスすると、そのユーザーはプロジェクトの割り当てを使用して呼び出しを行えるため、割り当ての消失や追加の課金が発生する可能性があります（課金が有効になっている場合）。API キーは、チューニング済みのモデルやファイルへのアクセスも保護します。\n\nGoogle AI Studio で [API キーを取得] をクリックし、Gemini API キーを新規または既存の Google Cloud プロジェクトのどちらでプロビジョニングするかを選択します。Google AI Studio の API キーリストには、Google AI Gemini API で使用するために AI Studio がプロビジョニングしたすべての API キーと、関連するすべての Google Cloud プロジェクトが表示されます。\n\nただし、Google Cloud プロジェクト内の任意の API キーを使用して、Google AI Gemini API を呼び出すことができます。すべてのプロジェクトの API キーは、Google Cloud コンソールの [API とサービス] > [認証情報] パネルで表示および管理できます。\n\nAPI キーの制限を追加すると、各 API キーで使用できるサーフェス領域を制限できます。デフォルトでは、Google AI Studio によって生成された Genmini API キーは、Google AI Genmini API（正式には「Generative Language API」または generativelanguage.googleapis.com と呼ばれています）でのみ使用できます。\n\nGoogle Cloud プロジェクト内に API の制限がない API キーや、Generative Language API の許可リストに登録されている API キーがある場合、それらのキーは Google AI Gemini API で使用できます。各 API キーは、そのキーを使用して呼び出す API のみに制限することをおすすめします。\nAPI キーに制限があっても、悪意のある人物が API キーを取得すると、その API キーの許可リストに登録されたすべての API に対するプロジェクトの割り当てを使用して呼び出しが行われる可能性があります。\n\nGemini API キーのセキュリティ管理は、お客様の責任となります。\n\nGemini API キーはソース管理に組み込まないでください。\nクライアントサイド アプリケーション（Android、Swift、ウェブ、Dart/Flutter）では、API キーが公開されるリスクがあるため、本番環境アプリで Google AI クライアント SDK を使用して、モバイルアプリやウェブアプリから直接 Google AI Gemini API を呼び出すことはおすすめしません。API キーを保護するための言語固有のベスト プラクティスについては、SDK クイックスタートをご覧ください。\n\n一般的なベスト プラクティスについては、こちらのサポート記事もご覧ください。\n\n次のステップ\nAPI キーを保護し、使用するためのベスト プラクティスについては、API クイックスタートをご覧ください。\nこの情報は役に立ちましたか？\nフィードバックを送信\n\n特に記載のない限り、このページのコンテンツはクリエイティブ・コモンズの表示 4.0 ライセンスにより使用許諾されます。コードサンプルは Apache 2.0 ライセンスにより使用許諾されます。詳しくは、Google Developers サイトのポリシーをご覧ください。Java は Oracle および関連会社の登録商標です。\n\n最終更新日 2024-04-24 UTC。\n\n利用規約\nプライバシー",
            "word_count": 329,
            "filtered_content": "このページの内容\nAPI キーを取得する \nGemini API を使用するには、API キーが必要です。Google AI Studio ではワンクリックでキーを作成できます。\n重要: API キーは安全に使用することを忘れないでください。API キーを安全に保護するを確認した後、API クイックスタートを確認し、API キーを保護するための言語別のベスト プラクティスを確認してください。\n設定の確認には curl コマンドを使用します。API キーは、次のいずれかの URL で渡すことができます。\nまたは x-goog-api-key ヘッダーで次のようにします。\nGemini API キーは安全に保管することが重要です。Gemini API キーを使用する際は、以下の点にご注意ください。\nGoogle AI Gemini API は、認証に API キーを使用します。他のユーザーが Gemini API キーにアクセスすると、そのユーザーはプロジェクトの割り当てを使用して呼び出しを行えるため、割り当ての消失や追加の課金が発生する可能性があります（課金が有効になっている場合）。API キーは、チューニング済みのモデルやファイルへのアクセスも保護します。\nGoogle AI Studio で [API キーを取得] をクリックし、Gemini API キーを新規または既存の Google Cloud プロジェクトのどちらでプロビジョニングするかを選択します。Google AI Studio の API キーリストには、Google AI Gemini API で使用するために AI Studio がプロビジョニングしたすべての API キーと、関連するすべての Google Cloud プロジェクトが表示されます。\nただし、Google Cloud プロジェクト内の任意の API キーを使用して、Google AI Gemini API を呼び出すことができます。すべてのプロジェクトの API キーは、Google Cloud コンソールの [API とサービス] > [認証情報] パネルで表示および管理できます。\nAPI キーの制限を追加すると、各 API キーで使用できるサーフェス領域を制限できます。デフォルトでは、Google AI Studio によって生成された Genmini API キーは、Google AI Genmini API（正式には「Generative Language API」または generativelanguage.googleapis.com と呼ばれています）でのみ使用できます。\nGoogle Cloud プロジェクト内に API の制限がない API キーや、Generative Language API の許可リストに登録されている API キーがある場合、それらのキーは Google AI Gemini API で使用できます。各 API キーは、そのキーを使用して呼び出す API のみに制限することをおすすめします。\nAPI キーに制限があっても、悪意のある人物が API キーを取得すると、その API キーの許可リストに登録されたすべての API に対するプロジェクトの割り当てを使用して呼び出しが行われる可能性があります。\nGemini API キーのセキュリティ管理は、お客様の責任となります。\nGemini API キーはソース管理に組み込まないでください。\nクライアントサイド アプリケーション（Android、Swift、ウェブ、Dart/Flutter）では、API キーが公開されるリスクがあるため、本番環境アプリで Google AI クライアント SDK を使用して、モバイルアプリやウェブアプリから直接 Google AI Gemini API を呼び出すことはおすすめしません。API キーを保護するための言語固有のベスト プラクティスについては、SDK クイックスタートをご覧ください。\n一般的なベスト プラクティスについては、こちらのサポート記事もご覧ください。\nAPI キーを保護し、使用するためのベスト プラクティスについては、API クイックスタートをご覧ください。\n最終更新日 2024-04-24 UTC。",
            "filtered_word_count": 166
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ko": {
            "status": "Looks good",
            "content": "제품\n예\n로그인\nDocs\nAPI 참조\n개요\n시작하기\nAPI 키 가져오기\nGemini API 빠른 시작\nGoogle AI 스튜디오 빠른 시작\n시작 가이드\n모델\n생성 모델 정보\nGemini\nGemini API\nAPI 개요\nAPI 참조 문서\nAPI 버전\n출시 노트\n기능\n모델 조정\n함수 호출\n임베딩\n안전\n가이드\n메시지 표시\n시스템 안내\n시맨틱 검색\nOAuth 인증\nFirebase Extensions\n클라우드로 마이그레이션\n튜토리얼\n함수 호출\n임베딩\n애플리케이션\n문제해결\n문제 해결 가이드\nWorkspace를 사용하여 AI Studio에 액세스\nAI Studio 문제 해결\n할당량 추가 요청\n커뮤니티\n담화 포럼\nPaLM API (기존)\nGemini로 이전\nPaLM 문서\n법률\n서비스 약관\n(미리보기) 서비스 약관\n사용 가능한 리전\n이 페이지의 내용\ncurl 명령어로 API 키 확인\nAPI 키 보안 유지\n다음 단계\n새로운 Gemini API 설명서와 커뮤니티 포럼을 확인하세요.\n 이 페이지는 Cloud Translation API를 통해 번역되었습니다.\nGoogle AI for Developers\n제품\n도움이 되었나요?\n의견 보내기\nAPI 키 가져오기 \nbookmark_border\n\nGemini API를 사용하려면 API 키가 필요합니다. Google AI Studio에서 클릭 한 번으로 키를 만들 수 있습니다.\n\nAPI 키 가져오기\n\n중요: API 키를 안전하게 사용해야 합니다. API 키 보안 유지를 검토한 후 API 빠른 시작을 확인하여 API 키 보안을 위한 언어별 권장사항을 알아보세요.\ncurl 명령어로 API 키 확인\n\ncurl 명령어를 사용하여 설정을 확인할 수 있습니다. 다음 URL로 API 키를 전달할 수 있습니다.\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\n또는 x-goog-api-key 헤더에서 다음을 실행합니다.\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nAPI 키 보안 유지\n\nGemini API 키를 안전하게 보호하는 것이 중요합니다. Gemini API 키를 사용할 때 유의해야 할 몇 가지 사항은 다음과 같습니다.\n\nGoogle AI Gemini API는 승인에 API 키를 사용합니다. 다른 사용자가 내 Gemini API 키에 액세스할 수 있는 경우 내 프로젝트의 할당량을 사용하여 호출할 수 있으며, 이로 인해 할당량이 손실되거나 추가 결제 요금이 발생할 수 있습니다 (결제가 사용 설정된 경우). 또한 API 키는 조정된 모델 및 파일에 대한 액세스를 보호합니다.\n\nGoogle AI Studio에서 API 키 가져오기를 클릭하면 Gemini API 키를 신규 또는 기존 Google Cloud 프로젝트 중 어디에 프로비저닝할지 선택합니다. Google AI Studio의 API 키 목록에는 AI Studio가 Google AI Gemini API에 사용하기 위해 프로비저닝한 모든 API 키와 함께 연결된 모든 Google Cloud 프로젝트가 표시됩니다.\n\n하지만 Google Cloud 프로젝트 내의 모든 API 키를 Google AI Gemini API를 호출하는 데 사용할 수 있습니다. Google Cloud 콘솔의 API 및 서비스 > 사용자 인증 정보 패널에서 프로젝트의 모든 API 키를 보고 관리할 수 있습니다.\n\nAPI 키 제한사항을 추가하면 각 API 키를 통해 사용할 수 있는 노출 영역을 제한할 수 있습니다. 기본적으로 Google AI 스튜디오에서 생성된 Gemini API 키는 Google AI Gemini API (공식적으로 'Generative Language API' 또는 generativelanguage.googleapis.com라고 함)에서만 사용할 수 있습니다.\n\nGoogle Cloud 프로젝트 내에 API 제한사항이 없거나 Generative Language API를 허용 목록에 추가한 API 키가 있는 경우 해당 키를 Google AI Gemini API와 함께 사용할 수 있습니다. 각 API 키는 해당 키를 사용하여 호출하는 API로만 제한하는 것이 가장 좋습니다.\nAPI 키 제한이 있더라도 악의적인 행위자가 API 키를 획득하면 해당 API 키의 허용 목록에 포함된 모든 API에 대해 프로젝트의 할당량을 사용하여 호출할 수 있습니다.\n\nGemini API 키를 안전하게 유지할 책임은 개발자에게 있습니다.\n\n소스 제어에 Gemini API 키를 확인하지 마세요.\n클라이언트 측 애플리케이션 (Android, Swift, 웹, Dart/Flutter)은 API 키가 노출될 위험이 있으므로 프로덕션 앱에서 Google AI 클라이언트 SDK를 사용하여 모바일 및 웹 앱에서 직접 Google AI Gemini API를 호출하지 않는 것이 좋습니다. API 키 보안을 위한 언어별 권장사항을 알아보려면 SDK 빠른 시작을 확인하세요.\n\n이 지원 도움말에서 몇 가지 일반적인 권장사항을 확인할 수도 있습니다.\n\n다음 단계\nAPI 키를 보호하고 사용하기 위한 권장사항을 알아보려면 API 빠른 시작을 확인하세요.\n도움이 되었나요?\n의견 보내기\n\n달리 명시되지 않는 한 이 페이지의 콘텐츠에는 Creative Commons Attribution 4.0 라이선스에 따라 라이선스가 부여되며, 코드 샘플에는 Apache 2.0 라이선스에 따라 라이선스가 부여됩니다. 자세한 내용은 Google Developers 사이트 정책을 참조하세요. 자바는 Oracle 및/또는 Oracle 계열사의 등록 상표입니다.\n\n최종 업데이트: 2024-04-24(UTC)\n\n약관\n개인정보처리방침",
            "word_count": 628,
            "filtered_content": "이 페이지의 내용\nAPI 키 가져오기 \nGemini API를 사용하려면 API 키가 필요합니다. Google AI Studio에서 클릭 한 번으로 키를 만들 수 있습니다.\n중요: API 키를 안전하게 사용해야 합니다. API 키 보안 유지를 검토한 후 API 빠른 시작을 확인하여 API 키 보안을 위한 언어별 권장사항을 알아보세요.\ncurl 명령어를 사용하여 설정을 확인할 수 있습니다. 다음 URL로 API 키를 전달할 수 있습니다.\n또는 x-goog-api-key 헤더에서 다음을 실행합니다.\nGemini API 키를 안전하게 보호하는 것이 중요합니다. Gemini API 키를 사용할 때 유의해야 할 몇 가지 사항은 다음과 같습니다.\nGoogle AI Gemini API는 승인에 API 키를 사용합니다. 다른 사용자가 내 Gemini API 키에 액세스할 수 있는 경우 내 프로젝트의 할당량을 사용하여 호출할 수 있으며, 이로 인해 할당량이 손실되거나 추가 결제 요금이 발생할 수 있습니다 (결제가 사용 설정된 경우). 또한 API 키는 조정된 모델 및 파일에 대한 액세스를 보호합니다.\nGoogle AI Studio에서 API 키 가져오기를 클릭하면 Gemini API 키를 신규 또는 기존 Google Cloud 프로젝트 중 어디에 프로비저닝할지 선택합니다. Google AI Studio의 API 키 목록에는 AI Studio가 Google AI Gemini API에 사용하기 위해 프로비저닝한 모든 API 키와 함께 연결된 모든 Google Cloud 프로젝트가 표시됩니다.\n하지만 Google Cloud 프로젝트 내의 모든 API 키를 Google AI Gemini API를 호출하는 데 사용할 수 있습니다. Google Cloud 콘솔의 API 및 서비스 > 사용자 인증 정보 패널에서 프로젝트의 모든 API 키를 보고 관리할 수 있습니다.\nAPI 키 제한사항을 추가하면 각 API 키를 통해 사용할 수 있는 노출 영역을 제한할 수 있습니다. 기본적으로 Google AI 스튜디오에서 생성된 Gemini API 키는 Google AI Gemini API (공식적으로 'Generative Language API' 또는 generativelanguage.googleapis.com라고 함)에서만 사용할 수 있습니다.\nGoogle Cloud 프로젝트 내에 API 제한사항이 없거나 Generative Language API를 허용 목록에 추가한 API 키가 있는 경우 해당 키를 Google AI Gemini API와 함께 사용할 수 있습니다. 각 API 키는 해당 키를 사용하여 호출하는 API로만 제한하는 것이 가장 좋습니다.\nAPI 키 제한이 있더라도 악의적인 행위자가 API 키를 획득하면 해당 API 키의 허용 목록에 포함된 모든 API에 대해 프로젝트의 할당량을 사용하여 호출할 수 있습니다.\nGemini API 키를 안전하게 유지할 책임은 개발자에게 있습니다.\n소스 제어에 Gemini API 키를 확인하지 마세요.\n클라이언트 측 애플리케이션 (Android, Swift, 웹, Dart/Flutter)은 API 키가 노출될 위험이 있으므로 프로덕션 앱에서 Google AI 클라이언트 SDK를 사용하여 모바일 및 웹 앱에서 직접 Google AI Gemini API를 호출하지 않는 것이 좋습니다. API 키 보안을 위한 언어별 권장사항을 알아보려면 SDK 빠른 시작을 확인하세요.\n이 지원 도움말에서 몇 가지 일반적인 권장사항을 확인할 수도 있습니다.\nAPI 키를 보호하고 사용하기 위한 권장사항을 알아보려면 API 빠른 시작을 확인하세요.\n최종 업데이트: 2024-04-24(UTC)",
            "filtered_word_count": 396
        },
        "https://ai.google.dev/gemini-api/docs/api-key#verify-key-with-curl": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nVerify your API key with a curl command\nKeep your API key secure\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet an API key \nbookmark_border\n\nTo use the Gemini API, you need an API key. You can create a key with one click in Google AI Studio.\n\nGet an API key\n\nImportant: Remember to use your API keys securely. Review Keep your API key secure and then check out the API quickstarts to learn language-specific best practices for securing your API key.\nVerify your API key with a curl command\n\nYou can use a curl command to verify your setup. You can pass the API key either in the URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOr in the x-goog-api-key header:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nKeep your API key secure\n\nIt's important to keep your Gemini API key secure. Here are a few things to keep in mind when using your Gemini API key:\n\nThe Google AI Gemini API uses API keys for authorization. If others get access to your Gemini API key, they can make calls using your project's quota, which could result in lost quota or additional billing charges (if billing is enabled). API keys also guard access to tuned models and files.\n\nWhen you click Get API key in Google AI Studio, you choose whether to provision a Gemini API key in a new or existing Google Cloud project. The API keys list in Google AI Studio shows all the API keys that AI Studio has provisioned for use with the Google AI Gemini API (along with all their associated Google Cloud projects).\n\nHowever, any API keys within the Google Cloud project can potentially be used to call the Google AI Gemini API. You can view and manage all your project's API keys in the APIs & Services > Credentials panel in the Google Cloud console.\n\nAdding API key restrictions can help limit the surface area usable through each API key. By default, the Gemini API key generated by Google AI Studio can only be used with the Google AI Gemini API (officially called the \"Generative Language API\" or generativelanguage.googleapis.com).\n\nIf there are any API keys within your Google Cloud project that lack API restrictions or any API keys that have allowlisted the Generative Language API, then those keys can be used with the Google AI Gemini API. It's best practice to restrict each API key to only the APIs that you call using that key.\nNote that even with API key restrictions, if a malicious actor obtains your API key, they can use it to make calls using your project's quota for all the APIs allowlisted for that API key.\n\nYou're responsible for keeping your Gemini API key secure.\n\nDo NOT check Gemini API keys into source control.\nClient-side applications (Android, Swift, web, and Dart/Flutter) risk exposing API keys, so we do not recommend using the Google AI client SDKs in production apps to call the Google AI Gemini API directly from your mobile and web apps. Check out the SDK quickstarts to learn language-specific best practices for securing your API key.\n\nFor some general best practices, you can also review this support article.\n\nNext steps\nCheck out the API quickstarts to learn best practices for securing your API key and using it.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy",
            "word_count": 754,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/api-key#security": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nVerify your API key with a curl command\nKeep your API key secure\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet an API key \nbookmark_border\n\nTo use the Gemini API, you need an API key. You can create a key with one click in Google AI Studio.\n\nGet an API key\n\nImportant: Remember to use your API keys securely. Review Keep your API key secure and then check out the API quickstarts to learn language-specific best practices for securing your API key.\nVerify your API key with a curl command\n\nYou can use a curl command to verify your setup. You can pass the API key either in the URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOr in the x-goog-api-key header:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nKeep your API key secure\n\nIt's important to keep your Gemini API key secure. Here are a few things to keep in mind when using your Gemini API key:\n\nThe Google AI Gemini API uses API keys for authorization. If others get access to your Gemini API key, they can make calls using your project's quota, which could result in lost quota or additional billing charges (if billing is enabled). API keys also guard access to tuned models and files.\n\nWhen you click Get API key in Google AI Studio, you choose whether to provision a Gemini API key in a new or existing Google Cloud project. The API keys list in Google AI Studio shows all the API keys that AI Studio has provisioned for use with the Google AI Gemini API (along with all their associated Google Cloud projects).\n\nHowever, any API keys within the Google Cloud project can potentially be used to call the Google AI Gemini API. You can view and manage all your project's API keys in the APIs & Services > Credentials panel in the Google Cloud console.\n\nAdding API key restrictions can help limit the surface area usable through each API key. By default, the Gemini API key generated by Google AI Studio can only be used with the Google AI Gemini API (officially called the \"Generative Language API\" or generativelanguage.googleapis.com).\n\nIf there are any API keys within your Google Cloud project that lack API restrictions or any API keys that have allowlisted the Generative Language API, then those keys can be used with the Google AI Gemini API. It's best practice to restrict each API key to only the APIs that you call using that key.\nNote that even with API key restrictions, if a malicious actor obtains your API key, they can use it to make calls using your project's quota for all the APIs allowlisted for that API key.\n\nYou're responsible for keeping your Gemini API key secure.\n\nDo NOT check Gemini API keys into source control.\nClient-side applications (Android, Swift, web, and Dart/Flutter) risk exposing API keys, so we do not recommend using the Google AI client SDKs in production apps to call the Google AI Gemini API directly from your mobile and web apps. Check out the SDK quickstarts to learn language-specific best practices for securing your API key.\n\nFor some general best practices, you can also review this support article.\n\nNext steps\nCheck out the API quickstarts to learn best practices for securing your API key and using it.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy\nThe new page has loaded.",
            "word_count": 759,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/api-key#next-steps": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nVerify your API key with a curl command\nKeep your API key secure\nNext steps\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGet an API key \nbookmark_border\n\nTo use the Gemini API, you need an API key. You can create a key with one click in Google AI Studio.\n\nGet an API key\n\nImportant: Remember to use your API keys securely. Review Keep your API key secure and then check out the API quickstarts to learn language-specific best practices for securing your API key.\nVerify your API key with a curl command\n\nYou can use a curl command to verify your setup. You can pass the API key either in the URL:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}\"\n\n\nOr in the x-goog-api-key header:\n\nAPI_KEY=\"YOUR_API_KEY\"\ncurl -H 'Content-Type: application/json' \\\n     -H \"x-goog-api-key: ${API_KEY}\" \\\n     -d '{\"contents\":[\n            {\"role\": \"user\",\n              \"parts\":[{\"text\": \"Give me five subcategories of jazz?\"}]}]}' \\\n     \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n\nKeep your API key secure\n\nIt's important to keep your Gemini API key secure. Here are a few things to keep in mind when using your Gemini API key:\n\nThe Google AI Gemini API uses API keys for authorization. If others get access to your Gemini API key, they can make calls using your project's quota, which could result in lost quota or additional billing charges (if billing is enabled). API keys also guard access to tuned models and files.\n\nWhen you click Get API key in Google AI Studio, you choose whether to provision a Gemini API key in a new or existing Google Cloud project. The API keys list in Google AI Studio shows all the API keys that AI Studio has provisioned for use with the Google AI Gemini API (along with all their associated Google Cloud projects).\n\nHowever, any API keys within the Google Cloud project can potentially be used to call the Google AI Gemini API. You can view and manage all your project's API keys in the APIs & Services > Credentials panel in the Google Cloud console.\n\nAdding API key restrictions can help limit the surface area usable through each API key. By default, the Gemini API key generated by Google AI Studio can only be used with the Google AI Gemini API (officially called the \"Generative Language API\" or generativelanguage.googleapis.com).\n\nIf there are any API keys within your Google Cloud project that lack API restrictions or any API keys that have allowlisted the Generative Language API, then those keys can be used with the Google AI Gemini API. It's best practice to restrict each API key to only the APIs that you call using that key.\nNote that even with API key restrictions, if a malicious actor obtains your API key, they can use it to make calls using your project's quota for all the APIs allowlisted for that API key.\n\nYou're responsible for keeping your Gemini API key secure.\n\nDo NOT check Gemini API keys into source control.\nClient-side applications (Android, Swift, web, and Dart/Flutter) risk exposing API keys, so we do not recommend using the Google AI client SDKs in production apps to call the Google AI Gemini API directly from your mobile and web apps. Check out the SDK quickstarts to learn language-specific best practices for securing your API key.\n\nFor some general best practices, you can also review this support article.\n\nNext steps\nCheck out the API quickstarts to learn best practices for securing your API key and using it.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-23 UTC.\n\nTerms\nPrivacy\nThe new page has loaded..",
            "word_count": 759,
            "filtered_content": "The new page has loaded..",
            "filtered_word_count": 5
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 501,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de": {
            "status": "Looks good",
            "content": "Produkte\nBeispiele\nAnmelden\nDokumentation\nAPI-Referenz\nÜberblick\nJetzt starten\nAPI-Schlüssel anfordern\nGemini API – Kurzanleitung\nGoogle AI Studio – Kurzanleitung\nAnleitungen für den Einstieg\nModelle\nInformationen zu generativen Modellen\nGemini\nGemini API\nAPI-Übersicht\nAPI-Referenz\nAPI-Versionen\nVersionshinweise\nLeistungsspektrum\nModellabstimmung\nFunktionsaufruf\nEinbettungen\nSicherheit\nLeitfäden\nAufforderungen\nSystemanleitung\nSemantischer Abruf\nAuthentifizierung mit OAuth\nFirebase-Erweiterungen\nZu Cloud migrieren\nAnleitungen\nFunktionsaufruf\nEinbettungen\nAnwendungen\nProblembehebung\nTipps zur Fehlerbehebung\nÜber Workspace auf AI Studio zugreifen\nFehlerbehebung in AI Studio\nHöheres Kontingent beantragen\nCommunity\nDiskursforum\nPaLM API (alt)\nZu Gemini migrieren\nPaLM-Dokumentation\nRecht\nNutzungsbedingungen\n(Vorschau) Nutzungsbedingungen\nVerfügbare Regionen\nAuf dieser Seite\nVoraussetzungen\nAPI-Schlüssel einrichten\nSDK Installieren\nGeneratives Modell initialisieren\nText generieren\nNächste Schritte\nSehen Sie sich das neue Cookbook zur Gemini API und unser Community-Forum an.\n Diese Seite wurde von der Cloud Translation API übersetzt.\nGoogle AI for Developers\nProdukte\nWar das hilfreich?\nFeedback geben\nGemini API – Kurzanleitung \nbookmark_border\n\nIn dieser Kurzanleitung werden die ersten Schritte mit der Gemini API mit dem SDK Ihrer Wahl beschrieben.\n\nVoraussetzungen\nPython\nOk\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nIn Google Colab ausführen\n\t\nNotebook auf GitHub ansehen\n\nWenn Sie diese Kurzanleitung lokal ausführen möchten, achten Sie darauf, dass Ihre Entwicklungsumgebung die folgenden Anforderungen erfüllt:\n\nPython 3.9 oder höher\nEine Installation von jupyter zum Ausführen des Notebooks.\nAPI-Schlüssel einrichten\n\nSie benötigen einen API-Schlüssel, um die Gemini API zu verwenden. Erstellen Sie einen Schlüssel in Google AI Studio, falls noch nicht geschehen.\n\nAPI-Schlüssel anfordern\n\nKonfigurieren Sie dann Ihren Schlüssel.\n\nPython\nOk\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nEs wird dringend empfohlen, einen API-Schlüssel nicht in das Versionsverwaltungssystem einzuchecken. In dieser Kurzanleitung wird davon ausgegangen, dass Sie auf Ihren API-Schlüssel als Umgebungsvariable zugreifen.\n\nWeisen Sie Ihren API-Schlüssel einer Umgebungsvariablen zu:\n\nexport API_KEY=<YOUR_API_KEY>\n\nSDK Installieren\nPython\nOk\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nDas Python SDK für die Gemini API ist im Paket google-generativeai enthalten. Installieren Sie die Abhängigkeit mit „Pip“:\n\npip install -q -U google-generativeai\n\nGeneratives Modell initialisieren\nPython\nOk\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBevor Sie API-Aufrufe ausführen können, müssen Sie das generative Modell importieren und initialisieren.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nText generieren\nPython\nOk\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nNächste Schritte\n\nWeitere Informationen zur Verwendung der Gemini API finden Sie in der Anleitung für Ihre bevorzugte Sprache.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (auf dem Gerät)\n\nSie können auch curl-Befehle verwenden, um die Gemini API zu testen:\n\nREST API\n\nWenn Sie mit generativen KI-Modellen noch nicht vertraut sind, sollten Sie sich den Konzeptleitfaden und die Gemini API-Übersicht ansehen, bevor Sie eine Kurzanleitung ausprobieren.\n\nWar das hilfreich?\nFeedback geben\n\nSofern nicht anders angegeben, sind die Inhalte dieser Seite unter der Creative Commons Attribution 4.0 License und Codebeispiele unter der Apache 2.0 License lizenziert. Weitere Informationen finden Sie in den Websiterichtlinien von Google Developers. Java ist eine eingetragene Marke von Oracle und/oder seinen Partnern.\n\nZuletzt aktualisiert: 2024-04-26 (UTC).\n\nNutzungsbedingungen\nDatenschutz",
            "word_count": 483,
            "filtered_content": "Gemini API – Kurzanleitung \nIn dieser Kurzanleitung werden die ersten Schritte mit der Gemini API mit dem SDK Ihrer Wahl beschrieben.\nIn Google Colab ausführen\nNotebook auf GitHub ansehen\nWenn Sie diese Kurzanleitung lokal ausführen möchten, achten Sie darauf, dass Ihre Entwicklungsumgebung die folgenden Anforderungen erfüllt:\nPython 3.9 oder höher\nEine Installation von jupyter zum Ausführen des Notebooks.\nSie benötigen einen API-Schlüssel, um die Gemini API zu verwenden. Erstellen Sie einen Schlüssel in Google AI Studio, falls noch nicht geschehen.\nKonfigurieren Sie dann Ihren Schlüssel.\nEs wird dringend empfohlen, einen API-Schlüssel nicht in das Versionsverwaltungssystem einzuchecken. In dieser Kurzanleitung wird davon ausgegangen, dass Sie auf Ihren API-Schlüssel als Umgebungsvariable zugreifen.\nWeisen Sie Ihren API-Schlüssel einer Umgebungsvariablen zu:\nDas Python SDK für die Gemini API ist im Paket google-generativeai enthalten. Installieren Sie die Abhängigkeit mit „Pip“:\nBevor Sie API-Aufrufe ausführen können, müssen Sie das generative Modell importieren und initialisieren.\nWeitere Informationen zur Verwendung der Gemini API finden Sie in der Anleitung für Ihre bevorzugte Sprache.\nAndroid (auf dem Gerät)\nSie können auch curl-Befehle verwenden, um die Gemini API zu testen:\nWenn Sie mit generativen KI-Modellen noch nicht vertraut sind, sollten Sie sich den Konzeptleitfaden und die Gemini API-Übersicht ansehen, bevor Sie eine Kurzanleitung ausprobieren.\nZuletzt aktualisiert: 2024-04-26 (UTC).",
            "filtered_word_count": 207
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419": {
            "status": "Looks good",
            "content": "Productos\nEjemplos\nAcceder\nDocumentos\nReferencia de la API\nResumen\nComenzar\nObtén una clave de API\nGuía de inicio rápido de la API de Gemini\nGuía de inicio rápido de Google AI Studio\nInstructivos de introducción\nModelos\nAcerca de los modelos generativos\nGemini\nGemini API\nDescripción general de la API\nReferencia de la API\nVersiones de API\nNotas de la versión\nFunciones\nAjuste del modelo\nLlamada a función\nIncorporaciones\nSeguridad\nGuías\nMensajes\nInstrucciones del sistema\nRecuperación semántica\nAutenticación de OAuth\nExtensiones de Firebase\nMigra a Cloud\nInstructivos\nLlamada a función\nIncorporaciones\nAplicaciones\nSolución de problemas\nGuía de solución de problemas\nAccede a AI Studio con Workspace\nSolución de problemas de AI Studio\nCómo solicitar una cuota mayor\nComunidad\nForo del discurso\nAPI de PaLM (heredada)\nCómo migrar a Gemini\nDocumentos de PaLM\nLegal\nCondiciones del Servicio\n(vista previa) Condiciones del Servicio\nRegiones disponibles\nEn esta página\nRequisitos previos\nCómo configurar tu clave de API\nCómo instalar el SDK\nInicializa el modelo generativo\nGenerar texto\nPróximos pasos\nConsulta la nueva Guía de soluciones de la API de Gemini y nuestro foro de la comunidad.\n Se usó la API de Cloud Translation para traducir esta página.\nGoogle AI for Developers\nProductos\n¿Te resultó útil?\nEnviar comentarios\nGuía de inicio rápido de la API de Gemini \nbookmark_border\n\nEn esta guía de inicio rápido, se muestra cómo comenzar a usar la API de Gemini con el SDK que elijas.\n\nRequisitos previos\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nEjecutar en Google Colab\n\t\nVer notebook en GitHub\n\nPara completar esta guía de inicio rápido de manera local, asegúrate de que tu entorno de desarrollo cumpla con los siguientes requisitos:\n\nPython 3.9 y versiones posteriores\nUna instalación de jupyter para ejecutar el notebook\nCómo configurar tu clave de API\n\nPara usar la API de Gemini, necesitarás una clave de API. Si aún no tienes una, crea una clave en Google AI Studio.\n\nObtén una clave de API.\n\nLuego, configura tu clave.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nTe recomendamos que no registres una clave de API en tu sistema de control de versión. En esta guía de inicio rápido, se supone que accedes a tu clave de API como una variable de entorno.\n\nAsigna tu clave de API a una variable de entorno:\n\nexport API_KEY=<YOUR_API_KEY>\n\nCómo instalar el SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nEl SDK de Python para la API de Gemini se encuentra en el paquete google-generativeai. Instala la dependencia con pip:\n\npip install -q -U google-generativeai\n\nInicializa el modelo generativo\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nAntes de que puedas hacer llamadas a la API, debes importar e inicializar el modelo generativo.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerar texto\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nPróximos pasos\n\nSi quieres obtener más información para trabajar con la API de Gemini, consulta el instructivo del lenguaje que elijas.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (integrado en el dispositivo)\n\nTambién puedes usar los comandos de curl para probar la API de Gemini:\n\nAPI de REST\n\nSi eres nuevo en los modelos de IA generativa, te recomendamos consultar la guía de conceptos y la descripción general de la API de Gemini antes de probar una guía de inicio rápido.\n\n¿Te resultó útil?\nEnviar comentarios\n\nSalvo que se indique lo contrario, el contenido de esta página está sujeto a la licencia Atribución 4.0 de Creative Commons, y los ejemplos de código están sujetos a la licencia Apache 2.0. Para obtener más información, consulta las políticas del sitio de Google Developers. Java es una marca registrada de Oracle o sus afiliados.\n\nÚltima actualización: 2024-04-26 (UTC)\n\nCondiciones\nPrivacidad",
            "word_count": 623,
            "filtered_content": "Guía de inicio rápido de la API de Gemini \nEn esta guía de inicio rápido, se muestra cómo comenzar a usar la API de Gemini con el SDK que elijas.\nEjecutar en Google Colab\nVer notebook en GitHub\nPara completar esta guía de inicio rápido de manera local, asegúrate de que tu entorno de desarrollo cumpla con los siguientes requisitos:\nPython 3.9 y versiones posteriores\nUna instalación de jupyter para ejecutar el notebook\nPara usar la API de Gemini, necesitarás una clave de API. Si aún no tienes una, crea una clave en Google AI Studio.\nLuego, configura tu clave.\nTe recomendamos que no registres una clave de API en tu sistema de control de versión. En esta guía de inicio rápido, se supone que accedes a tu clave de API como una variable de entorno.\nAsigna tu clave de API a una variable de entorno:\nEl SDK de Python para la API de Gemini se encuentra en el paquete google-generativeai. Instala la dependencia con pip:\nAntes de que puedas hacer llamadas a la API, debes importar e inicializar el modelo generativo.\nSi quieres obtener más información para trabajar con la API de Gemini, consulta el instructivo del lenguaje que elijas.\nAndroid (integrado en el dispositivo)\nTambién puedes usar los comandos de curl para probar la API de Gemini:\nAPI de REST\nSi eres nuevo en los modelos de IA generativa, te recomendamos consultar la guía de conceptos y la descripción general de la API de Gemini antes de probar una guía de inicio rápido.\nÚltima actualización: 2024-04-26 (UTC)",
            "filtered_word_count": 259
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr": {
            "status": "Looks good",
            "content": "Produits\nExemples\nConnexion\nDocumentation\nDocument de référence de l'API\nVue d'ensemble\nPremiers pas\nObtenir une clé d'API\nGuide de démarrage rapide de l'API Gemini\nGuide de démarrage rapide de Google AI Studio\nTutoriels de démarrage\nModèles\nÀ propos des modèles génératifs\nGemini\nGemini API\nPrésentation de l'API\nDocumentation de référence des API\nVersions d'API\nNotes de version\nCapacités\nRéglage du modèle\nAppel de fonction\nReprésentations vectorielles continues\nSécurité\nGuides\nInvites\nInstructions système\nRécupération sémantique\nAuthentification OAuth\nExtensions Firebase\nMigrer vers le cloud\nTutoriels\nAppel de fonction\nReprésentations vectorielles continues\nApplications\nDépannage\nGuide de dépannage\nAccéder à AI Studio à l'aide de Workspace\nRésoudre les problèmes liés à AI Studio\nDemander plus de quotas\nCommunauté\nForum de Discourse\nAPI PaLM (ancienne version)\nMigrer vers Gemini\nDocumentation sur PaLM\nJuridique\nConditions d'utilisation\n(Preview) Conditions d'utilisation\nRégions disponibles\nSur cette page\nPrérequis\nConfigurer votre clé API\nInstaller le SDK\nInitialiser le modèle génératif\nGénérer du texte\nÉtapes suivantes\nDécouvrez le livre de recettes avec l'API Gemini et notre forum de la communauté.\n Cette page a été traduite par l'API Cloud Translation.\nGoogle AI for Developers\nProduits\nCe contenu vous a-t-il été utile ?\nEnvoyer des commentaires\nGuide de démarrage rapide de l'API Gemini \nbookmark_border\n\nCe guide de démarrage rapide vous explique comment utiliser l'API Gemini à l'aide du SDK de votre choix.\n\nPrérequis\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nExécuter dans Google Colab\n\t\nAfficher le notebook sur GitHub\n\nPour suivre ce guide de démarrage rapide en local, assurez-vous que votre environnement de développement répond aux exigences suivantes:\n\nPython 3.9 ou version ultérieure\nUne installation de jupyter pour exécuter le notebook.\nConfigurer votre clé API\n\nPour utiliser l'API Gemini, vous avez besoin d'une clé API. Si vous n'en avez pas, créez-en une dans Google AI Studio.\n\nObtenir une clé API\n\nEnsuite, configurez votre clé.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nNous vous recommandons vivement de ne pas vérifier une clé API dans votre système de contrôle des versions. Dans ce guide, nous partons du principe que vous accédez à votre clé API en tant que variable d'environnement.\n\nAttribuez votre clé API à une variable d'environnement:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstaller le SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nLe SDK Python pour l'API Gemini est contenu dans le package google-generativeai. Installez la dépendance à l'aide de pip:\n\npip install -q -U google-generativeai\n\nInitialiser le modèle génératif\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nAvant de pouvoir effectuer des appels d'API, vous devez importer et initialiser le modèle génératif.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGénérer du texte\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nÉtapes suivantes\n\nPour en savoir plus sur l'utilisation de l'API Gemini, consultez le tutoriel correspondant au langage de votre choix.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (sur l'appareil)\n\nVous pouvez également utiliser les commandes curl pour essayer l'API Gemini:\n\nAPI REST\n\nSi vous débutez avec les modèles d'IA générative, vous pouvez consulter le guide des concepts et la présentation de l'API Gemini avant de vous lancer dans le guide de démarrage rapide.\n\nCe contenu vous a-t-il été utile ?\nEnvoyer des commentaires\n\nSauf indication contraire, le contenu de cette page est régi par une licence Creative Commons Attribution 4.0, et les échantillons de code sont régis par une licence Apache 2.0. Pour en savoir plus, consultez les Règles du site Google Developers. Java est une marque déposée d'Oracle et/ou de ses sociétés affiliées.\n\nDernière mise à jour le 2024/04/26 (UTC).\n\nConditions d'utilisation\nRègles de confidentialité",
            "word_count": 596,
            "filtered_content": "Guide de démarrage rapide de l'API Gemini \nCe guide de démarrage rapide vous explique comment utiliser l'API Gemini à l'aide du SDK de votre choix.\nExécuter dans Google Colab\nAfficher le notebook sur GitHub\nPour suivre ce guide de démarrage rapide en local, assurez-vous que votre environnement de développement répond aux exigences suivantes:\nPython 3.9 ou version ultérieure\nUne installation de jupyter pour exécuter le notebook.\nPour utiliser l'API Gemini, vous avez besoin d'une clé API. Si vous n'en avez pas, créez-en une dans Google AI Studio.\nEnsuite, configurez votre clé.\nNous vous recommandons vivement de ne pas vérifier une clé API dans votre système de contrôle des versions. Dans ce guide, nous partons du principe que vous accédez à votre clé API en tant que variable d'environnement.\nAttribuez votre clé API à une variable d'environnement:\nLe SDK Python pour l'API Gemini est contenu dans le package google-generativeai. Installez la dépendance à l'aide de pip:\nAvant de pouvoir effectuer des appels d'API, vous devez importer et initialiser le modèle génératif.\nPour en savoir plus sur l'utilisation de l'API Gemini, consultez le tutoriel correspondant au langage de votre choix.\nAndroid (sur l'appareil)\nVous pouvez également utiliser les commandes curl pour essayer l'API Gemini:\nAPI REST\nSi vous débutez avec les modèles d'IA générative, vous pouvez consulter le guide des concepts et la présentation de l'API Gemini avant de vous lancer dans le guide de démarrage rapide.\nDernière mise à jour le 2024/04/26 (UTC).",
            "filtered_word_count": 242
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id": {
            "status": "Looks good",
            "content": "Produk\nContoh\nMasuk\nDokumen\nReferensi API\nRingkasan\nMulai\nMendapatkan kunci API\nPanduan memulai Gemini API\nPanduan memulai Google AI Studio\nTutorial memulai\nModel\nTentang model generatif\nGemini\nGemini API\nRingkasan API\nReferensi API\nVersi API\nCatatan rilis\nKemampuan\nPenyesuaian model\nPanggilan fungsi\nEmbedding\nKeamanan\nPanduan\nMeminta\nPetunjuk sistem\nPengambilan semantik\nAutentikasi OAuth\nEkstensi Firebase\nBermigrasi ke Cloud\nTutorial\nPanggilan fungsi\nEmbedding\nAplikasi\nPemecahan masalah\nPanduan pemecahan masalah\nMengakses AI Studio menggunakan Workspace\nMemecahkan masalah AI Studio\nMeminta lebih banyak kuota\nKomunitas\nForum wacana\nPaLM API (lama)\nBermigrasi ke Gemini\nDokumen PaLM\nHukum\nPersyaratan layanan\nPersyaratan layanan (Pratinjau)\nRegion yang tersedia\nPada halaman ini\nPrasyarat\nMenyiapkan kunci API\nMenginstal SDK\nMenginisialisasi model generatif\nMembuat teks\nLangkah selanjutnya\nLihat Cookbook Gemini API baru dan forum komunitas kami.\n Halaman ini diterjemahkan oleh Cloud Translation API.\nGoogle AI for Developers\nProduk\nApakah informasi ini membantu?\nKirim masukan\nPanduan memulai Gemini API \nbookmark_border\n\nPanduan memulai ini menunjukkan cara memulai Gemini API menggunakan SDK pilihan Anda.\n\nPrasyarat\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nMenjalankan di Google Colab\n\t\nLihat notebook di GitHub\n\nUntuk menyelesaikan panduan memulai ini secara lokal, pastikan lingkungan pengembangan Anda memenuhi persyaratan berikut:\n\nPython 3.9 dan yang lebih baru\nPenginstalan jupyter untuk menjalankan notebook.\nMenyiapkan kunci API\n\nUntuk menggunakan Gemini API, Anda memerlukan kunci API. Jika Anda belum memilikinya, buat kunci di Google AI Studio.\n\nMendapatkan kunci API\n\nKemudian, konfigurasikan kunci Anda.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nSebaiknya Anda tidak melakukan check in kunci API ke dalam sistem kontrol versi Anda. Panduan memulai ini mengasumsikan bahwa Anda mengakses kunci API sebagai variabel lingkungan.\n\nTetapkan kunci API Anda ke variabel lingkungan:\n\nexport API_KEY=<YOUR_API_KEY>\n\nMenginstal SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nPython SDK untuk Gemini API terdapat dalam paket google-generativeai. Instal dependensi menggunakan pip:\n\npip install -q -U google-generativeai\n\nMenginisialisasi model generatif\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nSebelum dapat melakukan panggilan API, Anda perlu mengimpor dan menginisialisasi model generatif.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nMembuat teks\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nLangkah selanjutnya\n\nUntuk mempelajari lebih lanjut cara menggunakan Gemini API, lihat tutorial untuk bahasa pilihan Anda.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (di perangkat)\n\nAnda juga dapat menggunakan perintah curl untuk mencoba Gemini API:\n\nREST API\n\nJika baru mengenal model AI generatif, Anda mungkin ingin membaca panduan konsep dan ringkasan Gemini API sebelum mencoba panduan memulai.\n\nApakah informasi ini membantu?\nKirim masukan\n\nKecuali dinyatakan lain, konten di halaman ini dilisensikan berdasarkan Lisensi Creative Commons Attribution 4.0, sedangkan contoh kode dilisensikan berdasarkan Lisensi Apache 2.0. Untuk mengetahui informasi selengkapnya, lihat Kebijakan Situs Google Developers. Java adalah merek dagang terdaftar dari Oracle dan/atau afiliasinya.\n\nTerakhir diperbarui pada 2024-04-26 UTC.\n\nPersyaratan\nPrivasi",
            "word_count": 464,
            "filtered_content": "Panduan memulai Gemini API \nPanduan memulai ini menunjukkan cara memulai Gemini API menggunakan SDK pilihan Anda.\nMenjalankan di Google Colab\nLihat notebook di GitHub\nUntuk menyelesaikan panduan memulai ini secara lokal, pastikan lingkungan pengembangan Anda memenuhi persyaratan berikut:\nPython 3.9 dan yang lebih baru\nPenginstalan jupyter untuk menjalankan notebook.\nUntuk menggunakan Gemini API, Anda memerlukan kunci API. Jika Anda belum memilikinya, buat kunci di Google AI Studio.\nKemudian, konfigurasikan kunci Anda.\nSebaiknya Anda tidak melakukan check in kunci API ke dalam sistem kontrol versi Anda. Panduan memulai ini mengasumsikan bahwa Anda mengakses kunci API sebagai variabel lingkungan.\nTetapkan kunci API Anda ke variabel lingkungan:\nPython SDK untuk Gemini API terdapat dalam paket google-generativeai. Instal dependensi menggunakan pip:\nSebelum dapat melakukan panggilan API, Anda perlu mengimpor dan menginisialisasi model generatif.\nUntuk mempelajari lebih lanjut cara menggunakan Gemini API, lihat tutorial untuk bahasa pilihan Anda.\nAndroid (di perangkat)\nAnda juga dapat menggunakan perintah curl untuk mencoba Gemini API:\nJika baru mengenal model AI generatif, Anda mungkin ingin membaca panduan konsep dan ringkasan Gemini API sebelum mencoba panduan memulai.\nTerakhir diperbarui pada 2024-04-26 UTC.",
            "filtered_word_count": 181
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it": {
            "status": "Looks good",
            "content": "Prodotti\nEsempi\nAccedi\nDocumenti\nRiferimento API\nPanoramica\nInizia\nOttieni una chiave API\nGuida rapida dell'API Gemini\nGuida rapida di Google AI Studio\nTutorial introduttivi\nModelli\nInformazioni sui modelli generativi\nGemini\nGemini API\nPanoramica dell'API\nRiferimento API\nVersioni API\nNote di rilascio\nFunzionalità\nOttimizzazione del modello\nChiamata di funzione\nIncorporamenti\nSicurezza\nGuide\nPrompt\nIstruzioni di sistema\nRecupero semantico\nAutenticazione OAuth\nEstensioni Firebase\nEsegui la migrazione a Cloud\nTutorial\nChiamata di funzione\nIncorporamenti\nApplicazioni\nRisoluzione dei problemi\nRisoluzione dei problemi\nAccedere ad AI Studio utilizzando Workspace\nRisoluzione dei problemi relativi ad AI Studio\nRichiedere una quota maggiore\ncommunity\nForum del discorso\nAPI PaLM (legacy)\nEsegui la migrazione a Gemini\nDocumenti PaLM\nLegale\nTermini di servizio\n(Anteprima) Termini di servizio\nAree geografiche disponibili\nSu questa pagina\nPrerequisiti\nConfigura la chiave API\nInstalla l'SDK\nInizializzare il modello generativo\nGenera testo\nPassaggi successivi\nDai un'occhiata al nuovo Cookbook dell'API Gemini e al nostro forum della community.\n Questa pagina è stata tradotta dall'API Cloud Translation.\nGoogle AI for Developers\nProdotti\nQuesta pagina è stata utile?\nInvia feedback\nGuida rapida dell'API Gemini \nbookmark_border\n\nQuesta guida rapida mostra come iniziare a utilizzare l'API Gemini con l'SDK che preferisci.\n\nPrerequisiti\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nEsegui in Google Colab\n\t\nVisualizza blocco note su GitHub\n\nPer completare questa guida rapida a livello locale, assicurati che il tuo ambiente di sviluppo soddisfi i seguenti requisiti:\n\nPython 3.9 e versioni successive\nUn'installazione di jupyter per eseguire il blocco note.\nConfigura la chiave API\n\nPer utilizzare l'API Gemini, hai bisogno di una chiave API. Se non ne hai già una, crea una chiave in Google AI Studio.\n\nOttenere una chiave API\n\nQuindi, configura la chiave.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nTi consigliamo vivamente di non controllare una chiave API nel tuo sistema di controllo della versione. Questa guida rapida presuppone che tu stia accedendo alla chiave API come variabile di ambiente.\n\nAssegna la chiave API a una variabile di ambiente:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstalla l'SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nL'SDK Python per l'API Gemini è contenuto nel pacchetto google-generativeai. Installa la dipendenza utilizzando pip:\n\npip install -q -U google-generativeai\n\nInizializzare il modello generativo\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nPrima di poter effettuare chiamate API, devi importare e inizializzare il modello generativo.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenera testo\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nPassaggi successivi\n\nPer scoprire di più sull'utilizzo dell'API Gemini, guarda il tutorial per la lingua preferita.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nRapida\nAndroid\nAndroid (sul dispositivo)\n\nPuoi anche utilizzare i comandi curl per provare l'API Gemini:\n\nAPI REST\n\nSe non hai mai utilizzato i modelli di IA generativa, ti consigliamo di dare un'occhiata alla guida ai concetti e alla panoramica dell'API Gemini prima di provare la guida rapida.\n\nQuesta pagina è stata utile?\nInvia feedback\n\nSalvo quando diversamente specificato, i contenuti di questa pagina sono concessi in base alla licenza Creative Commons Attribution 4.0, mentre gli esempi di codice sono concessi in base alla licenza Apache 2.0. Per ulteriori dettagli, consulta le norme del sito di Google Developers. Java è un marchio registrato di Oracle e/o delle sue consociate.\n\nUltimo aggiornamento 2024-04-26 UTC.\n\nTermini\nPrivacy",
            "word_count": 544,
            "filtered_content": "Guida rapida dell'API Gemini \nQuesta guida rapida mostra come iniziare a utilizzare l'API Gemini con l'SDK che preferisci.\nEsegui in Google Colab\nVisualizza blocco note su GitHub\nPer completare questa guida rapida a livello locale, assicurati che il tuo ambiente di sviluppo soddisfi i seguenti requisiti:\nPython 3.9 e versioni successive\nUn'installazione di jupyter per eseguire il blocco note.\nPer utilizzare l'API Gemini, hai bisogno di una chiave API. Se non ne hai già una, crea una chiave in Google AI Studio.\nQuindi, configura la chiave.\nTi consigliamo vivamente di non controllare una chiave API nel tuo sistema di controllo della versione. Questa guida rapida presuppone che tu stia accedendo alla chiave API come variabile di ambiente.\nAssegna la chiave API a una variabile di ambiente:\nL'SDK Python per l'API Gemini è contenuto nel pacchetto google-generativeai. Installa la dipendenza utilizzando pip:\nPrima di poter effettuare chiamate API, devi importare e inizializzare il modello generativo.\nPer scoprire di più sull'utilizzo dell'API Gemini, guarda il tutorial per la lingua preferita.\nRapida\nAndroid (sul dispositivo)\nPuoi anche utilizzare i comandi curl per provare l'API Gemini:\nAPI REST\nSe non hai mai utilizzato i modelli di IA generativa, ti consigliamo di dare un'occhiata alla guida ai concetti e alla panoramica dell'API Gemini prima di provare la guida rapida.\nUltimo aggiornamento 2024-04-26 UTC.",
            "filtered_word_count": 218
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl": {
            "status": "Looks good",
            "content": "Produkty\nPrzykłady\nZaloguj się\nDokumenty\nDokumentacja API\nPrzegląd\nRozpocznij\nUzyskiwanie klucza interfejsu API\nKrótkie wprowadzenie do interfejsu Gemini API\nKrótkie wprowadzenie do Google AI Studio\nSamouczki na początek\nModele\nInformacje o modelach generatywnych\nGemini\nGemini API\nPrzegląd interfejsów API\nDokumentacja API\nWersje interfejsu API\nInformacje o wersjach\nMożliwości\nDostrajanie modeli\nWywoływanie funkcji\nOsadzone elementy\nBezpieczeństwo\nPrzewodniki\nPrompt\nInstrukcje systemowe\nPobieranie semantyczne\nUwierzytelnianie OAuth\nRozszerzenia Firebase\nMigracja do Cloud\nSamouczki\nWywoływanie funkcji\nOsadzone elementy\nAplikacje\nRozwiązywanie problemów\nPrzewodnik rozwiązywania problemów\nDostęp do AI Studio za pomocą Workspace\nRozwiązywanie problemów z AI Studio\nZgłaszanie prośby o dodatkowy limit\nSpołeczność\nForum dyskusyjne\nPaLM API (starsza wersja)\nMigracja do Gemini\nDokumentacja PaLM\nLegal\nWarunki korzystania z usługi\n(Wersja testowa) Warunki korzystania z usługi\nRegiony, w których działa ta usługa\nNa tej stronie\nWymagania wstępne\nKonfigurowanie klucza interfejsu API\nZainstaluj pakiet SDK\nInicjowanie modelu generatywnego\nGenerowanie tekstu\nCo dalej\nZapoznaj się z nową książką kucharską na temat interfejsu Gemini API i poznaj nasze forum społeczności.\n Ta strona została przetłumaczona przez Cloud Translation API.\nGoogle AI for Developers\nProdukty\nCzy te wskazówki były pomocne?\nPrześlij opinię\nKrótkie wprowadzenie do interfejsu Gemini API \nbookmark_border\n\nZ tego krótkiego wprowadzenia dowiesz się, jak rozpocząć korzystanie z interfejsu Gemini API przy użyciu wybranego pakietu SDK.\n\nWymagania wstępne\nPython\nGo\nNode.js\nWeb\nRzutki (zrzuty)\nSwift\nAndroid\nUruchom w Google Colab\n\t\nWyświetl notatnik w GitHub\n\nAby wykonać to krótkie wprowadzenie lokalnie, sprawdź, czy Twoje środowisko programistyczne spełnia te wymagania:\n\nPython 3.9 lub nowszy\nInstalacja pakietu jupyter do uruchamiania notatnika.\nKonfigurowanie klucza interfejsu API\n\nAby korzystać z interfejsu Gemini API, potrzebujesz klucza interfejsu API. Jeśli nie masz jeszcze klucza, utwórz go w Google AI Studio.\n\nUzyskiwanie klucza interfejsu API\n\nNastępnie skonfiguruj klucz.\n\nPython\nGo\nNode.js\nWeb\nRzutki (zrzuty)\nSwift\nAndroid\n\nZdecydowanie zalecamy, aby nie sprawdzać klucza interfejsu API w systemie kontroli wersji. W tym krótkim wprowadzeniu zakładamy, że użytkownik uzyskuje dostęp do klucza interfejsu API w postaci zmiennej środowiskowej.\n\nPrzypisz klucz interfejsu API do zmiennej środowiskowej:\n\nexport API_KEY=<YOUR_API_KEY>\n\nZainstaluj pakiet SDK\nPython\nGo\nNode.js\nWeb\nRzutki (zrzuty)\nSwift\nAndroid\n\nPakiet SDK Pythona dla interfejsu Gemini API znajduje się w pakiecie google-generativeai. Zainstaluj zależność za pomocą narzędzia pip:\n\npip install -q -U google-generativeai\n\nInicjowanie modelu generatywnego\nPython\nGo\nNode.js\nWeb\nRzutki (zrzuty)\nSwift\nAndroid\n\nZanim zaczniesz wywoływać interfejs API, musisz zaimportować i zainicjować model generatywny.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerowanie tekstu\nPython\nGo\nNode.js\nWeb\nRzutki (zrzuty)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nCo dalej\n\nWięcej informacji o korzystaniu z interfejsu Gemini API znajdziesz w samouczku dotyczący wybranego języka.\n\nPython\nGo\nNode.js\nSieć\nDart (Flutter)\nSwift,\nAndroid\nAndroid (na urządzeniu)\n\nAby wypróbować interfejs Gemini API, możesz też używać poleceń curl:\n\nAPI typu REST\n\nJeśli nie masz doświadczenia z modelami generatywnej AI, zanim zaczniesz krótkie wprowadzenie, zapoznaj się z przewodnikiem po koncepcjach i omówieniem interfejsu Gemini API.\n\nCzy te wskazówki były pomocne?\nPrześlij opinię\n\nO ile nie stwierdzono inaczej, treść tej strony jest objęta licencją Creative Commons – uznanie autorstwa 4.0, a fragmenty kodu są dostępne na licencji Apache 2.0. Szczegółowe informacje na ten temat zawierają zasady dotyczące witryny Google Developers. Java jest zastrzeżonym znakiem towarowym firmy Oracle i jej podmiotów stowarzyszonych.\n\nOstatnia aktualizacja: 2024-04-26 UTC.\n\nWarunki\nPrywatność",
            "word_count": 533,
            "filtered_content": "Krótkie wprowadzenie do interfejsu Gemini API \nZ tego krótkiego wprowadzenia dowiesz się, jak rozpocząć korzystanie z interfejsu Gemini API przy użyciu wybranego pakietu SDK.\nUruchom w Google Colab\nWyświetl notatnik w GitHub\nAby wykonać to krótkie wprowadzenie lokalnie, sprawdź, czy Twoje środowisko programistyczne spełnia te wymagania:\nPython 3.9 lub nowszy\nInstalacja pakietu jupyter do uruchamiania notatnika.\nAby korzystać z interfejsu Gemini API, potrzebujesz klucza interfejsu API. Jeśli nie masz jeszcze klucza, utwórz go w Google AI Studio.\nNastępnie skonfiguruj klucz.\nZdecydowanie zalecamy, aby nie sprawdzać klucza interfejsu API w systemie kontroli wersji. W tym krótkim wprowadzeniu zakładamy, że użytkownik uzyskuje dostęp do klucza interfejsu API w postaci zmiennej środowiskowej.\nPrzypisz klucz interfejsu API do zmiennej środowiskowej:\nPakiet SDK Pythona dla interfejsu Gemini API znajduje się w pakiecie google-generativeai. Zainstaluj zależność za pomocą narzędzia pip:\nZanim zaczniesz wywoływać interfejs API, musisz zaimportować i zainicjować model generatywny.\nWięcej informacji o korzystaniu z interfejsu Gemini API znajdziesz w samouczku dotyczący wybranego języka.\nSieć\nSwift,\nAndroid (na urządzeniu)\nAby wypróbować interfejs Gemini API, możesz też używać poleceń curl:\nAPI typu REST\nJeśli nie masz doświadczenia z modelami generatywnej AI, zanim zaczniesz krótkie wprowadzenie, zapoznaj się z przewodnikiem po koncepcjach i omówieniem interfejsu Gemini API.\nOstatnia aktualizacja: 2024-04-26 UTC.",
            "filtered_word_count": 204
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br": {
            "status": "Looks good",
            "content": "Produtos\nExemplos\nFazer login\nDocs\nReferência da API\nVisão geral\nComeçar\nObter uma chave de API\nGuia de início rápido da API Gemini\nGuia de início rápido do Google AI Studio\nTutoriais com os primeiros passos\nModelos\nSobre modelos generativos\nGemini\nGemini API\nVisão geral da API\nReferência da API\nVersões da API\nNotas da versão\nRecursos\nAjuste do modelo\nChamadas de funções\nEmbeddings\nSegurança\nGuias\nSolicitações de prompt\nInstruções do sistema\nRecuperação semântica\nAutenticação OAuth\nExtensões do Firebase\nMigrar para o Cloud\nTutoriais\nChamadas de funções\nEmbeddings\nAplicativos\nSolução de problemas\nGuia de solução de problemas\nAcessar o AI Studio usando o Workspace\nComo solucionar problemas no AI Studio\nSolicitar mais cotas\nComunidade\nFórum do Discourse\nAPI PaLM (legada)\nMigrar para o Gêmeos\nDocumentos do PaLM\nJurídico\nTermos de Serviço\n(Prévia) Termos de Serviço\nRegiões disponíveis\nNesta página\nPré-requisitos\nConfigurar sua chave de API\nInstalar o SDK\nInicializar o modelo generativo\nGerar texto\nA seguir\nConfira o Cookbook da nova API Gemini e nosso fórum da comunidade.\n Esta página foi traduzida pela API Cloud Translation.\nGoogle AI for Developers\nProdutos\nIsso foi útil?\nEnvie comentários\nGuia de início rápido da API Gemini \nbookmark_border\n\nEste guia de início rápido mostra como começar a usar a API Gemini usando o SDK da sua escolha.\n\nPré-requisitos\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nExecutar no Google Colab\n\t\nAcessar o notebook no GitHub\n(em inglês)\n\nPara concluir este guia de início rápido localmente, verifique se o ambiente de desenvolvimento atende aos seguintes requisitos:\n\nPython 3.9 ou superior\nUma instalação de jupyter para executar o notebook.\nConfigurar sua chave de API\n\nPara usar a API Gemini, você precisa de uma chave de API. Se você ainda não tiver uma, crie uma chave no Google AI Studio.\n\nGerar uma chave de API\n\nEm seguida, configure a chave.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nRecomendamos que você não verifique uma chave de API no seu sistema de controle de versões. Neste guia de início rápido, presumimos que você esteja acessando sua chave de API como uma variável de ambiente.\n\nAtribua sua chave de API a uma variável de ambiente:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstalar o SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nO SDK do Python para a API Gemini está incluído no pacote google-generativeai. Instale a dependência usando pip:\n\npip install -q -U google-generativeai\n\nInicializar o modelo generativo\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nAntes de fazer qualquer chamada de API, é preciso importar e inicializar o modelo generativo.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGerar texto\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nA seguir\n\nPara saber mais sobre como trabalhar com a API Gemini, consulte o tutorial da linguagem de sua preferência.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (no dispositivo)\n\nVocê também pode usar os comandos curl para testar a API Gemini:\n\nAPI REST\n\nSe você não tem experiência com modelos de IA generativa, consulte o guia de conceitos e a visão geral da API Generative antes de seguir este guia de início rápido.\n\nIsso foi útil?\nEnvie comentários\n\nExceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.\n\nÚltima atualização 2024-04-26 UTC.\n\nTermos de Serviço\nPrivacidade",
            "word_count": 592,
            "filtered_content": "Guia de início rápido da API Gemini \nEste guia de início rápido mostra como começar a usar a API Gemini usando o SDK da sua escolha.\nExecutar no Google Colab\nAcessar o notebook no GitHub\n(em inglês)\nPara concluir este guia de início rápido localmente, verifique se o ambiente de desenvolvimento atende aos seguintes requisitos:\nPython 3.9 ou superior\nUma instalação de jupyter para executar o notebook.\nPara usar a API Gemini, você precisa de uma chave de API. Se você ainda não tiver uma, crie uma chave no Google AI Studio.\nEm seguida, configure a chave.\nRecomendamos que você não verifique uma chave de API no seu sistema de controle de versões. Neste guia de início rápido, presumimos que você esteja acessando sua chave de API como uma variável de ambiente.\nAtribua sua chave de API a uma variável de ambiente:\nO SDK do Python para a API Gemini está incluído no pacote google-generativeai. Instale a dependência usando pip:\nAntes de fazer qualquer chamada de API, é preciso importar e inicializar o modelo generativo.\nPara saber mais sobre como trabalhar com a API Gemini, consulte o tutorial da linguagem de sua preferência.\nAndroid (no dispositivo)\nVocê também pode usar os comandos curl para testar a API Gemini:\nSe você não tem experiência com modelos de IA generativa, consulte o guia de conceitos e a visão geral da API Generative antes de seguir este guia de início rápido.\nÚltima atualização 2024-04-26 UTC.",
            "filtered_word_count": 242
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi": {
            "status": "Looks good",
            "content": "Sản phẩm\nVí dụ\nĐăng nhập\nTài liệu\nTài liệu tham khảo API\nTổng quan\nBắt đầu\nNhận khoá API\nBắt đầu nhanh API Gemini\nHướng dẫn nhanh về Google AI Studio\nHướng dẫn bắt đầu sử dụng\nMô hình\nGiới thiệu về các mô hình tạo sinh\nGemini\nGemini API\nTổng quan về API\nTài liệu tham khảo API\nPhiên bản API\nGhi chú phát hành\nChức năng\nĐiều chỉnh mô hình\nGọi hàm\nNhúng\nAn toàn\nHướng dẫn\nNhắc nhở\nHướng dẫn hệ thống\nTruy xuất ngữ nghĩa\nXác thực OAuth\nTiện ích Firebase\nDi chuyển sang nền tảng đám mây\nHướng dẫn\nGọi hàm\nNhúng\nỨng dụng\nKhắc phục sự cố\nHướng dẫn khắc phục sự cố\nTruy cập vào AI Studio bằng Workspace\nKhắc phục sự cố với AI Studio\nYêu cầu tăng hạn mức\nCộng đồng\nDiễn đàn Discourse\nAPI PaLM (cũ)\nDi chuyển sang Gemini\nTài liệu PaLM\nPháp lý\nĐiều khoản dịch vụ\n(Bản xem trước) Điều khoản dịch vụ\nKhu vực khả dụng\nTrên trang này\nĐiều kiện tiên quyết\nThiết lập khoá API\nCài đặt SDK\nKhởi động mô hình tạo sinh\nTạo văn bản\nBước tiếp theo\nHãy khám phá Cookbook API mới và diễn đàn cộng đồng của chúng tôi.\n Trang này được dịch bởi Cloud Translation API.\nGoogle AI for Developers\nSản phẩm\nThông tin này có hữu ích không cho bạn không?\nGửi ý kiến phản hồi\nBắt đầu nhanh API Gemini \nbookmark_border\n\nHướng dẫn bắt đầu nhanh này sẽ hướng dẫn bạn cách bắt đầu sử dụng API Gemini bằng SDK mà bạn chọn.\n\nĐiều kiện tiên quyết\nPython\nGo\nNode.js\nWeb\nPhi tiêu (Flutter)\nSwift\nAndroid\nChạy trong Google Colab\n\t\nXem sổ tay trên GitHub\n\nĐể hoàn tất quy trình bắt đầu nhanh này trên thiết bị, hãy đảm bảo môi trường phát triển của bạn đáp ứng các yêu cầu sau:\n\nPython 3.9 trở lên\nCài đặt jupyter để chạy sổ tay.\nThiết lập khoá API\n\nĐể sử dụng API Gemini, bạn cần có một khoá API. Nếu bạn chưa có khoá, hãy tạo khoá trong Google AI Studio.\n\nLấy khoá API\n\nSau đó, hãy định cấu hình khoá của bạn.\n\nPython\nGo\nNode.js\nWeb\nPhi tiêu (Flutter)\nSwift\nAndroid\n\nBạn không nên kiểm tra khoá API trong hệ thống quản lý phiên bản. Quá trình bắt đầu nhanh này giả định rằng bạn đang truy cập vào khoá API dưới dạng một biến môi trường.\n\nChỉ định khoá API cho một biến môi trường:\n\nexport API_KEY=<YOUR_API_KEY>\n\nCài đặt SDK\nPython\nGo\nNode.js\nWeb\nPhi tiêu (Flutter)\nSwift\nAndroid\n\nSDK Python cho API Gemini có trong gói google-generativeai. Cài đặt phần phụ thuộc bằng pip:\n\npip install -q -U google-generativeai\n\nKhởi động mô hình tạo sinh\nPython\nGo\nNode.js\nWeb\nPhi tiêu (Flutter)\nSwift\nAndroid\n\nĐể có thể thực hiện bất kỳ lệnh gọi API nào, bạn cần nhập và khởi chạy mô hình tạo sinh.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nTạo văn bản\nPython\nGo\nNode.js\nWeb\nPhi tiêu (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nBước tiếp theo\n\nĐể tìm hiểu thêm về cách làm việc với API Gemini, hãy xem hướng dẫn dành cho ngôn ngữ bạn chọn.\n\nPython\nBắt đầu\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (trên thiết bị)\n\nBạn cũng có thể dùng các lệnh curl để dùng thử API Gemini:\n\nAPI REST\n\nNếu mới sử dụng các mô hình AI tạo sinh, bạn nên xem hướng dẫn về khái niệm và tổng quan về API Genmini trước khi thử hướng dẫn bắt đầu nhanh.\n\nThông tin này có hữu ích không cho bạn không?\nGửi ý kiến phản hồi\n\nTrừ khi có lưu ý khác, nội dung của trang này được cấp phép theo Giấy phép ghi nhận tác giả 4.0 của Creative Commons và các mẫu mã lập trình được cấp phép theo Giấy phép Apache 2.0. Để biết thông tin chi tiết, vui lòng tham khảo Chính sách trang web của Google Developers. Java là nhãn hiệu đã đăng ký của Oracle và/hoặc các đơn vị liên kết với Oracle.\n\nCập nhật lần gần đây nhất: 2024-04-26 UTC.\n\nĐiều khoản\nQuyền riêng tư",
            "word_count": 707,
            "filtered_content": "Bắt đầu nhanh API Gemini \nHướng dẫn bắt đầu nhanh này sẽ hướng dẫn bạn cách bắt đầu sử dụng API Gemini bằng SDK mà bạn chọn.\nChạy trong Google Colab\nXem sổ tay trên GitHub\nĐể hoàn tất quy trình bắt đầu nhanh này trên thiết bị, hãy đảm bảo môi trường phát triển của bạn đáp ứng các yêu cầu sau:\nPython 3.9 trở lên\nCài đặt jupyter để chạy sổ tay.\nĐể sử dụng API Gemini, bạn cần có một khoá API. Nếu bạn chưa có khoá, hãy tạo khoá trong Google AI Studio.\nSau đó, hãy định cấu hình khoá của bạn.\nBạn không nên kiểm tra khoá API trong hệ thống quản lý phiên bản. Quá trình bắt đầu nhanh này giả định rằng bạn đang truy cập vào khoá API dưới dạng một biến môi trường.\nChỉ định khoá API cho một biến môi trường:\nSDK Python cho API Gemini có trong gói google-generativeai. Cài đặt phần phụ thuộc bằng pip:\nĐể có thể thực hiện bất kỳ lệnh gọi API nào, bạn cần nhập và khởi chạy mô hình tạo sinh.\nĐể tìm hiểu thêm về cách làm việc với API Gemini, hãy xem hướng dẫn dành cho ngôn ngữ bạn chọn.\nAndroid (trên thiết bị)\nBạn cũng có thể dùng các lệnh curl để dùng thử API Gemini:\nNếu mới sử dụng các mô hình AI tạo sinh, bạn nên xem hướng dẫn về khái niệm và tổng quan về API Genmini trước khi thử hướng dẫn bắt đầu nhanh.\nCập nhật lần gần đây nhất: 2024-04-26 UTC.",
            "filtered_word_count": 266
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr": {
            "status": "Looks good",
            "content": "Ürünler\nÖrnekler\nOturum aç\nDokümanlar\nAPI Referansı\nGenel bakış\nBaşlama\nAPI anahtarı alma\nGemini API hızlı başlangıç kılavuzu\nGoogle AI Studio hızlı başlangıç kılavuzu\nBaşlangıç eğiticileri\nModeller\nÜretken modeller hakkında\nGemini\nGemini API\nAPI'ye genel bakış\nAPI referansı\nAPI sürümleri\nSürüm notları\nÖzellikler\nModel ince ayarı\nİşlev çağrısı\nYerleştirmeler\nGüvenlik\nRehberler\nİstemde bulunma\nSistem talimatları\nAnlamsal alma\nOAuth kimlik doğrulaması\nFirebase uzantıları\nCloud'a taşı\nEğitimler\nİşlev çağrısı\nYerleştirmeler\nUygulamalar\nSorun giderme\nSorun giderme kılavuzu\nWorkspace'i kullanarak AI Studio'ya erişme\nAI Studio ile ilgili sorunları giderme\nDaha fazla kota isteme\nTopluluk\nTartışma forumu\nPaLM API (eski)\nGemini'a taşıyın\nPaLM belgeleri\nHukuk\nHizmet şartları\n(Önizleme) Hizmet şartları\nKullanılabildiği bölgeler\nBu sayfada\nÖn koşullar\nAPI anahtarınızı oluşturma\nSDK'yı yükleyin\nÜretken modeli ilk kullanıma hazırlama\nMetin oluştur\nSırada ne var?\nYeni Gemini API Cookbook'una ve topluluk forumumuza göz atın.\n Bu sayfa, Cloud Translation API ile çevrilmiştir.\nGoogle AI for Developers\nÜrünler\nBu size yardımcı oldu mu?\nGeri bildirim gönderin\nGemini API hızlı başlangıç kılavuzu \nbookmark_border\n\nBu hızlı başlangıç kılavuzu, istediğiniz SDK'yı kullanarak Gemini API'yi kullanmaya nasıl başlayacağınızı gösterir.\n\nÖn koşullar\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nGoogle Colab'de çalıştır\n\t\nGitHub'da not defterini görüntüle\n\nBu hızlı başlangıç kılavuzunu yerel olarak tamamlamak için geliştirme ortamınızın aşağıdaki gereksinimleri karşıladığından emin olun:\n\nPython 3.9 ve üzeri\nNot defterini çalıştırmak için jupyter yüklemesi.\nAPI anahtarınızı oluşturma\n\nGemini API'yi kullanmak için API anahtarı gerekir. Anahtarınız yoksa Google AI Studio'da bir anahtar oluşturun.\n\nAPI anahtarı alma\n\nArdından anahtarınızı yapılandırın.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nSürüm kontrol sisteminizde bir API anahtarını kontrol etmemeniz kesinlikle önerilir. Bu hızlı başlangıç kılavuzunda, API anahtarınıza ortam değişkeni olarak eriştiğiniz varsayılır.\n\nAPI anahtarınızı bir ortam değişkenine atayın:\n\nexport API_KEY=<YOUR_API_KEY>\n\nSDK'yı yükleyin\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nGemini API için Python SDK, google-generativeai paketinde yer alır. Pip kullanarak bağımlılığı yükleyin:\n\npip install -q -U google-generativeai\n\nÜretken modeli ilk kullanıma hazırlama\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nHerhangi bir API çağrısı yapabilmeniz için önce üretici modeli içe aktarıp başlatmanız gerekir.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nMetin oluştur\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nSırada ne var?\n\nGemini API ile çalışma hakkında daha fazla bilgi edinmek için seçtiğiniz dile ilişkin eğiticiye göz atın.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nHızlıca\nAndroid\nAndroid (cihaz üzerinde)\n\nGemini API'yi denemek için curl komutlarını da kullanabilirsiniz:\n\nREST API\n\nÜretken yapay zeka modellerini kullanmaya yeni başladıysanız hızlı başlangıç kılavuzundan önce kavramlar kılavuzuna ve Gemini API'ye genel bakışa göz atabilirsiniz.\n\nBu size yardımcı oldu mu?\nGeri bildirim gönderin\n\nAksi belirtilmediği sürece bu sayfanın içeriği Creative Commons Atıf 4.0 Lisansı altında ve kod örnekleri Apache 2.0 Lisansı altında lisanslanmıştır. Ayrıntılı bilgi için Google Developers Site Politikaları'na göz atın. Java, Oracle ve/veya satış ortaklarının tescilli ticari markasıdır.\n\nSon güncelleme tarihi: 2024-04-26 UTC.\n\nŞartlar\nGizlilik",
            "word_count": 471,
            "filtered_content": "Gemini API hızlı başlangıç kılavuzu \nBu hızlı başlangıç kılavuzu, istediğiniz SDK'yı kullanarak Gemini API'yi kullanmaya nasıl başlayacağınızı gösterir.\nGoogle Colab'de çalıştır\nGitHub'da not defterini görüntüle\nBu hızlı başlangıç kılavuzunu yerel olarak tamamlamak için geliştirme ortamınızın aşağıdaki gereksinimleri karşıladığından emin olun:\nPython 3.9 ve üzeri\nNot defterini çalıştırmak için jupyter yüklemesi.\nGemini API'yi kullanmak için API anahtarı gerekir. Anahtarınız yoksa Google AI Studio'da bir anahtar oluşturun.\nArdından anahtarınızı yapılandırın.\nSürüm kontrol sisteminizde bir API anahtarını kontrol etmemeniz kesinlikle önerilir. Bu hızlı başlangıç kılavuzunda, API anahtarınıza ortam değişkeni olarak eriştiğiniz varsayılır.\nAPI anahtarınızı bir ortam değişkenine atayın:\nGemini API için Python SDK, google-generativeai paketinde yer alır. Pip kullanarak bağımlılığı yükleyin:\nHerhangi bir API çağrısı yapabilmeniz için önce üretici modeli içe aktarıp başlatmanız gerekir.\nGemini API ile çalışma hakkında daha fazla bilgi edinmek için seçtiğiniz dile ilişkin eğiticiye göz atın.\nHızlıca\nAndroid (cihaz üzerinde)\nGemini API'yi denemek için curl komutlarını da kullanabilirsiniz:\nÜretken yapay zeka modellerini kullanmaya yeni başladıysanız hızlı başlangıç kılavuzundan önce kavramlar kılavuzuna ve Gemini API'ye genel bakışa göz atabilirsiniz.\nSon güncelleme tarihi: 2024-04-26 UTC.",
            "filtered_word_count": 174
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru": {
            "status": "Looks good",
            "content": "Продукты\nПримеры\nВойти\nДокументы\nДокументация по API\nОбзор\nНачало работы\nПолучить ключ API\nКраткое руководство по API Gemini\nКраткое руководство по Google AI Studio\nУчебники по началу работы\nМодели\nО генеративных моделях\nGemini\nGemini API\nОбзор API\nСправочник по API\nВерсии API\nПримечания к выпускам\nВозможности, Возможности\nТюнинг модели\nВызов функции\nВложения\nБезопасность\nПутеводители\nПодсказка\nСистемные инструкции\nСемантический поиск\nOAuth-аутентификация\nРасширения Firebase\nМиграция в облако\nРуководства\nВызов функции\nВложения\nПриложения\nУстранение неполадок\nРуководство по устранению неполадок\nДоступ к AI Studio с помощью Workspace\nУстранение неполадок AI Studio\nКак увеличить квоту\nСообщество\nДискурс-форум\nPaLM API (устаревший)\nПерейти на Близнецы\nДокументы ПалМ\nЮридический\nУсловия использования\n(Предварительная версия) Условия использования\nДоступные регионы\nСодержание\nПредварительные условия\nНастройте свой ключ API\nУстановите SDK\nИнициализируйте генеративную модель\nСоздать текст\nЧто дальше\nОзнакомьтесь с новой кулинарной книгой Gemini API и форумом нашего сообщества .\n Эта страница переведена с помощью Cloud Translation API.\nGoogle AI for Developers\nПродукты\nЭта информация оказалась полезной?\nОтправить отзыв\nКраткое руководство по API Gemini \nbookmark_border\n\nВ этом кратком руководстве показано, как начать работу с Gemini API, используя выбранный вами SDK.\n\nПредварительные условия \nПитон\nИдти\nNode.js\nИнтернет\nДарт (Флаттер)\nБыстрый\nАндроид\nЗапустить в Google Colab\n\t\nПосмотреть блокнот на GitHub\n\nЧтобы выполнить это краткое руководство локально, убедитесь, что ваша среда разработки соответствует следующим требованиям:\n\nПитон 3.9+\nУстановка jupyter для запуска ноутбука.\nНастройте свой ключ API\n\nЧтобы использовать API Gemini, вам понадобится ключ API. Если у вас его еще нет, создайте ключ в Google AI Studio.\n\nПолучить ключ API\n\nЗатем настройте свой ключ.\n\nПитон\nИдти\nNode.js\nИнтернет\nДарт (Флаттер)\nБыстрый\nАндроид\n\nНастоятельно рекомендуется не проверять ключ API в вашей системе контроля версий. В этом кратком руководстве предполагается, что вы получаете доступ к своему ключу API как к переменной среды.\n\nНазначьте свой ключ API переменной среды:\n\nexport API_KEY=<YOUR_API_KEY>\n\nУстановите SDK\nПитон\nИдти\nNode.js\nИнтернет\nДарт (Флаттер)\nБыстрый\nАндроид\n\nPython SDK для Gemini API содержится в пакете google-generativeai . Установите зависимость с помощью pip:\n\npip install -q -U google-generativeai\n\nИнициализируйте генеративную модель\nПитон\nИдти\nNode.js\nИнтернет\nДарт (Флаттер)\nБыстрый\nАндроид\n\nПрежде чем вы сможете выполнять какие-либо вызовы API, вам необходимо импортировать и инициализировать генеративную модель.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nСоздать текст\nПитон\nИдти\nNode.js\nИнтернет\nДарт (Флаттер)\nБыстрый\nАндроид\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nЧто дальше\n\nЧтобы узнать больше о работе с Gemini API, ознакомьтесь с руководством для выбранного вами языка.\n\nПитон\nИдти\nNode.js\nИнтернет\nДарт (Флаттер)\nБыстрый\nАндроид\nAndroid (на устройстве)\n\nВы также можете использовать команды curl , чтобы опробовать Gemini API:\n\nОТДЫХ API\n\nЕсли вы новичок в генеративных моделях искусственного интеллекта, возможно, вам стоит просмотреть руководство по концепциям и обзор API Gemini, прежде чем приступать к быстрому началу работы.\n\nЭта информация оказалась полезной?\nОтправить отзыв\n\nЕсли не указано иное, контент на этой странице предоставляется по лицензии Creative Commons \"С указанием авторства 4.0\", а примеры кода – по лицензии Apache 2.0. Подробнее об этом написано в правилах сайта. Java – это зарегистрированный товарный знак корпорации Oracle и ее аффилированных лиц.\n\nПоследнее обновление: 2024-04-26 UTC.\n\nУсловия использования\nКонфиденциальность",
            "word_count": 499,
            "filtered_content": "Предварительные условия\nКраткое руководство по API Gemini \nВ этом кратком руководстве показано, как начать работу с Gemini API, используя выбранный вами SDK.\nПредварительные условия \nЗапустить в Google Colab\nПосмотреть блокнот на GitHub\nЧтобы выполнить это краткое руководство локально, убедитесь, что ваша среда разработки соответствует следующим требованиям:\nПитон 3.9+\nУстановка jupyter для запуска ноутбука.\nЧтобы использовать API Gemini, вам понадобится ключ API. Если у вас его еще нет, создайте ключ в Google AI Studio.\nЗатем настройте свой ключ.\nНастоятельно рекомендуется не проверять ключ API в вашей системе контроля версий. В этом кратком руководстве предполагается, что вы получаете доступ к своему ключу API как к переменной среды.\nНазначьте свой ключ API переменной среды:\nPython SDK для Gemini API содержится в пакете google-generativeai . Установите зависимость с помощью pip:\nПрежде чем вы сможете выполнять какие-либо вызовы API, вам необходимо импортировать и инициализировать генеративную модель.\nЧтобы узнать больше о работе с Gemini API, ознакомьтесь с руководством для выбранного вами языка.\nAndroid (на устройстве)\nВы также можете использовать команды curl , чтобы опробовать Gemini API:\nОТДЫХ API\nЕсли вы новичок в генеративных моделях искусственного интеллекта, возможно, вам стоит просмотреть руководство по концепциям и обзор API Gemini, прежде чем приступать к быстрому началу работы.\nПоследнее обновление: 2024-04-26 UTC.",
            "filtered_word_count": 202
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he": {
            "status": "Looks good",
            "content": "מוצרים\nדוגמאות\nהיכנס\nמסמכים\nהפניית API\nסקירה כללית\nשנתחיל?\nקבלת מפתח API\nהמדריך למתחילים של Gemini API\nהמדריך למתחילים של Google AI Studio\nמדריכים לתחילת העבודה\nדגמים\nמידע על מודלים גנרטיביים\nGemini\nGemini API\nסקירה כללית בנושא API\nהפניית API\nגרסאות API\nהערות מוצר\nיכולות\nכוונון של מודל\nהפעלת פונקציה\nהטמעות\nסייפטי\nמדריכים\nהנחיות\nהוראות המערכת\nאחזור סמנטי\nאימות OAuth\nתוספי Firebase\nהעברה לענן\nמדריכים\nהפעלת פונקציה\nהטמעות\nאפליקציות\nפתרון בעיות\nמדריך לפתרון בעיות\nגישה ל-AI Studio באמצעות Workspace\nפתרון בעיות ב-AI Studio\nבקשה למכסה נוספת\nקהילה\nפורום דיונים\nPaLM API (קודם)\nמעבר ל-Gemini\nמסמכי PaLM\nמשפטי\nתנאים והגבלות\n(תצוגה מקדימה) תנאים והגבלות\nאזורים זמינים\nבדף הזה\nדרישות מוקדמות\nהגדרת מפתח ה-API\nהתקנת ה-SDK\nמאתחלים את המודל הגנרטיבי\nיצירת טקסט\nהמאמרים הבאים\nכדאי לעיין בספר הבישול החדש של Gemini API ובפורום הקהילה שלנו.\n דף זה תורגם על ידי Cloud Translation API.\nGoogle AI for Developers\nמוצרים\nהמידע עזר לך?\nשליחת משוב\nהמדריך למתחילים של Gemini API \nbookmark_border\n\nבמדריך למתחילים נסביר איך להתחיל להשתמש ב-Gemini API באמצעות SDK לבחירתכם.\n\nדרישות מוקדמות\nPython\nGo\nNode.js\nאתרים\nקליעה למטרה (פלוטר)\nSwift\nAndroid\nהפעלה ב-Google Colab\n\t\nהצגת ה-notebook ב-GitHub\n\nכדי להשלים את המדריך למתחילים באופן מקומי, צריך לוודא שסביבת הפיתוח עומדת בדרישות הבאות:\n\nPython 3.9 ואילך\nהתקנה של jupyter להפעלת ה-notebook.\nהגדרת מפתח ה-API\n\nכדי להשתמש ב-Gemini API, תצטרכו מפתח API. אם עדיין אין לכם מפתח, עליכם ליצור מפתח ב-Google AI Studio.\n\nקבלת מפתח API\n\nלאחר מכן מגדירים את המפתח.\n\nPython\nGo\nNode.js\nאתרים\nקליעה למטרה (פלוטר)\nSwift\nAndroid\n\nמומלץ מאוד לא לבדוק את מפתח ה-API במערכת בקרת הגרסאות. ההנחה במדריך למתחילים היא שאתם ניגשים למפתח ה-API בתור משתנה סביבה.\n\nמקצים את מפתח ה-API למשתנה סביבה:\n\nexport API_KEY=<YOUR_API_KEY>\n\nהתקנת ה-SDK\nPython\nGo\nNode.js\nאתרים\nקליעה למטרה (פלוטר)\nSwift\nAndroid\n\nה-Python SDK ל-Gemini API נמצא בחבילה google-generativeai. מתקינים את התלות באמצעות PIP:\n\npip install -q -U google-generativeai\n\nמאתחלים את המודל הגנרטיבי\nPython\nGo\nNode.js\nאתרים\nקליעה למטרה (פלוטר)\nSwift\nAndroid\n\nלפני שתוכלו לבצע קריאות ל-API, עליכם לייבא ולהפעיל את המודל הגנרטיבי.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nיצירת טקסט\nPython\nGo\nNode.js\nאתרים\nקליעה למטרה (פלוטר)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nהמאמרים הבאים\n\nלמידע נוסף על העבודה עם Gemini API, קראו את המדריך בשפה הרלוונטית.\n\nPython\nGo\nNode.js\nאתר\nחיצים (פלוטר)\nSwift\nAndroid\nAndroid (במכשיר)\n\nתוכלו גם להשתמש בפקודות curl כדי לנסות את Gemini API:\n\nAPI ל-REST\n\nאם זו הפעם הראשונה שאתם משתמשים במודלים של בינה מלאכותית גנרטיבית, מומלץ לעיין במדריך המושגים ובסקירה הכללית על Gemini API לפני שמנסים את המדריך למתחילים.\n\nהמידע עזר לך?\nשליחת משוב\n\nאלא אם צוין אחרת, התוכן של דף זה הוא ברישיון Creative Commons Attribution 4.0 ודוגמאות הקוד הן ברישיון Apache 2.0. לפרטים, ניתן לעיין במדיניות האתר Google Developers‏.‏ Java הוא סימן מסחרי רשום של חברת Oracle ו/או של השותפים העצמאיים שלה.\n\nעדכון אחרון: 2024-04-26 (שעון UTC).\n\nתנאים\nפרטיות",
            "word_count": 468,
            "filtered_content": "המדריך למתחילים של Gemini API \nבמדריך למתחילים נסביר איך להתחיל להשתמש ב-Gemini API באמצעות SDK לבחירתכם.\nהפעלה ב-Google Colab\nהצגת ה-notebook ב-GitHub\nכדי להשלים את המדריך למתחילים באופן מקומי, צריך לוודא שסביבת הפיתוח עומדת בדרישות הבאות:\nPython 3.9 ואילך\nהתקנה של jupyter להפעלת ה-notebook.\nכדי להשתמש ב-Gemini API, תצטרכו מפתח API. אם עדיין אין לכם מפתח, עליכם ליצור מפתח ב-Google AI Studio.\nלאחר מכן מגדירים את המפתח.\nמומלץ מאוד לא לבדוק את מפתח ה-API במערכת בקרת הגרסאות. ההנחה במדריך למתחילים היא שאתם ניגשים למפתח ה-API בתור משתנה סביבה.\nמקצים את מפתח ה-API למשתנה סביבה:\nה-Python SDK ל-Gemini API נמצא בחבילה google-generativeai. מתקינים את התלות באמצעות PIP:\nלפני שתוכלו לבצע קריאות ל-API, עליכם לייבא ולהפעיל את המודל הגנרטיבי.\nלמידע נוסף על העבודה עם Gemini API, קראו את המדריך בשפה הרלוונטית.\nאתר\nחיצים (פלוטר)\nAndroid (במכשיר)\nתוכלו גם להשתמש בפקודות curl כדי לנסות את Gemini API:\nAPI ל-REST\nאם זו הפעם הראשונה שאתם משתמשים במודלים של בינה מלאכותית גנרטיבית, מומלץ לעיין במדריך המושגים ובסקירה הכללית על Gemini API לפני שמנסים את המדריך למתחילים.\nעדכון אחרון: 2024-04-26 (שעון UTC).",
            "filtered_word_count": 176
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar": {
            "status": "Looks good",
            "content": "المنتجات\nأمثلة\nتسجيل الدخول\nالمستندات\nمرجع واجهة برمجة تطبيقات\nنظرة عامة\nالبدء\nالحصول على مفتاح واجهة برمجة التطبيقات\nالبدء السريع لواجهة برمجة تطبيقات Gemini\nدليل البدء السريع لاستخدام Google AI Studio\nالبرامج التعليمية للبدء\nالنماذج\nلمحة عن النماذج التوليدية\nGemini\nGemini API\nنظرة عامة على واجهة برمجة التطبيقات\nمرجع واجهة برمجة التطبيقات\nإصدارات واجهة برمجة التطبيقات\nملاحظات الإصدار\nالإمكانيات\nضبط النموذج\nاستدعاء الدوالّ\nعمليات التضمين\nدفاع\nالأدلة\nجارٍ الطلب\nتعليمات النظام\nالاسترجاع الدلالي\nمصادقة OAuth\nإضافات Firebase\nنقل البيانات إلى السحابة الإلكترونية\nالبرامج التعليمية\nاستدعاء الدوالّ\nعمليات التضمين\nالتطبيقات\nتحديد المشاكل وحلّها\nدليل تحديد المشاكل وحلّها\nالوصول إلى AI Studio باستخدام Workspace\nتحديد المشاكل في AI Studio وحلّها\nطلب المزيد من الحصص\nفعالية مجتمعية\nمنتدى الحوار\nPaLM API (الإصدار القديم)\nالانتقال إلى حساب Gemini\nمستندات PaLM\nشؤون قانونية\nبنود الخدمة\n(معاينة) بنود الخدمة\nالمناطق المتاحة\nعلى هذه الصفحة\nالمتطلبات الأساسية\nإعداد مفتاح واجهة برمجة التطبيقات\nتثبيت حزمة تطوير البرامج (SDK)\nإعداد النموذج التوليدي\nإنشاء نص\nالخطوات التالية\nاطّلِع على دليل Gemini API الجديد والمنتدى الخاص بنا.\n تمت ترجمة هذه الصفحة بواسطة Cloud Translation API‏.\nGoogle AI for Developers\nالمنتجات\nهل كان المحتوى مفيدًا؟\nإرسال ملاحظات\nالبدء السريع لواجهة برمجة تطبيقات Gemini \nbookmark_border\n\nيشرح لك دليل البدء السريع هذا كيفية بدء استخدام Gemini API باستخدام حزمة تطوير البرامج (SDK) التي تختارها.\n\nالمتطلبات الأساسية\nPython\nالبدء\nNode.js\nالويب\nDart (Flutter)\nSwift\nAndroid\nالتشغيل في Google Colab\n\t\nعرض دفتر ملاحظات على GitHub\n\nلإكمال عملية البدء السريع هذه محليًا، تأكد من أن بيئة التطوير تفي بالمتطلبات التالية:\n\nPython 3.9 أو إصدار أحدث\nتثبيت jupyter لتشغيل دفتر الملاحظات.\nإعداد مفتاح واجهة برمجة التطبيقات\n\nلاستخدام Gemini API، يجب استخدام مفتاح واجهة برمجة التطبيقات. إذا لم يسبق لك إنشاء مفتاح، أنشئ مفتاحًا في Google AI Studio\n\nالحصول على مفتاح واجهة برمجة التطبيقات\n\nبعد ذلك، عليك ضبط المفتاح.\n\nPython\nالبدء\nNode.js\nالويب\nDart (Flutter)\nSwift\nAndroid\n\nننصحك بشدة بعدم التحقق من مفتاح واجهة برمجة التطبيقات في نظام التحكم في الإصدار. يفترض البدء السريع هذا أنك تصل إلى مفتاح واجهة برمجة التطبيقات الخاص بك كمتغير بيئة.\n\nتعيين مفتاح واجهة برمجة التطبيقات لمتغير بيئة:\n\nexport API_KEY=<YOUR_API_KEY>\n\nتثبيت حزمة تطوير البرامج (SDK)\nPython\nالبدء\nNode.js\nالويب\nDart (Flutter)\nSwift\nAndroid\n\nتمّ تضمين حزمة Python SDK لـ Gemini API في الحزمة google-generativeai. تثبيت التبعية باستخدام pip:\n\npip install -q -U google-generativeai\n\nإعداد النموذج التوليدي\nPython\nالبدء\nNode.js\nالويب\nDart (Flutter)\nSwift\nAndroid\n\nقبل أن تتمكن من إجراء أي طلبات بيانات من واجهة برمجة التطبيقات، عليك استيراد النموذج التوليدي وإعداده.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nإنشاء نص\nPython\nالبدء\nNode.js\nالويب\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nالخطوات التالية\n\nلمزيد من المعلومات حول استخدام واجهة Gemini API، يمكنك الاطّلاع على الدليل التوجيهي للّغة التي تختارها.\n\nPython\nانتقال\nNode.js\nالويب\nDart (Flutter)\nSwift\nAndroid\nAndroid (على الجهاز)\n\nيمكنك أيضًا استخدام طلبات curl لتجربة Gemini API:\n\nREST API\n\nإذا كنت مبتدئًا في مجال نماذج الذكاء الاصطناعي التوليدي، ننصحك بإلقاء نظرة على دليل المفاهيم ونظرة عامة حول Gemini API قبل تجربة الخطوات السريعة.\n\nهل كان المحتوى مفيدًا؟\nإرسال ملاحظات\n\nإنّ محتوى هذه الصفحة مرخّص بموجب ترخيص Creative Commons Attribution 4.0‏ ما لم يُنصّ على خلاف ذلك، ونماذج الرموز مرخّصة بموجب ترخيص Apache 2.0‏. للاطّلاع على التفاصيل، يُرجى مراجعة سياسات موقع Google Developers‏. إنّ Java هي علامة تجارية مسجَّلة لشركة Oracle و/أو شركائها التابعين.\n\nتاريخ التعديل الأخير: 2024-04-26 (حسب التوقيت العالمي المتفَّق عليه)\n\nالبنود\nالخصوصية",
            "word_count": 549,
            "filtered_content": "البدء السريع لواجهة برمجة تطبيقات Gemini \nيشرح لك دليل البدء السريع هذا كيفية بدء استخدام Gemini API باستخدام حزمة تطوير البرامج (SDK) التي تختارها.\nالتشغيل في Google Colab\nعرض دفتر ملاحظات على GitHub\nلإكمال عملية البدء السريع هذه محليًا، تأكد من أن بيئة التطوير تفي بالمتطلبات التالية:\nPython 3.9 أو إصدار أحدث\nتثبيت jupyter لتشغيل دفتر الملاحظات.\nلاستخدام Gemini API، يجب استخدام مفتاح واجهة برمجة التطبيقات. إذا لم يسبق لك إنشاء مفتاح، أنشئ مفتاحًا في Google AI Studio\nبعد ذلك، عليك ضبط المفتاح.\nننصحك بشدة بعدم التحقق من مفتاح واجهة برمجة التطبيقات في نظام التحكم في الإصدار. يفترض البدء السريع هذا أنك تصل إلى مفتاح واجهة برمجة التطبيقات الخاص بك كمتغير بيئة.\nتعيين مفتاح واجهة برمجة التطبيقات لمتغير بيئة:\nتمّ تضمين حزمة Python SDK لـ Gemini API في الحزمة google-generativeai. تثبيت التبعية باستخدام pip:\nقبل أن تتمكن من إجراء أي طلبات بيانات من واجهة برمجة التطبيقات، عليك استيراد النموذج التوليدي وإعداده.\nلمزيد من المعلومات حول استخدام واجهة Gemini API، يمكنك الاطّلاع على الدليل التوجيهي للّغة التي تختارها.\nانتقال\nAndroid (على الجهاز)\nيمكنك أيضًا استخدام طلبات curl لتجربة Gemini API:\nإذا كنت مبتدئًا في مجال نماذج الذكاء الاصطناعي التوليدي، ننصحك بإلقاء نظرة على دليل المفاهيم ونظرة عامة حول Gemini API قبل تجربة الخطوات السريعة.\nتاريخ التعديل الأخير: 2024-04-26 (حسب التوقيت العالمي المتفَّق عليه)",
            "filtered_word_count": 212
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa": {
            "status": "Looks good",
            "content": "محصولات\nمثال ها\nورود به برنامه\nاسناد\nمرجع API\nبررسی اجمالی\nشروع کنید\nیک کلید API دریافت کنید\nGemini API شروع سریع\nشروع سریع استودیوی هوش مصنوعی گوگل\nآموزش های شروع\nمدل ها\nدرباره مدل های مولد\nGemini\nGemini API\nنمای کلی API\nمرجع API\nنسخه های API\nیادداشت های انتشار\nقابلیت ها، قابلیت ها\nتیونینگ مدل\nفراخوانی تابع\nجاسازی ها\nایمنی\nراهنماها\nتحریک کردن\nدستورالعمل های سیستم\nبازیابی معنایی\nاحراز هویت OAuth\nافزونه های Firebase\nمهاجرت به ابر\nآموزش ها\nفراخوانی تابع\nجاسازی ها\nبرنامه های کاربردی\nعیب یابی\nراهنمای عیب یابی\nبا استفاده از Workspace به AI Studio دسترسی پیدا کنید\nعیب یابی AI Studio\nدرخواست سهمیه بیشتر\nانجمن\nانجمن گفتمان\nPalm API (میراث)\nبه جمینی مهاجرت کنید\nاسناد PalM\nمجاز\nشرایط استفاده از خدمات\n(پیش نمایش) شرایط خدمات\nمناطق در دسترس\nدر این صفحه\nپیش نیازها\nکلید API خود را تنظیم کنید\nSDK را نصب کنید\nمدل مولد را راه اندازی کنید\nتولید متن\nبعدش چی\nکتاب آشپزی جدید Gemini API و انجمن انجمن ما را بررسی کنید.\n این صفحه به‌وسیله ‏Cloud Translation API‏ ترجمه شده است.\nGoogle AI for Developers\nمحصولات\nاین مرور مفید بود؟\nارسال بازخورد\nGemini API شروع سریع \nbookmark_border\n\nاین شروع سریع به شما نشان می دهد که چگونه با استفاده از SDK انتخابی خود با Gemini API شروع کنید.\n\nپیش نیازها \nپایتون\nبرو\nNode.js\nوب\nدارت (فلاتر)\nسریع\nاندروید\nدر Google Colab اجرا شود\n\t\nمشاهده نوت بوک در GitHub\n\nبرای تکمیل این شروع سریع به صورت محلی، اطمینان حاصل کنید که محیط توسعه شما شرایط زیر را برآورده می کند:\n\nپایتون 3.9+\nنصب jupyter برای اجرای نوت بوک.\nکلید API خود را تنظیم کنید\n\nبرای استفاده از Gemini API، به یک کلید API نیاز دارید. اگر قبلاً یکی ندارید، یک کلید در Google AI Studio ایجاد کنید.\n\nیک کلید API دریافت کنید\n\nسپس کلید خود را پیکربندی کنید.\n\nپایتون\nبرو\nNode.js\nوب\nدارت (فلاتر)\nسریع\nاندروید\n\nاکیداً توصیه می شود که یک کلید API را در سیستم کنترل نسخه خود بررسی نکنید . این شروع سریع فرض می کند که شما به کلید API خود به عنوان یک متغیر محیطی دسترسی دارید.\n\nکلید API خود را به یک متغیر محیطی اختصاص دهید:\n\nexport API_KEY=<YOUR_API_KEY>\n\nSDK را نصب کنید\nپایتون\nبرو\nNode.js\nوب\nدارت (فلاتر)\nسریع\nاندروید\n\nPython SDK برای Gemini API در بسته google-generativeai موجود است. وابستگی را با استفاده از pip نصب کنید:\n\npip install -q -U google-generativeai\n\nمدل مولد را راه اندازی کنید\nپایتون\nبرو\nNode.js\nوب\nدارت (فلاتر)\nسریع\nاندروید\n\nقبل از اینکه بتوانید هر گونه تماس API را برقرار کنید، باید مدل تولیدی را وارد و مقداردهی اولیه کنید.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nتولید متن\nپایتون\nبرو\nNode.js\nوب\nدارت (فلاتر)\nسریع\nاندروید\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nبعدش چی\n\nبرای کسب اطلاعات بیشتر در مورد کار با Gemini API، به آموزش زبان انتخابی خود مراجعه کنید.\n\nپایتون\nبرو\nNode.js\nوب\nدارت (فلاتر)\nسریع\nاندروید\nاندروید (روی دستگاه)\n\nهمچنین می توانید از دستورات curl برای آزمایش Gemini API استفاده کنید:\n\nREST API\n\nاگر در مدل های هوش مصنوعی مولد تازه کار هستید، ممکن است بخواهید قبل از شروع سریع به راهنمای مفاهیم و نمای کلی Gemini API نگاه کنید.\n\nاین مرور مفید بود؟\nارسال بازخورد\n\nجز در مواردی که غیر از این ذکر شده باشد،‌محتوای این صفحه تحت مجوز Creative Commons Attribution 4.0 License است. نمونه کدها نیز دارای مجوز Apache 2.0 License است. برای اطلاع از جزئیات، به خطمشی‌های سایت Google Developers‏ مراجعه کنید. جاوا علامت تجاری ثبت‌شده Oracle و/یا شرکت‌های وابسته به آن است.\n\nتاریخ آخرین به‌روزرسانی 2024-04-26 به‌وقت ساعت هماهنگ جهانی.\n\nشرایط\nحریم خصوصی",
            "word_count": 598,
            "filtered_content": "پیش نیازها\nGemini API شروع سریع \nاین شروع سریع به شما نشان می دهد که چگونه با استفاده از SDK انتخابی خود با Gemini API شروع کنید.\nپیش نیازها \nدر Google Colab اجرا شود\nمشاهده نوت بوک در GitHub\nبرای تکمیل این شروع سریع به صورت محلی، اطمینان حاصل کنید که محیط توسعه شما شرایط زیر را برآورده می کند:\nپایتون 3.9+\nنصب jupyter برای اجرای نوت بوک.\nبرای استفاده از Gemini API، به یک کلید API نیاز دارید. اگر قبلاً یکی ندارید، یک کلید در Google AI Studio ایجاد کنید.\nسپس کلید خود را پیکربندی کنید.\nاکیداً توصیه می شود که یک کلید API را در سیستم کنترل نسخه خود بررسی نکنید . این شروع سریع فرض می کند که شما به کلید API خود به عنوان یک متغیر محیطی دسترسی دارید.\nکلید API خود را به یک متغیر محیطی اختصاص دهید:\nPython SDK برای Gemini API در بسته google-generativeai موجود است. وابستگی را با استفاده از pip نصب کنید:\nقبل از اینکه بتوانید هر گونه تماس API را برقرار کنید، باید مدل تولیدی را وارد و مقداردهی اولیه کنید.\nبرای کسب اطلاعات بیشتر در مورد کار با Gemini API، به آموزش زبان انتخابی خود مراجعه کنید.\nاندروید (روی دستگاه)\nهمچنین می توانید از دستورات curl برای آزمایش Gemini API استفاده کنید:\nاگر در مدل های هوش مصنوعی مولد تازه کار هستید، ممکن است بخواهید قبل از شروع سریع به راهنمای مفاهیم و نمای کلی Gemini API نگاه کنید.\nتاریخ آخرین به‌روزرسانی 2024-04-26 به‌وقت ساعت هماهنگ جهانی.",
            "filtered_word_count": 248
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi": {
            "status": "Looks good",
            "content": "प्रॉडक्ट\nउदाहरण\nप्रवेश करें\nDocs\nएपीआई का संदर्भ\nखास जानकारी\nशुरू करें\nएपीआई पासकोड पाएं\nGemini API क्विकस्टार्ट\nGoogle AI Studio क्विकस्टार्ट\nट्यूटोरियल शुरू करना\nमॉडल\nजनरेटिव मॉडल के बारे में जानकारी\nGemini\nGemini API\nएपीआई के बारे में खास जानकारी\nएपीआई का संदर्भ\nएपीआई वर्शन\nप्रॉडक्ट की जानकारी\nमिलने वाली अनुमतियां\nमॉडल ट्यूनिंग\nफ़ंक्शन कॉल करने की सुविधा\nएम्बेड करना\nसुरक्षा\nगाइड\nप्रॉम्प्ट करना\nसिस्टम से जुड़े निर्देश\nसिमैंटिक रिकवरी\nOAuth प्रमाणीकरण\nFirebase एक्सटेंशन\nCloud पर माइग्रेट करें\nट्यूटोरियल\nफ़ंक्शन कॉल करने की सुविधा\nएम्बेड करना\nऐप्लिकेशन\nसमस्या का हल\nसमस्या हल करने के लिए गाइड\nWorkspace की मदद से एआई स्टूडियो को ऐक्सेस करना\nAI Studio से जुड़ी समस्याएं हल करना\nअनुरोध भेजने की सीमा बढ़ाने का अनुरोध करना\nकम्यूनिटी\nबातचीत के लिए फ़ोरम\nPaLM API (लेगसी)\nGemini में माइग्रेट करें\nPaLM के दस्तावेज़\nकानूनी\nसेवा की शर्तें\n(झलक) सेवा की शर्तें\nउपलब्ध क्षेत्र\nइस पेज पर, यह जानकारी उपलब्ध है\nज़रूरी शर्तें\nअपनी एपीआई कुंजी सेट अप करें\nSDK टूल इंस्टॉल करें\nजनरेटिव मॉडल को शुरू करना\nटेक्स्ट जनरेट करें\nआगे क्या करना है\nनया Gemini API कुकबुक और हमारा कम्यूनिटी फ़ोरम देखें.\n इस पेज का अनुवाद Cloud Translation API से किया गया है.\nGoogle AI for Developers\nप्रॉडक्ट\nक्या इस कॉन्टेंट से आपको मदद मिली?\nसुझाव भेजें\nGemini API क्विकस्टार्ट \nbookmark_border\n\nइस क्विकस्टार्ट में बताया गया है कि अपनी पसंद के SDK टूल का इस्तेमाल करके, Gemini API का इस्तेमाल कैसे किया जा सकता है.\n\nज़रूरी शर्तें\nPython\nशुरू करें\nNode.js\nवेब\nडार्ट (फ़्लटर)\nSwift\nAndroid\nGoogle Colab में चलाएं\n\t\nGitHub पर notebook देखें\n\nइस क्विकस्टार्ट को स्थानीय तौर पर पूरा करने के लिए, पक्का करें कि आपका डेवलपमेंट एनवायरमेंट नीचे दी गई ज़रूरी शर्तों को पूरा करता हो:\n\nPython 3.9 और इसके बाद के वर्शन\nnotebook चलाने के लिए jupyter का इंस्टॉलेशन.\nअपनी एपीआई कुंजी सेट अप करें\n\nGemini API का इस्तेमाल करने के लिए, आपको एपीआई पासकोड की ज़रूरत होगी. अगर आपके पास पहले से कोई कुंजी नहीं है, तो Google AI Studio में कुंजी बनाएं.\n\nएपीआई पासकोड पाएं\n\nइसके बाद, अपनी कुंजी कॉन्फ़िगर करें.\n\nPython\nशुरू करें\nNode.js\nवेब\nडार्ट (फ़्लटर)\nSwift\nAndroid\n\nहमारा सुझाव है कि आप अपने वर्शन कंट्रोल सिस्टम में एपीआई पासकोड की जांच न करें. यह क्विकस्टार्ट यह मानता है कि अपनी एपीआई कुंजी को एनवायरमेंट वैरिएबल के तौर पर ऐक्सेस किया जा रहा है.\n\nअपनी एपीआई कुंजी को किसी एनवायरमेंट वैरिएबल पर असाइन करें:\n\nexport API_KEY=<YOUR_API_KEY>\n\nSDK टूल इंस्टॉल करें\nPython\nशुरू करें\nNode.js\nवेब\nडार्ट (फ़्लटर)\nSwift\nAndroid\n\nGemini API के लिए Python SDK टूल, google-generativeai पैकेज में शामिल होता है. पीआईपी (पिक्चर में पिक्चर) का इस्तेमाल करके डिपेंडेंसी इंस्टॉल करें:\n\npip install -q -U google-generativeai\n\nजनरेटिव मॉडल को शुरू करना\nPython\nशुरू करें\nNode.js\nवेब\nडार्ट (फ़्लटर)\nSwift\nAndroid\n\nकोई भी एपीआई कॉल करने से पहले, आपको जनरेटिव मॉडल को इंपोर्ट और शुरू करना होगा.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nटेक्स्ट जनरेट करें\nPython\nशुरू करें\nNode.js\nवेब\nडार्ट (फ़्लटर)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nआगे क्या करना है\n\nGemini API के साथ काम करने के बारे में ज़्यादा जानने के लिए, अपनी पसंद की भाषा का ट्यूटोरियल देखें.\n\nPython\nजाएं\nNode.js\nवेब\nडार्ट (फ़्लटर)\nस्विफ़्ट\nAndroid\nAndroid (डिवाइस पर मौजूद)\n\nGemini API को आज़माने के लिए, curl कमांड का भी इस्तेमाल किया जा सकता है:\n\nREST API\n\nअगर आपने जनरेटिव एआई मॉडल का इस्तेमाल पहले कभी नहीं किया है, तो क्विकस्टार्ट की सुविधा आज़माने से पहले, कॉन्सेप्ट से जुड़ी गाइड और Gemini API की खास जानकारी देखें.\n\nक्या इस कॉन्टेंट से आपको मदद मिली?\nसुझाव भेजें\n\nजब तक कुछ अलग से न बताया जाए, तब तक इस पेज की सामग्री को Creative Commons Attribution 4.0 License के तहत और कोड के नमूनों को Apache 2.0 License के तहत लाइसेंस मिला है. ज़्यादा जानकारी के लिए, Google Developers साइट नीतियां देखें. Oracle और/या इससे जुड़ी हुई कंपनियों का, Java एक रजिस्टर किया हुआ ट्रेडमार्क है.\n\nआखिरी बार 2024-04-26 (UTC) को अपडेट किया गया.\n\nशर्तें\nनिजता",
            "word_count": 659,
            "filtered_content": "Gemini API क्विकस्टार्ट \nइस क्विकस्टार्ट में बताया गया है कि अपनी पसंद के SDK टूल का इस्तेमाल करके, Gemini API का इस्तेमाल कैसे किया जा सकता है.\nGoogle Colab में चलाएं\nGitHub पर notebook देखें\nइस क्विकस्टार्ट को स्थानीय तौर पर पूरा करने के लिए, पक्का करें कि आपका डेवलपमेंट एनवायरमेंट नीचे दी गई ज़रूरी शर्तों को पूरा करता हो:\nPython 3.9 और इसके बाद के वर्शन\nnotebook चलाने के लिए jupyter का इंस्टॉलेशन.\nGemini API का इस्तेमाल करने के लिए, आपको एपीआई पासकोड की ज़रूरत होगी. अगर आपके पास पहले से कोई कुंजी नहीं है, तो Google AI Studio में कुंजी बनाएं.\nइसके बाद, अपनी कुंजी कॉन्फ़िगर करें.\nहमारा सुझाव है कि आप अपने वर्शन कंट्रोल सिस्टम में एपीआई पासकोड की जांच न करें. यह क्विकस्टार्ट यह मानता है कि अपनी एपीआई कुंजी को एनवायरमेंट वैरिएबल के तौर पर ऐक्सेस किया जा रहा है.\nअपनी एपीआई कुंजी को किसी एनवायरमेंट वैरिएबल पर असाइन करें:\nGemini API के लिए Python SDK टूल, google-generativeai पैकेज में शामिल होता है. पीआईपी (पिक्चर में पिक्चर) का इस्तेमाल करके डिपेंडेंसी इंस्टॉल करें:\nकोई भी एपीआई कॉल करने से पहले, आपको जनरेटिव मॉडल को इंपोर्ट और शुरू करना होगा.\nGemini API के साथ काम करने के बारे में ज़्यादा जानने के लिए, अपनी पसंद की भाषा का ट्यूटोरियल देखें.\nजाएं\nस्विफ़्ट\nAndroid (डिवाइस पर मौजूद)\nGemini API को आज़माने के लिए, curl कमांड का भी इस्तेमाल किया जा सकता है:\nअगर आपने जनरेटिव एआई मॉडल का इस्तेमाल पहले कभी नहीं किया है, तो क्विकस्टार्ट की सुविधा आज़माने से पहले, कॉन्सेप्ट से जुड़ी गाइड और Gemini API की खास जानकारी देखें.\nआखिरी बार 2024-04-26 (UTC) को अपडेट किया गया.",
            "filtered_word_count": 273
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn": {
            "status": "Looks good",
            "content": "পণ্য\nউদাহরণ\nসাইন-ইন করুন\nডক্স\nAPI রেফারেন্স\nওভারভিউ\nএবার শুরু করা যাক\nএকটি API কী পান\nজেমিনি API কুইকস্টার্ট\nগুগল এআই স্টুডিও দ্রুত শুরু\nটিউটোরিয়াল শুরু করা হচ্ছে\nমডেল\nজেনারেটিভ মডেল সম্পর্কে\nGemini\nGemini API\nAPI ওভারভিউ\nAPI রেফারেন্স\nAPI সংস্করণ\nঅব্যাহতি পত্র\nক্ষমতা, ক্ষমতা\nমডেল টিউনিং\nফাংশন কলিং\nএমবেডিং\nনিরাপত্তা\nগাইড\nপ্রম্পটিং\nসিস্টেম নির্দেশাবলী\nশব্দার্থিক পুনরুদ্ধার\nOAuth প্রমাণীকরণ\nফায়ারবেস এক্সটেনশন\nক্লাউডে মাইগ্রেট করুন\nটিউটোরিয়াল\nফাংশন কলিং\nএমবেডিং\nঅ্যাপ্লিকেশন\nসমস্যা সমাধান\nসমস্যা সমাধানের গাইড\nওয়ার্কস্পেস ব্যবহার করে এআই স্টুডিও অ্যাক্সেস করুন\nএআই স্টুডিওর সমস্যা সমাধান করা হচ্ছে\nআরো কোটা অনুরোধ\nসম্প্রদায়\nডিসকোর্স ফোরাম\nPaLM API (উত্তরাধিকার)\nমিথুন রাশিতে চলে যান\nPaLM ডক্স\nআইনি\nসেবা পাবার শর্ত\n(প্রিভিউ) পরিষেবার শর্তাবলী\nউপলব্ধ অঞ্চল\nএই পৃষ্ঠায় যা যা আছে\nপূর্বশর্ত\nআপনার API কী সেট আপ করুন\nSDK ইনস্টল করুন\nজেনারেটিভ মডেল শুরু করুন\nপাঠ্য তৈরি করুন\nএরপর কি\nনতুন জেমিনি API কুকবুক এবং আমাদের কমিউনিটি ফোরাম দেখুন।\n এই পৃষ্ঠাটি Cloud Translation API অনুবাদ করেছে।\nGoogle AI for Developers\nপণ্য\nএটি কাজে লেগেছে?\nমতামত জানান\nজেমিনি API কুইকস্টার্ট \nbookmark_border\n\nএই কুইকস্টার্ট আপনাকে দেখায় কিভাবে আপনার পছন্দের SDK ব্যবহার করে Gemini API দিয়ে শুরু করবেন।\n\nপূর্বশর্ত \nপাইথন\nযাওয়া\nNode.js\nওয়েব\nডার্ট (ফ্লটার)\nসুইফট\nঅ্যান্ড্রয়েড\nGoogle Colab-এ চালান\n\t\nGitHub এ নোটবুক দেখুন\n\nস্থানীয়ভাবে এই কুইকস্টার্টটি সম্পূর্ণ করতে, নিশ্চিত করুন যে আপনার উন্নয়ন পরিবেশ নিম্নলিখিত প্রয়োজনীয়তাগুলি পূরণ করে:\n\nPython 3.9+\nনোটবুক চালানোর জন্য jupyter একটি ইনস্টলেশন।\nআপনার API কী সেট আপ করুন\n\nGemini API ব্যবহার করতে, আপনার একটি API কী প্রয়োজন। আপনার যদি ইতিমধ্যে একটি না থাকে তবে Google AI স্টুডিওতে একটি কী তৈরি করুন৷\n\nএকটি API কী পান\n\nতারপর আপনার কী কনফিগার করুন।\n\nপাইথন\nযাওয়া\nNode.js\nওয়েব\nডার্ট (ফ্লটার)\nসুইফট\nঅ্যান্ড্রয়েড\n\nএটি দৃঢ়ভাবে সুপারিশ করা হয় যে আপনি আপনার সংস্করণ নিয়ন্ত্রণ সিস্টেমে একটি API কী চেক করবেন না ৷ এই কুইকস্টার্ট অনুমান করে যে আপনি একটি পরিবেশ পরিবর্তনশীল হিসাবে আপনার API কী অ্যাক্সেস করছেন।\n\nএকটি পরিবেশ পরিবর্তনশীল আপনার API কী বরাদ্দ করুন:\n\nexport API_KEY=<YOUR_API_KEY>\n\nSDK ইনস্টল করুন\nপাইথন\nযাওয়া\nNode.js\nওয়েব\nডার্ট (ফ্লটার)\nসুইফট\nঅ্যান্ড্রয়েড\n\nGemini API-এর জন্য Python SDK google-generativeai প্যাকেজে রয়েছে। পিপ ব্যবহার করে নির্ভরতা ইনস্টল করুন:\n\npip install -q -U google-generativeai\n\nজেনারেটিভ মডেল শুরু করুন\nপাইথন\nযাওয়া\nNode.js\nওয়েব\nডার্ট (ফ্লটার)\nসুইফট\nঅ্যান্ড্রয়েড\n\nআপনি যেকোন API কল করার আগে, আপনাকে জেনারেটিভ মডেলটি আমদানি এবং আরম্ভ করতে হবে।\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nপাঠ্য তৈরি করুন\nপাইথন\nযাওয়া\nNode.js\nওয়েব\nডার্ট (ফ্লটার)\nসুইফট\nঅ্যান্ড্রয়েড\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nএরপর কি\n\nGemini API-এর সাথে কাজ করার বিষয়ে আরও জানতে, আপনার পছন্দের ভাষার জন্য টিউটোরিয়ালটি দেখুন।\n\nপাইথন\nযাওয়া\nNode.js\nওয়েব\nডার্ট (ফ্লটার)\nসুইফট\nঅ্যান্ড্রয়েড\nঅ্যান্ড্রয়েড (অন-ডিভাইস)\n\nআপনি Gemini API ব্যবহার করে দেখতে curl কমান্ড ব্যবহার করতে পারেন:\n\nREST API\n\nআপনি যদি জেনারেটিভ AI মডেলগুলিতে নতুন হয়ে থাকেন, তাহলে আপনি দ্রুত স্টার্ট করার আগে ধারণার নির্দেশিকা এবং জেমিনি API ওভারভিউ দেখতে চাইতে পারেন।\n\nএটি কাজে লেগেছে?\nমতামত জানান\n\nঅন্য কিছু উল্লেখ না করা থাকলে, এই পৃষ্ঠার কন্টেন্ট Creative Commons Attribution 4.0 License-এর অধীনে এবং কোডের নমুনাগুলি Apache 2.0 License-এর অধীনে লাইসেন্স প্রাপ্ত। আরও জানতে, Google Developers সাইট নীতি দেখুন। Java হল Oracle এবং/অথবা তার অ্যাফিলিয়েট সংস্থার রেজিস্টার্ড ট্রেডমার্ক।\n\n2024-04-26 UTC-তে শেষবার আপডেট করা হয়েছে।\n\nশর্তাবলী\nগোপনীয়তা",
            "word_count": 508,
            "filtered_content": "পূর্বশর্ত\nজেমিনি API কুইকস্টার্ট \nএই কুইকস্টার্ট আপনাকে দেখায় কিভাবে আপনার পছন্দের SDK ব্যবহার করে Gemini API দিয়ে শুরু করবেন।\nপূর্বশর্ত \nGoogle Colab-এ চালান\nGitHub এ নোটবুক দেখুন\nস্থানীয়ভাবে এই কুইকস্টার্টটি সম্পূর্ণ করতে, নিশ্চিত করুন যে আপনার উন্নয়ন পরিবেশ নিম্নলিখিত প্রয়োজনীয়তাগুলি পূরণ করে:\nনোটবুক চালানোর জন্য jupyter একটি ইনস্টলেশন।\nGemini API ব্যবহার করতে, আপনার একটি API কী প্রয়োজন। আপনার যদি ইতিমধ্যে একটি না থাকে তবে Google AI স্টুডিওতে একটি কী তৈরি করুন৷\nতারপর আপনার কী কনফিগার করুন।\nএটি দৃঢ়ভাবে সুপারিশ করা হয় যে আপনি আপনার সংস্করণ নিয়ন্ত্রণ সিস্টেমে একটি API কী চেক করবেন না ৷ এই কুইকস্টার্ট অনুমান করে যে আপনি একটি পরিবেশ পরিবর্তনশীল হিসাবে আপনার API কী অ্যাক্সেস করছেন।\nএকটি পরিবেশ পরিবর্তনশীল আপনার API কী বরাদ্দ করুন:\nGemini API-এর জন্য Python SDK google-generativeai প্যাকেজে রয়েছে। পিপ ব্যবহার করে নির্ভরতা ইনস্টল করুন:\nআপনি যেকোন API কল করার আগে, আপনাকে জেনারেটিভ মডেলটি আমদানি এবং আরম্ভ করতে হবে।\nGemini API-এর সাথে কাজ করার বিষয়ে আরও জানতে, আপনার পছন্দের ভাষার জন্য টিউটোরিয়ালটি দেখুন।\nঅ্যান্ড্রয়েড (অন-ডিভাইস)\nআপনি Gemini API ব্যবহার করে দেখতে curl কমান্ড ব্যবহার করতে পারেন:\nআপনি যদি জেনারেটিভ AI মডেলগুলিতে নতুন হয়ে থাকেন, তাহলে আপনি দ্রুত স্টার্ট করার আগে ধারণার নির্দেশিকা এবং জেমিনি API ওভারভিউ দেখতে চাইতে পারেন।\n2024-04-26 UTC-তে শেষবার আপডেট করা হয়েছে।",
            "filtered_word_count": 201
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th": {
            "status": "Looks good",
            "content": "ผลิตภัณฑ์\nตัวอย่าง\nลงชื่อเข้าใช้\nเอกสาร\nเอกสารอ้างอิง API\nภาพรวม\nเริ่มต้น\nรับคีย์ API\nการเริ่มต้นใช้งาน Gemini API อย่างรวดเร็ว\nคู่มือเริ่มใช้งาน Google AI Studio อย่างรวดเร็ว\nบทแนะนําสําหรับเริ่มต้นใช้งาน\nรูปแบบ\nเกี่ยวกับโมเดล Generative\nGemini\nGemini API\nภาพรวม API\nเอกสารอ้างอิง API\nเวอร์ชัน API\nบันทึกประจำรุ่น\nความสามารถ\nการปรับแต่งโมเดล\nการเรียกใช้ฟังก์ชัน\nการฝัง\nความปลอดภัย\nคำแนะนำ\nข้อความแจ้ง\nวิธีการสำหรับระบบ\nการดึงข้อมูลความหมาย\nการตรวจสอบสิทธิ์ OAuth\nส่วนขยาย Firebase\nย้ายข้อมูลไปยังระบบคลาวด์\nบทแนะนำ\nการเรียกใช้ฟังก์ชัน\nการฝัง\nแอปพลิเคชัน\nการแก้ปัญหา\nคู่มือการแก้ปัญหา\nเข้าถึง AI Studio โดยใช้ Workspace\nการแก้ปัญหาเกี่ยวกับ AI Studio\nขอเพิ่มโควต้า\nชุมชน\nฟอรัมสนทนา\nPaLM API (เดิม)\nย้ายข้อมูลไปยัง Gemini\nเอกสาร PaLM\nกฎหมาย\nข้อกำหนดในการให้บริการ\n(ตัวอย่าง) ข้อกำหนดในการให้บริการ\nภูมิภาคที่สามารถใช้บริการได้\nในหน้านี้\nข้อกำหนดเบื้องต้น\nตั้งค่าคีย์ API\nติดตั้ง SDK\nเริ่มต้นโมเดล Generative\nสร้างข้อความ\nขั้นตอนถัดไป\nดูตำราอาหาร Gemini API และฟอรัมชุมชนของเรา\n หน้านี้ได้รับการแปลโดย Cloud Translation API\nGoogle AI for Developers\nผลิตภัณฑ์\nข้อมูลนี้มีประโยชน์ไหม\nส่งความคิดเห็น\nการเริ่มต้นใช้งาน Gemini API อย่างรวดเร็ว \nbookmark_border\n\nการเริ่มต้นอย่างรวดเร็วนี้จะแสดงวิธีเริ่มต้นใช้งาน Gemini API โดยใช้ SDK ที่คุณเลือก\n\nข้อกำหนดเบื้องต้น\nPython\nGo\nNode.js\nเว็บไซต์\nลูกดอก (Flutter)\nSwift\nAndroid\nเรียกใช้ใน Google Colab\n\t\nดูสมุดบันทึกใน GitHub\n\nโปรดตรวจสอบว่าสภาพแวดล้อมในการพัฒนาซอฟต์แวร์ของคุณเป็นไปตามข้อกำหนดต่อไปนี้ เพื่อให้การเริ่มต้นอย่างรวดเร็วนี้เสร็จสมบูรณ์ภายในเครื่อง\n\nPython 3.9 ขึ้นไป\nการติดตั้ง jupyter เพื่อเรียกใช้สมุดบันทึก\nตั้งค่าคีย์ API\n\nหากต้องการใช้ Gemini API คุณจะต้องมีคีย์ API หากยังไม่มี ให้ สร้างคีย์ใน Google AI Studio\n\nรับคีย์ API\n\nจากนั้นกำหนดค่าคีย์\n\nPython\nGo\nNode.js\nเว็บไซต์\nลูกดอก (Flutter)\nSwift\nAndroid\n\nขอแนะนำว่าอย่าตรวจสอบคีย์ API ในระบบควบคุมเวอร์ชัน การเริ่มต้นอย่างรวดเร็วนี้จะถือว่าคุณเข้าถึง คีย์ API เป็นตัวแปรสภาพแวดล้อม\n\nกำหนดคีย์ API ให้กับตัวแปรสภาพแวดล้อม\n\nexport API_KEY=<YOUR_API_KEY>\n\nติดตั้ง SDK\nPython\nGo\nNode.js\nเว็บไซต์\nลูกดอก (Flutter)\nSwift\nAndroid\n\nPython SDK สำหรับ Gemini API อยู่ในแพ็กเกจ google-generativeai ติดตั้งทรัพยากร Dependency โดยใช้ PIP:\n\npip install -q -U google-generativeai\n\nเริ่มต้นโมเดล Generative\nPython\nGo\nNode.js\nเว็บไซต์\nลูกดอก (Flutter)\nSwift\nAndroid\n\nคุณต้องนำเข้าและเริ่มต้นโมเดล Generative ก่อนจึงจะทำการเรียก API ได้\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nสร้างข้อความ\nPython\nGo\nNode.js\nเว็บไซต์\nลูกดอก (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nขั้นตอนถัดไป\n\nหากต้องการดูข้อมูลเพิ่มเติมเกี่ยวกับการทำงานกับ Gemini API โปรดดูบทแนะนำสำหรับภาษาที่คุณต้องการ\n\nPython\nGo\nNode.js\nเว็บ\nDart (Flutter)\nสวิฟต์\nAndroid\nAndroid (ในอุปกรณ์)\n\nคุณยังใช้คำสั่ง curl เพื่อลองใช้ Gemini API ได้ด้วย โดยทำดังนี้\n\nAPI ของ REST\n\nหากคุณเพิ่งเคยใช้โมเดล Generative AI ให้อ่านคู่มือแนวคิดและภาพรวมของ Gemini API ก่อนที่จะลองเริ่มใช้งานอย่างรวดเร็ว\n\nข้อมูลนี้มีประโยชน์ไหม\nส่งความคิดเห็น\n\nเนื้อหาของหน้าเว็บนี้ได้รับอนุญาตภายใต้ใบอนุญาตที่ต้องระบุที่มาของครีเอทีฟคอมมอนส์ 4.0 และตัวอย่างโค้ดได้รับอนุญาตภายใต้ใบอนุญาต Apache 2.0 เว้นแต่จะระบุไว้เป็นอย่างอื่น โปรดดูรายละเอียดที่นโยบายเว็บไซต์ Google Developers Java เป็นเครื่องหมายการค้าจดทะเบียนของ Oracle และ/หรือบริษัทในเครือ\n\nอัปเดตล่าสุด 2024-04-26 UTC\n\nข้อกำหนด\nความเป็นส่วนตัว",
            "word_count": 290,
            "filtered_content": "การเริ่มต้นใช้งาน Gemini API อย่างรวดเร็ว \nการเริ่มต้นอย่างรวดเร็วนี้จะแสดงวิธีเริ่มต้นใช้งาน Gemini API โดยใช้ SDK ที่คุณเลือก\nเรียกใช้ใน Google Colab\nดูสมุดบันทึกใน GitHub\nโปรดตรวจสอบว่าสภาพแวดล้อมในการพัฒนาซอฟต์แวร์ของคุณเป็นไปตามข้อกำหนดต่อไปนี้ เพื่อให้การเริ่มต้นอย่างรวดเร็วนี้เสร็จสมบูรณ์ภายในเครื่อง\nPython 3.9 ขึ้นไป\nการติดตั้ง jupyter เพื่อเรียกใช้สมุดบันทึก\nหากต้องการใช้ Gemini API คุณจะต้องมีคีย์ API หากยังไม่มี ให้ สร้างคีย์ใน Google AI Studio\nจากนั้นกำหนดค่าคีย์\nขอแนะนำว่าอย่าตรวจสอบคีย์ API ในระบบควบคุมเวอร์ชัน การเริ่มต้นอย่างรวดเร็วนี้จะถือว่าคุณเข้าถึง คีย์ API เป็นตัวแปรสภาพแวดล้อม\nกำหนดคีย์ API ให้กับตัวแปรสภาพแวดล้อม\nPython SDK สำหรับ Gemini API อยู่ในแพ็กเกจ google-generativeai ติดตั้งทรัพยากร Dependency โดยใช้ PIP:\nคุณต้องนำเข้าและเริ่มต้นโมเดล Generative ก่อนจึงจะทำการเรียก API ได้\nหากต้องการดูข้อมูลเพิ่มเติมเกี่ยวกับการทำงานกับ Gemini API โปรดดูบทแนะนำสำหรับภาษาที่คุณต้องการ\nเว็บ\nสวิฟต์\nAndroid (ในอุปกรณ์)\nคุณยังใช้คำสั่ง curl เพื่อลองใช้ Gemini API ได้ด้วย โดยทำดังนี้\nAPI ของ REST\nหากคุณเพิ่งเคยใช้โมเดล Generative AI ให้อ่านคู่มือแนวคิดและภาพรวมของ Gemini API ก่อนที่จะลองเริ่มใช้งานอย่างรวดเร็ว\nอัปเดตล่าสุด 2024-04-26 UTC",
            "filtered_word_count": 89
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn": {
            "status": "Looks good",
            "content": "产品\n示例\n登录\n文档\nAPI 参考文档\n概览\n开始使用\n获取 API 密钥\nGemini API 快速入门\nGoogle AI Studio 快速入门\n入门教程\n模型\n生成模型简介\nGemini\nGemini API\nAPI 概览\nAPI 参考\nAPI 版本\n版本说明\n功能\n模型调整\n函数调用\nEmbeddings\n安全\n指南\n提示\n系统说明\n语义检索\nOAuth 身份验证\nFirebase Extensions\n迁移到云端\n教程\n函数调用\nEmbeddings\n应用\n问题排查\n问题排查指南\n使用 Workspace 访问 AI Studio\n排查 AI Studio 问题\n申请增加配额\n社区\n对话论坛\nPaLM API（旧版）\n迁移到 Gemini\nPaLM 文档\n法律\n服务条款\n（预览版）服务条款\n可用区域\n本页内容\n前提条件\n设置您的 API 密钥\n安装 SDK\n初始化生成模型\n生成文本\n后续步骤\n查看全新 Gemini API 实战宝典和我们的社区论坛。\n 此页面由 Cloud Translation API 翻译。\nGoogle AI for Developers\n产品\n该内容对您有帮助吗？\n发送反馈\nGemini API 快速入门 \nbookmark_border\n\n本快速入门介绍了如何通过您选择的 SDK 开始使用 Gemini API。\n\n前提条件\nPython\nGo\nNode.js\n网站\nDart (Flutter)\nSwift\nAndroid\n在 Google Colab 中运行\n\t\n在 GitHub 上查看笔记本\n\n如需在本地完成本快速入门，请确保您的开发环境满足以下要求：\n\nPython 3.9 及更高版本\n安装了 jupyter，用于运行笔记本。\n设置您的 API 密钥\n\n您需要 API 密钥才能使用 Gemini API。如果您还没有密钥，请在 Google AI Studio 中创建密钥。\n\n获取 API 密钥\n\n然后配置密钥。\n\nPython\nGo\nNode.js\n网站\nDart (Flutter)\nSwift\nAndroid\n\n强烈建议您不要将 API 密钥签入版本控制系统。本快速入门假定您以环境变量的形式访问 API 密钥。\n\n将您的 API 密钥分配给环境变量：\n\nexport API_KEY=<YOUR_API_KEY>\n\n安装 SDK\nPython\nGo\nNode.js\n网站\nDart (Flutter)\nSwift\nAndroid\n\n适用于 Gemini API 的 Python SDK 包含在 google-generativeai 软件包中。使用 pip 安装依赖项：\n\npip install -q -U google-generativeai\n\n初始化生成模型\nPython\nGo\nNode.js\n网站\nDart (Flutter)\nSwift\nAndroid\n\n您需要先导入并初始化生成模型，然后才能进行任何 API 调用。\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\n生成文本\nPython\nGo\nNode.js\n网站\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\n后续步骤\n\n如需详细了解如何使用 Gemini API，请参阅与您所选语言对应的教程。\n\nPython\nGo\nNode.js\n网站\nDart (Flutter)\nSwift\nAndroid\nAndroid（设备端）\n\n您还可以使用 curl 命令来试用 Gemini API：\n\nREST API\n\n如果您刚开始接触生成式 AI 模型，不妨先查看概念指南和 Gemini API 概览，然后再尝试快速入门。\n\n该内容对您有帮助吗？\n发送反馈\n\n如未另行说明，那么本页面中的内容已根据知识共享署名 4.0 许可获得了许可，并且代码示例已根据 Apache 2.0 许可获得了许可。有关详情，请参阅 Google 开发者网站政策。Java 是 Oracle 和/或其关联公司的注册商标。\n\n最后更新时间 (UTC)：2024-04-26。\n\n条款\n隐私权政策",
            "word_count": 272,
            "filtered_content": "Gemini API 快速入门 \n本快速入门介绍了如何通过您选择的 SDK 开始使用 Gemini API。\n在 Google Colab 中运行\n在 GitHub 上查看笔记本\n如需在本地完成本快速入门，请确保您的开发环境满足以下要求：\nPython 3.9 及更高版本\n安装了 jupyter，用于运行笔记本。\n您需要 API 密钥才能使用 Gemini API。如果您还没有密钥，请在 Google AI Studio 中创建密钥。\n然后配置密钥。\n强烈建议您不要将 API 密钥签入版本控制系统。本快速入门假定您以环境变量的形式访问 API 密钥。\n将您的 API 密钥分配给环境变量：\n适用于 Gemini API 的 Python SDK 包含在 google-generativeai 软件包中。使用 pip 安装依赖项：\n您需要先导入并初始化生成模型，然后才能进行任何 API 调用。\n如需详细了解如何使用 Gemini API，请参阅与您所选语言对应的教程。\nAndroid（设备端）\n您还可以使用 curl 命令来试用 Gemini API：\n如果您刚开始接触生成式 AI 模型，不妨先查看概念指南和 Gemini API 概览，然后再尝试快速入门。\n最后更新时间 (UTC)：2024-04-26。",
            "filtered_word_count": 70
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw": {
            "status": "Looks good",
            "content": "產品\n範例\n登入\n文件\nAPI 參考資料\n總覽\n開始轉接\n取得 API 金鑰\nGemini API 快速入門導覽課程\nGoogle AI Studio 快速入門導覽課程\n入門教學課程\n模型\n關於生成式模型\nGemini\nGemini API\nAPI 總覽\nAPI 參考資料\nAPI 版本\n版本資訊\n功能\n模型調整\n函式呼叫\n嵌入\n安全分\n指南\n提示\n系統操作說明\n語意擷取\nOAuth 驗證\nFirebase 擴充功能\n遷移至 Cloud\n教學課程\n函式呼叫\n嵌入\n應用程式\n疑難排解\n疑難排解指南\n使用 Workspace 存取 AI Studio\nAI Studio 疑難排解\n要求提高配額\n社群\n討論論壇\nPaLM API (舊版)\n遷移至 Gemini\nPaLM 文件\nLegal\n服務條款\n(預先發布版) 服務條款\n可用地區\n這個頁面中的內容\n必要條件\n設定 API 金鑰\n安裝 SDK\n初始化生成式模型\n生成文字\n後續步驟\n有興趣看看全新的 Gemini API 教戰手冊和我們的社群論壇。\n 本頁面由 Cloud Translation API 翻譯而成。\nGoogle AI for Developers\n產品\n這對你有幫助嗎？\n提供意見\nGemini API 快速入門導覽課程 \nbookmark_border\n\n本快速入門導覽課程說明如何透過您選擇的 SDK 開始使用 Gemini API。\n\n必要條件\nPython\n查看\nNode.js\nWeb\n飛鏢 (Flutter)\nSwift\nAndroid\n在 Google Colab 中執行\n\t\n前往 GitHub 查看筆記本\n\n如要在本機完成本快速入門導覽課程，請確保您的開發環境符合下列需求：\n\nPython 3.9 以上版本\n安裝 jupyter 以執行筆記本。\n設定 API 金鑰\n\n如要使用 Gemini API，您必須具備 API 金鑰。如果您還沒有金鑰 請在 Google AI Studio 中建立金鑰\n\n取得 API 金鑰\n\n然後設定金鑰。\n\nPython\n查看\nNode.js\nWeb\n飛鏢 (Flutter)\nSwift\nAndroid\n\n強烈建議您「不要」將 API 金鑰登錄到版本管控系統。本快速入門導覽課程假設您存取 API 金鑰做為環境變數。\n\n將 API 金鑰指派給環境變數：\n\nexport API_KEY=<YOUR_API_KEY>\n\n安裝 SDK\nPython\n查看\nNode.js\nWeb\n飛鏢 (Flutter)\nSwift\nAndroid\n\nGemini API 的 Python SDK 已納入 google-generativeai 套件中。使用 pip 安裝依附元件：\n\npip install -q -U google-generativeai\n\n初始化生成式模型\nPython\n查看\nNode.js\nWeb\n飛鏢 (Flutter)\nSwift\nAndroid\n\n您必須先匯入並初始化生成式模型，才能進行任何 API 呼叫。\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\n生成文字\nPython\n查看\nNode.js\nWeb\n飛鏢 (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\n後續步驟\n\n如要進一步瞭解如何使用 Gemini API，請參閱您選擇的語言的教學課程。\n\nPython\nGo\nNode.js\n網頁\n飛鏢 (Flutter)\nSwift\nAndroid\nAndroid (裝置端)\n\n您也可以使用 curl 指令來試用 Gemini API：\n\nREST API\n\n如果您是第一次使用生成式 AI 模型，建議您先參閱概念指南和 Gemini API 總覽，然後再嘗試進行快速入門導覽課程。\n\n這對你有幫助嗎？\n提供意見\n\n除非另有註明，否則本頁面中的內容是採用創用 CC 姓名標示 4.0 授權，程式碼範例則為阿帕契 2.0 授權。詳情請參閱《Google Developers 網站政策》。Java 是 Oracle 和/或其關聯企業的註冊商標。\n\n上次更新時間：2024-04-26 (世界標準時間)。\n\n條款\n隱私權",
            "word_count": 277,
            "filtered_content": "Gemini API 快速入門導覽課程 \n本快速入門導覽課程說明如何透過您選擇的 SDK 開始使用 Gemini API。\n在 Google Colab 中執行\n前往 GitHub 查看筆記本\n如要在本機完成本快速入門導覽課程，請確保您的開發環境符合下列需求：\nPython 3.9 以上版本\n安裝 jupyter 以執行筆記本。\n如要使用 Gemini API，您必須具備 API 金鑰。如果您還沒有金鑰 請在 Google AI Studio 中建立金鑰\n然後設定金鑰。\n強烈建議您「不要」將 API 金鑰登錄到版本管控系統。本快速入門導覽課程假設您存取 API 金鑰做為環境變數。\n將 API 金鑰指派給環境變數：\nGemini API 的 Python SDK 已納入 google-generativeai 套件中。使用 pip 安裝依附元件：\n您必須先匯入並初始化生成式模型，才能進行任何 API 呼叫。\n如要進一步瞭解如何使用 Gemini API，請參閱您選擇的語言的教學課程。\n網頁\nAndroid (裝置端)\n您也可以使用 curl 指令來試用 Gemini API：\n如果您是第一次使用生成式 AI 模型，建議您先參閱概念指南和 Gemini API 總覽，然後再嘗試進行快速入門導覽課程。\n上次更新時間：2024-04-26 (世界標準時間)。",
            "filtered_word_count": 73
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja": {
            "status": "Looks good",
            "content": "プロダクト\n例\nログイン\nドキュメント\nAPI リファレンス\n概要\n使ってみる\nAPI キーを取得する\nGemini API クイックスタート\nGoogle AI Studio のクイックスタート\nスタートガイドのチュートリアル\nモデル\n生成モデルについて\nGemini\nGemini API\nAPI の概要\nAPI リファレンス\nAPI バージョン\nリリースノート\n機能\nモデルのチューニング\n関数呼び出し\nEmbeddings\n安全性\nガイド\nプロンプト\nシステムの説明\nセマンティック取得\nOAuth 認証\nFirebase Extensions\nクラウドに移行する\nチュートリアル\n関数呼び出し\nEmbeddings\nアプリケーション\nトラブルシューティング\nトラブルシューティング ガイド\nWorkspace を使用して AI Studio にアクセスする\nAI Studio のトラブルシューティング\n割り当ての増加をリクエストする\nコミュニティ\n対話フォーラム\nPaLM API（レガシー）\ngen に移行する\nPaLM ドキュメント\n法務\n利用規約\n（プレビュー）利用規約\n利用可能なリージョン\nこのページの内容\n前提条件\nAPI キーを設定する\nSDK をインストールする\n生成モデルを初期化する\nテキストを生成\n次のステップ\n新しい Gemini API クックブックとコミュニティ フォーラムをご覧ください。\n このページは Cloud Translation API によって翻訳されました。\nGoogle AI for Developers\nプロダクト\nこの情報は役に立ちましたか？\nフィードバックを送信\nGemini API クイックスタート \nbookmark_border\n\nこのクイックスタートでは、任意の SDK を使用して Gemini API の使用を開始する方法を説明します。\n\n前提条件\nPython\nGo\nNode.js\nウェブ\nDart（Flutter）\nSwift\nAndroid\nGoogle Colab で実行\n\t\nGitHub のノートブックを表示\n\nこのクイックスタートをローカルで完了するには、開発環境が次の要件を満たしていることを確認してください。\n\nPython 3.9 以降\nノートブックを実行するための jupyter のインストール。\nAPI キーを設定する\n\nGemini API を使用するには、API キーが必要です。まだ作成していない場合は、Google AI Studio でキーを作成します。\n\nAPI キーを取得する\n\n次に、鍵を構成します。\n\nPython\nGo\nNode.js\nウェブ\nDart（Flutter）\nSwift\nAndroid\n\nAPI キーはバージョン管理システムにチェックインしないことを強くおすすめします。このクイックスタートでは、環境変数として API キーにアクセスすることを前提としています。\n\nAPI キーを環境変数に割り当てます。\n\nexport API_KEY=<YOUR_API_KEY>\n\nSDK をインストールする\nPython\nGo\nNode.js\nウェブ\nDart（Flutter）\nSwift\nAndroid\n\nGemini API 用の Python SDK は、google-generativeai パッケージに含まれています。pip を使用して依存関係をインストールします。\n\npip install -q -U google-generativeai\n\n生成モデルを初期化する\nPython\nGo\nNode.js\nウェブ\nDart（Flutter）\nSwift\nAndroid\n\nAPI 呼び出しを行うには、生成モデルをインポートして初期化しておく必要があります。\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nテキストを生成\nPython\nGo\nNode.js\nウェブ\nDart（Flutter）\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\n次のステップ\n\nGemini API の操作について詳しくは、ご使用の言語のチュートリアルをご覧ください。\n\nPython\nGo\nNode.js\nウェブ\nDart（Flutter）\nSwift\nAndroid\nAndroid（オンデバイス）\n\ncurl コマンドを使用して Gemini API を試すこともできます。\n\nREST API\n\n生成 AI モデルを初めて使用する場合は、クイックスタートを試す前にコンセプト ガイドと Gemini API の概要をご覧ください。\n\nこの情報は役に立ちましたか？\nフィードバックを送信\n\n特に記載のない限り、このページのコンテンツはクリエイティブ・コモンズの表示 4.0 ライセンスにより使用許諾されます。コードサンプルは Apache 2.0 ライセンスにより使用許諾されます。詳しくは、Google Developers サイトのポリシーをご覧ください。Java は Oracle および関連会社の登録商標です。\n\n最終更新日 2024-04-26 UTC。\n\n利用規約\nプライバシー",
            "word_count": 257,
            "filtered_content": "Gemini API クイックスタート \nこのクイックスタートでは、任意の SDK を使用して Gemini API の使用を開始する方法を説明します。\nGoogle Colab で実行\nGitHub のノートブックを表示\nこのクイックスタートをローカルで完了するには、開発環境が次の要件を満たしていることを確認してください。\nPython 3.9 以降\nノートブックを実行するための jupyter のインストール。\nGemini API を使用するには、API キーが必要です。まだ作成していない場合は、Google AI Studio でキーを作成します。\n次に、鍵を構成します。\nAPI キーはバージョン管理システムにチェックインしないことを強くおすすめします。このクイックスタートでは、環境変数として API キーにアクセスすることを前提としています。\nAPI キーを環境変数に割り当てます。\nGemini API 用の Python SDK は、google-generativeai パッケージに含まれています。pip を使用して依存関係をインストールします。\nAPI 呼び出しを行うには、生成モデルをインポートして初期化しておく必要があります。\nGemini API の操作について詳しくは、ご使用の言語のチュートリアルをご覧ください。\nAndroid（オンデバイス）\ncurl コマンドを使用して Gemini API を試すこともできます。\n生成 AI モデルを初めて使用する場合は、クイックスタートを試す前にコンセプト ガイドと Gemini API の概要をご覧ください。\n最終更新日 2024-04-26 UTC。",
            "filtered_word_count": 64
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko": {
            "status": "Looks good",
            "content": "제품\n예\n로그인\nDocs\nAPI 참조\n개요\n시작하기\nAPI 키 가져오기\nGemini API 빠른 시작\nGoogle AI 스튜디오 빠른 시작\n시작 가이드\n모델\n생성 모델 정보\nGemini\nGemini API\nAPI 개요\nAPI 참조 문서\nAPI 버전\n출시 노트\n기능\n모델 조정\n함수 호출\n임베딩\n안전\n가이드\n메시지 표시\n시스템 안내\n시맨틱 검색\nOAuth 인증\nFirebase Extensions\n클라우드로 마이그레이션\n튜토리얼\n함수 호출\n임베딩\n애플리케이션\n문제해결\n문제 해결 가이드\nWorkspace를 사용하여 AI Studio에 액세스\nAI Studio 문제 해결\n할당량 추가 요청\n커뮤니티\n담화 포럼\nPaLM API (기존)\nGemini로 이전\nPaLM 문서\n법률\n서비스 약관\n(미리보기) 서비스 약관\n사용 가능한 리전\n이 페이지의 내용\n기본 요건\nAPI 키 설정\nSDK 설치\n생성 모델 초기화\n텍스트 생성\n다음 단계\n새로운 Gemini API 설명서와 커뮤니티 포럼을 확인하세요.\n 이 페이지는 Cloud Translation API를 통해 번역되었습니다.\nGoogle AI for Developers\n제품\n도움이 되었나요?\n의견 보내기\nGemini API 빠른 시작 \nbookmark_border\n\n이 빠른 시작에서는 원하는 SDK를 사용하여 Gemini API를 시작하는 방법을 보여줍니다.\n\n기본 요건\nPython\nGo\nNode.js\n웹\nDart (Flutter)\nSwift\nAndroid\nGoogle Colab에서 실행\n\t\nGitHub에서 노트북 보기\n\n이 빠른 시작을 로컬에서 완료하려면 개발 환경이 다음 요구사항을 충족하는지 확인하세요.\n\nPython 3.9 이상\n노트북을 실행할 jupyter 설치\nAPI 키 설정\n\nGemini API를 사용하려면 API 키가 필요합니다. 아직 키가 없으면 Google AI Studio에서 키를 만듭니다\n\nAPI 키 가져오기\n\n그런 다음 키를 구성합니다.\n\nPython\nGo\nNode.js\n웹\nDart (Flutter)\nSwift\nAndroid\n\n버전 제어 시스템에 API 키를 체크인하지 않는 것이 좋습니다. 이 빠른 시작에서는 API 키에 환경 변수로 액세스한다고 가정합니다.\n\nAPI 키를 환경 변수에 할당합니다.\n\nexport API_KEY=<YOUR_API_KEY>\n\nSDK 설치\nPython\nGo\nNode.js\n웹\nDart (Flutter)\nSwift\nAndroid\n\nGemini API용 Python SDK는 google-generativeai 패키지에 포함되어 있습니다. pip를 사용하여 종속 항목을 설치합니다.\n\npip install -q -U google-generativeai\n\n생성 모델 초기화\nPython\nGo\nNode.js\n웹\nDart (Flutter)\nSwift\nAndroid\n\nAPI를 호출하려면 먼저 생성 모델을 가져오고 초기화해야 합니다.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\n텍스트 생성\nPython\nGo\nNode.js\n웹\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\n다음 단계\n\nGemini API 작업에 관한 자세한 내용은 선택한 언어의 가이드를 참고하세요.\n\nPython\nGo\nNode.js\n웹\nDart (Flutter)\nSwift\nAndroid\nAndroid (온디바이스)\n\ncurl 명령어를 사용하여 Gemini API를 사용해 볼 수도 있습니다.\n\nREST API\n\n생성형 AI 모델을 처음 사용하는 경우 빠른 시작을 사용해 보기 전에 개념 가이드 및 Gemini API 개요를 살펴보는 것이 좋습니다.\n\n도움이 되었나요?\n의견 보내기\n\n달리 명시되지 않는 한 이 페이지의 콘텐츠에는 Creative Commons Attribution 4.0 라이선스에 따라 라이선스가 부여되며, 코드 샘플에는 Apache 2.0 라이선스에 따라 라이선스가 부여됩니다. 자세한 내용은 Google Developers 사이트 정책을 참조하세요. 자바는 Oracle 및/또는 Oracle 계열사의 등록 상표입니다.\n\n최종 업데이트: 2024-04-26(UTC)\n\n약관\n개인정보처리방침",
            "word_count": 419,
            "filtered_content": "Gemini API 빠른 시작 \n이 빠른 시작에서는 원하는 SDK를 사용하여 Gemini API를 시작하는 방법을 보여줍니다.\nGoogle Colab에서 실행\nGitHub에서 노트북 보기\n이 빠른 시작을 로컬에서 완료하려면 개발 환경이 다음 요구사항을 충족하는지 확인하세요.\nPython 3.9 이상\n노트북을 실행할 jupyter 설치\nGemini API를 사용하려면 API 키가 필요합니다. 아직 키가 없으면 Google AI Studio에서 키를 만듭니다\n그런 다음 키를 구성합니다.\n버전 제어 시스템에 API 키를 체크인하지 않는 것이 좋습니다. 이 빠른 시작에서는 API 키에 환경 변수로 액세스한다고 가정합니다.\nAPI 키를 환경 변수에 할당합니다.\nGemini API용 Python SDK는 google-generativeai 패키지에 포함되어 있습니다. pip를 사용하여 종속 항목을 설치합니다.\nAPI를 호출하려면 먼저 생성 모델을 가져오고 초기화해야 합니다.\nGemini API 작업에 관한 자세한 내용은 선택한 언어의 가이드를 참고하세요.\nAndroid (온디바이스)\ncurl 명령어를 사용하여 Gemini API를 사용해 볼 수도 있습니다.\n생성형 AI 모델을 처음 사용하는 경우 빠른 시작을 사용해 보기 전에 개념 가이드 및 Gemini API 개요를 살펴보는 것이 좋습니다.\n최종 업데이트: 2024-04-26(UTC)",
            "filtered_word_count": 145
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#prerequisites": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy",
            "word_count": 501,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#set-up-api-key": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded.",
            "word_count": 506,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#install-sdk": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded..",
            "word_count": 506,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#initialize-generative": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded.",
            "word_count": 506,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#generate-text": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded..",
            "word_count": 506,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#what's-next": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded.",
            "word_count": 506,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#python": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nRun in Google Colab\n\t\nView notebook on GitHub\n\nTo complete this quickstart locally, ensure that your development environment meets the following requirements:\n\nPython 3.9+\nAn installation of jupyter to run the notebook.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded..",
            "word_count": 506,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#go": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThis quickstart assumes that you're familiar with building applications with Go.\n\nTo complete this quickstart, make sure that your development environment meets the following requirements:\n\nGo 1.20+\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded.",
            "word_count": 501,
            "filtered_content": "This quickstart assumes that you're familiar with building applications with Go.\nTo complete this quickstart, make sure that your development environment meets the following requirements:",
            "filtered_word_count": 25
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#node.js": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThis quickstart assumes that you're familiar with building applications with Node.js.\n\nTo complete this quickstart, make sure that your development environment meets the following requirements:\n\nNode.js v18+\nnpm\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded..",
            "word_count": 502,
            "filtered_content": "This quickstart assumes that you're familiar with building applications with Node.js.",
            "filtered_word_count": 11
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#web": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThis quickstart assumes that you're familiar with using JavaScript to develop web apps. This guide is framework-independent.\n\nTo complete this quickstart, make sure that your development environment meets the following requirements:\n\n(Optional) Node.js\nModern web browser\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded.",
            "word_count": 510,
            "filtered_content": "This quickstart assumes that you're familiar with using JavaScript to develop web apps. This guide is framework-independent.",
            "filtered_word_count": 17
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#dart-flutter": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThis quickstart assumes you're familiar with building applications with Dart.\n\nTo complete this quickstart, make sure that your development environment meets the following requirements:\n\nDart 3.2.0+\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded..",
            "word_count": 500,
            "filtered_content": "This quickstart assumes you're familiar with building applications with Dart.",
            "filtered_word_count": 10
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#swift": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThis quickstart assumes that you're familiar with using Xcode to develop Swift apps.\n\nTo complete this quickstart, make sure that your development environment and Swift app meet the following requirements:\n\nXcode 15.0 or higher\nYour Swift app must target iOS 15 or higher, or macOS 12 or higher.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded.",
            "word_count": 522,
            "filtered_content": "This quickstart assumes that you're familiar with using Xcode to develop Swift apps.\nTo complete this quickstart, make sure that your development environment and Swift app meet the following requirements:",
            "filtered_word_count": 30
        },
        "https://ai.google.dev/gemini-api/docs/quickstart#android": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrerequisites\nSet up your API key\nInstall the SDK\nInitialize the generative model\nGenerate text\nWhat's next\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGemini API quickstart \nbookmark_border\n\nThis quickstart shows you how to get started with the Gemini API using the SDK of your choice.\n\nPrerequisites\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThis quickstart assumes that you're familiar with using Android Studio to develop Android apps.\n\nTo complete this quickstart, make sure that your development environment and Android app meet the following requirements:\n\nAndroid Studio (latest version)\nYour Android app must target API level 21 or higher.\nSet up your API key\n\nTo use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n\nGet an API key\n\nThen configure your key.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nIt's strongly recommended that you do not check an API key into your version control system. This quickstart assumes that you're accessing your API key as an environment variable.\n\nAssign your API key to an environment variable:\n\nexport API_KEY=<YOUR_API_KEY>\n\nInstall the SDK\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nThe Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using pip:\n\npip install -q -U google-generativeai\n\nInitialize the generative model\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\n\nBefore you can make any API calls, you need to import and initialize the generative model.\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-pro')\n\nGenerate text\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\nprint(response.text)\n\nWhat's next\n\nTo learn more about working with the Gemini API, see the tutorial for your language of choice.\n\nPython\nGo\nNode.js\nWeb\nDart (Flutter)\nSwift\nAndroid\nAndroid (on-device)\n\nYou can also use curl commands to try out the Gemini API:\n\nREST API\n\nIf you're new to generative AI models, you might want to look at the concepts guide and the Gemini API overview before trying a quickstart.\n\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-26 UTC.\n\nTerms\nPrivacy\nThe new page has loaded..",
            "word_count": 519,
            "filtered_content": "This quickstart assumes that you're familiar with using Android Studio to develop Android apps.\nTo complete this quickstart, make sure that your development environment and Android app meet the following requirements:",
            "filtered_word_count": 31
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#": {
            "status": "Looks good",
            "content": "Products\nExamples\nSign in\nDocs\nAPI Reference\nOverview\nGet started\nGet an API key\nGemini API quickstart\nGoogle AI Studio quickstart\nGetting started tutorials\nModels\nAbout generative models\nGemini\nGemini API\nAPI overview\nAPI reference\nAPI versions\nRelease notes\nCapabilities\nModel tuning\nFunction calling\nEmbeddings\nSafety\nGuides\nPrompting\nSystem instructions\nSemantic retrieval\nOAuth authentication\nFirebase extensions\nMigrate to Cloud\nTutorials\nFunction calling\nEmbeddings\nApplications\nTroubleshooting\nTroubleshooting guide\nAccess AI Studio using Workspace\nTroubleshooting AI Studio\nRequest more quota\nCommunity\nDiscourse forum\nPaLM API (legacy)\nMigrate to Gemini\nPaLM docs\nLegal\nTerms of service\n(Preview) Terms of service\nAvailable regions\nOn this page\nPrompts and model tuning\nFreeform prompt example: Learn more about a building\nStep 1 - Create a prompt with text and images\nStep 2 - Add a replaceable variable to the prompt\nStep 3 - Experiment with model parameters\nStep 4 - Next steps\nStructured prompt example: Build a product copy generator\nStep 1 - Create a structured prompt\nStep 2 - Add examples\nStep 3 - Test your prompt\nStep 4 - Next steps\nChat prompt example: Build a custom chat application\nStep 1 - Create a chat prompt\nStep 2 - Teach your bot to chat better\nStep 3 - Experiment with model parameters\nStep 4 - Next steps\nFurther reading\nCheck out the new Gemini API Cookbook and our community forum.\nGoogle AI for Developers\nProducts\nWas this helpful?\nSend feedback\nGoogle AI Studio quickstart \nbookmark_border\n\nGoogle AI Studio is a browser-based IDE for prototyping with generative models. Google AI Studio lets you quickly try out models and experiment with different prompts. When you've built something you're happy with, you can export it to code in your preferred programming language, powered by the Gemini API.\n\nPrompts and model tuning\n\nGoogle AI Studio provides several interfaces for prompts that are designed for different use cases:\n\nFreeform prompts - These prompts offer an open-ended prompting experience for generating content and responses to instructions. You can use both images and text data for your prompts. Learn more\n\nStructured prompts - This prompting technique lets you guide model output by providing a set of example requests and replies. Use this approach when you need more control over the structure of model output. Learn more\n\nChat prompts - Use chat prompts to build conversational experiences. This prompting technique allows for multiple input and response turns to generate output. Learn more\n\nGoogle AI Studio also lets you to change the behavior of a model, using a technique called tuning:\n\nTuned model - Use this advanced technique to improve a model's responses for a specific task by providing more examples. Learn more\nFreeform prompt example: Learn more about a building\n\nGemini's multimodal abilities let you prompt the model with a combination of imagery and text. For example, you can use this feature to learn more about a building shown in an image.\n\nStep 1 - Create a prompt with text and images\n\nTo create a multimodal prompt:\n\nNavigate to Google AI Studio.\nIn the left panel, select Create new > Freeform prompt.\nIn the right column Model field, select a model that supports images, such as the Gemini Pro Vision model.\n\nIn the prompt text area, enter the following text:\n\nlook at the following picture and tell me who is the architect\n\n\nFrom the Insert bar above the prompt area, select Image, and choose one of the sample images of a building.\n\nAt the bottom of the app window, select Run to generate a reply for this request.\n\nStep 2 - Add a replaceable variable to the prompt\n\nIn step 1, you prompted the model with a fixed string of text and an image. But sometimes, you want to be able to dynamically change parts of a prompt. For example, if you're building an interactive application, you may want to modify your prompt with different user inputs. For this, you can parameterize your prompts using variables.\n\nTo add variables to your prompts:\n\nSelect the word or phrase you want to replace in your prompt. In this case, select the text: who is the architect.\nFrom the Insert: header above the prompt, select {{ }} Test input.\nIn the Test your prompt table below the prompt, add an additional value for your prompt by selecting Add test example and entering an additional prompt value. Feel free to add several new input values.\nAt the bottom of the app window, select Run to generate a reply for each of the varying requests.\nStep 3 - Experiment with model parameters\n\nAs you're prototyping your prompt, you can also play around with model run settings on the right side of the application. These are key settings to know about:\n\nModel - Select what model you want to respond to your prompts. For more information about the available models and capabilities, see Models.\nTemperature - Control how much randomness is allowed in the model's responses. Raising this value allows the model to produce more unexpected and creative responses.\nMax outputs - Increase the number of responses the model returns for each request. This option can be helpful for quickly testing prompts by generating multiple responses for a single prompt.\nSafety settings - Adjust safety settings for managing model responses. For more details about these controls, see the Safety settings.\nStep 4 - Next steps\n\nNow that you've prototyped a generative AI application, you can save your work or generate code to use this prompt in your own development environment.\n\nTo save the prompt you created:\n\nIn the top right corner of the Google AI Studio app, select Save.\nConnect the app to your Google Drive account, if you have not already done so.\nIn the Save Prompt dialog, enter a Prompt name, an optional Description, and then select Save.\n\nTo export the prompt you created as code:\n\nIn the top right corner of the Google AI Studio app, select Get code.\nSelect a programming language tab.\nSelect Copy to copy the code to your clipboard.\nNote: You need an API key to run the prompt code outside of Google AI Studio, so make sure to create a key and include it with your prompt code.\nCaution: Treat your API key like a password and protect it appropriately. Don't embed your key in publicly published code.\nStructured prompt example: Build a product copy generator\n\nSo far, you've seen how you can prompt your model with an instruction (look at the following picture and tell me who is the architect). Sometimes, however, you can get better results by prompting the model with a combination of instructions and examples. Structured prompts in Google AI Studio help you do just that–combine instructions with examples to show the model the kind of output you want, rather than just telling it what to do. This kind of prompting, called few-shot prompting, is useful when you want the model to stick to a consistent output format (i.e. structured json) or when it's difficult to describe in words what you want the model to do (i.e. write in a particular style). In this section, you'll see how to create structured prompts in Google AI Studio.\n\nNote: You can try this example out directly in Google AI Studio from the examples gallery.\nStep 1 - Create a structured prompt\n\nIn this example, you'll create a structured prompt that generates advertising copy for products. To start, you’ll define the structure for the prompt by creating two columns: a Product input column and a Product copy output column.\n\nTo create the structured prompt:\n\nIn the top left of the Google AI Studio web app, select Create new > Structured prompt.\n\nBelow the Insert: header, add the instructions for the structured prompt:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nAdd a descriptive header for the INPUT by replacing the default input: text description with Product:.\n\nAdd a descriptive header for the OUTPUT by replacing the default output: text description with Product copy:.\n\nTip: Add colons to the end of column names to make it easier for the model to parse the structure.\nStep 2 - Add examples\n\nNow that you've named your columns, provide some example rows. These rows should contain example inputs (product names for this example) and example outputs (corresponding product descriptions). By providing the model a couple of example product descriptions, you can guide it to replicate a similar style when generating its own outputs. You can enter examples manually or import from a file using the import data menu.\n\nTo manually enter examples:\n\nIn the top examples data table, select the field below the Product: header and type a product description.\n\nSelect the field below the Product copy: header and type marketing copy for this product.\n\nHere's an example of input and output values for this prompt:\n\nProduct:\tProduct copy:\nOld-school sneaker\tLet's lace up! These kicks bring an iconic look and a one of a kind color palette, while supporting you in style and function like no other shoe before.\nSupersoft hoodie\tStay cozy and stylish in our new unisex hoodie! Made from 100% cotton, this hoodie is soft and comfortable to wear all day long. The semi-brushed inside will keep you warm on even the coldest days.\n\nTip: If you're having writers block or don't have example product copy examples on hand, you can use the Freeform prompt to have the text model generate some for you.\n\nTo import examples from a file:\n\nIn the top, right corner of examples table, select Actions > Import examples.\n\nIn the dialog, select a CSV or Google Sheets file in your Google Drive, or upload from your computer.\n\nIn the import examples dialog, choose which columns to import and which to leave out. The dialog also lets you specify which data column imports to which table column in your structured prompt.\n\nStep 3 - Test your prompt\n\nOnce you have the examples that show the model what you want, test your prompt with new input in the Test your prompt table at the bottom. As with the text prompt type, you can adjust model parameters to test if they help produce better results for your use case.\n\nReview how examples are sent to the model\n\nUnder the hood, Google AI Studio constructs a prompt by combining the instructions with the examples you provide. As you add more examples, these get added to the text sent to the model. Depending on how long your examples are, you may start hitting the model's token limit. All generative AI models have a token limit, which is the maximum length of the text they can accept as input.\n\nTo see the complete content of your prompt:\n\nSelect the Text preview at the bottom of the Google AI Studio web app.\nNote: The model token limit is displayed at the bottom of the preview pane.\nStep 4 - Next steps\n\nOnce you're happy with your prompt, you can Save it or export it to code by clicking the Get Code button.\n\nYou can also export the individual few-shot examples to a CSV file or Google Sheet. Choose the Export examples option under the Action menu to export your examples.\n\nChat prompt example: Build a custom chat application\n\nIf you've used a general-purpose chatbot like Gemini , you've experienced first-hand how powerful generative AI models can be for open-ended dialog. While these general-purpose chatbots are useful, often they need to be tailored for particular use cases. For example, maybe you want to build a customer service chatbot that only supports conversations that talk about a company's product. You might want to build a chatbot that speaks with a particular tone or style: a bot that cracks lots of jokes, rhymes like a poet, or uses lots of emojis in its answers.\n\nThis example shows you how to use Google AI Studio to build a friendly chatbot that communicates as if it is an alien living on one of Jupiter's moons, Europa.\n\nStep 1 - Create a chat prompt\n\nIn the last section, you designed a structured prompt using a combination of input and output examples. Similarly, to build a chatbot, you need to provide examples of interactions between a user and the chatbot to guide the model to provide the responses you're looking for.\n\nTo create a chat prompt:\n\nIn the top left of the Google AI Studio web app, select Create new > Chat prompt.\n\nIn the Write your prompt examples column of the prompt interface, you can start providing examples of interactions. You can also provide additional context in the first example such as:\n\nUser: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModel: none Ok\n\nIn the User and the Model fields provide an example of what interactions between a user and your chatbot might look like:\n\nUser: none Hi!\n\nModel: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nAfter you've filled out an example, start testing your application by chatting with the model on the right pane of the chat prompt interface.\n\nTo test the chatbot behavior:\n\nIn the Test your prompt panel, select the input field at the bottom.\n\nType in a question or observation that a user might make, for example:\n\nUser: none What's the weather like?\n\nSelect the diamond button to the right of the input field to get a response from the chatbot, which may be something like the following:\n\nModel: none The weather on Europa is very cold and icy. ...\n\nStep 2 - Teach your bot to chat better\n\nBy providing a single statement and response example, you were able to build a basic Europa alien chatbot. However, a single example is usually not enough to ensure consistency and quality in the model's responses. Without further input, the model's response to a question about the weather tends to be very long, and sounds like it comes out of a textbook rather than from a friendly alien.\n\nCustomize the tone of your chatbot by using the model response and editing it to match the desired tone and style of your alien chatbot.\n\nTo add and edit examples for the chatbot definition:\n\nIn the Test your prompt panel, hold the cursor over the left side of the User heading, and select the Add to examples button.\n\nIn the Write your prompt examples column, edit the copied input and response to match the intended style and tone of your chatbot.\n\nYou can use this approach to add additional examples. Ask more questions, edit the answers, and improve the quality of your chatbot. Continue to add examples and test how they modify the behavior of your chatbot. Typically, more examples correspond to higher quality chatbot responses.\n\nUnder the hood, Google AI Studio constructs a prompt by combining:\n\nDialog examples\nConversation history\n\ninto a single block of text that's sent to the model. To see what the complete prompt looks like, click Preview at the bottom of the screen to bring up the preview pane.\n\nNote that, because every message between the model and user is included in the prompt (this is the “conversational history”), conversational prompts can grow quite long as a conversation goes on. Eventually, you may hit the model's token limit, the maximum length of the text the model can accept. You can see the complete conversation and token count in the Preview tab.\n\nStep 3 - Experiment with model parameters\n\nYou can also try adjusting the model parameters to see if they produce more appropriate results for your use case.\n\nStep 4 - Next steps\n\nSimilar to the other prompt types, once you have your prompt prototyped to your satisfaction, you can use the Get Code button to start coding or save your prompt to work on later and share with others.\n\nFurther reading\nIf you're ready to move on to code, see the API quickstarts.\nTo learn how to craft better prompts, check out the Prompt design guidelines.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-04-22 UTC.\n\nTerms\nPrivacy",
            "word_count": 2744,
            "filtered_content": "",
            "filtered_word_count": 0
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de": {
            "status": "Looks good",
            "content": "Produkte\nBeispiele\nAnmelden\nDokumentation\nAPI-Referenz\nÜberblick\nJetzt starten\nAPI-Schlüssel anfordern\nGemini API – Kurzanleitung\nGoogle AI Studio – Kurzanleitung\nAnleitungen für den Einstieg\nModelle\nInformationen zu generativen Modellen\nGemini\nGemini API\nAPI-Übersicht\nAPI-Referenz\nAPI-Versionen\nVersionshinweise\nLeistungsspektrum\nModellabstimmung\nFunktionsaufruf\nEinbettungen\nSicherheit\nLeitfäden\nAufforderungen\nSystemanleitung\nSemantischer Abruf\nAuthentifizierung mit OAuth\nFirebase-Erweiterungen\nZu Cloud migrieren\nAnleitungen\nFunktionsaufruf\nEinbettungen\nAnwendungen\nProblembehebung\nTipps zur Fehlerbehebung\nÜber Workspace auf AI Studio zugreifen\nFehlerbehebung in AI Studio\nHöheres Kontingent beantragen\nCommunity\nDiskursforum\nPaLM API (alt)\nZu Gemini migrieren\nPaLM-Dokumentation\nRecht\nNutzungsbedingungen\n(Vorschau) Nutzungsbedingungen\nVerfügbare Regionen\nAuf dieser Seite\nPrompts und Modellabstimmung\nBeispiel für einen Prompt im freien Format: Weitere Informationen zu einem Gebäude\nSchritt 1: Prompt mit Text und Bildern erstellen\nSchritt 2: Eine austauschbare Variable zum Prompt hinzufügen\nSchritt 3 – Mit Modellparametern experimentieren\nSchritt 4 – Nächste Schritte\nBeispiel für einen strukturierten Prompt: Generator für Produkttexte erstellen\nSchritt 1: Strukturierte Aufforderung erstellen\nSchritt 2 – Beispiele hinzufügen\nSchritt 3: Prompt testen\nSchritt 4 – Nächste Schritte\nBeispiel für Chat-Prompt: Benutzerdefinierte Chatanwendung erstellen\nSchritt 1: Chat-Prompt erstellen\nSchritt 2: Dem Bot beibringen, besser zu chatten\nSchritt 3 – Mit Modellparametern experimentieren\nSchritt 4 – Nächste Schritte\nWeitere Informationen\nSehen Sie sich das neue Cookbook zur Gemini API und unser Community-Forum an.\n Diese Seite wurde von der Cloud Translation API übersetzt.\nGoogle AI for Developers\nProdukte\nWar das hilfreich?\nFeedback geben\nGoogle AI Studio – Kurzanleitung \nbookmark_border\n\nGoogle AI Studio ist eine browserbasierte IDE für das Prototyping mit generativen Modellen. Mit Google AI Studio können Sie schnell Modelle testen und mit verschiedenen Prompts experimentieren. Wenn Sie etwas erstellt haben, mit dem Sie zufrieden sind, können Sie es mithilfe der Gemini API in Code in Ihrer bevorzugten Programmiersprache exportieren.\n\nPrompts und Modellabstimmung\n\nGoogle AI Studio bietet mehrere Schnittstellen für Prompts, die für verschiedene Anwendungsfälle entwickelt wurden:\n\nFreie Prompts: Diese Prompts bieten die Möglichkeit, Inhalte und Antworten auf Anweisungen zu generieren. Sie können für Ihre Prompts sowohl Bilder als auch Textdaten verwenden. Weitere Informationen\n\nStrukturierte Prompts: Mit dieser Prompt-Technik können Sie die Modellausgabe steuern, indem Sie eine Reihe von Beispielanfragen und -antworten bereitstellen. Verwenden Sie diesen Ansatz, wenn Sie mehr Kontrolle über die Struktur der Modellausgabe benötigen. Weitere Informationen\n\nChat-Aufforderungen: Verwenden Sie Chat-Aufforderungen, um einen Gesprächseinstieg zu ermöglichen. Bei dieser Prompt-Technik können mehrere Eingabe- und Antwortrunden eine Ausgabe generieren. Weitere Informationen\n\nMit Google AI Studio können Sie auch das Verhalten eines Modells mithilfe der Methode Abstimmung ändern:\n\nAbgestimmtes Modell: Verwenden Sie dieses erweiterte Verfahren, um die Antworten eines Modells für eine bestimmte Aufgabe durch zusätzliche Beispiele zu verbessern. Weitere Informationen\nBeispiel für einen Prompt im freien Format: Weitere Informationen zu einem Gebäude\n\nMit den multimodalen Funktionen von Gemini können Sie das Modell mit einer Kombination aus Bildern und Text auffordern. Sie können diese Funktion beispielsweise verwenden, um mehr über ein auf einem Bild dargestelltes Gebäude zu erfahren.\n\nSchritt 1: Prompt mit Text und Bildern erstellen\n\nSo erstellen Sie eine multimodale Aufforderung:\n\nRufen Sie Google AI Studio auf.\nWählen Sie im linken Bereich Neu erstellen > Prompt im freien Format aus.\nWählen Sie in der rechten Spalte im Feld Modell ein Modell aus, das Bilder unterstützt, z. B. das Modell Gemini Pro Vision.\n\nGeben Sie im Prompt-Textbereich den folgenden Text ein:\n\nlook at the following picture and tell me who is the architect\n\n\nWählen Sie in der Leiste Einfügen über dem Eingabeaufforderungsbereich die Option Bild und dann eines der Beispielbilder eines Gebäudes aus.\n\nWählen Sie unten im Anwendungsfenster Ausführen aus, um eine Antwort auf diese Anfrage zu generieren.\n\nSchritt 2: Eine austauschbare Variable zum Prompt hinzufügen\n\nIn Schritt 1 haben Sie dem Modell einen festen Textstring und ein Bild hinzugefügt. Manchmal möchten Sie jedoch Teile eines Prompts dynamisch ändern. Wenn Sie beispielsweise eine interaktive Anwendung erstellen, können Sie die Eingabeaufforderung mit anderen Nutzereingaben ändern. Dazu können Sie Ihre Aufforderungen mit Variablen parametrisieren.\n\nSo fügen Sie Ihren Prompts Variablen hinzu:\n\nWählen Sie das Wort oder die Wortgruppe aus, das bzw. die Sie in Ihrem Prompt ersetzen möchten. Wählen Sie in diesem Fall den Text who is the architect aus.\nWählen Sie im Header Einfügen: über dem Prompt die Option &lcub;&lcub; &rcub;&rcub; Testeingabe aus.\nGeben Sie in der Tabelle Prompt testen unter der Aufforderung einen zusätzlichen Wert für den Prompt ein. Wählen Sie dazu Testbeispiel hinzufügen aus und geben Sie einen zusätzlichen Wert für die Aufforderung ein. Sie können gerne mehrere neue Eingabewerte hinzufügen.\nWählen Sie unten im Anwendungsfenster Ausführen aus, um für jede der verschiedenen Anfragen eine Antwort zu generieren.\nSchritt 3 – Mit Modellparametern experimentieren\n\nWenn Sie einen Prototyp für Ihren Prompt erstellen, können Sie auch mit den Einstellungen für die Modellausführung auf der rechten Seite der Anwendung experimentieren. Dies sind die wichtigsten Einstellungen, die Sie kennen sollten:\n\nModell: Wählen Sie aus, welches Modell Sie auf Ihre Prompts beantworten möchten. Weitere Informationen zu den verfügbaren Modellen und Funktionen finden Sie unter Modelle.\nTemperatur: Hier können Sie festlegen, wie viel Zufälligkeit in den Modellantworten zulässig ist. Wenn Sie diesen Wert erhöhen, kann das Modell unerwartetere und kreativere Antworten liefern.\nMaximale Ausgaben: Erhöhen Sie die Anzahl der Antworten, die das Modell für jede Anfrage zurückgibt. Diese Option kann hilfreich sein, um Aufforderungen schnell zu testen, indem mehrere Antworten für eine einzelne Aufforderung generiert werden.\nSicherheitseinstellungen: Sicherheitseinstellungen für die Verwaltung von Modellantworten anpassen. Weitere Informationen zu diesen Steuerelementen finden Sie unter Sicherheitseinstellungen.\nSchritt 4 – Nächste Schritte\n\nNachdem Sie nun den Prototyp einer Anwendung mit generativer KI erstellt haben, können Sie Ihre Arbeit speichern oder Code generieren, um diesen Prompt in Ihrer eigenen Entwicklungsumgebung zu verwenden.\n\nSo speichern Sie den von Ihnen erstellten Prompt:\n\nWählen Sie rechts oben in der Google AI Studio App Speichern aus.\nVerbinden Sie die App mit Ihrem Google Drive-Konto, falls Sie dies noch nicht getan haben.\nGeben Sie im Dialogfeld Prompt speichern einen Namen der Aufforderung und eine optionale Beschreibung ein und wählen Sie dann Speichern aus.\n\nSo exportieren Sie den von Ihnen als Code erstellten Prompt:\n\nWählen Sie rechts oben in der Google AI Studio App Code abrufen aus.\nWählen Sie eine Registerkarte für eine Programmiersprache aus.\nWählen Sie Kopieren aus, um den Code in die Zwischenablage zu kopieren.\nHinweis: Sie benötigen einen API-Schlüssel, um den Eingabeaufforderungscode außerhalb von Google AI Studio auszuführen. Erstellen Sie also einen Schlüssel und fügen Sie ihn in Ihren Prompt-Code ein.\nAchtung:Behandeln Sie Ihren API-Schlüssel wie ein Passwort und schützen Sie ihn angemessen. Betten Sie Ihren Schlüssel nicht in öffentlich veröffentlichten Code ein.\nBeispiel für einen strukturierten Prompt: Generator für Produkttexte erstellen\n\nBisher haben Sie gesehen, wie Sie Ihr Modell mit einer Anweisung (look at the following picture and tell me who is the architect) auffordern können. Manchmal erhalten Sie jedoch bessere Ergebnisse, wenn Sie das Modell mit einer Kombination aus Anweisungen und Beispielen auffordern. Mit strukturierten Prompts in Google AI Studio können Sie genau das erreichen. Kombinieren Sie dazu Anleitungen mit Beispielen, um dem Modell die gewünschte Art von Ausgabe zu zeigen, anstatt ihm nur vorzugeben, was zu tun ist. Diese Art von Prompts, die als Wenige Aufforderungen bezeichnet werden, sind nützlich, wenn das Modell ein einheitliches Ausgabeformat beibehalten soll (z. B. strukturierte JSON-Datei) oder wenn es schwierig ist, das Modell mit Worten zu beschreiben. In diesem Abschnitt erfahren Sie, wie Sie strukturierte Prompts in Google AI Studio erstellen.\n\nHinweis: Sie können dieses Beispiel direkt in Google AI Studio in der Beispielgalerie ausprobieren.\nSchritt 1: Strukturierte Aufforderung erstellen\n\nIn diesem Beispiel erstellen Sie einen strukturierten Prompt, der Werbetext für Produkte generiert. Definieren Sie zuerst die Struktur für den Prompt. Dazu erstellen Sie zwei Spalten: eine Product-Eingabespalte und eine Product copy-Ausgabespalte.\n\nSo erstellen Sie den strukturierten Prompt:\n\nWählen Sie oben links in der Webanwendung Google AI Studio die Option Neu erstellen > Strukturierte Aufforderung aus.\n\nFügen Sie unter dem Header Insert: die Anleitung für den strukturierten Prompt hinzu:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nFügen Sie einen beschreibenden Header für INPUT hinzu. Ersetzen Sie dazu die Standardtextbeschreibung input: durch Product:.\n\nFügen Sie einen beschreibenden Header für AUSGABE hinzu. Ersetzen Sie dazu die Standardbeschreibung output: durch Product copy:.\n\nTipp: Fügen Sie am Ende der Spaltennamen Doppelpunkte hinzu, damit das Modell die Struktur leichter parsen kann.\nSchritt 2 – Beispiele hinzufügen\n\nNachdem Sie den Spalten einen Namen gegeben haben, geben Sie einige Beispielzeilen an. Diese Zeilen sollten Beispieleingaben (Produktnamen in diesem Beispiel) und Beispielausgaben (entsprechende Produktbeschreibungen) enthalten. Wenn Sie dem Modell einige Beispielproduktbeschreibungen zur Verfügung stellen, können Sie es anleiten, einen ähnlichen Stil zu replizieren, wenn es seine eigenen Ausgaben generiert. Sie können Beispiele manuell eingeben oder über das Menü „Daten importieren“ aus einer Datei importieren.\n\nSo geben Sie Beispiele manuell ein:\n\nWählen Sie in der obersten Datentabelle mit Beispielen das Feld unter der Überschrift Produkt: aus und geben Sie eine Produktbeschreibung ein.\n\nWählen Sie das Feld unter der Überschrift Produkttext: aus und geben Sie Marketingtext für das Produkt ein.\n\nHier ist ein Beispiel für Eingabe- und Ausgabewerte für diesen Prompt:\n\nProdukt:\tProduktbeschreibung:\nKlassische Sneaker\tSchnüren wir uns! Diese Schuhe zeugen von einem unverwechselbaren Look und einer einzigartigen Farbpalette – zugleich unterstützen sie dich stilvoll und funktionell wie kein anderer Schuh.\nSuperweicher Kapuzenpullover\tMit unserem neuen Unisex-Kapuzenpullover bleibst du stilvoll und gemütlich. Dieser Hoodie aus 100% Baumwolle ist weich und angenehm zu tragen. Die teilweise gebürstete Innenseite hält auch an kältesten Tagen warm.\n\nTipp :Wenn Sie Schreibblockaden haben oder keine Beispiel-Produkttexte zur Hand haben, können Sie den Freiform-Prompt verwenden, um das Textmodell einige für Sie generieren zu lassen.\n\nSo importieren Sie Beispiele aus einer Datei:\n\nWählen Sie rechts oben in der Tabelle Beispiele Aktionen > Beispiele importieren aus.\n\nWählen Sie im Dialogfeld eine CSV- oder Google Tabellen-Datei in Google Drive aus oder laden Sie sie von Ihrem Computer hoch.\n\nWählen Sie im Dialogfeld zum Importieren von Beispielen aus, welche Spalten importiert und welche ausgelassen werden sollen. Im Dialogfeld können Sie auch angeben, welche Datenspalte in welche Tabellenspalte in Ihrem strukturierten Prompt importiert werden soll.\n\nSchritt 3: Prompt testen\n\nSobald Sie die Beispiele haben, die das gewünschte Modell zeigen, testen Sie Ihre Aufforderung mit einer neuen Eingabe in der Tabelle Prompt testen unten. Wie bei Text-Prompts können Sie Modellparameter anpassen, um zu testen, ob sie bessere Ergebnisse für Ihren Anwendungsfall liefern.\n\nPrüfen, wie Beispiele an das Modell gesendet werden\n\nGoogle AI Studio erstellt einen Prompt, indem die Anleitung mit den von Ihnen bereitgestellten Beispielen kombiniert wird. Wenn Sie weitere Beispiele hinzufügen, werden diese dem Text hinzugefügt, der an das Modell gesendet wird. Je nachdem, wie lang Ihre Beispiele sind, kann es passieren, dass Sie das Tokenlimit des Modells erreichen. Alle generativen KI-Modelle haben ein Tokenlimit. Das ist die maximale Textlänge, die sie als Eingabe akzeptieren können.\n\nSo rufen Sie den gesamten Inhalt Ihres Prompts auf:\n\nWählen Sie unten in der Google AI Studio-Webanwendung die Textvorschau aus.\nHinweis: Das Limit für Modelltokens wird unten im Vorschaubereich angezeigt.\nSchritt 4 – Nächste Schritte\n\nWenn Sie mit dem Prompt zufrieden sind, können Sie ihn speichern oder in Code exportieren, indem Sie auf die Schaltfläche Code abrufen klicken.\n\nSie können die einzelnen Beispiele auch in eine CSV-Datei oder Google-Tabelle exportieren. Wählen Sie im Menü Aktion die Option Beispiele exportieren aus, um Ihre Beispiele zu exportieren.\n\nBeispiel für Chat-Prompt: Benutzerdefinierte Chatanwendung erstellen\n\nWenn Sie einen Chatbot für allgemeine Zwecke wie Gemini verwendet haben, haben Sie aus erster Hand erfahren, wie leistungsstark Generative AI-Modelle für offene Dialoge sein können. Diese Chatbots für allgemeine Zwecke sind zwar nützlich, müssen aber oft auf bestimmte Anwendungsfälle zugeschnitten werden. Angenommen, Sie möchten einen Kundenservice-Chatbot erstellen, der nur Unterhaltungen unterstützt, die über das Produkt eines Unternehmens sprechen. Vielleicht möchten Sie einen Chatbot erstellen, der mit einem bestimmten Ton oder Stil spricht: einen Bot, der viele Witze knackt, sich reimt wie ein Dichter oder in seinen Antworten viele Emojis verwendet.\n\nIn diesem Beispiel erfahren Sie, wie Sie mit Google AI Studio einen freundlichen Chatbot erstellen, der so kommuniziert, als wäre es ein Alien, der auf einem der Monde des Jupiters, Europa, lebt.\n\nSchritt 1: Chat-Prompt erstellen\n\nIm letzten Abschnitt haben Sie mit einer Kombination aus Eingabe- und Ausgabebeispielen einen strukturierten Prompt entworfen. Ebenso müssen Sie zum Erstellen eines Chatbots Beispiele für Interaktionen zwischen einem Nutzer und dem Chatbot bereitstellen, damit das Modell die gewünschten Antworten liefern kann.\n\nSo erstellen Sie einen Chat-Prompt:\n\nWählen Sie oben links in der Webanwendung Google AI Studio die Option Neu erstellen > Chat-Prompt aus.\n\nIn der Spalte Prompt-Beispiele schreiben der Aufforderungsoberfläche können Sie Beispiele für Interaktionen angeben. Sie können im ersten Beispiel auch zusätzlichen Kontext angeben, z. B.:\n\nNutzer: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModell: none Ok\n\nIn den Feldern Nutzer und Modell finden Sie ein Beispiel dafür, welche Interaktionen zwischen einem Nutzer und dem Chatbot aussehen könnten:\n\nNutzer: none Hi!\n\nModell: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nNachdem Sie ein Beispiel ausgefüllt haben, beginnen Sie mit dem Testen Ihrer Anwendung. Dazu chatten Sie mit dem Modell im rechten Bereich der Oberfläche der Chat-Eingabeaufforderung.\n\nSo testen Sie das Chatbot-Verhalten:\n\nWählen Sie im Bereich Prompt testen das Eingabefeld unten aus.\n\nGeben Sie eine Frage oder Beobachtung ein, die eine nutzende Person stellen könnte, zum Beispiel:\n\nNutzer: none What's the weather like?\n\nKlicken Sie auf das Diamantsymbol rechts neben dem Eingabefeld, um eine Antwort vom Chatbot zu erhalten, die in etwa so aussehen kann:\n\nModell: none The weather on Europa is very cold and icy. ...\n\nSchritt 2: Dem Bot beibringen, besser zu chatten\n\nMit einer einzelnen Aussage und einem Beispiel für eine Antwort konnten Sie einen einfachen Europa-Alien-Chatbot erstellen. Ein einzelnes Beispiel reicht jedoch in der Regel nicht aus, um Konsistenz und Qualität der Modellantworten zu gewährleisten. Ohne weitere Eingaben ist die Antwort des Modells auf eine Frage zum Wetter in der Regel sehr lang und klingt, als käme sie aus einem Lehrbuch und nicht von einem freundlichen Außerirdischen.\n\nPassen Sie den Ton Ihres Chatbots mithilfe der Modellantwort an den gewünschten Ton und Stil Ihres außerirdischen Chatbots an.\n\nSo fügen Sie Beispiele für die Chatbot-Definition hinzu und bearbeiten sie:\n\nBewegen Sie im Bereich Prompt testen den Mauszeiger auf die linke Seite der Überschrift User und wählen Sie die Schaltfläche Add to examples (Zu Beispielen hinzufügen) aus.\n\nBearbeiten Sie in der Spalte Geben Sie Ihre Prompt-Beispiele ein, um die kopierte Eingabe und Antwort so zu bearbeiten, dass sie zum gewünschten Stil und Ton Ihres Chatbots passen.\n\nMit diesem Ansatz können Sie weitere Beispiele hinzufügen. Stellen Sie weitere Fragen, bearbeiten Sie die Antworten und verbessern Sie die Qualität Ihres Chatbots. Fügen Sie weitere Beispiele hinzu und testen Sie, wie diese das Verhalten des Chatbots verändern. Mehr Beispiele entsprechen in der Regel hochwertigeren Chatbot-Antworten.\n\nIm Prinzip erstellt Google AI Studio einen Prompt, indem Folgendes kombiniert wird:\n\nBeispiele für Dialogfelder\nUnterhaltungsverlauf\n\nzu einem einzelnen Textblock zusammengefasst, der an das Modell gesendet wird. Um den gesamten Prompt zu sehen, klicken Sie unten auf dem Bildschirm auf Preview (Vorschau), um den Vorschaubereich aufzurufen.\n\nDa jede Nachricht zwischen dem Modell und dem Nutzer im Prompt enthalten ist (dies ist der „Unterhaltungsverlauf“), können dialogorientierte Prompts im Laufe einer Unterhaltung recht lange wachsen. Schließlich können Sie das Tokenlimit des Modells erreichen, also die maximale Textlänge, die das Modell akzeptieren kann. Auf dem Tab Vorschau sehen Sie die vollständige Unterhaltung und die Anzahl der Tokens.\n\nSchritt 3 – Mit Modellparametern experimentieren\n\nSie können auch versuchen, die Modellparameter anzupassen, um zu sehen, ob sie bessere Ergebnisse für Ihren Anwendungsfall liefern.\n\nSchritt 4 – Nächste Schritte\n\nÄhnlich wie bei den anderen Prompt-Typen können Sie, sobald Sie Ihren Prompt zu Ihrer Zufriedenheit erstellt haben, über die Schaltfläche Code abrufen mit dem Programmieren beginnen oder Ihre Aufforderung speichern, um sie später weiterzubearbeiten und mit anderen zu teilen.\n\nWeitere Informationen\nWenn Sie mit dem Programmieren fortfahren möchten, lesen Sie die API-Kurzanleitungen.\nInformationen zum Erstellen besserer Prompts finden Sie in den Richtlinien für das Design von Aufforderungen.\nWar das hilfreich?\nFeedback geben\n\nSofern nicht anders angegeben, sind die Inhalte dieser Seite unter der Creative Commons Attribution 4.0 License und Codebeispiele unter der Apache 2.0 License lizenziert. Weitere Informationen finden Sie in den Websiterichtlinien von Google Developers. Java ist eine eingetragene Marke von Oracle und/oder seinen Partnern.\n\nZuletzt aktualisiert: 2024-04-22 (UTC).\n\nNutzungsbedingungen\nDatenschutz",
            "word_count": 2700,
            "filtered_content": "Google AI Studio – Kurzanleitung \nGoogle AI Studio ist eine browserbasierte IDE für das Prototyping mit generativen Modellen. Mit Google AI Studio können Sie schnell Modelle testen und mit verschiedenen Prompts experimentieren. Wenn Sie etwas erstellt haben, mit dem Sie zufrieden sind, können Sie es mithilfe der Gemini API in Code in Ihrer bevorzugten Programmiersprache exportieren.\nGoogle AI Studio bietet mehrere Schnittstellen für Prompts, die für verschiedene Anwendungsfälle entwickelt wurden:\nFreie Prompts: Diese Prompts bieten die Möglichkeit, Inhalte und Antworten auf Anweisungen zu generieren. Sie können für Ihre Prompts sowohl Bilder als auch Textdaten verwenden. Weitere Informationen\nStrukturierte Prompts: Mit dieser Prompt-Technik können Sie die Modellausgabe steuern, indem Sie eine Reihe von Beispielanfragen und -antworten bereitstellen. Verwenden Sie diesen Ansatz, wenn Sie mehr Kontrolle über die Struktur der Modellausgabe benötigen. Weitere Informationen\nChat-Aufforderungen: Verwenden Sie Chat-Aufforderungen, um einen Gesprächseinstieg zu ermöglichen. Bei dieser Prompt-Technik können mehrere Eingabe- und Antwortrunden eine Ausgabe generieren. Weitere Informationen\nMit Google AI Studio können Sie auch das Verhalten eines Modells mithilfe der Methode Abstimmung ändern:\nAbgestimmtes Modell: Verwenden Sie dieses erweiterte Verfahren, um die Antworten eines Modells für eine bestimmte Aufgabe durch zusätzliche Beispiele zu verbessern. Weitere Informationen\nMit den multimodalen Funktionen von Gemini können Sie das Modell mit einer Kombination aus Bildern und Text auffordern. Sie können diese Funktion beispielsweise verwenden, um mehr über ein auf einem Bild dargestelltes Gebäude zu erfahren.\nSo erstellen Sie eine multimodale Aufforderung:\nRufen Sie Google AI Studio auf.\nWählen Sie im linken Bereich Neu erstellen > Prompt im freien Format aus.\nWählen Sie in der rechten Spalte im Feld Modell ein Modell aus, das Bilder unterstützt, z. B. das Modell Gemini Pro Vision.\nGeben Sie im Prompt-Textbereich den folgenden Text ein:\nWählen Sie in der Leiste Einfügen über dem Eingabeaufforderungsbereich die Option Bild und dann eines der Beispielbilder eines Gebäudes aus.\nWählen Sie unten im Anwendungsfenster Ausführen aus, um eine Antwort auf diese Anfrage zu generieren.\nIn Schritt 1 haben Sie dem Modell einen festen Textstring und ein Bild hinzugefügt. Manchmal möchten Sie jedoch Teile eines Prompts dynamisch ändern. Wenn Sie beispielsweise eine interaktive Anwendung erstellen, können Sie die Eingabeaufforderung mit anderen Nutzereingaben ändern. Dazu können Sie Ihre Aufforderungen mit Variablen parametrisieren.\nSo fügen Sie Ihren Prompts Variablen hinzu:\nWählen Sie das Wort oder die Wortgruppe aus, das bzw. die Sie in Ihrem Prompt ersetzen möchten. Wählen Sie in diesem Fall den Text who is the architect aus.\nWählen Sie im Header Einfügen: über dem Prompt die Option &lcub;&lcub; &rcub;&rcub; Testeingabe aus.\nGeben Sie in der Tabelle Prompt testen unter der Aufforderung einen zusätzlichen Wert für den Prompt ein. Wählen Sie dazu Testbeispiel hinzufügen aus und geben Sie einen zusätzlichen Wert für die Aufforderung ein. Sie können gerne mehrere neue Eingabewerte hinzufügen.\nWählen Sie unten im Anwendungsfenster Ausführen aus, um für jede der verschiedenen Anfragen eine Antwort zu generieren.\nWenn Sie einen Prototyp für Ihren Prompt erstellen, können Sie auch mit den Einstellungen für die Modellausführung auf der rechten Seite der Anwendung experimentieren. Dies sind die wichtigsten Einstellungen, die Sie kennen sollten:\nModell: Wählen Sie aus, welches Modell Sie auf Ihre Prompts beantworten möchten. Weitere Informationen zu den verfügbaren Modellen und Funktionen finden Sie unter Modelle.\nTemperatur: Hier können Sie festlegen, wie viel Zufälligkeit in den Modellantworten zulässig ist. Wenn Sie diesen Wert erhöhen, kann das Modell unerwartetere und kreativere Antworten liefern.\nMaximale Ausgaben: Erhöhen Sie die Anzahl der Antworten, die das Modell für jede Anfrage zurückgibt. Diese Option kann hilfreich sein, um Aufforderungen schnell zu testen, indem mehrere Antworten für eine einzelne Aufforderung generiert werden.\nSicherheitseinstellungen: Sicherheitseinstellungen für die Verwaltung von Modellantworten anpassen. Weitere Informationen zu diesen Steuerelementen finden Sie unter Sicherheitseinstellungen.\nNachdem Sie nun den Prototyp einer Anwendung mit generativer KI erstellt haben, können Sie Ihre Arbeit speichern oder Code generieren, um diesen Prompt in Ihrer eigenen Entwicklungsumgebung zu verwenden.\nSo speichern Sie den von Ihnen erstellten Prompt:\nWählen Sie rechts oben in der Google AI Studio App Speichern aus.\nVerbinden Sie die App mit Ihrem Google Drive-Konto, falls Sie dies noch nicht getan haben.\nGeben Sie im Dialogfeld Prompt speichern einen Namen der Aufforderung und eine optionale Beschreibung ein und wählen Sie dann Speichern aus.\nSo exportieren Sie den von Ihnen als Code erstellten Prompt:\nWählen Sie rechts oben in der Google AI Studio App Code abrufen aus.\nWählen Sie eine Registerkarte für eine Programmiersprache aus.\nWählen Sie Kopieren aus, um den Code in die Zwischenablage zu kopieren.\nHinweis: Sie benötigen einen API-Schlüssel, um den Eingabeaufforderungscode außerhalb von Google AI Studio auszuführen. Erstellen Sie also einen Schlüssel und fügen Sie ihn in Ihren Prompt-Code ein.\nAchtung:Behandeln Sie Ihren API-Schlüssel wie ein Passwort und schützen Sie ihn angemessen. Betten Sie Ihren Schlüssel nicht in öffentlich veröffentlichten Code ein.\nBisher haben Sie gesehen, wie Sie Ihr Modell mit einer Anweisung (look at the following picture and tell me who is the architect) auffordern können. Manchmal erhalten Sie jedoch bessere Ergebnisse, wenn Sie das Modell mit einer Kombination aus Anweisungen und Beispielen auffordern. Mit strukturierten Prompts in Google AI Studio können Sie genau das erreichen. Kombinieren Sie dazu Anleitungen mit Beispielen, um dem Modell die gewünschte Art von Ausgabe zu zeigen, anstatt ihm nur vorzugeben, was zu tun ist. Diese Art von Prompts, die als Wenige Aufforderungen bezeichnet werden, sind nützlich, wenn das Modell ein einheitliches Ausgabeformat beibehalten soll (z. B. strukturierte JSON-Datei) oder wenn es schwierig ist, das Modell mit Worten zu beschreiben. In diesem Abschnitt erfahren Sie, wie Sie strukturierte Prompts in Google AI Studio erstellen.\nHinweis: Sie können dieses Beispiel direkt in Google AI Studio in der Beispielgalerie ausprobieren.\nIn diesem Beispiel erstellen Sie einen strukturierten Prompt, der Werbetext für Produkte generiert. Definieren Sie zuerst die Struktur für den Prompt. Dazu erstellen Sie zwei Spalten: eine Product-Eingabespalte und eine Product copy-Ausgabespalte.\nSo erstellen Sie den strukturierten Prompt:\nWählen Sie oben links in der Webanwendung Google AI Studio die Option Neu erstellen > Strukturierte Aufforderung aus.\nFügen Sie unter dem Header Insert: die Anleitung für den strukturierten Prompt hinzu:\nFügen Sie einen beschreibenden Header für INPUT hinzu. Ersetzen Sie dazu die Standardtextbeschreibung input: durch Product:.\nFügen Sie einen beschreibenden Header für AUSGABE hinzu. Ersetzen Sie dazu die Standardbeschreibung output: durch Product copy:.\nTipp: Fügen Sie am Ende der Spaltennamen Doppelpunkte hinzu, damit das Modell die Struktur leichter parsen kann.\nNachdem Sie den Spalten einen Namen gegeben haben, geben Sie einige Beispielzeilen an. Diese Zeilen sollten Beispieleingaben (Produktnamen in diesem Beispiel) und Beispielausgaben (entsprechende Produktbeschreibungen) enthalten. Wenn Sie dem Modell einige Beispielproduktbeschreibungen zur Verfügung stellen, können Sie es anleiten, einen ähnlichen Stil zu replizieren, wenn es seine eigenen Ausgaben generiert. Sie können Beispiele manuell eingeben oder über das Menü „Daten importieren“ aus einer Datei importieren.\nSo geben Sie Beispiele manuell ein:\nWählen Sie in der obersten Datentabelle mit Beispielen das Feld unter der Überschrift Produkt: aus und geben Sie eine Produktbeschreibung ein.\nWählen Sie das Feld unter der Überschrift Produkttext: aus und geben Sie Marketingtext für das Produkt ein.\nHier ist ein Beispiel für Eingabe- und Ausgabewerte für diesen Prompt:\nProdukt:\tProduktbeschreibung:\nKlassische Sneaker\tSchnüren wir uns! Diese Schuhe zeugen von einem unverwechselbaren Look und einer einzigartigen Farbpalette – zugleich unterstützen sie dich stilvoll und funktionell wie kein anderer Schuh.\nSuperweicher Kapuzenpullover\tMit unserem neuen Unisex-Kapuzenpullover bleibst du stilvoll und gemütlich. Dieser Hoodie aus 100% Baumwolle ist weich und angenehm zu tragen. Die teilweise gebürstete Innenseite hält auch an kältesten Tagen warm.\nTipp :Wenn Sie Schreibblockaden haben oder keine Beispiel-Produkttexte zur Hand haben, können Sie den Freiform-Prompt verwenden, um das Textmodell einige für Sie generieren zu lassen.\nSo importieren Sie Beispiele aus einer Datei:\nWählen Sie rechts oben in der Tabelle Beispiele Aktionen > Beispiele importieren aus.\nWählen Sie im Dialogfeld eine CSV- oder Google Tabellen-Datei in Google Drive aus oder laden Sie sie von Ihrem Computer hoch.\nWählen Sie im Dialogfeld zum Importieren von Beispielen aus, welche Spalten importiert und welche ausgelassen werden sollen. Im Dialogfeld können Sie auch angeben, welche Datenspalte in welche Tabellenspalte in Ihrem strukturierten Prompt importiert werden soll.\nSobald Sie die Beispiele haben, die das gewünschte Modell zeigen, testen Sie Ihre Aufforderung mit einer neuen Eingabe in der Tabelle Prompt testen unten. Wie bei Text-Prompts können Sie Modellparameter anpassen, um zu testen, ob sie bessere Ergebnisse für Ihren Anwendungsfall liefern.\nPrüfen, wie Beispiele an das Modell gesendet werden\nGoogle AI Studio erstellt einen Prompt, indem die Anleitung mit den von Ihnen bereitgestellten Beispielen kombiniert wird. Wenn Sie weitere Beispiele hinzufügen, werden diese dem Text hinzugefügt, der an das Modell gesendet wird. Je nachdem, wie lang Ihre Beispiele sind, kann es passieren, dass Sie das Tokenlimit des Modells erreichen. Alle generativen KI-Modelle haben ein Tokenlimit. Das ist die maximale Textlänge, die sie als Eingabe akzeptieren können.\nSo rufen Sie den gesamten Inhalt Ihres Prompts auf:\nWählen Sie unten in der Google AI Studio-Webanwendung die Textvorschau aus.\nHinweis: Das Limit für Modelltokens wird unten im Vorschaubereich angezeigt.\nWenn Sie mit dem Prompt zufrieden sind, können Sie ihn speichern oder in Code exportieren, indem Sie auf die Schaltfläche Code abrufen klicken.\nSie können die einzelnen Beispiele auch in eine CSV-Datei oder Google-Tabelle exportieren. Wählen Sie im Menü Aktion die Option Beispiele exportieren aus, um Ihre Beispiele zu exportieren.\nWenn Sie einen Chatbot für allgemeine Zwecke wie Gemini verwendet haben, haben Sie aus erster Hand erfahren, wie leistungsstark Generative AI-Modelle für offene Dialoge sein können. Diese Chatbots für allgemeine Zwecke sind zwar nützlich, müssen aber oft auf bestimmte Anwendungsfälle zugeschnitten werden. Angenommen, Sie möchten einen Kundenservice-Chatbot erstellen, der nur Unterhaltungen unterstützt, die über das Produkt eines Unternehmens sprechen. Vielleicht möchten Sie einen Chatbot erstellen, der mit einem bestimmten Ton oder Stil spricht: einen Bot, der viele Witze knackt, sich reimt wie ein Dichter oder in seinen Antworten viele Emojis verwendet.\nIn diesem Beispiel erfahren Sie, wie Sie mit Google AI Studio einen freundlichen Chatbot erstellen, der so kommuniziert, als wäre es ein Alien, der auf einem der Monde des Jupiters, Europa, lebt.\nIm letzten Abschnitt haben Sie mit einer Kombination aus Eingabe- und Ausgabebeispielen einen strukturierten Prompt entworfen. Ebenso müssen Sie zum Erstellen eines Chatbots Beispiele für Interaktionen zwischen einem Nutzer und dem Chatbot bereitstellen, damit das Modell die gewünschten Antworten liefern kann.\nSo erstellen Sie einen Chat-Prompt:\nWählen Sie oben links in der Webanwendung Google AI Studio die Option Neu erstellen > Chat-Prompt aus.\nIn der Spalte Prompt-Beispiele schreiben der Aufforderungsoberfläche können Sie Beispiele für Interaktionen angeben. Sie können im ersten Beispiel auch zusätzlichen Kontext angeben, z. B.:\nNutzer: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nModell: none Ok\nIn den Feldern Nutzer und Modell finden Sie ein Beispiel dafür, welche Interaktionen zwischen einem Nutzer und dem Chatbot aussehen könnten:\nNutzer: none Hi!\nModell: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\nNachdem Sie ein Beispiel ausgefüllt haben, beginnen Sie mit dem Testen Ihrer Anwendung. Dazu chatten Sie mit dem Modell im rechten Bereich der Oberfläche der Chat-Eingabeaufforderung.\nSo testen Sie das Chatbot-Verhalten:\nWählen Sie im Bereich Prompt testen das Eingabefeld unten aus.\nGeben Sie eine Frage oder Beobachtung ein, die eine nutzende Person stellen könnte, zum Beispiel:\nNutzer: none What's the weather like?\nKlicken Sie auf das Diamantsymbol rechts neben dem Eingabefeld, um eine Antwort vom Chatbot zu erhalten, die in etwa so aussehen kann:\nModell: none The weather on Europa is very cold and icy. ...\nMit einer einzelnen Aussage und einem Beispiel für eine Antwort konnten Sie einen einfachen Europa-Alien-Chatbot erstellen. Ein einzelnes Beispiel reicht jedoch in der Regel nicht aus, um Konsistenz und Qualität der Modellantworten zu gewährleisten. Ohne weitere Eingaben ist die Antwort des Modells auf eine Frage zum Wetter in der Regel sehr lang und klingt, als käme sie aus einem Lehrbuch und nicht von einem freundlichen Außerirdischen.\nPassen Sie den Ton Ihres Chatbots mithilfe der Modellantwort an den gewünschten Ton und Stil Ihres außerirdischen Chatbots an.\nSo fügen Sie Beispiele für die Chatbot-Definition hinzu und bearbeiten sie:\nBewegen Sie im Bereich Prompt testen den Mauszeiger auf die linke Seite der Überschrift User und wählen Sie die Schaltfläche Add to examples (Zu Beispielen hinzufügen) aus.\nBearbeiten Sie in der Spalte Geben Sie Ihre Prompt-Beispiele ein, um die kopierte Eingabe und Antwort so zu bearbeiten, dass sie zum gewünschten Stil und Ton Ihres Chatbots passen.\nMit diesem Ansatz können Sie weitere Beispiele hinzufügen. Stellen Sie weitere Fragen, bearbeiten Sie die Antworten und verbessern Sie die Qualität Ihres Chatbots. Fügen Sie weitere Beispiele hinzu und testen Sie, wie diese das Verhalten des Chatbots verändern. Mehr Beispiele entsprechen in der Regel hochwertigeren Chatbot-Antworten.\nIm Prinzip erstellt Google AI Studio einen Prompt, indem Folgendes kombiniert wird:\nBeispiele für Dialogfelder\nUnterhaltungsverlauf\nzu einem einzelnen Textblock zusammengefasst, der an das Modell gesendet wird. Um den gesamten Prompt zu sehen, klicken Sie unten auf dem Bildschirm auf Preview (Vorschau), um den Vorschaubereich aufzurufen.\nDa jede Nachricht zwischen dem Modell und dem Nutzer im Prompt enthalten ist (dies ist der „Unterhaltungsverlauf“), können dialogorientierte Prompts im Laufe einer Unterhaltung recht lange wachsen. Schließlich können Sie das Tokenlimit des Modells erreichen, also die maximale Textlänge, die das Modell akzeptieren kann. Auf dem Tab Vorschau sehen Sie die vollständige Unterhaltung und die Anzahl der Tokens.\nSie können auch versuchen, die Modellparameter anzupassen, um zu sehen, ob sie bessere Ergebnisse für Ihren Anwendungsfall liefern.\nÄhnlich wie bei den anderen Prompt-Typen können Sie, sobald Sie Ihren Prompt zu Ihrer Zufriedenheit erstellt haben, über die Schaltfläche Code abrufen mit dem Programmieren beginnen oder Ihre Aufforderung speichern, um sie später weiterzubearbeiten und mit anderen zu teilen.\nWenn Sie mit dem Programmieren fortfahren möchten, lesen Sie die API-Kurzanleitungen.\nInformationen zum Erstellen besserer Prompts finden Sie in den Richtlinien für das Design von Aufforderungen.\nZuletzt aktualisiert: 2024-04-22 (UTC).",
            "filtered_word_count": 2282
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419": {
            "status": "Looks good",
            "content": "Productos\nEjemplos\nAcceder\nDocumentos\nReferencia de la API\nResumen\nComenzar\nObtén una clave de API\nGuía de inicio rápido de la API de Gemini\nGuía de inicio rápido de Google AI Studio\nInstructivos de introducción\nModelos\nAcerca de los modelos generativos\nGemini\nGemini API\nDescripción general de la API\nReferencia de la API\nVersiones de API\nNotas de la versión\nFunciones\nAjuste del modelo\nLlamada a función\nIncorporaciones\nSeguridad\nGuías\nMensajes\nInstrucciones del sistema\nRecuperación semántica\nAutenticación de OAuth\nExtensiones de Firebase\nMigra a Cloud\nInstructivos\nLlamada a función\nIncorporaciones\nAplicaciones\nSolución de problemas\nGuía de solución de problemas\nAccede a AI Studio con Workspace\nSolución de problemas de AI Studio\nCómo solicitar una cuota mayor\nComunidad\nForo del discurso\nAPI de PaLM (heredada)\nCómo migrar a Gemini\nDocumentos de PaLM\nLegal\nCondiciones del Servicio\n(vista previa) Condiciones del Servicio\nRegiones disponibles\nEn esta página\nInstrucciones y ajuste de modelos\nEjemplo de instrucción de formato libre: Más información sobre un edificio\nPaso 1: Crea una instrucción con imágenes y texto\nPaso 2: Agrega una variable reemplazable al mensaje\nPaso 3: experimenta con los parámetros del modelo\nPaso 4: Próximos pasos\nEjemplo de instrucción estructurada: Crea un generador de textos de productos\nPaso 1: Crea una instrucción estructurada\nPaso 2 - Agrega ejemplos\nPaso 3: Prueba tu mensaje\nPaso 4: Próximos pasos\nEjemplo de instrucción de chat: Compila una aplicación de chat personalizada\nPaso 1: Crea un mensaje de chat\nPaso 2: Enséñale al bot a chatear mejor\nPaso 3: experimenta con los parámetros del modelo\nPaso 4: Próximos pasos\nLecturas adicionales\nConsulta la nueva Guía de soluciones de la API de Gemini y nuestro foro de la comunidad.\n Se usó la API de Cloud Translation para traducir esta página.\nGoogle AI for Developers\nProductos\n¿Te resultó útil?\nEnviar comentarios\nGuía de inicio rápido de Google AI Studio \nbookmark_border\n\nGoogle AI Studio es un IDE basado en el navegador para el prototipado con modelos generativos. Google AI Studio permite probar modelos rápidamente y experimentar con distintas instrucciones. Cuando hayas compilado algo que te guste, puedes exportarlo al código en tu lenguaje de programación preferido, con la tecnología de la API de Gemini.\n\nInstrucciones y ajuste de modelos\n\nGoogle AI Studio proporciona varias interfaces para instrucciones diseñadas para diferentes casos de uso:\n\nMensajes en formato libre: Estos mensajes ofrecen una experiencia de instrucciones abierta para generar contenido y respuestas a instrucciones. Puedes usar imágenes y datos de texto para tus instrucciones. Obtén más información.\n\nMensajes estructurados: Esta técnica de instrucciones te permite guiar la salida del modelo proporcionando un conjunto de solicitudes y respuestas de ejemplo. Usa este enfoque cuando necesites un mayor control sobre la estructura de la salida del modelo. Más información\n\nInstrucciones de chat: Usa instrucciones de chat para crear experiencias de conversación. Esta técnica de instrucción permite varios turnos de entrada y respuesta para generar resultados. Obtén más información.\n\nGoogle AI Studio también te permite cambiar el comportamiento de un modelo mediante una técnica llamada ajuste:\n\nModelo ajustado: Usa esta técnica avanzada para proporcionar más ejemplos a fin de mejorar las respuestas de un modelo para una tarea específica. Obtén más información.\nEjemplo de instrucción de formato libre: Más información sobre un edificio\n\nLas capacidades multimodales de Gemini te permiten indicar el modelo con una combinación de imágenes y texto. Por ejemplo, puedes usar esta función para obtener más información sobre un edificio que se muestra en una imagen.\n\nPaso 1: Crea una instrucción con imágenes y texto\n\nSigue estos pasos para crear una instrucción multimodal:\n\nNavega a Google AI Studio.\nEn el panel izquierdo, selecciona Crear nuevo > Instrucción de formato libre.\nEn el campo Modelo de la columna de la derecha, selecciona un modelo que admita imágenes, como el modelo Gemini Pro Vision.\n\nEn el área de texto de la instrucción, ingresa el siguiente texto:\n\nlook at the following picture and tell me who is the architect\n\n\nEn la barra Insertar que aparece sobre el área del mensaje, selecciona Imagen y elige una de las imágenes de muestra de un edificio.\n\nEn la parte inferior de la ventana de la app, selecciona Ejecutar para generar una respuesta a esta solicitud.\n\nPaso 2: Agrega una variable reemplazable al mensaje\n\nEn el paso 1, le solicitaste al modelo una cadena fija de texto y una imagen. Sin embargo, a veces, deseas poder cambiar de forma dinámica partes de una instrucción. Por ejemplo, si compilas una aplicación interactiva, es posible que quieras modificar tu instrucción con diferentes entradas del usuario. Para ello, puedes parametrizar tus mensajes mediante variables.\n\nPara agregar variables a tus instrucciones, haz lo siguiente:\n\nSelecciona la palabra o frase que quieres reemplazar en la instrucción. En este caso, selecciona el texto: who is the architect.\nEn el encabezado Insert: que aparece sobre el mensaje, selecciona &lcub;&lcub; &rcub; Test input.\nEn la tabla Prueba tu instrucción que aparece debajo de la indicación, agrega un valor adicional a la indicación. Para ello, selecciona Agregar ejemplo de prueba y, luego, ingresa un valor de mensaje adicional. Siéntete libre de agregar varios valores de entrada nuevos.\nEn la parte inferior de la ventana de la app, selecciona Ejecutar a fin de generar una respuesta para cada una de las solicitudes variables.\nPaso 3: experimenta con los parámetros del modelo\n\nA medida que prototipas la instrucción, también puedes experimentar con la configuración de ejecución del modelo en el lado derecho de la aplicación. Estos son los parámetros de configuración clave que debes conocer:\n\nModelo: Selecciona el modelo que deseas que responda a tus instrucciones. Para obtener más información sobre los modelos y las capacidades disponibles, consulta Modelos.\nTemperatura: Controla cuánta aleatoriedad se permite en las respuestas del modelo. Aumentar este valor permite que el modelo produzca respuestas más inesperadas y creativas.\nCantidad máxima de resultados: aumenta la cantidad de respuestas que el modelo muestra para cada solicitud. Esta opción puede ser útil a fin de probar con rapidez los mensajes mediante la generación de varias respuestas para un solo mensaje.\nConfiguración de seguridad: ajusta la configuración de seguridad para administrar las respuestas de los modelos. Para obtener más detalles sobre estos controles, consulta la Configuración de seguridad.\nPaso 4: Próximos pasos\n\nAhora que creaste un prototipo de una aplicación de IA generativa, puedes guardar tu trabajo o generar código para usar esta instrucción en tu propio entorno de desarrollo.\n\nPara guardar la instrucción que creaste, haz lo siguiente:\n\nEn la esquina superior derecha de la app de Google AI Studio, selecciona Guardar.\nConecta la app a tu cuenta de Google Drive, si aún no lo hiciste.\nEn el diálogo Save Prompt, ingresa un Prompt name y una Description opcional y, luego, selecciona Save.\n\nPara exportar la instrucción que creaste como código, haz lo siguiente:\n\nEn la esquina superior derecha de la app de Google AI Studio, selecciona Obtener código.\nSelecciona una pestaña de lenguaje de programación.\nSelecciona Copiar para copiar el código en el portapapeles.\nNota: Necesitas una clave de API para ejecutar el código de instrucción fuera de Google AI Studio, así que asegúrate de crear una clave y de incluirla en el código del mensaje.\nPrecaución: Trata tu clave de API como una contraseña y protégela de forma adecuada. No incorpores tu clave en un código publicado de forma pública.\nEjemplo de instrucción estructurada: Crea un generador de textos de productos\n\nHasta ahora, has visto cómo puedes indicarle al modelo con una instrucción (look at the following picture and tell me who is the architect). Sin embargo, a veces, puedes obtener mejores resultados si le solicitas al modelo con una combinación de instrucciones y ejemplos. Las instrucciones estructuradas en Google AI Studio te ayudan a hacerlo: combinar instrucciones con ejemplos para mostrarle al modelo el tipo de resultado que deseas, en lugar de solo decirle qué hacer. Este tipo de instrucciones, llamada instrucciones con ejemplos limitados, es útil cuando deseas que el modelo mantenga un formato de salida coherente (es decir, JSON estructurado) o cuando es difícil describir con palabras lo que quieres (es decir, cuando es difícil describir con un estilo en particular). En esta sección, verás cómo crear instrucciones estructuradas en Google AI Studio.\n\nNota: Puedes probar este ejemplo directamente en Google AI Studio desde la galería de ejemplos.\nPaso 1: Crea una instrucción estructurada\n\nEn este ejemplo, crearás una instrucción estructurada que genere texto publicitario para los productos. Para comenzar, definirás la estructura de la instrucción creando dos columnas: una de entrada Product y una de salida Product copy.\n\nPara crear la instrucción estructurada, haz lo siguiente:\n\nEn la esquina superior izquierda de la app web de Google AI Studio, selecciona Crear nuevo > Instrucción estructurada.\n\nDebajo del encabezado Insert:, agrega las instrucciones para la instrucción estructurada:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nAgrega un encabezado descriptivo para la INPUT. Para ello, reemplaza la descripción de texto predeterminada input: por Product:.\n\nAgrega un encabezado descriptivo para SALIDA; para ello, reemplaza la descripción de texto predeterminada output: por Product copy:.\n\nSugerencia: Agrega dos puntos al final de los nombres de las columnas para facilitar que el modelo analice la estructura.\nPaso 2 - Agrega ejemplos\n\nAhora que le asignaste un nombre a tus columnas, proporciona algunas filas de ejemplo. Estas filas deben contener entradas de ejemplo (nombres de productos para este ejemplo) y resultados de ejemplo (descripciones de productos correspondientes). Si proporcionas al modelo un par de descripciones de productos de ejemplo, puedes guiarlo para que replique un estilo similar cuando genere sus propios resultados. Puedes ingresar ejemplos de forma manual o importarlos desde un archivo desde el menú Importar datos.\n\nPara ingresar ejemplos de forma manual, sigue estos pasos:\n\nEn la tabla de datos de los ejemplos principales, selecciona el campo debajo del encabezado Product: y escribe una descripción del producto.\n\nSelecciona el campo debajo del encabezado Product copy: y escribe texto de marketing para este producto.\n\nEste es un ejemplo de los valores de entrada y salida para esta instrucción:\n\nProducto:\tTexto del producto:\nCalzado tradicional\t¡Acordémonos! Estas zapatillas aportan un estilo emblemático y una paleta de colores única, además de ofrecer un estilo que te ayude a funcionar como ningún otro zapato.\nSudadera supersuave\tMantente cómodo y elegante con nuestra nueva sudadera unisex. Esta sudadera con capucha, hecha 100% algodón, es suave y cómoda de usarla todo el día. El interior semipulido te mantendrá abrigado incluso en los días más fríos.\n\nSugerencia: Si tienes un bloqueo de escritores o no tienes ejemplos de copias de productos a mano, puedes usar el mensaje en formato libre para que el modelo de texto genere algunos por ti.\n\nPara importar ejemplos desde un archivo:\n\nEn la esquina superior derecha de la tabla de ejemplos, selecciona Acciones > Importar ejemplos.\n\nEn el cuadro de diálogo, selecciona un archivo de Hojas de cálculo de Google o CSV en tu unidad de Google Drive, o bien súbelo desde tu computadora.\n\nEn el diálogo de ejemplos de importación, elige qué columnas importar y cuáles descartar. El diálogo también te permite especificar qué columna de datos importa a qué columna de la tabla en tu instrucción estructurada.\n\nPaso 3: Prueba tu mensaje\n\nUna vez que tengas los ejemplos que muestran el modelo lo que deseas, prueba tu instrucción con una entrada nueva en la tabla Prueba tu instrucción en la parte inferior. Al igual que con el tipo de instrucción de texto, puedes ajustar los parámetros del modelo para probar si ayudan a producir mejores resultados para tu caso de uso.\n\nRevisa cómo se envían ejemplos al modelo\n\nDe forma interna, Google AI Studio crea una instrucción combinando las instrucciones con los ejemplos que proporciones. A medida que agregues más ejemplos, estos se agregarán al texto enviado al modelo. Según la longitud de los ejemplos, puedes comenzar a alcanzar el límite de tokens del modelo. Todos los modelos de IA generativa tienen un límite de tokens, que es la longitud máxima del texto que pueden aceptar como entrada.\n\nPara ver el contenido completo de la instrucción, haz lo siguiente:\n\nSelecciona la vista previa del texto en la parte inferior de la aplicación web de Google AI Studio.\nNota: El límite de tokens del modelo se muestra en la parte inferior del panel de vista previa.\nPaso 4: Próximos pasos\n\nCuando estés conforme con el mensaje, puedes guardarlo o exportarlo al código con un clic en el botón Obtener código.\n\nTambién puedes exportar los ejemplos individuales de ejemplos limitados a un archivo CSV o a una hoja de cálculo de Google. Elige la opción Exportar ejemplos en el menú Acción para exportar tus ejemplos.\n\nEjemplo de instrucción de chat: Compila una aplicación de chat personalizada\n\nSi usaste un chatbot de uso general como Gemini, ya sabes de primera mano lo potentes que pueden ser los modelos de IA generativa para los diálogos abiertos. Si bien estos chatbots de uso general son útiles, a menudo deben adaptarse a casos prácticos particulares. Por ejemplo, es posible que desees compilar un chatbot de atención al cliente que solo admita conversaciones sobre el producto de una empresa. Se recomienda compilar un chatbot que hable con un tono o estilo particular, por ejemplo, un bot que haga muchas bromas, rime como un poeta o use muchos emojis en sus respuestas.\n\nEn este ejemplo, se muestra cómo usar Google AI Studio para compilar un chatbot amigable que se comunica como si fuera un extraterrestre que vive en una de las lunas de Júpiter, Europa.\n\nPaso 1: Crea un mensaje de chat\n\nEn la última sección, diseñaste una instrucción estructurada con una combinación de ejemplos de entrada y salida. De manera similar, para compilar un chatbot, debes proporcionar ejemplos de interacciones entre un usuario y el chatbot para guiar al modelo y proporcionar las respuestas que buscas.\n\nPara crear un mensaje de chat, sigue estos pasos:\n\nEn la esquina superior izquierda de la app web de Google AI Studio, selecciona Crear nuevo > Mensaje de chat.\n\nEn la columna Escribe tus ejemplos de instrucciones de la interfaz de instrucciones, puedes comenzar a proporcionar ejemplos de interacciones. También puedes proporcionar contexto adicional en el primer ejemplo, como los siguientes:\n\nUsuario: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModelo: none Ok\n\nEn los campos Usuario y Modelo, se proporciona un ejemplo de cómo se verían las interacciones entre un usuario y el chatbot:\n\nUsuario: none Hi!\n\nModelo: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nDespués de completar un ejemplo, comienza a probar tu aplicación chateando con el modelo en el panel derecho de la interfaz de instrucción de chat.\n\nPara probar el comportamiento del chatbot, haz lo siguiente:\n\nEn el panel Test your prompt, selecciona el campo de entrada en la parte inferior.\n\nEscribe una pregunta o una observación que pueda hacer un usuario, por ejemplo:\n\nUsuario: none What's the weather like?\n\nSelecciona el botón de diamante a la derecha del campo de entrada para obtener una respuesta del chatbot, que puede ser similar a la siguiente:\n\nModelo: none The weather on Europa is very cold and icy. ...\n\nPaso 2: Enséñale al bot a chatear mejor\n\nCuando proporcionaste una sola declaración y un ejemplo de respuesta, pudiste compilar un chatbot alien básico de Europa. Sin embargo, un solo ejemplo no suele ser suficiente para garantizar la coherencia y la calidad en las respuestas del modelo. Sin más entradas, la respuesta del modelo a una pregunta sobre el clima suele ser muy larga y parece que proviene de un libro de texto y no de un alienígena amigable.\n\nUsa la respuesta del modelo y edítala para que coincida con el tono y el estilo deseados de tu chatbot extraterrestre a fin de personalizar el tono.\n\nSi deseas agregar y editar ejemplos para la definición del chatbot, sigue estos pasos:\n\nEn el panel Test your prompt, mantén el cursor sobre el lado izquierdo del encabezado User (Usuario) y selecciona el botón Add to example (Agregar a ejemplos).\n\nEn la columna Escribe tus ejemplos de instrucciones, edita la entrada y la respuesta copiadas para que coincidan con el estilo y tono previstos de tu chatbot.\n\nPuedes usar este enfoque para agregar ejemplos adicionales. Haz más preguntas, edita las respuestas y mejora la calidad de tu chatbot. Agrega ejemplos y prueba cómo modifican el comportamiento del chatbot. Por lo general, más ejemplos corresponden a respuestas de chatbot de mayor calidad.\n\nDe forma interna, Google AI Studio construye una instrucción combinando lo siguiente:\n\nEjemplos de diálogo\nHistorial de conversaciones\n\nen un solo bloque de texto que se envía al modelo. Si deseas comprobar cómo se ve el mensaje completo, haz clic en Preview en la parte inferior de la pantalla para abrir el panel de vista previa.\n\nTen en cuenta que, debido a que cada mensaje entre el modelo y el usuario se incluye en la instrucción (este es el “historial de conversaciones”), los mensajes conversacionales pueden crecer durante mucho tiempo. Con el tiempo, puedes alcanzar el límite de tokens del modelo, la longitud máxima del texto que el modelo puede aceptar. Puedes ver la conversación completa y el recuento de tokens en la pestaña Preview.\n\nPaso 3: experimenta con los parámetros del modelo\n\nTambién puedes intentar ajustar los parámetros del modelo para ver si producen resultados más apropiados para tu caso de uso.\n\nPaso 4: Próximos pasos\n\nAl igual que los otros tipos de instrucciones, una vez que prototipes tus instrucciones de forma satisfactoria, puedes usar el botón Obtener código para comenzar a programar o guardar tu instrucción para trabajar en ella más tarde y compartirla con otras personas.\n\nLecturas adicionales\nSi estás listo para pasar al código, consulta las guías de inicio rápido de la API.\nPara aprender a crear mejores instrucciones, consulta los lineamientos para el diseño de instrucciones.\n¿Te resultó útil?\nEnviar comentarios\n\nSalvo que se indique lo contrario, el contenido de esta página está sujeto a la licencia Atribución 4.0 de Creative Commons, y los ejemplos de código están sujetos a la licencia Apache 2.0. Para obtener más información, consulta las políticas del sitio de Google Developers. Java es una marca registrada de Oracle o sus afiliados.\n\nÚltima actualización: 2024-04-22 (UTC)\n\nCondiciones\nPrivacidad",
            "word_count": 3056,
            "filtered_content": "Guía de inicio rápido de Google AI Studio \nGoogle AI Studio es un IDE basado en el navegador para el prototipado con modelos generativos. Google AI Studio permite probar modelos rápidamente y experimentar con distintas instrucciones. Cuando hayas compilado algo que te guste, puedes exportarlo al código en tu lenguaje de programación preferido, con la tecnología de la API de Gemini.\nGoogle AI Studio proporciona varias interfaces para instrucciones diseñadas para diferentes casos de uso:\nMensajes en formato libre: Estos mensajes ofrecen una experiencia de instrucciones abierta para generar contenido y respuestas a instrucciones. Puedes usar imágenes y datos de texto para tus instrucciones. Obtén más información.\nMensajes estructurados: Esta técnica de instrucciones te permite guiar la salida del modelo proporcionando un conjunto de solicitudes y respuestas de ejemplo. Usa este enfoque cuando necesites un mayor control sobre la estructura de la salida del modelo. Más información\nInstrucciones de chat: Usa instrucciones de chat para crear experiencias de conversación. Esta técnica de instrucción permite varios turnos de entrada y respuesta para generar resultados. Obtén más información.\nGoogle AI Studio también te permite cambiar el comportamiento de un modelo mediante una técnica llamada ajuste:\nModelo ajustado: Usa esta técnica avanzada para proporcionar más ejemplos a fin de mejorar las respuestas de un modelo para una tarea específica. Obtén más información.\nLas capacidades multimodales de Gemini te permiten indicar el modelo con una combinación de imágenes y texto. Por ejemplo, puedes usar esta función para obtener más información sobre un edificio que se muestra en una imagen.\nSigue estos pasos para crear una instrucción multimodal:\nNavega a Google AI Studio.\nEn el panel izquierdo, selecciona Crear nuevo > Instrucción de formato libre.\nEn el campo Modelo de la columna de la derecha, selecciona un modelo que admita imágenes, como el modelo Gemini Pro Vision.\nEn el área de texto de la instrucción, ingresa el siguiente texto:\nEn la barra Insertar que aparece sobre el área del mensaje, selecciona Imagen y elige una de las imágenes de muestra de un edificio.\nEn la parte inferior de la ventana de la app, selecciona Ejecutar para generar una respuesta a esta solicitud.\nEn el paso 1, le solicitaste al modelo una cadena fija de texto y una imagen. Sin embargo, a veces, deseas poder cambiar de forma dinámica partes de una instrucción. Por ejemplo, si compilas una aplicación interactiva, es posible que quieras modificar tu instrucción con diferentes entradas del usuario. Para ello, puedes parametrizar tus mensajes mediante variables.\nPara agregar variables a tus instrucciones, haz lo siguiente:\nSelecciona la palabra o frase que quieres reemplazar en la instrucción. En este caso, selecciona el texto: who is the architect.\nEn el encabezado Insert: que aparece sobre el mensaje, selecciona &lcub;&lcub; &rcub; Test input.\nEn la tabla Prueba tu instrucción que aparece debajo de la indicación, agrega un valor adicional a la indicación. Para ello, selecciona Agregar ejemplo de prueba y, luego, ingresa un valor de mensaje adicional. Siéntete libre de agregar varios valores de entrada nuevos.\nEn la parte inferior de la ventana de la app, selecciona Ejecutar a fin de generar una respuesta para cada una de las solicitudes variables.\nA medida que prototipas la instrucción, también puedes experimentar con la configuración de ejecución del modelo en el lado derecho de la aplicación. Estos son los parámetros de configuración clave que debes conocer:\nModelo: Selecciona el modelo que deseas que responda a tus instrucciones. Para obtener más información sobre los modelos y las capacidades disponibles, consulta Modelos.\nTemperatura: Controla cuánta aleatoriedad se permite en las respuestas del modelo. Aumentar este valor permite que el modelo produzca respuestas más inesperadas y creativas.\nCantidad máxima de resultados: aumenta la cantidad de respuestas que el modelo muestra para cada solicitud. Esta opción puede ser útil a fin de probar con rapidez los mensajes mediante la generación de varias respuestas para un solo mensaje.\nConfiguración de seguridad: ajusta la configuración de seguridad para administrar las respuestas de los modelos. Para obtener más detalles sobre estos controles, consulta la Configuración de seguridad.\nAhora que creaste un prototipo de una aplicación de IA generativa, puedes guardar tu trabajo o generar código para usar esta instrucción en tu propio entorno de desarrollo.\nPara guardar la instrucción que creaste, haz lo siguiente:\nEn la esquina superior derecha de la app de Google AI Studio, selecciona Guardar.\nConecta la app a tu cuenta de Google Drive, si aún no lo hiciste.\nEn el diálogo Save Prompt, ingresa un Prompt name y una Description opcional y, luego, selecciona Save.\nPara exportar la instrucción que creaste como código, haz lo siguiente:\nEn la esquina superior derecha de la app de Google AI Studio, selecciona Obtener código.\nSelecciona una pestaña de lenguaje de programación.\nSelecciona Copiar para copiar el código en el portapapeles.\nNota: Necesitas una clave de API para ejecutar el código de instrucción fuera de Google AI Studio, así que asegúrate de crear una clave y de incluirla en el código del mensaje.\nPrecaución: Trata tu clave de API como una contraseña y protégela de forma adecuada. No incorpores tu clave en un código publicado de forma pública.\nHasta ahora, has visto cómo puedes indicarle al modelo con una instrucción (look at the following picture and tell me who is the architect). Sin embargo, a veces, puedes obtener mejores resultados si le solicitas al modelo con una combinación de instrucciones y ejemplos. Las instrucciones estructuradas en Google AI Studio te ayudan a hacerlo: combinar instrucciones con ejemplos para mostrarle al modelo el tipo de resultado que deseas, en lugar de solo decirle qué hacer. Este tipo de instrucciones, llamada instrucciones con ejemplos limitados, es útil cuando deseas que el modelo mantenga un formato de salida coherente (es decir, JSON estructurado) o cuando es difícil describir con palabras lo que quieres (es decir, cuando es difícil describir con un estilo en particular). En esta sección, verás cómo crear instrucciones estructuradas en Google AI Studio.\nNota: Puedes probar este ejemplo directamente en Google AI Studio desde la galería de ejemplos.\nEn este ejemplo, crearás una instrucción estructurada que genere texto publicitario para los productos. Para comenzar, definirás la estructura de la instrucción creando dos columnas: una de entrada Product y una de salida Product copy.\nPara crear la instrucción estructurada, haz lo siguiente:\nEn la esquina superior izquierda de la app web de Google AI Studio, selecciona Crear nuevo > Instrucción estructurada.\nDebajo del encabezado Insert:, agrega las instrucciones para la instrucción estructurada:\nAgrega un encabezado descriptivo para la INPUT. Para ello, reemplaza la descripción de texto predeterminada input: por Product:.\nAgrega un encabezado descriptivo para SALIDA; para ello, reemplaza la descripción de texto predeterminada output: por Product copy:.\nSugerencia: Agrega dos puntos al final de los nombres de las columnas para facilitar que el modelo analice la estructura.\nAhora que le asignaste un nombre a tus columnas, proporciona algunas filas de ejemplo. Estas filas deben contener entradas de ejemplo (nombres de productos para este ejemplo) y resultados de ejemplo (descripciones de productos correspondientes). Si proporcionas al modelo un par de descripciones de productos de ejemplo, puedes guiarlo para que replique un estilo similar cuando genere sus propios resultados. Puedes ingresar ejemplos de forma manual o importarlos desde un archivo desde el menú Importar datos.\nPara ingresar ejemplos de forma manual, sigue estos pasos:\nEn la tabla de datos de los ejemplos principales, selecciona el campo debajo del encabezado Product: y escribe una descripción del producto.\nSelecciona el campo debajo del encabezado Product copy: y escribe texto de marketing para este producto.\nEste es un ejemplo de los valores de entrada y salida para esta instrucción:\nProducto:\tTexto del producto:\nCalzado tradicional\t¡Acordémonos! Estas zapatillas aportan un estilo emblemático y una paleta de colores única, además de ofrecer un estilo que te ayude a funcionar como ningún otro zapato.\nSudadera supersuave\tMantente cómodo y elegante con nuestra nueva sudadera unisex. Esta sudadera con capucha, hecha 100% algodón, es suave y cómoda de usarla todo el día. El interior semipulido te mantendrá abrigado incluso en los días más fríos.\nSugerencia: Si tienes un bloqueo de escritores o no tienes ejemplos de copias de productos a mano, puedes usar el mensaje en formato libre para que el modelo de texto genere algunos por ti.\nPara importar ejemplos desde un archivo:\nEn la esquina superior derecha de la tabla de ejemplos, selecciona Acciones > Importar ejemplos.\nEn el cuadro de diálogo, selecciona un archivo de Hojas de cálculo de Google o CSV en tu unidad de Google Drive, o bien súbelo desde tu computadora.\nEn el diálogo de ejemplos de importación, elige qué columnas importar y cuáles descartar. El diálogo también te permite especificar qué columna de datos importa a qué columna de la tabla en tu instrucción estructurada.\nUna vez que tengas los ejemplos que muestran el modelo lo que deseas, prueba tu instrucción con una entrada nueva en la tabla Prueba tu instrucción en la parte inferior. Al igual que con el tipo de instrucción de texto, puedes ajustar los parámetros del modelo para probar si ayudan a producir mejores resultados para tu caso de uso.\nRevisa cómo se envían ejemplos al modelo\nDe forma interna, Google AI Studio crea una instrucción combinando las instrucciones con los ejemplos que proporciones. A medida que agregues más ejemplos, estos se agregarán al texto enviado al modelo. Según la longitud de los ejemplos, puedes comenzar a alcanzar el límite de tokens del modelo. Todos los modelos de IA generativa tienen un límite de tokens, que es la longitud máxima del texto que pueden aceptar como entrada.\nPara ver el contenido completo de la instrucción, haz lo siguiente:\nSelecciona la vista previa del texto en la parte inferior de la aplicación web de Google AI Studio.\nNota: El límite de tokens del modelo se muestra en la parte inferior del panel de vista previa.\nCuando estés conforme con el mensaje, puedes guardarlo o exportarlo al código con un clic en el botón Obtener código.\nTambién puedes exportar los ejemplos individuales de ejemplos limitados a un archivo CSV o a una hoja de cálculo de Google. Elige la opción Exportar ejemplos en el menú Acción para exportar tus ejemplos.\nSi usaste un chatbot de uso general como Gemini, ya sabes de primera mano lo potentes que pueden ser los modelos de IA generativa para los diálogos abiertos. Si bien estos chatbots de uso general son útiles, a menudo deben adaptarse a casos prácticos particulares. Por ejemplo, es posible que desees compilar un chatbot de atención al cliente que solo admita conversaciones sobre el producto de una empresa. Se recomienda compilar un chatbot que hable con un tono o estilo particular, por ejemplo, un bot que haga muchas bromas, rime como un poeta o use muchos emojis en sus respuestas.\nEn este ejemplo, se muestra cómo usar Google AI Studio para compilar un chatbot amigable que se comunica como si fuera un extraterrestre que vive en una de las lunas de Júpiter, Europa.\nEn la última sección, diseñaste una instrucción estructurada con una combinación de ejemplos de entrada y salida. De manera similar, para compilar un chatbot, debes proporcionar ejemplos de interacciones entre un usuario y el chatbot para guiar al modelo y proporcionar las respuestas que buscas.\nPara crear un mensaje de chat, sigue estos pasos:\nEn la esquina superior izquierda de la app web de Google AI Studio, selecciona Crear nuevo > Mensaje de chat.\nEn la columna Escribe tus ejemplos de instrucciones de la interfaz de instrucciones, puedes comenzar a proporcionar ejemplos de interacciones. También puedes proporcionar contexto adicional en el primer ejemplo, como los siguientes:\nUsuario: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nModelo: none Ok\nEn los campos Usuario y Modelo, se proporciona un ejemplo de cómo se verían las interacciones entre un usuario y el chatbot:\nUsuario: none Hi!\nModelo: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\nDespués de completar un ejemplo, comienza a probar tu aplicación chateando con el modelo en el panel derecho de la interfaz de instrucción de chat.\nPara probar el comportamiento del chatbot, haz lo siguiente:\nEn el panel Test your prompt, selecciona el campo de entrada en la parte inferior.\nEscribe una pregunta o una observación que pueda hacer un usuario, por ejemplo:\nUsuario: none What's the weather like?\nSelecciona el botón de diamante a la derecha del campo de entrada para obtener una respuesta del chatbot, que puede ser similar a la siguiente:\nModelo: none The weather on Europa is very cold and icy. ...\nCuando proporcionaste una sola declaración y un ejemplo de respuesta, pudiste compilar un chatbot alien básico de Europa. Sin embargo, un solo ejemplo no suele ser suficiente para garantizar la coherencia y la calidad en las respuestas del modelo. Sin más entradas, la respuesta del modelo a una pregunta sobre el clima suele ser muy larga y parece que proviene de un libro de texto y no de un alienígena amigable.\nUsa la respuesta del modelo y edítala para que coincida con el tono y el estilo deseados de tu chatbot extraterrestre a fin de personalizar el tono.\nSi deseas agregar y editar ejemplos para la definición del chatbot, sigue estos pasos:\nEn el panel Test your prompt, mantén el cursor sobre el lado izquierdo del encabezado User (Usuario) y selecciona el botón Add to example (Agregar a ejemplos).\nEn la columna Escribe tus ejemplos de instrucciones, edita la entrada y la respuesta copiadas para que coincidan con el estilo y tono previstos de tu chatbot.\nPuedes usar este enfoque para agregar ejemplos adicionales. Haz más preguntas, edita las respuestas y mejora la calidad de tu chatbot. Agrega ejemplos y prueba cómo modifican el comportamiento del chatbot. Por lo general, más ejemplos corresponden a respuestas de chatbot de mayor calidad.\nDe forma interna, Google AI Studio construye una instrucción combinando lo siguiente:\nEjemplos de diálogo\nHistorial de conversaciones\nen un solo bloque de texto que se envía al modelo. Si deseas comprobar cómo se ve el mensaje completo, haz clic en Preview en la parte inferior de la pantalla para abrir el panel de vista previa.\nTen en cuenta que, debido a que cada mensaje entre el modelo y el usuario se incluye en la instrucción (este es el “historial de conversaciones”), los mensajes conversacionales pueden crecer durante mucho tiempo. Con el tiempo, puedes alcanzar el límite de tokens del modelo, la longitud máxima del texto que el modelo puede aceptar. Puedes ver la conversación completa y el recuento de tokens en la pestaña Preview.\nTambién puedes intentar ajustar los parámetros del modelo para ver si producen resultados más apropiados para tu caso de uso.\nAl igual que los otros tipos de instrucciones, una vez que prototipes tus instrucciones de forma satisfactoria, puedes usar el botón Obtener código para comenzar a programar o guardar tu instrucción para trabajar en ella más tarde y compartirla con otras personas.\nSi estás listo para pasar al código, consulta las guías de inicio rápido de la API.\nPara aprender a crear mejores instrucciones, consulta los lineamientos para el diseño de instrucciones.\nÚltima actualización: 2024-04-22 (UTC)",
            "filtered_word_count": 2537
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr": {
            "status": "Looks good",
            "content": "Produits\nExemples\nConnexion\nDocumentation\nDocument de référence de l'API\nVue d'ensemble\nPremiers pas\nObtenir une clé d'API\nGuide de démarrage rapide de l'API Gemini\nGuide de démarrage rapide de Google AI Studio\nTutoriels de démarrage\nModèles\nÀ propos des modèles génératifs\nGemini\nGemini API\nPrésentation de l'API\nDocumentation de référence des API\nVersions d'API\nNotes de version\nCapacités\nRéglage du modèle\nAppel de fonction\nReprésentations vectorielles continues\nSécurité\nGuides\nInvites\nInstructions système\nRécupération sémantique\nAuthentification OAuth\nExtensions Firebase\nMigrer vers le cloud\nTutoriels\nAppel de fonction\nReprésentations vectorielles continues\nApplications\nDépannage\nGuide de dépannage\nAccéder à AI Studio à l'aide de Workspace\nRésoudre les problèmes liés à AI Studio\nDemander plus de quotas\nCommunauté\nForum de Discourse\nAPI PaLM (ancienne version)\nMigrer vers Gemini\nDocumentation sur PaLM\nJuridique\nConditions d'utilisation\n(Preview) Conditions d'utilisation\nRégions disponibles\nSur cette page\nRequêtes et réglage du modèle\nExemple d'invite de forme libre: en savoir plus sur un bâtiment\nÉtape 1 : Créez une requête avec du texte et des images\nÉtape 2 : Ajoutez une variable remplaçable à l'invite\nÉtape 3 : Testez les paramètres du modèle\nÉtape 4 : Étapes suivantes\nExemple de requête structurée: créer un générateur de copie de produit\nÉtape 1 : Créez une requête structurée\nÉtape 2 : Ajoutez des exemples\nÉtape 3 : Testez votre invite\nÉtape 4 : Étapes suivantes\nExemple d'invite de chat: créer une application de chat personnalisée\nÉtape 1 : Créez une requête de chat\nÉtape 2 : Apprenez à votre bot à mieux discuter\nÉtape 3 : Testez les paramètres du modèle\nÉtape 4 : Étapes suivantes\nComplément d'informations\nDécouvrez le livre de recettes avec l'API Gemini et notre forum de la communauté.\n Cette page a été traduite par l'API Cloud Translation.\nGoogle AI for Developers\nProduits\nCe contenu vous a-t-il été utile ?\nEnvoyer des commentaires\nGuide de démarrage rapide de Google AI Studio \nbookmark_border\n\nGoogle AI Studio est un IDE basé sur navigateur qui permet de réaliser des prototypes à l'aide de modèles génératifs. Google AI Studio permet d'essayer des modèles et de tester différentes requêtes rapidement. Lorsque vous êtes satisfait de ce que vous avez créé, vous pouvez l'exporter vers le code dans le langage de programmation de votre choix, optimisé par l'API Gemini.\n\nRequêtes et réglage du modèle\n\nGoogle AI Studio fournit plusieurs interfaces pour les requêtes conçues pour différents cas d'utilisation:\n\nInvites de format libre : ces invites offrent une expérience de requête ouverte permettant de générer du contenu et des réponses aux instructions. Vous pouvez utiliser à la fois des images et des données textuelles pour vos requêtes. En savoir plus\n\nRequêtes structurées : cette technique de requête vous permet de guider la sortie du modèle en fournissant un ensemble d'exemples de requêtes et de réponses. Utilisez cette approche lorsque vous avez besoin de mieux contrôler la structure de sortie du modèle. En savoir plus\n\nInvites de chat : utilisez des invites de chat pour créer des expériences de conversation. Cette technique de requête permet plusieurs tours d'entrée et de réponse pour générer une sortie. En savoir plus\n\nGoogle AI Studio vous permet également de modifier le comportement d'un modèle à l'aide d'une technique appelée réglage:\n\nModèle réglé : utilisez cette technique avancée pour améliorer les réponses d'un modèle à une tâche spécifique en fournissant plus d'exemples. En savoir plus\nExemple d'invite de forme libre: en savoir plus sur un bâtiment\n\nLes fonctionnalités multimodales de Gemini vous permettent d'interroger le modèle avec une combinaison d'images et de texte. Par exemple, vous pouvez utiliser cette fonctionnalité pour en savoir plus sur un bâtiment représenté dans une image.\n\nÉtape 1 : Créez une requête avec du texte et des images\n\nPour créer une requête multimodale, procédez comme suit:\n\nAccédez à Google AI Studio.\nDans le panneau de gauche, sélectionnez Créer > Invite de forme libre.\nDans le champ Modèle de la colonne de droite, sélectionnez un modèle compatible avec les images, par exemple le modèle Gemini Pro Vision.\n\nDans la zone de texte de la requête, saisissez le texte suivant:\n\nlook at the following picture and tell me who is the architect\n\n\nDans la barre Insérer située au-dessus de la zone d'invite, sélectionnez Image, puis choisissez l'un des exemples d'images de bâtiment.\n\nEn bas de la fenêtre de l'application, sélectionnez Run (Exécuter) pour générer une réponse pour cette requête.\n\nÉtape 2 : Ajoutez une variable remplaçable à l'invite\n\nÀ l'étape 1, vous avez invité le modèle avec une chaîne de texte fixe et une image. Toutefois, vous souhaitez parfois pouvoir modifier certaines parties d'une requête de manière dynamique. Par exemple, si vous créez une application interactive, vous pouvez modifier votre requête avec différentes entrées utilisateur. Pour ce faire, vous pouvez paramétrer vos invites à l'aide de variables.\n\nPour ajouter des variables à vos requêtes:\n\nSélectionnez le mot ou l'expression que vous souhaitez remplacer dans votre requête. Dans ce cas, sélectionnez le texte: who is the architect.\nDans l'en-tête Insert: au-dessus de l'invite, sélectionnez &lcub;&lcub; &rcub;&rcub; Test input.\nDans le tableau Tester votre invite situé sous l'invite, ajoutez une valeur supplémentaire à votre invite en sélectionnant Ajouter un exemple de test et en saisissant une valeur supplémentaire. N'hésitez pas à ajouter plusieurs valeurs d'entrée.\nEn bas de la fenêtre de l'application, sélectionnez Run (Exécuter) pour générer une réponse pour chacune des différentes requêtes.\nÉtape 3 : Testez les paramètres du modèle\n\nPendant le prototypage de votre requête, vous pouvez également tester les paramètres d'exécution du modèle sur le côté droit de l'application. Voici les paramètres clés à connaître:\n\nModèle : sélectionnez le modèle auquel vous souhaitez répondre à vos invites. Pour en savoir plus sur les modèles et les fonctionnalités disponibles, consultez la page Modèles.\nTempérature : contrôlez le degré de hasard autorisé dans les réponses du modèle. Augmenter cette valeur permet au modèle de produire des réponses plus inattendues et créatives.\nNombre maximal de sorties : augmentez le nombre de réponses renvoyées par le modèle pour chaque requête. Cette option peut s'avérer utile pour tester rapidement les requêtes en générant plusieurs réponses pour une seule requête.\nParamètres de sécurité : ajustez les paramètres de sécurité pour gérer les réponses du modèle. Pour en savoir plus sur ces commandes, consultez la section Paramètres de sécurité.\nÉtape 4 : Étapes suivantes\n\nMaintenant que vous avez prototypé une application d'IA générative, vous pouvez enregistrer votre travail ou générer du code pour utiliser cette requête dans votre propre environnement de développement.\n\nPour enregistrer la requête que vous avez créée:\n\nEn haut à droite de l'application Google AI Studio, sélectionnez Enregistrer.\nConnectez l'application à votre compte Google Drive, si ce n'est pas déjà fait.\nDans la boîte de dialogue Enregistrer la requête, saisissez un nom de requête, une description facultative, puis sélectionnez Enregistrer.\n\nPour exporter la requête que vous avez créée sous forme de code:\n\nEn haut à droite de l'application Google AI Studio, sélectionnez Obtenir le code.\nSélectionnez l'onglet d'un langage de programmation.\nSélectionnez Copier pour copier le code dans le presse-papiers.\nRemarque:Vous avez besoin d'une clé API pour exécuter le code d'invite en dehors de Google AI Studio. Veillez donc à en créer une et à l'inclure dans votre code d'invite.\nAttention:Utilisez votre clé API comme un mot de passe et protégez-la de manière appropriée. N'intégrez pas votre clé dans du code public.\nExemple de requête structurée: créer un générateur de copie de produit\n\nJusqu'à présent, vous avez vu comment interroger votre modèle avec une instruction (look at the following picture and tell me who is the architect). Cependant, vous pouvez parfois obtenir de meilleurs résultats en invitant le modèle avec une combinaison d'instructions et d'exemples. Les requêtes structurées de Google AI Studio vous aident à le faire : combiner des instructions avec des exemples pour montrer au modèle le type de sortie souhaité, au lieu de simplement lui indiquer ce qu'il doit faire. Ce type de requête, appelé requête few-shot, est utile lorsque vous souhaitez que le modèle respecte un format de sortie cohérent (par exemple, JSON) ou qu'il est difficile de décrire ce que vous voulez dans un style structuré en particulier. Dans cette section, vous allez apprendre à créer des requêtes structurées dans Google AI Studio.\n\nRemarque :Vous pouvez essayer cet exemple directement dans Google AI Studio à partir de la galerie d'exemples.\nÉtape 1 : Créez une requête structurée\n\nDans cet exemple, vous allez créer une requête structurée qui génère du contenu publicitaire pour les produits. Pour commencer, vous allez définir la structure de l'invite en créant deux colonnes: une colonne d'entrée Product et une colonne de sortie Product copy.\n\nPour créer une requête structurée, procédez comme suit:\n\nEn haut à gauche de l'application Web Google AI Studio, sélectionnez Créer > Requête structurée.\n\nSous l'en-tête Insert:, ajoutez les instructions pour la requête structurée:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nAjoutez un en-tête descriptif pour l'INPUT en remplaçant la description textuelle input: par défaut par Product:.\n\nAjoutez un en-tête descriptif pour la valeur OUTPUT en remplaçant la description textuelle par défaut output: par Product copy:.\n\nConseil :Ajoutez des deux-points à la fin des noms de colonne pour permettre au modèle d'analyser plus facilement la structure.\nÉtape 2 : Ajoutez des exemples\n\nMaintenant que vous avez nommé vos colonnes, fournissez quelques exemples de lignes. Ces lignes doivent contenir des exemples d'entrées (noms de produits pour cet exemple) et des exemples de sorties (les descriptions de produits correspondantes). En fournissant au modèle quelques exemples de descriptions de produits, vous pouvez l'aider à reproduire un style similaire lors de la génération de ses propres résultats. Vous pouvez saisir des exemples manuellement ou les importer à partir d'un fichier à l'aide du menu \"Import Data\" (Importer des données).\n\nPour saisir manuellement des exemples:\n\nDans le tableau de données examples en haut, sélectionnez le champ situé sous l'en-tête Product: et saisissez une description du produit.\n\nSélectionnez le champ sous l'en-tête Product copy: (Texte du produit) et saisissez le contenu marketing de ce produit.\n\nVoici un exemple de valeurs d'entrée et de sortie pour cette requête:\n\nProduit :\tTexte pour le produit:\nBaskets à l'ancienne\tC'est parti ! Ces tenues de sport apportent un look emblématique et une palette de couleurs unique, tout en vous soutenant avec style et fonction comme aucune autre chaussure de sport auparavant.\nSweat à capuche super souple\tRestez confortable et élégant avec notre nouveau sweat à capuche unisexe ! Composé à 100% de coton, ce sweat à capuche est doux et confortable à porter toute la journée. Son intérieur semi-brossé vous tiendra chaud même les jours les plus froids.\n\nConseil :Si les rédacteurs bloquent ou n'ont pas d'exemples de textes de produit sous la main, vous pouvez utiliser l'invite de forme libre pour que le modèle de texte en génère pour vous.\n\nPour importer des exemples à partir d'un fichier:\n\nEn haut à droite du tableau Exemples, sélectionnez Actions > Importer des exemples.\n\nDans la boîte de dialogue, sélectionnez un fichier CSV ou Google Sheets dans votre Google Drive, ou importez-le à partir de votre ordinateur.\n\nDans la boîte de dialogue des exemples d'importation, choisissez les colonnes à importer et celles à exclure. La boîte de dialogue vous permet également de spécifier les colonnes de données à importer dans quelle colonne de table de votre requête structurée.\n\nÉtape 3 : Testez votre invite\n\nUne fois que vous disposez des exemples qui montrent ce que vous voulez au modèle, testez votre requête avec une nouvelle entrée dans le tableau Test your prompt (Tester votre invite) en bas de l'écran. Comme pour le type d'invite de texte, vous pouvez ajuster les paramètres de modèle pour vérifier s'ils permettent de générer de meilleurs résultats pour votre cas d'utilisation.\n\nExaminer comment les exemples sont envoyés au modèle\n\nEn arrière-plan, Google AI Studio construit une requête en combinant les instructions avec les exemples que vous fournissez. À mesure que vous ajoutez des exemples, ils sont ajoutés au texte envoyé au modèle. Selon la durée de vos exemples, vous pouvez commencer à atteindre la limite de jetons du modèle. Tous les modèles d'IA générative ont une limite de jetons, qui correspond à la longueur maximale du texte qu'ils peuvent accepter en entrée.\n\nPour afficher le contenu complet de votre requête:\n\nSélectionnez Text Preview (Aperçu du texte) en bas de l'application Web Google AI Studio.\nRemarque :La limite de jetons de modèle s'affiche en bas du volet d'aperçu.\nÉtape 4 : Étapes suivantes\n\nUne fois que vous êtes satisfait de votre invite, vous pouvez l'enregistrer ou l'exporter sous forme de code en cliquant sur le bouton Obtenir le code.\n\nVous pouvez également exporter les exemples few-shot individuels vers un fichier CSV ou une feuille Google Sheets. Pour exporter vos exemples, sélectionnez l'option Export samples (Exporter les exemples) dans le menu Action.\n\nExemple d'invite de chat: créer une application de chat personnalisée\n\nSi vous avez utilisé un chatbot à usage général comme Gemini, vous avez pu constater par vous-même à quel point les modèles d'IA générative peuvent être puissants pour les dialogues ouverts. Bien que ces chatbots à usage général soient utiles, ils doivent souvent être adaptés à des cas d'utilisation particuliers. Par exemple, vous souhaitez peut-être créer un chatbot de service client qui ne prend en charge que les conversations qui parlent du produit d'une entreprise. Vous voudrez peut-être créer un chatbot qui parle avec un ton ou un style particulier: un bot qui fait des blagues, des rimes comme un poète ou qui utilise beaucoup d'emoji dans ses réponses.\n\nCet exemple montre comment utiliser Google AI Studio pour créer un chatbot convivial qui communique comme s'il s'agissait d'un extraterrestre vivant sur Europe, l'une des lunes de Jupiter.\n\nÉtape 1 : Créez une requête de chat\n\nDans la dernière section, vous avez conçu une requête structurée à l'aide d'une combinaison d'exemples d'entrée et de sortie. De même, pour créer un chatbot, vous devez fournir des exemples d'interactions entre un utilisateur et le chatbot afin de guider le modèle et de fournir les réponses souhaitées.\n\nPour créer une requête de chat:\n\nEn haut à gauche de l'application Web Google AI Studio, sélectionnez Créer > Requête Chat.\n\nDans la colonne Écrire vos exemples de requête de l'interface de requête, vous pouvez commencer à fournir des exemples d'interactions. Vous pouvez également fournir du contexte supplémentaire dans le premier exemple, par exemple:\n\nUtilisateur : none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModel (Modèle) : none Ok\n\nLes champs User (Utilisateur) et Model (Modèle) fournissent des exemples de ce à quoi peuvent ressembler les interactions entre un utilisateur et votre chatbot:\n\nUtilisateur : none Hi!\n\nModel (Modèle) : none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nAprès avoir rempli un exemple, commencez à tester votre application en discutant avec le modèle dans le volet droit de l'interface de requête de chat.\n\nPour tester le comportement du chatbot, procédez comme suit:\n\nDans le panneau Tester votre invite, sélectionnez le champ de saisie en bas.\n\nSaisissez une question ou une observation qu'un utilisateur pourrait formuler. Par exemple:\n\nUtilisateur : none What's the weather like?\n\nSélectionnez le bouton en forme de losange situé à droite du champ de saisie pour obtenir une réponse du chatbot, qui peut se présenter comme suit:\n\nModel (Modèle) : none The weather on Europa is very cold and icy. ...\n\nÉtape 2 : Apprenez à votre bot à mieux discuter\n\nEn fournissant un exemple d'instruction et de réponse unique, vous avez pu créer un chatbot Europa extraterrestre de base. Toutefois, un seul exemple ne suffit généralement pas à garantir la cohérence et la qualité des réponses du modèle. Sans autre entrée, la réponse du modèle à une question sur la météo a tendance à être très longue et semble provenir d'un manuel plutôt que d'un extraterrestre sympathique.\n\nPersonnalisez le ton de votre chatbot en utilisant la réponse du modèle et en la modifiant pour qu'elle corresponde au ton et au style souhaités pour votre chatbot extraterrestre.\n\nPour ajouter et modifier des exemples pour la définition du chatbot:\n\nDans le panneau Tester votre invite, maintenez le curseur sur le côté gauche de l'en-tête Utilisateur, puis sélectionnez le bouton Ajouter aux exemples.\n\nDans la colonne Écrire vos exemples de requêtes, modifiez l'entrée et la réponse copiées pour qu'elles correspondent au style et au ton souhaités de votre chatbot.\n\nVous pouvez utiliser cette approche pour ajouter des exemples supplémentaires. Posez plus de questions, modifiez les réponses et améliorez la qualité de votre chatbot. Continuez à ajouter des exemples et testez comment ils modifient le comportement de votre chatbot. En général, plus d'exemples correspondent à des réponses de chatbot de meilleure qualité.\n\nEn arrière-plan, Google AI Studio élabore une requête en combinant les éléments suivants:\n\nExemples de boîtes de dialogue\nHistorique de la conversation\n\nen un seul bloc de texte envoyé au modèle. Pour voir à quoi ressemble l'invite complète, cliquez sur Preview (Aperçu) au bas de l'écran pour afficher le volet d'aperçu.\n\nNotez que chaque message entre le modèle et l'utilisateur est inclus dans l'invite (il s'agit de l'historique de la conversation). Par conséquent, les invites de conversation peuvent s'étendre assez longtemps à mesure qu'une conversation se poursuit. Vous pouvez à terme atteindre la limite de jetons du modèle, c'est-à-dire la longueur maximale du texte que le modèle peut accepter. Vous pouvez voir l'ensemble des conversations et le nombre de jetons dans l'onglet Preview (Aperçu).\n\nÉtape 3 : Testez les paramètres du modèle\n\nVous pouvez également essayer d'ajuster les paramètres du modèle pour voir s'ils produisent des résultats plus adaptés à votre cas d'utilisation.\n\nÉtape 4 : Étapes suivantes\n\nComme pour les autres types de requêtes, une fois que votre requête a été prototypée, vous pouvez utiliser le bouton Obtenir le code pour commencer à coder, ou enregistrer votre invite pour travailler plus tard et la partager avec d'autres utilisateurs.\n\nComplément d'informations\nSi vous êtes prêt à passer au code, consultez les guides de démarrage rapide de l'API.\nPour savoir comment créer de meilleures requêtes, consultez les consignes de conception des requêtes.\nCe contenu vous a-t-il été utile ?\nEnvoyer des commentaires\n\nSauf indication contraire, le contenu de cette page est régi par une licence Creative Commons Attribution 4.0, et les échantillons de code sont régis par une licence Apache 2.0. Pour en savoir plus, consultez les Règles du site Google Developers. Java est une marque déposée d'Oracle et/ou de ses sociétés affiliées.\n\nDernière mise à jour le 2024/04/22 (UTC).\n\nConditions d'utilisation\nRègles de confidentialité",
            "word_count": 3095,
            "filtered_content": "Guide de démarrage rapide de Google AI Studio \nGoogle AI Studio est un IDE basé sur navigateur qui permet de réaliser des prototypes à l'aide de modèles génératifs. Google AI Studio permet d'essayer des modèles et de tester différentes requêtes rapidement. Lorsque vous êtes satisfait de ce que vous avez créé, vous pouvez l'exporter vers le code dans le langage de programmation de votre choix, optimisé par l'API Gemini.\nGoogle AI Studio fournit plusieurs interfaces pour les requêtes conçues pour différents cas d'utilisation:\nInvites de format libre : ces invites offrent une expérience de requête ouverte permettant de générer du contenu et des réponses aux instructions. Vous pouvez utiliser à la fois des images et des données textuelles pour vos requêtes. En savoir plus\nRequêtes structurées : cette technique de requête vous permet de guider la sortie du modèle en fournissant un ensemble d'exemples de requêtes et de réponses. Utilisez cette approche lorsque vous avez besoin de mieux contrôler la structure de sortie du modèle. En savoir plus\nInvites de chat : utilisez des invites de chat pour créer des expériences de conversation. Cette technique de requête permet plusieurs tours d'entrée et de réponse pour générer une sortie. En savoir plus\nGoogle AI Studio vous permet également de modifier le comportement d'un modèle à l'aide d'une technique appelée réglage:\nModèle réglé : utilisez cette technique avancée pour améliorer les réponses d'un modèle à une tâche spécifique en fournissant plus d'exemples. En savoir plus\nLes fonctionnalités multimodales de Gemini vous permettent d'interroger le modèle avec une combinaison d'images et de texte. Par exemple, vous pouvez utiliser cette fonctionnalité pour en savoir plus sur un bâtiment représenté dans une image.\nPour créer une requête multimodale, procédez comme suit:\nAccédez à Google AI Studio.\nDans le panneau de gauche, sélectionnez Créer > Invite de forme libre.\nDans le champ Modèle de la colonne de droite, sélectionnez un modèle compatible avec les images, par exemple le modèle Gemini Pro Vision.\nDans la zone de texte de la requête, saisissez le texte suivant:\nDans la barre Insérer située au-dessus de la zone d'invite, sélectionnez Image, puis choisissez l'un des exemples d'images de bâtiment.\nEn bas de la fenêtre de l'application, sélectionnez Run (Exécuter) pour générer une réponse pour cette requête.\nÀ l'étape 1, vous avez invité le modèle avec une chaîne de texte fixe et une image. Toutefois, vous souhaitez parfois pouvoir modifier certaines parties d'une requête de manière dynamique. Par exemple, si vous créez une application interactive, vous pouvez modifier votre requête avec différentes entrées utilisateur. Pour ce faire, vous pouvez paramétrer vos invites à l'aide de variables.\nPour ajouter des variables à vos requêtes:\nSélectionnez le mot ou l'expression que vous souhaitez remplacer dans votre requête. Dans ce cas, sélectionnez le texte: who is the architect.\nDans l'en-tête Insert: au-dessus de l'invite, sélectionnez &lcub;&lcub; &rcub;&rcub; Test input.\nDans le tableau Tester votre invite situé sous l'invite, ajoutez une valeur supplémentaire à votre invite en sélectionnant Ajouter un exemple de test et en saisissant une valeur supplémentaire. N'hésitez pas à ajouter plusieurs valeurs d'entrée.\nEn bas de la fenêtre de l'application, sélectionnez Run (Exécuter) pour générer une réponse pour chacune des différentes requêtes.\nPendant le prototypage de votre requête, vous pouvez également tester les paramètres d'exécution du modèle sur le côté droit de l'application. Voici les paramètres clés à connaître:\nModèle : sélectionnez le modèle auquel vous souhaitez répondre à vos invites. Pour en savoir plus sur les modèles et les fonctionnalités disponibles, consultez la page Modèles.\nTempérature : contrôlez le degré de hasard autorisé dans les réponses du modèle. Augmenter cette valeur permet au modèle de produire des réponses plus inattendues et créatives.\nNombre maximal de sorties : augmentez le nombre de réponses renvoyées par le modèle pour chaque requête. Cette option peut s'avérer utile pour tester rapidement les requêtes en générant plusieurs réponses pour une seule requête.\nParamètres de sécurité : ajustez les paramètres de sécurité pour gérer les réponses du modèle. Pour en savoir plus sur ces commandes, consultez la section Paramètres de sécurité.\nMaintenant que vous avez prototypé une application d'IA générative, vous pouvez enregistrer votre travail ou générer du code pour utiliser cette requête dans votre propre environnement de développement.\nPour enregistrer la requête que vous avez créée:\nEn haut à droite de l'application Google AI Studio, sélectionnez Enregistrer.\nConnectez l'application à votre compte Google Drive, si ce n'est pas déjà fait.\nDans la boîte de dialogue Enregistrer la requête, saisissez un nom de requête, une description facultative, puis sélectionnez Enregistrer.\nPour exporter la requête que vous avez créée sous forme de code:\nEn haut à droite de l'application Google AI Studio, sélectionnez Obtenir le code.\nSélectionnez l'onglet d'un langage de programmation.\nSélectionnez Copier pour copier le code dans le presse-papiers.\nRemarque:Vous avez besoin d'une clé API pour exécuter le code d'invite en dehors de Google AI Studio. Veillez donc à en créer une et à l'inclure dans votre code d'invite.\nAttention:Utilisez votre clé API comme un mot de passe et protégez-la de manière appropriée. N'intégrez pas votre clé dans du code public.\nJusqu'à présent, vous avez vu comment interroger votre modèle avec une instruction (look at the following picture and tell me who is the architect). Cependant, vous pouvez parfois obtenir de meilleurs résultats en invitant le modèle avec une combinaison d'instructions et d'exemples. Les requêtes structurées de Google AI Studio vous aident à le faire : combiner des instructions avec des exemples pour montrer au modèle le type de sortie souhaité, au lieu de simplement lui indiquer ce qu'il doit faire. Ce type de requête, appelé requête few-shot, est utile lorsque vous souhaitez que le modèle respecte un format de sortie cohérent (par exemple, JSON) ou qu'il est difficile de décrire ce que vous voulez dans un style structuré en particulier. Dans cette section, vous allez apprendre à créer des requêtes structurées dans Google AI Studio.\nRemarque :Vous pouvez essayer cet exemple directement dans Google AI Studio à partir de la galerie d'exemples.\nDans cet exemple, vous allez créer une requête structurée qui génère du contenu publicitaire pour les produits. Pour commencer, vous allez définir la structure de l'invite en créant deux colonnes: une colonne d'entrée Product et une colonne de sortie Product copy.\nPour créer une requête structurée, procédez comme suit:\nEn haut à gauche de l'application Web Google AI Studio, sélectionnez Créer > Requête structurée.\nSous l'en-tête Insert:, ajoutez les instructions pour la requête structurée:\nAjoutez un en-tête descriptif pour l'INPUT en remplaçant la description textuelle input: par défaut par Product:.\nAjoutez un en-tête descriptif pour la valeur OUTPUT en remplaçant la description textuelle par défaut output: par Product copy:.\nConseil :Ajoutez des deux-points à la fin des noms de colonne pour permettre au modèle d'analyser plus facilement la structure.\nMaintenant que vous avez nommé vos colonnes, fournissez quelques exemples de lignes. Ces lignes doivent contenir des exemples d'entrées (noms de produits pour cet exemple) et des exemples de sorties (les descriptions de produits correspondantes). En fournissant au modèle quelques exemples de descriptions de produits, vous pouvez l'aider à reproduire un style similaire lors de la génération de ses propres résultats. Vous pouvez saisir des exemples manuellement ou les importer à partir d'un fichier à l'aide du menu \"Import Data\" (Importer des données).\nPour saisir manuellement des exemples:\nDans le tableau de données examples en haut, sélectionnez le champ situé sous l'en-tête Product: et saisissez une description du produit.\nSélectionnez le champ sous l'en-tête Product copy: (Texte du produit) et saisissez le contenu marketing de ce produit.\nVoici un exemple de valeurs d'entrée et de sortie pour cette requête:\nProduit :\tTexte pour le produit:\nBaskets à l'ancienne\tC'est parti ! Ces tenues de sport apportent un look emblématique et une palette de couleurs unique, tout en vous soutenant avec style et fonction comme aucune autre chaussure de sport auparavant.\nSweat à capuche super souple\tRestez confortable et élégant avec notre nouveau sweat à capuche unisexe ! Composé à 100% de coton, ce sweat à capuche est doux et confortable à porter toute la journée. Son intérieur semi-brossé vous tiendra chaud même les jours les plus froids.\nConseil :Si les rédacteurs bloquent ou n'ont pas d'exemples de textes de produit sous la main, vous pouvez utiliser l'invite de forme libre pour que le modèle de texte en génère pour vous.\nPour importer des exemples à partir d'un fichier:\nEn haut à droite du tableau Exemples, sélectionnez Actions > Importer des exemples.\nDans la boîte de dialogue, sélectionnez un fichier CSV ou Google Sheets dans votre Google Drive, ou importez-le à partir de votre ordinateur.\nDans la boîte de dialogue des exemples d'importation, choisissez les colonnes à importer et celles à exclure. La boîte de dialogue vous permet également de spécifier les colonnes de données à importer dans quelle colonne de table de votre requête structurée.\nUne fois que vous disposez des exemples qui montrent ce que vous voulez au modèle, testez votre requête avec une nouvelle entrée dans le tableau Test your prompt (Tester votre invite) en bas de l'écran. Comme pour le type d'invite de texte, vous pouvez ajuster les paramètres de modèle pour vérifier s'ils permettent de générer de meilleurs résultats pour votre cas d'utilisation.\nExaminer comment les exemples sont envoyés au modèle\nEn arrière-plan, Google AI Studio construit une requête en combinant les instructions avec les exemples que vous fournissez. À mesure que vous ajoutez des exemples, ils sont ajoutés au texte envoyé au modèle. Selon la durée de vos exemples, vous pouvez commencer à atteindre la limite de jetons du modèle. Tous les modèles d'IA générative ont une limite de jetons, qui correspond à la longueur maximale du texte qu'ils peuvent accepter en entrée.\nPour afficher le contenu complet de votre requête:\nSélectionnez Text Preview (Aperçu du texte) en bas de l'application Web Google AI Studio.\nRemarque :La limite de jetons de modèle s'affiche en bas du volet d'aperçu.\nUne fois que vous êtes satisfait de votre invite, vous pouvez l'enregistrer ou l'exporter sous forme de code en cliquant sur le bouton Obtenir le code.\nVous pouvez également exporter les exemples few-shot individuels vers un fichier CSV ou une feuille Google Sheets. Pour exporter vos exemples, sélectionnez l'option Export samples (Exporter les exemples) dans le menu Action.\nSi vous avez utilisé un chatbot à usage général comme Gemini, vous avez pu constater par vous-même à quel point les modèles d'IA générative peuvent être puissants pour les dialogues ouverts. Bien que ces chatbots à usage général soient utiles, ils doivent souvent être adaptés à des cas d'utilisation particuliers. Par exemple, vous souhaitez peut-être créer un chatbot de service client qui ne prend en charge que les conversations qui parlent du produit d'une entreprise. Vous voudrez peut-être créer un chatbot qui parle avec un ton ou un style particulier: un bot qui fait des blagues, des rimes comme un poète ou qui utilise beaucoup d'emoji dans ses réponses.\nCet exemple montre comment utiliser Google AI Studio pour créer un chatbot convivial qui communique comme s'il s'agissait d'un extraterrestre vivant sur Europe, l'une des lunes de Jupiter.\nDans la dernière section, vous avez conçu une requête structurée à l'aide d'une combinaison d'exemples d'entrée et de sortie. De même, pour créer un chatbot, vous devez fournir des exemples d'interactions entre un utilisateur et le chatbot afin de guider le modèle et de fournir les réponses souhaitées.\nPour créer une requête de chat:\nEn haut à gauche de l'application Web Google AI Studio, sélectionnez Créer > Requête Chat.\nDans la colonne Écrire vos exemples de requête de l'interface de requête, vous pouvez commencer à fournir des exemples d'interactions. Vous pouvez également fournir du contexte supplémentaire dans le premier exemple, par exemple:\nUtilisateur : none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nModel (Modèle) : none Ok\nLes champs User (Utilisateur) et Model (Modèle) fournissent des exemples de ce à quoi peuvent ressembler les interactions entre un utilisateur et votre chatbot:\nUtilisateur : none Hi!\nModel (Modèle) : none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\nAprès avoir rempli un exemple, commencez à tester votre application en discutant avec le modèle dans le volet droit de l'interface de requête de chat.\nPour tester le comportement du chatbot, procédez comme suit:\nDans le panneau Tester votre invite, sélectionnez le champ de saisie en bas.\nSaisissez une question ou une observation qu'un utilisateur pourrait formuler. Par exemple:\nUtilisateur : none What's the weather like?\nSélectionnez le bouton en forme de losange situé à droite du champ de saisie pour obtenir une réponse du chatbot, qui peut se présenter comme suit:\nModel (Modèle) : none The weather on Europa is very cold and icy. ...\nEn fournissant un exemple d'instruction et de réponse unique, vous avez pu créer un chatbot Europa extraterrestre de base. Toutefois, un seul exemple ne suffit généralement pas à garantir la cohérence et la qualité des réponses du modèle. Sans autre entrée, la réponse du modèle à une question sur la météo a tendance à être très longue et semble provenir d'un manuel plutôt que d'un extraterrestre sympathique.\nPersonnalisez le ton de votre chatbot en utilisant la réponse du modèle et en la modifiant pour qu'elle corresponde au ton et au style souhaités pour votre chatbot extraterrestre.\nPour ajouter et modifier des exemples pour la définition du chatbot:\nDans le panneau Tester votre invite, maintenez le curseur sur le côté gauche de l'en-tête Utilisateur, puis sélectionnez le bouton Ajouter aux exemples.\nDans la colonne Écrire vos exemples de requêtes, modifiez l'entrée et la réponse copiées pour qu'elles correspondent au style et au ton souhaités de votre chatbot.\nVous pouvez utiliser cette approche pour ajouter des exemples supplémentaires. Posez plus de questions, modifiez les réponses et améliorez la qualité de votre chatbot. Continuez à ajouter des exemples et testez comment ils modifient le comportement de votre chatbot. En général, plus d'exemples correspondent à des réponses de chatbot de meilleure qualité.\nEn arrière-plan, Google AI Studio élabore une requête en combinant les éléments suivants:\nExemples de boîtes de dialogue\nHistorique de la conversation\nen un seul bloc de texte envoyé au modèle. Pour voir à quoi ressemble l'invite complète, cliquez sur Preview (Aperçu) au bas de l'écran pour afficher le volet d'aperçu.\nNotez que chaque message entre le modèle et l'utilisateur est inclus dans l'invite (il s'agit de l'historique de la conversation). Par conséquent, les invites de conversation peuvent s'étendre assez longtemps à mesure qu'une conversation se poursuit. Vous pouvez à terme atteindre la limite de jetons du modèle, c'est-à-dire la longueur maximale du texte que le modèle peut accepter. Vous pouvez voir l'ensemble des conversations et le nombre de jetons dans l'onglet Preview (Aperçu).\nVous pouvez également essayer d'ajuster les paramètres du modèle pour voir s'ils produisent des résultats plus adaptés à votre cas d'utilisation.\nComme pour les autres types de requêtes, une fois que votre requête a été prototypée, vous pouvez utiliser le bouton Obtenir le code pour commencer à coder, ou enregistrer votre invite pour travailler plus tard et la partager avec d'autres utilisateurs.\nSi vous êtes prêt à passer au code, consultez les guides de démarrage rapide de l'API.\nPour savoir comment créer de meilleures requêtes, consultez les consignes de conception des requêtes.\nDernière mise à jour le 2024/04/22 (UTC).",
            "filtered_word_count": 2555
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id": {
            "status": "Looks good",
            "content": "Produk\nContoh\nMasuk\nDokumen\nReferensi API\nRingkasan\nMulai\nMendapatkan kunci API\nPanduan memulai Gemini API\nPanduan memulai Google AI Studio\nTutorial memulai\nModel\nTentang model generatif\nGemini\nGemini API\nRingkasan API\nReferensi API\nVersi API\nCatatan rilis\nKemampuan\nPenyesuaian model\nPanggilan fungsi\nEmbedding\nKeamanan\nPanduan\nMeminta\nPetunjuk sistem\nPengambilan semantik\nAutentikasi OAuth\nEkstensi Firebase\nBermigrasi ke Cloud\nTutorial\nPanggilan fungsi\nEmbedding\nAplikasi\nPemecahan masalah\nPanduan pemecahan masalah\nMengakses AI Studio menggunakan Workspace\nMemecahkan masalah AI Studio\nMeminta lebih banyak kuota\nKomunitas\nForum wacana\nPaLM API (lama)\nBermigrasi ke Gemini\nDokumen PaLM\nHukum\nPersyaratan layanan\nPersyaratan layanan (Pratinjau)\nRegion yang tersedia\nPada halaman ini\nPerintah dan penyesuaian model\nContoh perintah berformat bebas: Pelajari sebuah bangunan lebih lanjut\nLangkah 1 - Buat perintah dengan teks dan gambar\nLangkah 2 - Tambahkan variabel yang dapat diganti ke perintah\nLangkah 3 - Bereksperimen dengan parameter model\nLangkah 4 - Langkah berikutnya\nContoh perintah terstruktur: Membuat pembuat teks produk\nLangkah 1 - Buat perintah terstruktur\nLangkah 2 - Tambahkan contoh\nLangkah 3 - Uji perintah Anda\nLangkah 4 - Langkah berikutnya\nContoh perintah Chat: Membangun aplikasi chat kustom\nLangkah 1 - Buat perintah chat\nLangkah 2 - Ajari bot Anda untuk melakukan chat dengan lebih baik\nLangkah 3 - Bereksperimen dengan parameter model\nLangkah 4 - Langkah berikutnya\nBacaan lebih lanjut\nLihat Cookbook Gemini API baru dan forum komunitas kami.\n Halaman ini diterjemahkan oleh Cloud Translation API.\nGoogle AI for Developers\nProduk\nApakah informasi ini membantu?\nKirim masukan\nPanduan memulai Google AI Studio \nbookmark_border\n\nGoogle AI Studio adalah IDE berbasis browser untuk membuat prototipe dengan model generatif. Dengan Google AI Studio, Anda dapat dengan cepat mencoba model dan bereksperimen dengan berbagai perintah. Jika membuat sesuatu yang disukai, Anda dapat mengekspornya ke kode dalam bahasa pemrograman pilihan Anda, yang didukung oleh Gemini API.\n\nPerintah dan penyesuaian model\n\nGoogle AI Studio menyediakan beberapa antarmuka untuk prompt yang didesain untuk berbagai kasus penggunaan:\n\nPerintah berformat bebas - Perintah ini menawarkan pengalaman perintah yang bersifat terbuka untuk membuat konten dan respons terhadap petunjuk. Anda dapat menggunakan gambar dan data teks untuk perintah Anda. Pelajari lebih lanjut\n\nPerintah terstruktur - Teknik permintaan ini memungkinkan Anda memandu output model dengan memberikan serangkaian contoh permintaan dan balasan. Gunakan pendekatan ini saat Anda membutuhkan lebih banyak kontrol atas struktur output model. Pelajari lebih lanjut\n\nPerintah chat - Gunakan perintah chat untuk menciptakan pengalaman percakapan. Teknik prompting ini memungkinkan beberapa putaran input dan respons untuk menghasilkan output. Pelajari lebih lanjut\n\nGoogle AI Studio juga memungkinkan Anda mengubah perilaku model, menggunakan teknik yang disebut tuning:\n\nModel yang disesuaikan - Gunakan teknik lanjutan ini untuk meningkatkan respons model untuk tugas tertentu dengan memberikan lebih banyak contoh. Pelajari lebih lanjut\nContoh perintah berformat bebas: Pelajari sebuah bangunan lebih lanjut\n\nKemampuan multimodal Gemini memungkinkan Anda menjalankan perintah pada model dengan kombinasi gambar dan teks. Misalnya, Anda dapat menggunakan fitur ini untuk mempelajari lebih lanjut bangunan yang ditampilkan dalam gambar.\n\nLangkah 1 - Buat perintah dengan teks dan gambar\n\nUntuk membuat prompt multimodal:\n\nBuka Google AI Studio.\nDi panel kiri, pilih Create new > Freeform prompt.\nDi kolom Model sebelah kanan, pilih model yang mendukung gambar, seperti model Gemini Pro Vision.\n\nDi area teks perintah, masukkan teks berikut:\n\nlook at the following picture and tell me who is the architect\n\n\nDari panel Sisipkan di atas area perintah, pilih Gambar, lalu pilih salah satu contoh gambar bangunan.\n\nDi bagian bawah jendela aplikasi, pilih Run untuk membuat balasan untuk permintaan ini.\n\nLangkah 2 - Tambahkan variabel yang dapat diganti ke perintah\n\nPada langkah 1, Anda meminta model dengan string teks dan gambar tetap. Namun, terkadang, Anda ingin dapat mengubah bagian prompt secara dinamis. Misalnya, jika membangun aplikasi interaktif, Anda mungkin ingin mengubah perintah dengan input pengguna yang berbeda. Untuk itu, Anda dapat membuat parameter perintah menggunakan variabel.\n\nUntuk menambahkan variabel ke perintah Anda:\n\nPilih kata atau frasa yang ingin Anda ganti di perintah Anda. Dalam hal ini, pilih teks: who is the architect.\nDari header Insert: di atas dialog, pilih &lcub;&lcub; &rcub;&rcub; Test input.\nPada tabel Test your prompt di bawah perintah, tambahkan nilai tambahan untuk perintah Anda dengan memilih Add test example, lalu memasukkan nilai perintah tambahan. Jangan ragu untuk menambahkan beberapa nilai input baru.\nDi bagian bawah jendela aplikasi, pilih Run untuk membuat balasan bagi setiap berbagai permintaan.\nLangkah 3 - Bereksperimen dengan parameter model\n\nSaat membuat prototipe prompt, Anda juga dapat bermain-main dengan setelan run model di sisi kanan aplikasi. Berikut adalah setelan utama yang perlu diketahui:\n\nModel - Pilih model yang ingin Anda respons terhadap perintah Anda. Untuk mengetahui informasi selengkapnya tentang model dan kemampuan yang tersedia, baca Model.\nTemperature - Kontrol seberapa banyak keacakan yang diizinkan dalam respons model. Dengan meningkatkan nilai ini, model dapat menghasilkan lebih banyak respons yang tidak terduga dan kreatif.\nOutput maksimum - Tingkatkan jumlah respons yang ditampilkan model untuk setiap permintaan. Opsi ini dapat berguna untuk menguji perintah secara cepat dengan membuat beberapa respons untuk satu perintah.\nSetelan keamanan - Menyesuaikan setelan keamanan untuk mengelola respons model. Untuk detail selengkapnya tentang kontrol ini, lihat Setelan keamanan.\nLangkah 4 - Langkah berikutnya\n\nSetelah membuat prototipe aplikasi AI generatif, Anda dapat menyimpan pekerjaan atau membuat kode untuk menggunakan prompt ini di lingkungan pengembangan Anda sendiri.\n\nUntuk menyimpan perintah yang Anda buat:\n\nDi sudut kanan atas aplikasi Google AI Studio, pilih Simpan.\nHubungkan aplikasi ke akun Google Drive, jika Anda belum melakukannya.\nDalam dialog Save Prompt, masukkan Prompt name, Description opsional, lalu pilih Save.\n\nUntuk mengekspor perintah yang Anda buat sebagai kode:\n\nDi sudut kanan atas aplikasi Google AI Studio, pilih Dapatkan kode.\nPilih tab bahasa pemrograman.\nPilih Copy untuk menyalin kode ke papan klip.\nCatatan: Anda memerlukan kunci API untuk menjalankan kode prompt di luar Google AI Studio, jadi pastikan untuk membuat kunci dan menyertakannya bersama kode prompt Anda.\nPerhatian: Perlakukan kunci API Anda seperti sandi dan lindungi kunci API Anda dengan tepat. Jangan sematkan kunci Anda dalam kode yang dipublikasikan secara publik.\nContoh perintah terstruktur: Membuat pembuat teks produk\n\nSejauh ini, Anda telah melihat cara meminta perintah pada model dengan instruksi (look at the following picture and tell me who is the architect). Namun, terkadang Anda bisa mendapatkan hasil yang lebih baik dengan meminta model menggunakan kombinasi petunjuk dan contoh. Perintah terstruktur di Google AI Studio membantu Anda melakukan hal tersebut–menggabungkan petunjuk dengan contoh untuk menunjukkan jenis output yang Anda inginkan kepada model, bukan sekadar memberi tahu apa yang harus dilakukan. Jenis prompting ini, yang disebut few-shot prompting, berguna saat Anda ingin agar model tetap menggunakan format output yang konsisten (yaitu, model terstruktur dalam json). Di bagian ini, Anda akan mempelajari cara membuat perintah terstruktur di Google AI Studio.\n\nCatatan: Anda dapat mencoba contoh ini langsung di Google AI Studio dari galeri contoh.\nLangkah 1 - Buat perintah terstruktur\n\nDalam contoh ini, Anda akan membuat perintah terstruktur yang menghasilkan salinan iklan untuk produk. Untuk memulai, Anda akan menentukan struktur dialog dengan membuat dua kolom: kolom input Product dan kolom output Product copy.\n\nUntuk membuat prompt terstruktur:\n\nDi kiri atas aplikasi web Google AI Studio, pilih Create new > Structured prompt.\n\nDi bawah header Insert:, tambahkan petunjuk untuk dialog terstruktur:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nTambahkan header deskriptif untuk INPUT dengan mengganti deskripsi teks input: default dengan Product:.\n\nTambahkan header deskriptif untuk OUTPUT dengan mengganti deskripsi teks output: default dengan Product copy:.\n\nTips: Tambahkan titik dua di akhir nama kolom untuk memudahkan model mengurai struktur.\nLangkah 2 - Tambahkan contoh\n\nSetelah Anda menamai kolom, berikan beberapa contoh baris. Baris ini harus berisi contoh input (nama produk untuk contoh ini) dan contoh output (deskripsi produk yang sesuai). Dengan memberikan beberapa contoh deskripsi produk kepada model, Anda dapat memandunya untuk mereplikasi gaya serupa saat menghasilkan output-nya sendiri. Anda dapat memasukkan contoh secara manual atau mengimpor dari {i>file<i} menggunakan menu {i>import data<i}.\n\nUntuk memasukkan contoh secara manual:\n\nPada tabel data examples teratas, pilih kolom di bawah header Product: dan ketik deskripsi produk.\n\nPilih kolom di bawah header Product copy: dan teks pemasaran jenis untuk produk ini.\n\nBerikut adalah contoh nilai input dan output untuk prompt ini:\n\nProduk:\tSalinan produk:\nSepatu sneaker kuno\tMari kita kenakan talinya! Sepatu olahraga ini menghadirkan tampilan ikonik dan palet warna yang unik, sekaligus mendukung Anda dengan gaya dan fungsi yang berbeda dari sepatu sebelumnya.\nHoodie super lembut\tTetap nyaman dan bergaya dengan hoodie uniseks baru kami! Terbuat dari katun 100%, hoodie ini lembut dan nyaman dipakai sepanjang hari. Bagian dalamnya yang digosok akan membuat Anda tetap hangat bahkan di hari terdingin.\n\nTips: Jika penulis mengalami pemblokiran atau tidak memiliki contoh contoh salinan produk, Anda dapat menggunakan Perintah berformat bebas agar model teks membuat beberapa contoh untuk Anda.\n\nUntuk mengimpor contoh dari file:\n\nDi pojok kanan atas tabel examples, pilih Actions > Import examples.\n\nDalam dialog, pilih file CSV atau Google Spreadsheet di Google Drive Anda, atau upload dari komputer Anda.\n\nDalam dialog contoh impor, pilih kolom yang akan diimpor dan yang akan diabaikan. Dialog ini juga memungkinkan Anda menentukan kolom data mana yang diimpor ke kolom tabel mana dalam perintah terstruktur Anda.\n\nLangkah 3 - Uji perintah Anda\n\nSetelah Anda memiliki contoh yang menunjukkan model yang Anda inginkan, uji prompt Anda dengan input baru dalam tabel Test your prompt di bagian bawah. Seperti jenis perintah teks, Anda dapat menyesuaikan parameter model untuk menguji apakah parameter tersebut membantu memberikan hasil yang lebih baik untuk kasus penggunaan Anda atau tidak.\n\nMeninjau cara pengiriman contoh ke model\n\nPada prinsipnya, Google AI Studio membuat prompt dengan menggabungkan petunjuk dengan contoh yang Anda berikan. Saat Anda menambahkan contoh lainnya, nilai ini akan ditambahkan ke teks yang dikirim ke model. Bergantung pada durasi contoh, Anda dapat mulai mencapai batas token model. Semua model AI generatif memiliki batas token, yaitu panjang maksimum teks yang dapat diterima sebagai input.\n\nUntuk melihat konten lengkap perintah Anda:\n\nPilih Text preview di bagian bawah aplikasi web Google AI Studio.\nCatatan: Batas token model ditampilkan di bagian bawah panel pratinjau.\nLangkah 4 - Langkah berikutnya\n\nSetelah puas dengan perintah, Anda dapat memilih Simpan atau mengekspornya ke kode dengan mengklik tombol Dapatkan Kode.\n\nAnda juga dapat mengekspor contoh few-shot individual ke file CSV atau Google Spreadsheet. Pilih opsi Export examples di menu Action untuk mengekspor contoh Anda.\n\nContoh perintah Chat: Membangun aplikasi chat kustom\n\nJika Anda pernah menggunakan chatbot untuk tujuan umum seperti Gemini, Anda telah merasakan langsung betapa canggihnya model AI generatif untuk dialog terbuka. Meskipun chatbot tujuan umum ini berguna, sering kali perlu disesuaikan untuk kasus penggunaan tertentu. Misalnya, mungkin Anda ingin membuat chatbot layanan pelanggan yang hanya mendukung percakapan tentang produk perusahaan. Anda mungkin ingin membuat chatbot yang berbicara dengan nada atau gaya tertentu: bot yang memecahkan banyak lelucon, sajak seperti penyair, atau menggunakan banyak emoji dalam jawabannya.\n\nContoh ini menunjukkan cara menggunakan Google AI Studio untuk membuat chatbot ramah yang berkomunikasi seolah-olah ia adalah alien yang tinggal di salah satu bulan Jupiter, Europa.\n\nLangkah 1 - Buat perintah chat\n\nDi bagian terakhir, Anda telah mendesain prompt terstruktur menggunakan kombinasi contoh input dan output. Demikian pula, untuk membuat chatbot, Anda perlu memberikan contoh interaksi antara pengguna dan chatbot untuk memandu model guna memberikan respons yang Anda cari.\n\nUntuk membuat prompt chat:\n\nDi kiri atas aplikasi web Google AI Studio, pilih Create new > Chat prompt.\n\nDi kolom Tulis contoh perintah Anda di antarmuka perintah, Anda dapat mulai memberikan contoh interaksi. Anda juga dapat memberikan konteks tambahan dalam contoh pertama seperti:\n\nPengguna: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModel: none Ok\n\nDi kolom User dan Model, berikan contoh seperti apa interaksi antara pengguna dan chatbot Anda:\n\nPengguna: none Hi!\n\nModel: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nSetelah Anda mengisi contoh, mulai pengujian aplikasi Anda dengan melakukan chat dengan model di panel kanan antarmuka prompt chat.\n\nUntuk menguji perilaku chatbot:\n\nDi panel Test your prompt, pilih kolom input di bagian bawah.\n\nKetik pertanyaan atau pengamatan yang mungkin dilakukan pengguna, misalnya:\n\nPengguna: none What's the weather like?\n\nPilih tombol diamond di sebelah kanan kolom input untuk mendapatkan respons dari chatbot, yang mungkin tampak seperti berikut:\n\nModel: none The weather on Europa is very cold and icy. ...\n\nLangkah 2 - Ajari bot Anda untuk melakukan chat dengan lebih baik\n\nDengan memberikan satu pernyataan dan contoh respons, Anda dapat membuat chatbot alien Europa dasar. Namun, satu contoh biasanya tidak cukup untuk memastikan konsistensi dan kualitas respons model. Tanpa input lebih lanjut, respons model terhadap pertanyaan tentang cuaca cenderung sangat panjang, dan terdengar seperti berasal dari buku teks, bukan dari alien yang bersahabat.\n\nSesuaikan nuansa chatbot dengan respons model dan edit agar cocok dengan nuansa dan gaya chatbot alien yang diinginkan.\n\nUntuk menambahkan dan mengedit contoh definisi chatbot:\n\nDi panel Test your prompt, tahan kursor di sisi kiri judul User, lalu pilih tombol Add to examples.\n\nDi kolom Write your prompt examples, edit input dan respons yang disalin agar sesuai dengan gaya dan nuansa chatbot yang diinginkan.\n\nAnda dapat menggunakan pendekatan ini untuk menambahkan contoh lainnya. Ajukan lebih banyak pertanyaan, edit jawaban, dan tingkatkan kualitas chatbot Anda. Lanjutkan menambahkan contoh dan menguji bagaimana contoh tersebut mengubah perilaku chatbot Anda. Biasanya, contoh lainnya sesuai dengan respons chatbot berkualitas lebih tinggi.\n\nDi balik layar, Google AI Studio membuat perintah dengan menggabungkan:\n\nContoh dialog\nHistori percakapan\n\nmenjadi satu blok teks yang dikirim ke model. Untuk melihat tampilan permintaan lengkapnya, klik Preview di bagian bawah layar untuk membuka panel pratinjau.\n\nPerlu diperhatikan bahwa, karena setiap pesan antara model dan pengguna disertakan dalam perintah (ini adalah \"histori percakapan\"), perintah percakapan dapat berkembang cukup lama seiring berjalannya percakapan. Pada akhirnya, Anda dapat mencapai batas token model, yaitu panjang teks maksimum yang dapat diterima model. Anda dapat melihat percakapan lengkap dan jumlah token di tab Preview.\n\nLangkah 3 - Bereksperimen dengan parameter model\n\nAnda juga dapat mencoba menyesuaikan parameter model untuk melihat apakah parameter tersebut memberikan hasil yang lebih sesuai untuk kasus penggunaan Anda.\n\nLangkah 4 - Langkah berikutnya\n\nSerupa dengan jenis perintah lainnya, setelah prototipe selesai dibuat, Anda dapat menggunakan tombol Dapatkan Kode untuk memulai coding atau menyimpan perintah untuk dikerjakan nanti dan membagikannya kepada orang lain.\n\nBacaan lebih lanjut\nJika Anda sudah siap untuk mempelajari kode, lihat panduan memulai API.\nUntuk mempelajari cara membuat perintah yang lebih baik, lihat Panduan desain prompt.\nApakah informasi ini membantu?\nKirim masukan\n\nKecuali dinyatakan lain, konten di halaman ini dilisensikan berdasarkan Lisensi Creative Commons Attribution 4.0, sedangkan contoh kode dilisensikan berdasarkan Lisensi Apache 2.0. Untuk mengetahui informasi selengkapnya, lihat Kebijakan Situs Google Developers. Java adalah merek dagang terdaftar dari Oracle dan/atau afiliasinya.\n\nTerakhir diperbarui pada 2024-04-22 UTC.\n\nPersyaratan\nPrivasi",
            "word_count": 2441,
            "filtered_content": "Panduan memulai Google AI Studio \nGoogle AI Studio adalah IDE berbasis browser untuk membuat prototipe dengan model generatif. Dengan Google AI Studio, Anda dapat dengan cepat mencoba model dan bereksperimen dengan berbagai perintah. Jika membuat sesuatu yang disukai, Anda dapat mengekspornya ke kode dalam bahasa pemrograman pilihan Anda, yang didukung oleh Gemini API.\nGoogle AI Studio menyediakan beberapa antarmuka untuk prompt yang didesain untuk berbagai kasus penggunaan:\nPerintah berformat bebas - Perintah ini menawarkan pengalaman perintah yang bersifat terbuka untuk membuat konten dan respons terhadap petunjuk. Anda dapat menggunakan gambar dan data teks untuk perintah Anda. Pelajari lebih lanjut\nPerintah terstruktur - Teknik permintaan ini memungkinkan Anda memandu output model dengan memberikan serangkaian contoh permintaan dan balasan. Gunakan pendekatan ini saat Anda membutuhkan lebih banyak kontrol atas struktur output model. Pelajari lebih lanjut\nPerintah chat - Gunakan perintah chat untuk menciptakan pengalaman percakapan. Teknik prompting ini memungkinkan beberapa putaran input dan respons untuk menghasilkan output. Pelajari lebih lanjut\nGoogle AI Studio juga memungkinkan Anda mengubah perilaku model, menggunakan teknik yang disebut tuning:\nModel yang disesuaikan - Gunakan teknik lanjutan ini untuk meningkatkan respons model untuk tugas tertentu dengan memberikan lebih banyak contoh. Pelajari lebih lanjut\nKemampuan multimodal Gemini memungkinkan Anda menjalankan perintah pada model dengan kombinasi gambar dan teks. Misalnya, Anda dapat menggunakan fitur ini untuk mempelajari lebih lanjut bangunan yang ditampilkan dalam gambar.\nUntuk membuat prompt multimodal:\nBuka Google AI Studio.\nDi panel kiri, pilih Create new > Freeform prompt.\nDi kolom Model sebelah kanan, pilih model yang mendukung gambar, seperti model Gemini Pro Vision.\nDi area teks perintah, masukkan teks berikut:\nDari panel Sisipkan di atas area perintah, pilih Gambar, lalu pilih salah satu contoh gambar bangunan.\nDi bagian bawah jendela aplikasi, pilih Run untuk membuat balasan untuk permintaan ini.\nPada langkah 1, Anda meminta model dengan string teks dan gambar tetap. Namun, terkadang, Anda ingin dapat mengubah bagian prompt secara dinamis. Misalnya, jika membangun aplikasi interaktif, Anda mungkin ingin mengubah perintah dengan input pengguna yang berbeda. Untuk itu, Anda dapat membuat parameter perintah menggunakan variabel.\nUntuk menambahkan variabel ke perintah Anda:\nPilih kata atau frasa yang ingin Anda ganti di perintah Anda. Dalam hal ini, pilih teks: who is the architect.\nDari header Insert: di atas dialog, pilih &lcub;&lcub; &rcub;&rcub; Test input.\nPada tabel Test your prompt di bawah perintah, tambahkan nilai tambahan untuk perintah Anda dengan memilih Add test example, lalu memasukkan nilai perintah tambahan. Jangan ragu untuk menambahkan beberapa nilai input baru.\nDi bagian bawah jendela aplikasi, pilih Run untuk membuat balasan bagi setiap berbagai permintaan.\nSaat membuat prototipe prompt, Anda juga dapat bermain-main dengan setelan run model di sisi kanan aplikasi. Berikut adalah setelan utama yang perlu diketahui:\nModel - Pilih model yang ingin Anda respons terhadap perintah Anda. Untuk mengetahui informasi selengkapnya tentang model dan kemampuan yang tersedia, baca Model.\nTemperature - Kontrol seberapa banyak keacakan yang diizinkan dalam respons model. Dengan meningkatkan nilai ini, model dapat menghasilkan lebih banyak respons yang tidak terduga dan kreatif.\nOutput maksimum - Tingkatkan jumlah respons yang ditampilkan model untuk setiap permintaan. Opsi ini dapat berguna untuk menguji perintah secara cepat dengan membuat beberapa respons untuk satu perintah.\nSetelan keamanan - Menyesuaikan setelan keamanan untuk mengelola respons model. Untuk detail selengkapnya tentang kontrol ini, lihat Setelan keamanan.\nSetelah membuat prototipe aplikasi AI generatif, Anda dapat menyimpan pekerjaan atau membuat kode untuk menggunakan prompt ini di lingkungan pengembangan Anda sendiri.\nUntuk menyimpan perintah yang Anda buat:\nDi sudut kanan atas aplikasi Google AI Studio, pilih Simpan.\nHubungkan aplikasi ke akun Google Drive, jika Anda belum melakukannya.\nDalam dialog Save Prompt, masukkan Prompt name, Description opsional, lalu pilih Save.\nUntuk mengekspor perintah yang Anda buat sebagai kode:\nDi sudut kanan atas aplikasi Google AI Studio, pilih Dapatkan kode.\nPilih tab bahasa pemrograman.\nPilih Copy untuk menyalin kode ke papan klip.\nCatatan: Anda memerlukan kunci API untuk menjalankan kode prompt di luar Google AI Studio, jadi pastikan untuk membuat kunci dan menyertakannya bersama kode prompt Anda.\nPerhatian: Perlakukan kunci API Anda seperti sandi dan lindungi kunci API Anda dengan tepat. Jangan sematkan kunci Anda dalam kode yang dipublikasikan secara publik.\nSejauh ini, Anda telah melihat cara meminta perintah pada model dengan instruksi (look at the following picture and tell me who is the architect). Namun, terkadang Anda bisa mendapatkan hasil yang lebih baik dengan meminta model menggunakan kombinasi petunjuk dan contoh. Perintah terstruktur di Google AI Studio membantu Anda melakukan hal tersebut–menggabungkan petunjuk dengan contoh untuk menunjukkan jenis output yang Anda inginkan kepada model, bukan sekadar memberi tahu apa yang harus dilakukan. Jenis prompting ini, yang disebut few-shot prompting, berguna saat Anda ingin agar model tetap menggunakan format output yang konsisten (yaitu, model terstruktur dalam json). Di bagian ini, Anda akan mempelajari cara membuat perintah terstruktur di Google AI Studio.\nCatatan: Anda dapat mencoba contoh ini langsung di Google AI Studio dari galeri contoh.\nDalam contoh ini, Anda akan membuat perintah terstruktur yang menghasilkan salinan iklan untuk produk. Untuk memulai, Anda akan menentukan struktur dialog dengan membuat dua kolom: kolom input Product dan kolom output Product copy.\nUntuk membuat prompt terstruktur:\nDi kiri atas aplikasi web Google AI Studio, pilih Create new > Structured prompt.\nDi bawah header Insert:, tambahkan petunjuk untuk dialog terstruktur:\nTambahkan header deskriptif untuk INPUT dengan mengganti deskripsi teks input: default dengan Product:.\nTambahkan header deskriptif untuk OUTPUT dengan mengganti deskripsi teks output: default dengan Product copy:.\nTips: Tambahkan titik dua di akhir nama kolom untuk memudahkan model mengurai struktur.\nSetelah Anda menamai kolom, berikan beberapa contoh baris. Baris ini harus berisi contoh input (nama produk untuk contoh ini) dan contoh output (deskripsi produk yang sesuai). Dengan memberikan beberapa contoh deskripsi produk kepada model, Anda dapat memandunya untuk mereplikasi gaya serupa saat menghasilkan output-nya sendiri. Anda dapat memasukkan contoh secara manual atau mengimpor dari {i>file<i} menggunakan menu {i>import data<i}.\nUntuk memasukkan contoh secara manual:\nPada tabel data examples teratas, pilih kolom di bawah header Product: dan ketik deskripsi produk.\nPilih kolom di bawah header Product copy: dan teks pemasaran jenis untuk produk ini.\nBerikut adalah contoh nilai input dan output untuk prompt ini:\nProduk:\tSalinan produk:\nSepatu sneaker kuno\tMari kita kenakan talinya! Sepatu olahraga ini menghadirkan tampilan ikonik dan palet warna yang unik, sekaligus mendukung Anda dengan gaya dan fungsi yang berbeda dari sepatu sebelumnya.\nHoodie super lembut\tTetap nyaman dan bergaya dengan hoodie uniseks baru kami! Terbuat dari katun 100%, hoodie ini lembut dan nyaman dipakai sepanjang hari. Bagian dalamnya yang digosok akan membuat Anda tetap hangat bahkan di hari terdingin.\nTips: Jika penulis mengalami pemblokiran atau tidak memiliki contoh contoh salinan produk, Anda dapat menggunakan Perintah berformat bebas agar model teks membuat beberapa contoh untuk Anda.\nUntuk mengimpor contoh dari file:\nDi pojok kanan atas tabel examples, pilih Actions > Import examples.\nDalam dialog, pilih file CSV atau Google Spreadsheet di Google Drive Anda, atau upload dari komputer Anda.\nDalam dialog contoh impor, pilih kolom yang akan diimpor dan yang akan diabaikan. Dialog ini juga memungkinkan Anda menentukan kolom data mana yang diimpor ke kolom tabel mana dalam perintah terstruktur Anda.\nSetelah Anda memiliki contoh yang menunjukkan model yang Anda inginkan, uji prompt Anda dengan input baru dalam tabel Test your prompt di bagian bawah. Seperti jenis perintah teks, Anda dapat menyesuaikan parameter model untuk menguji apakah parameter tersebut membantu memberikan hasil yang lebih baik untuk kasus penggunaan Anda atau tidak.\nMeninjau cara pengiriman contoh ke model\nPada prinsipnya, Google AI Studio membuat prompt dengan menggabungkan petunjuk dengan contoh yang Anda berikan. Saat Anda menambahkan contoh lainnya, nilai ini akan ditambahkan ke teks yang dikirim ke model. Bergantung pada durasi contoh, Anda dapat mulai mencapai batas token model. Semua model AI generatif memiliki batas token, yaitu panjang maksimum teks yang dapat diterima sebagai input.\nUntuk melihat konten lengkap perintah Anda:\nPilih Text preview di bagian bawah aplikasi web Google AI Studio.\nCatatan: Batas token model ditampilkan di bagian bawah panel pratinjau.\nSetelah puas dengan perintah, Anda dapat memilih Simpan atau mengekspornya ke kode dengan mengklik tombol Dapatkan Kode.\nAnda juga dapat mengekspor contoh few-shot individual ke file CSV atau Google Spreadsheet. Pilih opsi Export examples di menu Action untuk mengekspor contoh Anda.\nJika Anda pernah menggunakan chatbot untuk tujuan umum seperti Gemini, Anda telah merasakan langsung betapa canggihnya model AI generatif untuk dialog terbuka. Meskipun chatbot tujuan umum ini berguna, sering kali perlu disesuaikan untuk kasus penggunaan tertentu. Misalnya, mungkin Anda ingin membuat chatbot layanan pelanggan yang hanya mendukung percakapan tentang produk perusahaan. Anda mungkin ingin membuat chatbot yang berbicara dengan nada atau gaya tertentu: bot yang memecahkan banyak lelucon, sajak seperti penyair, atau menggunakan banyak emoji dalam jawabannya.\nContoh ini menunjukkan cara menggunakan Google AI Studio untuk membuat chatbot ramah yang berkomunikasi seolah-olah ia adalah alien yang tinggal di salah satu bulan Jupiter, Europa.\nDi bagian terakhir, Anda telah mendesain prompt terstruktur menggunakan kombinasi contoh input dan output. Demikian pula, untuk membuat chatbot, Anda perlu memberikan contoh interaksi antara pengguna dan chatbot untuk memandu model guna memberikan respons yang Anda cari.\nUntuk membuat prompt chat:\nDi kiri atas aplikasi web Google AI Studio, pilih Create new > Chat prompt.\nDi kolom Tulis contoh perintah Anda di antarmuka perintah, Anda dapat mulai memberikan contoh interaksi. Anda juga dapat memberikan konteks tambahan dalam contoh pertama seperti:\nPengguna: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nDi kolom User dan Model, berikan contoh seperti apa interaksi antara pengguna dan chatbot Anda:\nPengguna: none Hi!\nSetelah Anda mengisi contoh, mulai pengujian aplikasi Anda dengan melakukan chat dengan model di panel kanan antarmuka prompt chat.\nUntuk menguji perilaku chatbot:\nDi panel Test your prompt, pilih kolom input di bagian bawah.\nKetik pertanyaan atau pengamatan yang mungkin dilakukan pengguna, misalnya:\nPengguna: none What's the weather like?\nPilih tombol diamond di sebelah kanan kolom input untuk mendapatkan respons dari chatbot, yang mungkin tampak seperti berikut:\nDengan memberikan satu pernyataan dan contoh respons, Anda dapat membuat chatbot alien Europa dasar. Namun, satu contoh biasanya tidak cukup untuk memastikan konsistensi dan kualitas respons model. Tanpa input lebih lanjut, respons model terhadap pertanyaan tentang cuaca cenderung sangat panjang, dan terdengar seperti berasal dari buku teks, bukan dari alien yang bersahabat.\nSesuaikan nuansa chatbot dengan respons model dan edit agar cocok dengan nuansa dan gaya chatbot alien yang diinginkan.\nUntuk menambahkan dan mengedit contoh definisi chatbot:\nDi panel Test your prompt, tahan kursor di sisi kiri judul User, lalu pilih tombol Add to examples.\nDi kolom Write your prompt examples, edit input dan respons yang disalin agar sesuai dengan gaya dan nuansa chatbot yang diinginkan.\nAnda dapat menggunakan pendekatan ini untuk menambahkan contoh lainnya. Ajukan lebih banyak pertanyaan, edit jawaban, dan tingkatkan kualitas chatbot Anda. Lanjutkan menambahkan contoh dan menguji bagaimana contoh tersebut mengubah perilaku chatbot Anda. Biasanya, contoh lainnya sesuai dengan respons chatbot berkualitas lebih tinggi.\nDi balik layar, Google AI Studio membuat perintah dengan menggabungkan:\nContoh dialog\nHistori percakapan\nmenjadi satu blok teks yang dikirim ke model. Untuk melihat tampilan permintaan lengkapnya, klik Preview di bagian bawah layar untuk membuka panel pratinjau.\nPerlu diperhatikan bahwa, karena setiap pesan antara model dan pengguna disertakan dalam perintah (ini adalah \"histori percakapan\"), perintah percakapan dapat berkembang cukup lama seiring berjalannya percakapan. Pada akhirnya, Anda dapat mencapai batas token model, yaitu panjang teks maksimum yang dapat diterima model. Anda dapat melihat percakapan lengkap dan jumlah token di tab Preview.\nAnda juga dapat mencoba menyesuaikan parameter model untuk melihat apakah parameter tersebut memberikan hasil yang lebih sesuai untuk kasus penggunaan Anda.\nSerupa dengan jenis perintah lainnya, setelah prototipe selesai dibuat, Anda dapat menggunakan tombol Dapatkan Kode untuk memulai coding atau menyimpan perintah untuk dikerjakan nanti dan membagikannya kepada orang lain.\nJika Anda sudah siap untuk mempelajari kode, lihat panduan memulai API.\nUntuk mempelajari cara membuat perintah yang lebih baik, lihat Panduan desain prompt.\nTerakhir diperbarui pada 2024-04-22 UTC.",
            "filtered_word_count": 1959
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it": {
            "status": "Looks good",
            "content": "Prodotti\nEsempi\nAccedi\nDocumenti\nRiferimento API\nPanoramica\nInizia\nOttieni una chiave API\nGuida rapida dell'API Gemini\nGuida rapida di Google AI Studio\nTutorial introduttivi\nModelli\nInformazioni sui modelli generativi\nGemini\nGemini API\nPanoramica dell'API\nRiferimento API\nVersioni API\nNote di rilascio\nFunzionalità\nOttimizzazione del modello\nChiamata di funzione\nIncorporamenti\nSicurezza\nGuide\nPrompt\nIstruzioni di sistema\nRecupero semantico\nAutenticazione OAuth\nEstensioni Firebase\nEsegui la migrazione a Cloud\nTutorial\nChiamata di funzione\nIncorporamenti\nApplicazioni\nRisoluzione dei problemi\nRisoluzione dei problemi\nAccedere ad AI Studio utilizzando Workspace\nRisoluzione dei problemi relativi ad AI Studio\nRichiedere una quota maggiore\ncommunity\nForum del discorso\nAPI PaLM (legacy)\nEsegui la migrazione a Gemini\nDocumenti PaLM\nLegale\nTermini di servizio\n(Anteprima) Termini di servizio\nAree geografiche disponibili\nSu questa pagina\nPrompt e ottimizzazione del modello\nEsempio di prompt in formato libero: scopri di più su un edificio\nPassaggio 1: crea un prompt con testo e immagini\nPassaggio 2: aggiungi una variabile sostituibile al prompt\nPassaggio 3 - Sperimenta i parametri del modello\nPassaggio 4 - Passaggi successivi\nEsempio di prompt strutturato: creare un generatore di testo per il prodotto\nPassaggio 1: crea un prompt strutturato\nPassaggio 2 - Aggiungi esempi\nPassaggio 3 - Testa la richiesta\nPassaggio 4 - Passaggi successivi\nEsempio di prompt di chat: creare un'applicazione di chat personalizzata\nPassaggio 1: crea un prompt di chat\nPassaggio 2: insegna al bot a chattare meglio\nPassaggio 3 - Sperimenta i parametri del modello\nPassaggio 4 - Passaggi successivi\nPer approfondire\nDai un'occhiata al nuovo Cookbook dell'API Gemini e al nostro forum della community.\n Questa pagina è stata tradotta dall'API Cloud Translation.\nGoogle AI for Developers\nProdotti\nQuesta pagina è stata utile?\nInvia feedback\nGuida rapida di Google AI Studio \nbookmark_border\n\nGoogle AI Studio è un IDE basato su browser per la prototipazione con modelli generativi. Google AI Studio consente di provare rapidamente i modelli e sperimentare vari prompt. Una volta creato qualcosa che ti soddisfa, puoi esportarlo in codice nel tuo linguaggio di programmazione preferito, basato sull'API Gemini.\n\nPrompt e ottimizzazione del modello\n\nGoogle AI Studio offre diverse interfacce per i prompt progettati per diversi casi d'uso:\n\nPrompt in formato libero: questi prompt offrono un'esperienza di prompt aperto per generare contenuti e risposte alle istruzioni. Puoi utilizzare sia immagini che dati di testo per i tuoi prompt. Scopri di più\n\nPrompt strutturati: questa tecnica di prompt ti consente di guidare l'output del modello fornendo un insieme di richieste e risposte di esempio. Usa questo approccio quando hai bisogno di un maggiore controllo sulla struttura dell'output del modello. Scopri di più\n\nPrompt di chat: utilizza i prompt di chat per creare esperienze di conversazione. Questa tecnica di prompt consente di generare output più volte con input e risposte. Scopri di più\n\nGoogle AI Studio ti consente anche di modificare il comportamento di un modello utilizzando una tecnica chiamata ottimizzazione:\n\nModello ottimizzato: utilizza questa tecnica avanzata per migliorare le risposte di un modello per un'attività specifica, fornendo un numero maggiore di esempi. Scopri di più\nEsempio di prompt in formato libero: scopri di più su un edificio\n\nLe abilità multimodali di Gemini consentono di richiedere al modello una combinazione di immagini e testo. Puoi usare questa funzionalità per scoprire di più su un edificio mostrato in un'immagine.\n\nPassaggio 1: crea un prompt con testo e immagini\n\nPer creare un prompt multimodale:\n\nVai a Google AI Studio.\nNel riquadro a sinistra, seleziona Crea nuovo > Prompt in formato libero.\nNel campo Modello della colonna a destra, seleziona un modello che supporti le immagini, ad esempio Gemini Pro Vision.\n\nNell'area di testo del prompt, inserisci il seguente testo:\n\nlook at the following picture and tell me who is the architect\n\n\nNella barra Inserisci sopra l'area del prompt, seleziona Immagine e scegli una delle immagini di esempio di un edificio.\n\nNella parte inferiore della finestra dell'app, seleziona Esegui per generare una risposta per questa richiesta.\n\nPassaggio 2: aggiungi una variabile sostituibile al prompt\n\nNel passaggio 1, hai richiesto al modello una stringa di testo fissa e un'immagine. Tuttavia, a volte vuoi essere in grado di modificare in modo dinamico le parti di un prompt. Ad esempio, se stai creando un'applicazione interattiva, potresti voler modificare il prompt con input utente diversi. Per questo, puoi parametrizzare le richieste utilizzando le variabili.\n\nPer aggiungere variabili ai prompt:\n\nSeleziona la parola o la frase da sostituire nel prompt. In questo caso, seleziona il testo: who is the architect.\nDall'intestazione Inserisci: sopra il prompt, seleziona &lcub;&lcub; &rcub;&rcub; Prova input.\nNella tabella Verifica il prompt sotto il prompt, aggiungi un valore aggiuntivo per il prompt selezionando Aggiungi esempio di test e inserendo un valore aggiuntivo per il prompt. Puoi aggiungere diversi nuovi valori di input.\nNella parte inferiore della finestra dell'app, seleziona Esegui per generare una risposta per ciascuna delle richieste variabili.\nPassaggio 3 - Sperimenta i parametri del modello\n\nDurante la prototipazione del prompt, puoi anche sperimentare le impostazioni di esecuzione del modello sul lato destro dell'applicazione. Queste sono le impostazioni principali da conoscere:\n\nModello: seleziona il modello che vuoi rispondere ai prompt. Per ulteriori informazioni sui modelli e sulle funzionalità disponibili, consulta Modelli.\nTemperatura: controlla la casualità consentita nelle risposte del modello. Questo valore consente al modello di produrre più risposte inaspettate e creative.\nOutput max: aumenta il numero di risposte che il modello restituisce per ogni richiesta. Questa opzione può essere utile per testare rapidamente i prompt generando più risposte per un singolo prompt.\nImpostazioni di sicurezza: regola le impostazioni di sicurezza per gestire le risposte del modello. Per maggiori dettagli su questi controlli, vedi Impostazioni di sicurezza.\nPassaggio 4 - Passaggi successivi\n\nOra che hai prototipato un'applicazione di IA generativa, puoi salvare il tuo lavoro o generare codice per utilizzare questo prompt nel tuo ambiente di sviluppo.\n\nPer salvare il prompt creato:\n\nNell'angolo in alto a destra dell'app Google AI Studio, seleziona Salva.\nCollega l'app al tuo account Google Drive, se non l'hai ancora fatto.\nNella finestra di dialogo Salva prompt, inserisci un Nome del prompt, una Descrizione facoltativa, quindi seleziona Salva.\n\nPer esportare il prompt che hai creato come codice:\n\nNell'angolo in alto a destra dell'app Google AI Studio, seleziona Genera codice.\nSeleziona la scheda di un linguaggio di programmazione.\nSeleziona Copia per copiare il codice negli appunti.\nNota: hai bisogno di una chiave API per eseguire il codice del prompt al di fuori di Google AI Studio, quindi assicurati di creare una chiave e includerla nel codice del prompt.\nAttenzione: tratta la chiave API come una password e proteggila in modo appropriato. Non incorporare la chiave nel codice pubblico.\nEsempio di prompt strutturato: creare un generatore di testo per il prodotto\n\nFinora hai visto come inviare al modello un prompt con un'istruzione (look at the following picture and tell me who is the architect). A volte, però, puoi ottenere risultati migliori richiedendo al modello una combinazione di istruzioni ed esempi. I prompt strutturati in Google AI Studio ti aiutano a farlo: combina le istruzioni con gli esempi per mostrare al modello il tipo di output che vuoi, anziché limitarsi a dirgli cosa fare. Questo tipo di prompt, chiamato prompting few-shot, è utile quando vuoi che il modello si attesti a un formato di output coerente (ad es. JSON strutturato) o quando è difficile descrivere un modello specifico. In questa sezione, vedremo come creare richieste strutturati in Google AI Studio.\n\nNota: puoi provare questo esempio direttamente in Google AI Studio dalla galleria di esempi.\nPassaggio 1: crea un prompt strutturato\n\nIn questo esempio, creerai un prompt strutturato che genera un testo pubblicitario per i prodotti. Per iniziare, definisci la struttura del prompt creando due colonne: una colonna di input Product e una colonna di output Product copy.\n\nPer creare il prompt strutturato:\n\nIn alto a sinistra nell'app web Google AI Studio, seleziona Crea nuovo > Prompt strutturato.\n\nSotto l'intestazione Inserisci:, aggiungi le istruzioni per la richiesta strutturata:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nAggiungi un'intestazione descrittiva per INPUT sostituendo la descrizione testuale input: predefinita con Product:.\n\nAggiungi un'intestazione descrittiva per l'elemento OUTPUT sostituendo la descrizione testuale output: predefinita con Product copy:.\n\nSuggerimento: aggiungi due punti alla fine dei nomi delle colonne per semplificare l'analisi della struttura da parte del modello.\nPassaggio 2 - Aggiungi esempi\n\nOra che hai assegnato un nome alle colonne, fornisci alcune righe di esempio. Queste righe devono contenere input di esempio (nomi dei prodotti per questo esempio) ed output di esempio (descrizioni dei prodotti corrispondenti). Fornendo al modello un paio di descrizioni di prodotto di esempio, puoi guidarlo a replicare uno stile simile durante la generazione dei propri output. Puoi inserire gli esempi manualmente o importarli da un file usando il menu Importa dati.\n\nPer inserire manualmente gli esempi:\n\nNella tabella di dati degli esempi in alto, seleziona il campo sotto l'intestazione Product: e digita una descrizione del prodotto.\n\nSeleziona il campo sotto l'intestazione Testo del prodotto: e digita testo di marketing per il prodotto.\n\nEcco un esempio di valori di input e di output per questo prompt:\n\nProdotto:\tTesto del prodotto:\nSneaker vecchia scuola\tAllacciate le cinture! Questi calzini conferiscono un look iconico e una tavolozza di colori unica, supportandoti allo stesso tempo nello stile e nella funzionalità come nessun'altra scarpa prima d'ora.\nFelpa con cappuccio super morbida\tComodo da indossare e alla moda con la nostra nuova felpa unisex con cappuccio! Realizzata al 100% in cotone, questa felpa con cappuccio è morbida e comoda da indossare tutto il giorno. L'interno, parzialmente spazzolato, ti terrà al caldo anche nei giorni più freddi.\n\nSuggerimento: se gli autori bloccano gli autori o non hai a disposizione esempi di testi di prodotto, puoi utilizzare il prompt in formato libero per fare in modo che il modello di testo generi alcuni per te.\n\nPer importare esempi da un file:\n\nNell'angolo in alto a destra della tabella examples, seleziona Azioni > Importa esempi.\n\nNella finestra di dialogo, seleziona un file CSV o Fogli Google su Google Drive oppure caricalo dal tuo computer.\n\nNella finestra di dialogo degli esempi di importazione, scegli quali colonne importare e quali escludere. La finestra di dialogo consente anche di specificare quali colonne di dati vengono importate in quale colonna della tabella del prompt strutturato.\n\nPassaggio 3 - Testa la richiesta\n\nUna volta ottenuti gli esempi che mostrano il modello, verifica il prompt con un nuovo input nella tabella Testare il prompt in basso. Come per il tipo di prompt testuale, puoi regolare i parametri del modello per verificare se consentono di produrre risultati migliori per il tuo caso d'uso.\n\nEsamina come gli esempi vengono inviati al modello\n\nDi base, Google AI Studio crea un prompt combinando le istruzioni con gli esempi che fornisci. Man mano che aggiungi altri esempi, questi vengono aggiunti al testo inviato al modello. A seconda della durata dei tuoi esempi, potresti iniziare a raggiungere il limite di token del modello. Tutti i modelli di IA generativa hanno un limite per token, che corrisponde alla lunghezza massima del testo che possono accettare come input.\n\nPer visualizzare il contenuto completo del prompt:\n\nSeleziona Anteprima testo nella parte inferiore dell'app web Google AI Studio.\nNota: il limite di token del modello è visualizzato nella parte inferiore del riquadro di anteprima.\nPassaggio 4 - Passaggi successivi\n\nQuando il prompt ti soddisfa, puoi salvarlo o esportarlo in codice facendo clic sul pulsante Acquisisci codice.\n\nPuoi anche esportare i singoli esempi di pochi scatti in un file CSV o in un foglio Google. Scegli l'opzione Esporta esempi dal menu Azione per esportare gli esempi.\n\nEsempio di prompt di chat: creare un'applicazione di chat personalizzata\n\nSe hai utilizzato un chatbot generico come Gemini , hai potuto conoscere in prima persona la potenza dei modelli di IA generativa per i dialoghi aperti. Sebbene questi chatbot generici siano utili, spesso devono essere adattati a casi d'uso particolari. Ad esempio, potresti voler creare un chatbot di assistenza clienti che supporti solo conversazioni che parlano del prodotto di un'azienda. Potresti voler creare un chatbot che parli con un tono o uno stile specifici: un bot che fa molte battute, che fa rima come un poeta o che utilizzi molte emoji nelle sue risposte.\n\nQuesto esempio mostra come utilizzare Google AI Studio per creare un chatbot simpatico che comunica come se fosse un alieno che vive su una delle lune di Giove, Europa.\n\nPassaggio 1: crea un prompt di chat\n\nNell'ultima sezione hai progettato un prompt strutturato utilizzando una combinazione di esempi di input e output. Analogamente, per creare un chatbot, devi fornire esempi di interazioni tra un utente e il chatbot per guidare il modello in modo che fornisca le risposte che cerchi.\n\nPer creare un prompt di chat:\n\nIn alto a sinistra nell'app web Google AI Studio, seleziona Crea nuovo > Prompt di chat.\n\nNella colonna Scrivi i tuoi esempi di prompt dell'interfaccia del prompt, puoi iniziare a fornire esempi di interazioni. Puoi anche fornire un contesto aggiuntivo nel primo esempio, ad esempio:\n\nUtente: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModello: none Ok\n\nNei campi Utente e Modello, fornisci un esempio di quale potrebbero essere le interazioni tra un utente e il tuo chatbot:\n\nUtente: none Hi!\n\nModello: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nDopo aver compilato un esempio, inizia a testare l'applicazione chattando con il modello nel riquadro a destra dell'interfaccia del prompt di chat.\n\nPer verificare il comportamento del chatbot:\n\nNel riquadro Verifica il prompt, seleziona il campo di immissione in basso.\n\nDigita una domanda o un'osservazione che un utente potrebbe fare, ad esempio:\n\nUtente: none What's the weather like?\n\nSeleziona il pulsante a forma di rombo a destra del campo di immissione per ricevere una risposta dal chatbot, che potrebbe essere simile alla seguente:\n\nModello: none The weather on Europa is very cold and icy. ...\n\nPassaggio 2: insegna al bot a chattare meglio\n\nFornendo un'unica dichiarazione e un singolo esempio di risposta, hai potuto creare un chatbot alieno di base Europa. Tuttavia, di solito un singolo esempio non è sufficiente per garantire coerenza e qualità delle risposte del modello. Senza ulteriori input, la risposta del modello a una domanda sul meteo tende a essere molto lunga e sembra essere tratta da un libro di testo anziché da un simpatico alieno.\n\nPersonalizza il tono del tuo chatbot utilizzando la risposta del modello e modificandola in base al tono e allo stile desiderati del tuo chatbot alieno.\n\nPer aggiungere e modificare esempi per la definizione del chatbot:\n\nNel riquadro Verifica il prompt, tieni il cursore sul lato sinistro dell'intestazione Utente e seleziona il pulsante Aggiungi agli esempi.\n\nNella colonna Scrivi i tuoi esempi di prompt, modifica l'input e la risposta copiati in modo che corrispondano allo stile e al tono previsti del tuo chatbot.\n\nPuoi utilizzare questo approccio per aggiungere altri esempi. Fai altre domande, modifica le risposte e migliora la qualità del tuo chatbot. Continua ad aggiungere esempi e a testare come modificano il comportamento del tuo chatbot. In genere, più esempi corrispondono a risposte del chatbot di qualità superiore.\n\nDi base, Google AI Studio crea un prompt combinando:\n\nEsempi di finestre di dialogo\nCronologia conversazione\n\nin un unico blocco di testo inviato al modello. Per vedere l'aspetto completo del prompt, fai clic su Anteprima nella parte inferiore dello schermo per aprire il riquadro di anteprima.\n\nTieni presente che, poiché ogni messaggio tra il modello e l'utente è incluso nel prompt (si tratta della \"cronologia conversazionale\"), i prompt di conversazione possono durare abbastanza a lungo man mano che una conversazione va avanti. Alla fine, potresti raggiungere il limite di token del modello, ovvero la lunghezza massima del testo che il modello può accettare. Puoi visualizzare la conversazione completa e il numero di token nella scheda Anteprima.\n\nPassaggio 3 - Sperimenta i parametri del modello\n\nPuoi anche provare a modificare i parametri del modello per vedere se producono risultati più appropriati per il tuo caso d'uso.\n\nPassaggio 4 - Passaggi successivi\n\nCome per gli altri tipi di prompt, una volta prototipato il prompt in base alle tue esigenze, puoi utilizzare il pulsante Genera codice per iniziare a programmare o salvare il prompt per lavorarci in un secondo momento e condividerlo con altri.\n\nPer approfondire\nSe è tutto pronto per passare al codice, consulta le guide rapide sulle API.\nPer scoprire come creare prompt migliori, consulta le linee guida per la progettazione dei prompt.\nQuesta pagina è stata utile?\nInvia feedback\n\nSalvo quando diversamente specificato, i contenuti di questa pagina sono concessi in base alla licenza Creative Commons Attribution 4.0, mentre gli esempi di codice sono concessi in base alla licenza Apache 2.0. Per ulteriori dettagli, consulta le norme del sito di Google Developers. Java è un marchio registrato di Oracle e/o delle sue consociate.\n\nUltimo aggiornamento 2024-04-22 UTC.\n\nTermini\nPrivacy",
            "word_count": 2815,
            "filtered_content": "Guida rapida di Google AI Studio \nGoogle AI Studio è un IDE basato su browser per la prototipazione con modelli generativi. Google AI Studio consente di provare rapidamente i modelli e sperimentare vari prompt. Una volta creato qualcosa che ti soddisfa, puoi esportarlo in codice nel tuo linguaggio di programmazione preferito, basato sull'API Gemini.\nGoogle AI Studio offre diverse interfacce per i prompt progettati per diversi casi d'uso:\nPrompt in formato libero: questi prompt offrono un'esperienza di prompt aperto per generare contenuti e risposte alle istruzioni. Puoi utilizzare sia immagini che dati di testo per i tuoi prompt. Scopri di più\nPrompt strutturati: questa tecnica di prompt ti consente di guidare l'output del modello fornendo un insieme di richieste e risposte di esempio. Usa questo approccio quando hai bisogno di un maggiore controllo sulla struttura dell'output del modello. Scopri di più\nPrompt di chat: utilizza i prompt di chat per creare esperienze di conversazione. Questa tecnica di prompt consente di generare output più volte con input e risposte. Scopri di più\nGoogle AI Studio ti consente anche di modificare il comportamento di un modello utilizzando una tecnica chiamata ottimizzazione:\nModello ottimizzato: utilizza questa tecnica avanzata per migliorare le risposte di un modello per un'attività specifica, fornendo un numero maggiore di esempi. Scopri di più\nLe abilità multimodali di Gemini consentono di richiedere al modello una combinazione di immagini e testo. Puoi usare questa funzionalità per scoprire di più su un edificio mostrato in un'immagine.\nPer creare un prompt multimodale:\nVai a Google AI Studio.\nNel riquadro a sinistra, seleziona Crea nuovo > Prompt in formato libero.\nNel campo Modello della colonna a destra, seleziona un modello che supporti le immagini, ad esempio Gemini Pro Vision.\nNell'area di testo del prompt, inserisci il seguente testo:\nNella barra Inserisci sopra l'area del prompt, seleziona Immagine e scegli una delle immagini di esempio di un edificio.\nNella parte inferiore della finestra dell'app, seleziona Esegui per generare una risposta per questa richiesta.\nNel passaggio 1, hai richiesto al modello una stringa di testo fissa e un'immagine. Tuttavia, a volte vuoi essere in grado di modificare in modo dinamico le parti di un prompt. Ad esempio, se stai creando un'applicazione interattiva, potresti voler modificare il prompt con input utente diversi. Per questo, puoi parametrizzare le richieste utilizzando le variabili.\nPer aggiungere variabili ai prompt:\nSeleziona la parola o la frase da sostituire nel prompt. In questo caso, seleziona il testo: who is the architect.\nDall'intestazione Inserisci: sopra il prompt, seleziona &lcub;&lcub; &rcub;&rcub; Prova input.\nNella tabella Verifica il prompt sotto il prompt, aggiungi un valore aggiuntivo per il prompt selezionando Aggiungi esempio di test e inserendo un valore aggiuntivo per il prompt. Puoi aggiungere diversi nuovi valori di input.\nNella parte inferiore della finestra dell'app, seleziona Esegui per generare una risposta per ciascuna delle richieste variabili.\nDurante la prototipazione del prompt, puoi anche sperimentare le impostazioni di esecuzione del modello sul lato destro dell'applicazione. Queste sono le impostazioni principali da conoscere:\nModello: seleziona il modello che vuoi rispondere ai prompt. Per ulteriori informazioni sui modelli e sulle funzionalità disponibili, consulta Modelli.\nTemperatura: controlla la casualità consentita nelle risposte del modello. Questo valore consente al modello di produrre più risposte inaspettate e creative.\nOutput max: aumenta il numero di risposte che il modello restituisce per ogni richiesta. Questa opzione può essere utile per testare rapidamente i prompt generando più risposte per un singolo prompt.\nImpostazioni di sicurezza: regola le impostazioni di sicurezza per gestire le risposte del modello. Per maggiori dettagli su questi controlli, vedi Impostazioni di sicurezza.\nOra che hai prototipato un'applicazione di IA generativa, puoi salvare il tuo lavoro o generare codice per utilizzare questo prompt nel tuo ambiente di sviluppo.\nPer salvare il prompt creato:\nNell'angolo in alto a destra dell'app Google AI Studio, seleziona Salva.\nCollega l'app al tuo account Google Drive, se non l'hai ancora fatto.\nNella finestra di dialogo Salva prompt, inserisci un Nome del prompt, una Descrizione facoltativa, quindi seleziona Salva.\nPer esportare il prompt che hai creato come codice:\nNell'angolo in alto a destra dell'app Google AI Studio, seleziona Genera codice.\nSeleziona la scheda di un linguaggio di programmazione.\nSeleziona Copia per copiare il codice negli appunti.\nNota: hai bisogno di una chiave API per eseguire il codice del prompt al di fuori di Google AI Studio, quindi assicurati di creare una chiave e includerla nel codice del prompt.\nAttenzione: tratta la chiave API come una password e proteggila in modo appropriato. Non incorporare la chiave nel codice pubblico.\nFinora hai visto come inviare al modello un prompt con un'istruzione (look at the following picture and tell me who is the architect). A volte, però, puoi ottenere risultati migliori richiedendo al modello una combinazione di istruzioni ed esempi. I prompt strutturati in Google AI Studio ti aiutano a farlo: combina le istruzioni con gli esempi per mostrare al modello il tipo di output che vuoi, anziché limitarsi a dirgli cosa fare. Questo tipo di prompt, chiamato prompting few-shot, è utile quando vuoi che il modello si attesti a un formato di output coerente (ad es. JSON strutturato) o quando è difficile descrivere un modello specifico. In questa sezione, vedremo come creare richieste strutturati in Google AI Studio.\nNota: puoi provare questo esempio direttamente in Google AI Studio dalla galleria di esempi.\nIn questo esempio, creerai un prompt strutturato che genera un testo pubblicitario per i prodotti. Per iniziare, definisci la struttura del prompt creando due colonne: una colonna di input Product e una colonna di output Product copy.\nPer creare il prompt strutturato:\nIn alto a sinistra nell'app web Google AI Studio, seleziona Crea nuovo > Prompt strutturato.\nSotto l'intestazione Inserisci:, aggiungi le istruzioni per la richiesta strutturata:\nAggiungi un'intestazione descrittiva per INPUT sostituendo la descrizione testuale input: predefinita con Product:.\nAggiungi un'intestazione descrittiva per l'elemento OUTPUT sostituendo la descrizione testuale output: predefinita con Product copy:.\nSuggerimento: aggiungi due punti alla fine dei nomi delle colonne per semplificare l'analisi della struttura da parte del modello.\nOra che hai assegnato un nome alle colonne, fornisci alcune righe di esempio. Queste righe devono contenere input di esempio (nomi dei prodotti per questo esempio) ed output di esempio (descrizioni dei prodotti corrispondenti). Fornendo al modello un paio di descrizioni di prodotto di esempio, puoi guidarlo a replicare uno stile simile durante la generazione dei propri output. Puoi inserire gli esempi manualmente o importarli da un file usando il menu Importa dati.\nPer inserire manualmente gli esempi:\nNella tabella di dati degli esempi in alto, seleziona il campo sotto l'intestazione Product: e digita una descrizione del prodotto.\nSeleziona il campo sotto l'intestazione Testo del prodotto: e digita testo di marketing per il prodotto.\nEcco un esempio di valori di input e di output per questo prompt:\nProdotto:\tTesto del prodotto:\nSneaker vecchia scuola\tAllacciate le cinture! Questi calzini conferiscono un look iconico e una tavolozza di colori unica, supportandoti allo stesso tempo nello stile e nella funzionalità come nessun'altra scarpa prima d'ora.\nFelpa con cappuccio super morbida\tComodo da indossare e alla moda con la nostra nuova felpa unisex con cappuccio! Realizzata al 100% in cotone, questa felpa con cappuccio è morbida e comoda da indossare tutto il giorno. L'interno, parzialmente spazzolato, ti terrà al caldo anche nei giorni più freddi.\nSuggerimento: se gli autori bloccano gli autori o non hai a disposizione esempi di testi di prodotto, puoi utilizzare il prompt in formato libero per fare in modo che il modello di testo generi alcuni per te.\nPer importare esempi da un file:\nNell'angolo in alto a destra della tabella examples, seleziona Azioni > Importa esempi.\nNella finestra di dialogo, seleziona un file CSV o Fogli Google su Google Drive oppure caricalo dal tuo computer.\nNella finestra di dialogo degli esempi di importazione, scegli quali colonne importare e quali escludere. La finestra di dialogo consente anche di specificare quali colonne di dati vengono importate in quale colonna della tabella del prompt strutturato.\nUna volta ottenuti gli esempi che mostrano il modello, verifica il prompt con un nuovo input nella tabella Testare il prompt in basso. Come per il tipo di prompt testuale, puoi regolare i parametri del modello per verificare se consentono di produrre risultati migliori per il tuo caso d'uso.\nEsamina come gli esempi vengono inviati al modello\nDi base, Google AI Studio crea un prompt combinando le istruzioni con gli esempi che fornisci. Man mano che aggiungi altri esempi, questi vengono aggiunti al testo inviato al modello. A seconda della durata dei tuoi esempi, potresti iniziare a raggiungere il limite di token del modello. Tutti i modelli di IA generativa hanno un limite per token, che corrisponde alla lunghezza massima del testo che possono accettare come input.\nPer visualizzare il contenuto completo del prompt:\nSeleziona Anteprima testo nella parte inferiore dell'app web Google AI Studio.\nNota: il limite di token del modello è visualizzato nella parte inferiore del riquadro di anteprima.\nQuando il prompt ti soddisfa, puoi salvarlo o esportarlo in codice facendo clic sul pulsante Acquisisci codice.\nPuoi anche esportare i singoli esempi di pochi scatti in un file CSV o in un foglio Google. Scegli l'opzione Esporta esempi dal menu Azione per esportare gli esempi.\nSe hai utilizzato un chatbot generico come Gemini , hai potuto conoscere in prima persona la potenza dei modelli di IA generativa per i dialoghi aperti. Sebbene questi chatbot generici siano utili, spesso devono essere adattati a casi d'uso particolari. Ad esempio, potresti voler creare un chatbot di assistenza clienti che supporti solo conversazioni che parlano del prodotto di un'azienda. Potresti voler creare un chatbot che parli con un tono o uno stile specifici: un bot che fa molte battute, che fa rima come un poeta o che utilizzi molte emoji nelle sue risposte.\nQuesto esempio mostra come utilizzare Google AI Studio per creare un chatbot simpatico che comunica come se fosse un alieno che vive su una delle lune di Giove, Europa.\nNell'ultima sezione hai progettato un prompt strutturato utilizzando una combinazione di esempi di input e output. Analogamente, per creare un chatbot, devi fornire esempi di interazioni tra un utente e il chatbot per guidare il modello in modo che fornisca le risposte che cerchi.\nPer creare un prompt di chat:\nIn alto a sinistra nell'app web Google AI Studio, seleziona Crea nuovo > Prompt di chat.\nNella colonna Scrivi i tuoi esempi di prompt dell'interfaccia del prompt, puoi iniziare a fornire esempi di interazioni. Puoi anche fornire un contesto aggiuntivo nel primo esempio, ad esempio:\nUtente: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nModello: none Ok\nNei campi Utente e Modello, fornisci un esempio di quale potrebbero essere le interazioni tra un utente e il tuo chatbot:\nUtente: none Hi!\nModello: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\nDopo aver compilato un esempio, inizia a testare l'applicazione chattando con il modello nel riquadro a destra dell'interfaccia del prompt di chat.\nPer verificare il comportamento del chatbot:\nNel riquadro Verifica il prompt, seleziona il campo di immissione in basso.\nDigita una domanda o un'osservazione che un utente potrebbe fare, ad esempio:\nUtente: none What's the weather like?\nSeleziona il pulsante a forma di rombo a destra del campo di immissione per ricevere una risposta dal chatbot, che potrebbe essere simile alla seguente:\nModello: none The weather on Europa is very cold and icy. ...\nFornendo un'unica dichiarazione e un singolo esempio di risposta, hai potuto creare un chatbot alieno di base Europa. Tuttavia, di solito un singolo esempio non è sufficiente per garantire coerenza e qualità delle risposte del modello. Senza ulteriori input, la risposta del modello a una domanda sul meteo tende a essere molto lunga e sembra essere tratta da un libro di testo anziché da un simpatico alieno.\nPersonalizza il tono del tuo chatbot utilizzando la risposta del modello e modificandola in base al tono e allo stile desiderati del tuo chatbot alieno.\nPer aggiungere e modificare esempi per la definizione del chatbot:\nNel riquadro Verifica il prompt, tieni il cursore sul lato sinistro dell'intestazione Utente e seleziona il pulsante Aggiungi agli esempi.\nNella colonna Scrivi i tuoi esempi di prompt, modifica l'input e la risposta copiati in modo che corrispondano allo stile e al tono previsti del tuo chatbot.\nPuoi utilizzare questo approccio per aggiungere altri esempi. Fai altre domande, modifica le risposte e migliora la qualità del tuo chatbot. Continua ad aggiungere esempi e a testare come modificano il comportamento del tuo chatbot. In genere, più esempi corrispondono a risposte del chatbot di qualità superiore.\nDi base, Google AI Studio crea un prompt combinando:\nEsempi di finestre di dialogo\nCronologia conversazione\nin un unico blocco di testo inviato al modello. Per vedere l'aspetto completo del prompt, fai clic su Anteprima nella parte inferiore dello schermo per aprire il riquadro di anteprima.\nTieni presente che, poiché ogni messaggio tra il modello e l'utente è incluso nel prompt (si tratta della \"cronologia conversazionale\"), i prompt di conversazione possono durare abbastanza a lungo man mano che una conversazione va avanti. Alla fine, potresti raggiungere il limite di token del modello, ovvero la lunghezza massima del testo che il modello può accettare. Puoi visualizzare la conversazione completa e il numero di token nella scheda Anteprima.\nPuoi anche provare a modificare i parametri del modello per vedere se producono risultati più appropriati per il tuo caso d'uso.\nCome per gli altri tipi di prompt, una volta prototipato il prompt in base alle tue esigenze, puoi utilizzare il pulsante Genera codice per iniziare a programmare o salvare il prompt per lavorarci in un secondo momento e condividerlo con altri.\nSe è tutto pronto per passare al codice, consulta le guide rapide sulle API.\nPer scoprire come creare prompt migliori, consulta le linee guida per la progettazione dei prompt.\nUltimo aggiornamento 2024-04-22 UTC.",
            "filtered_word_count": 2312
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl": {
            "status": "Looks good",
            "content": "Produkty\nPrzykłady\nZaloguj się\nDokumenty\nDokumentacja API\nPrzegląd\nRozpocznij\nUzyskiwanie klucza interfejsu API\nKrótkie wprowadzenie do interfejsu Gemini API\nKrótkie wprowadzenie do Google AI Studio\nSamouczki na początek\nModele\nInformacje o modelach generatywnych\nGemini\nGemini API\nPrzegląd interfejsów API\nDokumentacja API\nWersje interfejsu API\nInformacje o wersjach\nMożliwości\nDostrajanie modeli\nWywoływanie funkcji\nOsadzone elementy\nBezpieczeństwo\nPrzewodniki\nPrompt\nInstrukcje systemowe\nPobieranie semantyczne\nUwierzytelnianie OAuth\nRozszerzenia Firebase\nMigracja do Cloud\nSamouczki\nWywoływanie funkcji\nOsadzone elementy\nAplikacje\nRozwiązywanie problemów\nPrzewodnik rozwiązywania problemów\nDostęp do AI Studio za pomocą Workspace\nRozwiązywanie problemów z AI Studio\nZgłaszanie prośby o dodatkowy limit\nSpołeczność\nForum dyskusyjne\nPaLM API (starsza wersja)\nMigracja do Gemini\nDokumentacja PaLM\nLegal\nWarunki korzystania z usługi\n(Wersja testowa) Warunki korzystania z usługi\nRegiony, w których działa ta usługa\nNa tej stronie\nPrompty i dostrajanie modelu\nPrzykład promptu dowolnego: więcej informacji o budynku\nKrok 1. Utwórz prompt z tekstem i obrazami\nKrok 2. Dodaj do promptu zmienną wymienną\nKrok 3. Eksperymentuj z parametrami modelu\nKrok 4 – Dalsze kroki\nPrzykład uporządkowanych promptów: tworzenie generatora tekstów produktów\nKrok 1. Utwórz ustrukturyzowany prompt\nKrok 2. Dodaj przykłady\nKrok 3. Przetestuj prompt\nKrok 4 – Dalsze kroki\nPrzykład promptu na czacie: tworzenie niestandardowej aplikacji czatu\nKrok 1. Utwórz prompt na czacie\nKrok 2. Naucz swojego bota, jak lepiej czatować\nKrok 3. Eksperymentuj z parametrami modelu\nKrok 4 – Dalsze kroki\nWięcej informacji\nZapoznaj się z nową książką kucharską na temat interfejsu Gemini API i poznaj nasze forum społeczności.\n Ta strona została przetłumaczona przez Cloud Translation API.\nGoogle AI for Developers\nProdukty\nCzy te wskazówki były pomocne?\nPrześlij opinię\nKrótkie wprowadzenie do Google AI Studio \nbookmark_border\n\nGoogle AI Studio to środowisko IDE dostępne w przeglądarce, które umożliwia prototypowanie z użyciem modeli generatywnych. Google AI Studio pozwala szybko wypróbowywać modele i eksperymentować z różnymi promptami. Po utworzeniu elementu, który Ci się podoba, możesz go wyeksportować do kodu w preferowanym języku programowania, korzystając z interfejsu API Gemini.\n\nPrompty i dostrajanie modelu\n\nGoogle AI Studio udostępnia kilka interfejsów promptów przeznaczonych do różnych przypadków użycia:\n\nSwobodne prompty – są to otwarte prompty, które mogą służyć do generowania treści i odpowiedzi na instrukcje. W promptach możesz używać zarówno obrazów, jak i tekstów. Więcej informacji\n\nUporządkowane prompty – ta metoda promptów pozwala nakierować wynikiem modelu przez udostępnienie zestawu przykładowych żądań i odpowiedzi. Skorzystaj z tego podejścia, jeśli potrzebujesz większej kontroli nad strukturą danych wyjściowych modelu. Więcej informacji\n\nPotwierdzenia na czacie – używaj promptów na czacie, aby prowadzić rozmowy. Ta metoda promptów pozwala generować dane wyjściowe wielokrotnie z wykorzystaniem wielu cykli wprowadzania i odpowiedzi. Więcej informacji\n\nGoogle AI Studio umożliwia też zmianę działania modelu z użyciem metody nazywanej dostrajaniem:\n\nModel dostrojony – ta zaawansowana metoda służy do ulepszania odpowiedzi modelu w przypadku konkretnego zadania przez podanie większej liczby przykładów. Więcej informacji\nPrzykład promptu dowolnego: więcej informacji o budynku\n\nDzięki multimodalnym funkcjom Gemini model może zawierać zarówno obrazy, jak i tekst. Dzięki tej funkcji możesz na przykład dowiedzieć się więcej o budynku widocznym na zdjęciu.\n\nKrok 1. Utwórz prompt z tekstem i obrazami\n\nAby utworzyć multimodalny prompt:\n\nOtwórz Google AI Studio.\nW panelu po lewej stronie wybierz Utwórz nowy > Swobodny prompt.\nW polu Model w prawej kolumnie wybierz model, który obsługuje obrazy, na przykład model Gemini Pro Vision.\n\nW obszarze tekstowym promptu wpisz ten tekst:\n\nlook at the following picture and tell me who is the architect\n\n\nNa pasku Wstaw nad obszarem promptu kliknij Obraz i wybierz jedno z przykładowych zdjęć budynku.\n\nU dołu okna aplikacji kliknij Uruchom, aby wygenerować odpowiedź na to żądanie.\n\nKrok 2. Dodaj do promptu zmienną wymienną\n\nW kroku 1 poprosiłeś model o ustalony ciąg tekstu i obraz. Czasem warto jednak mieć możliwość dynamicznego zmieniania niektórych fragmentów promptów. Jeśli np. tworzysz aplikację interaktywną, możesz zmodyfikować prompt, dodając inne dane wejściowe użytkownika. W tym celu możesz określić parametry promptów za pomocą zmiennych.\n\nAby dodać zmienne do promptów:\n\nWybierz słowo lub wyrażenie, które chcesz zastąpić w prompcie. W tym przypadku zaznacz tekst: who is the architect.\nW nagłówku Insert: nad promptem wybierz &lcub;&lcub; &rcub;&rcub; Test wejściowych.\nW tabeli Testowanie promptu pod promptem dodaj dodatkową wartość promptu: wybierz Dodaj przykład testowy i wpisz dodatkową wartość promptu. Możesz dodać kilka nowych wartości wejściowych.\nU dołu okna aplikacji wybierz Uruchom, aby wygenerować odpowiedź dla każdego z różnych żądań.\nKrok 3. Eksperymentuj z parametrami modelu\n\nW trakcie tworzenia prototypu promptu możesz też eksperymentować z ustawieniami uruchamiania modelu po prawej stronie aplikacji. Oto najważniejsze ustawienia, o których warto wiedzieć:\n\nModel – wybierz model, który ma odpowiadać na prompty. Więcej informacji o dostępnych modelach i możliwościach znajdziesz w sekcji Modele.\nTemperatura – kontroluj, jak bardzo losowe odpowiedzi są dozwolone w odpowiedziach modelu. Zwiększenie tej wartości umożliwia modelowi generowanie bardziej nieoczekiwanych i kreatywnych odpowiedzi.\nMaksymalna liczba danych wyjściowych – zwiększ liczbę odpowiedzi zwracanych przez model dla każdego żądania. Ta opcja może być przydatna do szybkiego testowania promptów przez generowanie wielu odpowiedzi na 1 prompt.\nUstawienia bezpieczeństwa – możesz dostosować ustawienia bezpieczeństwa na potrzeby zarządzania odpowiedziami modelu. Więcej informacji o tych opcjach znajdziesz w sekcji Ustawienia zabezpieczeń.\nKrok 4 – Dalsze kroki\n\nPo utworzeniu prototypu aplikacji generatywnej AI możesz zapisać swoją pracę lub wygenerować kod do wykorzystania tego promptu w swoim środowisku programistycznym.\n\nAby zapisać utworzony prompt:\n\nW prawym górnym rogu aplikacji Google AI Studio kliknij Zapisz.\nPołącz aplikację z kontem Dysku Google, jeśli jeszcze nie jest z nią połączony.\nW oknie Zapisz prompt wpisz nazwę promptu i (opcjonalnie) opis, a następnie wybierz Zapisz.\n\nAby wyeksportować prompt utworzony jako kod:\n\nW prawym górnym rogu aplikacji Google AI Studio kliknij Pobierz kod.\nWybierz kartę języka programowania.\nKliknij Kopiuj, aby skopiować kod do schowka.\nUwaga: aby uruchomić kod promptu poza Google AI Studio, potrzebujesz klucza interfejsu API. Utwórz klucz i dodaj go do kodu promptu.\nUwaga: traktuj swój klucz interfejsu API jako hasło i odpowiednio go chroń. Nie umieszczaj swojego klucza w publicznie opublikowanym kodzie.\nPrzykład uporządkowanych promptów: tworzenie generatora tekstów produktów\n\nNa razie wiesz, jak wprowadzić do modelu instrukcję (look at the following picture and tell me who is the architect). Czasami możesz jednak uzyskać lepsze wyniki, sugerując model z kombinacją instrukcji i przykładów. Pomogą Ci w tym uporządkowane prompty w Google AI Studio – połącz instrukcje z przykładami, aby pokazać modelowi, jakiego rodzaju dane wyjściowe chcesz mieć, a nie tylko informowanie mu, co ma zrobić. Ten rodzaj promptów, zwany promptami typufew-shot, przydaje się, gdy model ma trzymać się stałego formatu wyjściowego (np. uporządkowanego pliku JSON) lub gdy trudno jest go opisać słowami. W tej sekcji dowiesz się, jak tworzyć uporządkowane prompty w Google AI Studio.\n\nUwaga: ten przykład możesz wypróbować bezpośrednio w Google AI Studio z galerii przykładów.\nKrok 1. Utwórz ustrukturyzowany prompt\n\nW tym przykładzie utworzysz ustrukturyzowany prompt generujący tekst reklamowy produktów. Najpierw zdefiniuj strukturę promptu, tworząc 2 kolumny: kolumnę wejściową Product i kolumnę wyjściową Product copy.\n\nAby utworzyć uporządkowany prompt:\n\nW lewym górnym rogu aplikacji internetowej Google AI Studio kliknij Utwórz nowy > Uporządkowany prompt.\n\nPod nagłówkiem Insert: dodaj instrukcje dotyczące promptu uporządkowanych:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nDodaj opisowy nagłówek do elementu INPUT, zastępując domyślny opis tekstowy input: wartością Product:.\n\nDodaj opisowy nagłówek dla parametru OUTPUT, zastępując domyślny opis tekstowy output: wartością Product copy:.\n\nWskazówka: dodaj dwukropki na końcu nazw kolumn, aby ułatwić modelowi analizę struktury.\nKrok 2. Dodaj przykłady\n\nPo nazwaniu kolumn sprawdź przykładowe wiersze. Powinny one zawierać przykładowe dane wejściowe (w tym przykładzie nazwy produktów) i przykładowe dane wyjściowe (odpowiadające im opisy produktów). Podając modelowi kilka przykładowych opisów produktów, możesz ukierunkować go na skopiowanie podobnego stylu podczas generowania własnych danych wyjściowych. Przykłady można wpisać ręcznie lub zaimportować z pliku, używając menu importu danych.\n\nAby ręcznie wpisać przykłady:\n\nW tabeli danych przykładowe u góry wybierz pole pod nagłówkiem Produkt: i wpisz opis produktu.\n\nWybierz pole pod nagłówkiem Tekst produktu: i wpisz dla niego tekst marketingowy tej usługi.\n\nOto przykład wartości wejściowych i wyjściowych dla tego promptu:\n\nUsługa:\tOpis produktu:\nTrampki w stylu retro\tCzas na sznurowanie! Te buty dają kultowy wygląd i wyjątkową paletę kolorów, jednocześnie dbając o Twój styl i funkcjonalność.\nSupermiękka bluza z kapturem\tCiesz się przytulnym i stylowym wyglądem naszej nowej bluzy uniseks z kapturem. Ta bluza z kapturem jest wykonana w 100% z bawełny, jest miękka i wygodna. Można ją nosić przez cały dzień. Częściowo szczotkowane wnętrze zapewni Ci ciepło nawet w najchłodniejsze dni.\n\nWskazówka: jeśli masz blokadę autorów lub nie masz przygotowanych przykładowych tekstów usługi, możesz użyć opcji Swobodny prompt, aby model tekstowy wygenerował dla Ciebie odpowiedni tekst.\n\nAby zaimportować przykłady z pliku:\n\nW prawym górnym rogu tabeli przykłady kliknij Działania > Importuj przykłady.\n\nW oknie dialogowym wybierz plik CSV lub Arkusze Google na Dysku Google albo prześlij go z komputera.\n\nW oknie z przykładami importu wybierz kolumny, które chcesz zaimportować, a które pominąć. Okno pozwala też określić, która kolumna danych ma być importowana do której kolumny tabeli w uporządkowanym promptie.\n\nKrok 3. Przetestuj prompt\n\nGdy uzyskasz przykłady, które pokazują odpowiedni model, sprawdź prompt z użyciem nowych danych wejściowych w tabeli Przetestuj prompt u dołu. Podobnie jak w przypadku typu promptu tekstowego, możesz dostosowywać parametry modelu, aby sprawdzić, czy pomagają uzyskać lepsze wyniki w Twoim przypadku.\n\nSprawdzanie sposobu przesyłania przykładów do modelu\n\nNajpierw Google AI Studio tworzy prompt, łącząc instrukcje z przesłanymi przez Ciebie przykładami. W miarę dodawania kolejnych przykładów będą one dodawane do tekstu wysyłanego do modelu. W zależności od tego, jak długie są przykłady, możesz zacząć zbliżać się do limitu tokenów modelu. Wszystkie modele generatywnej AI mają limit tokenów, czyli maksymalną długość tekstu, które mogą zaakceptować jako dane wejściowe.\n\nAby zobaczyć pełną treść promptu:\n\nU dołu aplikacji internetowej Google AI Studio wybierz Podgląd tekstu.\nUwaga: limit tokenów modelu jest wyświetlany u dołu okienka podglądu.\nKrok 4 – Dalsze kroki\n\nGdy prompt będzie gotowy, możesz go zapisać lub wyeksportować do kodu, klikając przycisk Pobierz kod.\n\nMożesz też wyeksportować poszczególne przykłady kilku zdjęć do pliku CSV lub Arkuszy Google. Aby wyeksportować przykłady, w menu Działanie wybierz opcję Eksportuj przykłady.\n\nPrzykład promptu na czacie: tworzenie niestandardowej aplikacji czatu\n\nJeśli korzystasz z czatbota ogólnego przeznaczenia, takiego jak Gemini, przekonasz się na własne oczy, jak wydajne mogą być modele generatywnej AI w przypadku otwartego dialogu. Czatboty te są przydatne, ale często muszą być dostosowane do konkretnych przypadków użycia. Możesz np. utworzyć czatbota do obsługi klienta, który będzie obsługiwać tylko rozmowy o produkcie firmy. Dobrym pomysłem może być stworzenie czatbota, który będzie mówił o konkretnym tonie lub stylu – np. niszczy mnóstwo żartów, rymuje się jak poeta albo używa wielu emotikonów w odpowiedziach.\n\nTen przykład pokazuje, jak za pomocą Google AI Studio zbudować przyjazny czatbot, który komunikuje się tak, jakby to kosmita żyjący na jednym z księżyców Jowisza – Europy.\n\nKrok 1. Utwórz prompt na czacie\n\nW ostatniej sekcji zaprojektowaliśmy uporządkowany prompt, używając kombinacji przykładów danych wejściowych i wyjściowych. Podobnie, aby utworzyć czatbota, musisz podać przykłady interakcji między użytkownikiem a czatbotem, aby pokierować modelem do odpowiedzi, których szukasz.\n\nAby utworzyć prompt na czacie:\n\nW lewym górnym rogu aplikacji internetowej Google AI Studio kliknij Utwórz nowy > Wiadomość od Google Chat.\n\nPrzykłady interakcji możesz zacząć podawać w kolumnie Wpisz przykłady promptów w interfejsie. W pierwszym przykładzie możesz też podać dodatkowy kontekst, na przykład:\n\nUżytkownik: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModel: none Ok\n\nW polach Użytkownik i Model widać, jak mogą wyglądać interakcje między użytkownikiem a czatbotem:\n\nUżytkownik: none Hi!\n\nModel: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nGdy podasz już przykład, zacznij testować swoją aplikację, rozmawiając z modelem w prawym panelu interfejsu promptu na czacie.\n\nAby przetestować działanie czatbota:\n\nU dołu panelu Testowanie promptu wybierz pole do wprowadzania danych.\n\nWpisz pytanie lub obserwację użytkownika, na przykład:\n\nUżytkownik: none What's the weather like?\n\nKliknij przycisk rombu po prawej stronie pola do wprowadzania danych, aby uzyskać odpowiedź od czatbota, na przykład taką:\n\nModel: none The weather on Europa is very cold and icy. ...\n\nKrok 2. Naucz swojego bota, jak lepiej czatować\n\nUdało Ci się stworzyć prostego czatbota obcych Europa, korzystając z jednego przykładu z odpowiedzią. Jednak pojedynczy przykład zwykle nie wystarcza do zapewnienia spójności i jakości odpowiedzi modelu. Bez dodatkowych danych odpowiedź modelu na pytanie o pogodę jest zwykle bardzo długa i wydaje się, że pochodzi z podręcznika, a nie od przyjaznego kosmity.\n\nDostosuj ton swojego czatbota, korzystając z odpowiedzi modelu i edytuj ją tak, aby pasowała do danego tonu i stylu czatbota obcych.\n\nAby dodać i edytować przykłady definicji czatbota:\n\nW panelu Testowanie promptu najedź kursorem na lewą stronę nagłówka Użytkownik i kliknij przycisk Dodaj do przykładów.\n\nW kolumnie Wpisz przykłady promptów edytuj skopiowane dane wejściowe i odpowiedzi, aby pasowały do stylu i tonu czatbota.\n\nW ten sposób możesz dodać więcej przykładów. Zadawaj więcej pytań, edytuj odpowiedzi i poprawiaj jakość czatbota. Dodawaj przykłady i sprawdzaj, jak wpływają one na zachowanie Twojego czatbota. Im więcej przykładów, tym lepsza jest jakość odpowiedzi czatbota.\n\nW tle Google AI Studio tworzy prompt, łącząc:\n\nPrzykłady okien dialogowych\nHistoria rozmowy\n\nw jeden blok tekstu wysyłany do modelu. Jeśli chcesz zobaczyć, jak wygląda pełny komunikat, kliknij Podgląd u dołu ekranu, by otworzyć okienko podglądu.\n\nPonieważ prompt zawiera każdą wiadomość między modelem a użytkownikiem (jest to „historia rozmowy”), komunikaty konwersacyjne mogą trwać dość długo. W końcu możesz osiągnąć limit tokenów modelu, czyli maksymalną długość tekstu akceptowanego przez model. Pełną liczbę wątków i tokenów możesz zobaczyć na karcie Podgląd.\n\nKrok 3. Eksperymentuj z parametrami modelu\n\nMożesz też spróbować dostosować parametry modelu, aby sprawdzić, czy dają one lepsze wyniki w Twoim przypadku.\n\nKrok 4 – Dalsze kroki\n\nPodobnie jak w przypadku innych typów promptów, gdy już otrzymasz satysfakcjonujący prototyp, możesz użyć przycisku Pobierz kod, aby zacząć kodować, lub zapisać prompt, aby później nad nim pracować i udostępnić go innym.\n\nWięcej informacji\nJeśli chcesz już przejść do kodu, zapoznaj się z krótkimi wprowadzeniami do interfejsu API.\nAby dowiedzieć się, jak tworzyć lepsze prompty, zapoznaj się ze wskazówkami dotyczącymi projektowania promptów.\nCzy te wskazówki były pomocne?\nPrześlij opinię\n\nO ile nie stwierdzono inaczej, treść tej strony jest objęta licencją Creative Commons – uznanie autorstwa 4.0, a fragmenty kodu są dostępne na licencji Apache 2.0. Szczegółowe informacje na ten temat zawierają zasady dotyczące witryny Google Developers. Java jest zastrzeżonym znakiem towarowym firmy Oracle i jej podmiotów stowarzyszonych.\n\nOstatnia aktualizacja: 2024-04-22 UTC.\n\nWarunki\nPrywatność",
            "word_count": 2370,
            "filtered_content": "Krótkie wprowadzenie do Google AI Studio \nGoogle AI Studio to środowisko IDE dostępne w przeglądarce, które umożliwia prototypowanie z użyciem modeli generatywnych. Google AI Studio pozwala szybko wypróbowywać modele i eksperymentować z różnymi promptami. Po utworzeniu elementu, który Ci się podoba, możesz go wyeksportować do kodu w preferowanym języku programowania, korzystając z interfejsu API Gemini.\nGoogle AI Studio udostępnia kilka interfejsów promptów przeznaczonych do różnych przypadków użycia:\nSwobodne prompty – są to otwarte prompty, które mogą służyć do generowania treści i odpowiedzi na instrukcje. W promptach możesz używać zarówno obrazów, jak i tekstów. Więcej informacji\nUporządkowane prompty – ta metoda promptów pozwala nakierować wynikiem modelu przez udostępnienie zestawu przykładowych żądań i odpowiedzi. Skorzystaj z tego podejścia, jeśli potrzebujesz większej kontroli nad strukturą danych wyjściowych modelu. Więcej informacji\nPotwierdzenia na czacie – używaj promptów na czacie, aby prowadzić rozmowy. Ta metoda promptów pozwala generować dane wyjściowe wielokrotnie z wykorzystaniem wielu cykli wprowadzania i odpowiedzi. Więcej informacji\nGoogle AI Studio umożliwia też zmianę działania modelu z użyciem metody nazywanej dostrajaniem:\nModel dostrojony – ta zaawansowana metoda służy do ulepszania odpowiedzi modelu w przypadku konkretnego zadania przez podanie większej liczby przykładów. Więcej informacji\nDzięki multimodalnym funkcjom Gemini model może zawierać zarówno obrazy, jak i tekst. Dzięki tej funkcji możesz na przykład dowiedzieć się więcej o budynku widocznym na zdjęciu.\nAby utworzyć multimodalny prompt:\nOtwórz Google AI Studio.\nW panelu po lewej stronie wybierz Utwórz nowy > Swobodny prompt.\nW polu Model w prawej kolumnie wybierz model, który obsługuje obrazy, na przykład model Gemini Pro Vision.\nW obszarze tekstowym promptu wpisz ten tekst:\nNa pasku Wstaw nad obszarem promptu kliknij Obraz i wybierz jedno z przykładowych zdjęć budynku.\nU dołu okna aplikacji kliknij Uruchom, aby wygenerować odpowiedź na to żądanie.\nW kroku 1 poprosiłeś model o ustalony ciąg tekstu i obraz. Czasem warto jednak mieć możliwość dynamicznego zmieniania niektórych fragmentów promptów. Jeśli np. tworzysz aplikację interaktywną, możesz zmodyfikować prompt, dodając inne dane wejściowe użytkownika. W tym celu możesz określić parametry promptów za pomocą zmiennych.\nAby dodać zmienne do promptów:\nWybierz słowo lub wyrażenie, które chcesz zastąpić w prompcie. W tym przypadku zaznacz tekst: who is the architect.\nW nagłówku Insert: nad promptem wybierz &lcub;&lcub; &rcub;&rcub; Test wejściowych.\nW tabeli Testowanie promptu pod promptem dodaj dodatkową wartość promptu: wybierz Dodaj przykład testowy i wpisz dodatkową wartość promptu. Możesz dodać kilka nowych wartości wejściowych.\nU dołu okna aplikacji wybierz Uruchom, aby wygenerować odpowiedź dla każdego z różnych żądań.\nW trakcie tworzenia prototypu promptu możesz też eksperymentować z ustawieniami uruchamiania modelu po prawej stronie aplikacji. Oto najważniejsze ustawienia, o których warto wiedzieć:\nModel – wybierz model, który ma odpowiadać na prompty. Więcej informacji o dostępnych modelach i możliwościach znajdziesz w sekcji Modele.\nTemperatura – kontroluj, jak bardzo losowe odpowiedzi są dozwolone w odpowiedziach modelu. Zwiększenie tej wartości umożliwia modelowi generowanie bardziej nieoczekiwanych i kreatywnych odpowiedzi.\nMaksymalna liczba danych wyjściowych – zwiększ liczbę odpowiedzi zwracanych przez model dla każdego żądania. Ta opcja może być przydatna do szybkiego testowania promptów przez generowanie wielu odpowiedzi na 1 prompt.\nUstawienia bezpieczeństwa – możesz dostosować ustawienia bezpieczeństwa na potrzeby zarządzania odpowiedziami modelu. Więcej informacji o tych opcjach znajdziesz w sekcji Ustawienia zabezpieczeń.\nPo utworzeniu prototypu aplikacji generatywnej AI możesz zapisać swoją pracę lub wygenerować kod do wykorzystania tego promptu w swoim środowisku programistycznym.\nAby zapisać utworzony prompt:\nW prawym górnym rogu aplikacji Google AI Studio kliknij Zapisz.\nPołącz aplikację z kontem Dysku Google, jeśli jeszcze nie jest z nią połączony.\nW oknie Zapisz prompt wpisz nazwę promptu i (opcjonalnie) opis, a następnie wybierz Zapisz.\nAby wyeksportować prompt utworzony jako kod:\nW prawym górnym rogu aplikacji Google AI Studio kliknij Pobierz kod.\nWybierz kartę języka programowania.\nKliknij Kopiuj, aby skopiować kod do schowka.\nUwaga: aby uruchomić kod promptu poza Google AI Studio, potrzebujesz klucza interfejsu API. Utwórz klucz i dodaj go do kodu promptu.\nUwaga: traktuj swój klucz interfejsu API jako hasło i odpowiednio go chroń. Nie umieszczaj swojego klucza w publicznie opublikowanym kodzie.\nNa razie wiesz, jak wprowadzić do modelu instrukcję (look at the following picture and tell me who is the architect). Czasami możesz jednak uzyskać lepsze wyniki, sugerując model z kombinacją instrukcji i przykładów. Pomogą Ci w tym uporządkowane prompty w Google AI Studio – połącz instrukcje z przykładami, aby pokazać modelowi, jakiego rodzaju dane wyjściowe chcesz mieć, a nie tylko informowanie mu, co ma zrobić. Ten rodzaj promptów, zwany promptami typufew-shot, przydaje się, gdy model ma trzymać się stałego formatu wyjściowego (np. uporządkowanego pliku JSON) lub gdy trudno jest go opisać słowami. W tej sekcji dowiesz się, jak tworzyć uporządkowane prompty w Google AI Studio.\nUwaga: ten przykład możesz wypróbować bezpośrednio w Google AI Studio z galerii przykładów.\nW tym przykładzie utworzysz ustrukturyzowany prompt generujący tekst reklamowy produktów. Najpierw zdefiniuj strukturę promptu, tworząc 2 kolumny: kolumnę wejściową Product i kolumnę wyjściową Product copy.\nAby utworzyć uporządkowany prompt:\nW lewym górnym rogu aplikacji internetowej Google AI Studio kliknij Utwórz nowy > Uporządkowany prompt.\nPod nagłówkiem Insert: dodaj instrukcje dotyczące promptu uporządkowanych:\nDodaj opisowy nagłówek do elementu INPUT, zastępując domyślny opis tekstowy input: wartością Product:.\nDodaj opisowy nagłówek dla parametru OUTPUT, zastępując domyślny opis tekstowy output: wartością Product copy:.\nWskazówka: dodaj dwukropki na końcu nazw kolumn, aby ułatwić modelowi analizę struktury.\nPo nazwaniu kolumn sprawdź przykładowe wiersze. Powinny one zawierać przykładowe dane wejściowe (w tym przykładzie nazwy produktów) i przykładowe dane wyjściowe (odpowiadające im opisy produktów). Podając modelowi kilka przykładowych opisów produktów, możesz ukierunkować go na skopiowanie podobnego stylu podczas generowania własnych danych wyjściowych. Przykłady można wpisać ręcznie lub zaimportować z pliku, używając menu importu danych.\nAby ręcznie wpisać przykłady:\nW tabeli danych przykładowe u góry wybierz pole pod nagłówkiem Produkt: i wpisz opis produktu.\nWybierz pole pod nagłówkiem Tekst produktu: i wpisz dla niego tekst marketingowy tej usługi.\nOto przykład wartości wejściowych i wyjściowych dla tego promptu:\nUsługa:\tOpis produktu:\nTrampki w stylu retro\tCzas na sznurowanie! Te buty dają kultowy wygląd i wyjątkową paletę kolorów, jednocześnie dbając o Twój styl i funkcjonalność.\nSupermiękka bluza z kapturem\tCiesz się przytulnym i stylowym wyglądem naszej nowej bluzy uniseks z kapturem. Ta bluza z kapturem jest wykonana w 100% z bawełny, jest miękka i wygodna. Można ją nosić przez cały dzień. Częściowo szczotkowane wnętrze zapewni Ci ciepło nawet w najchłodniejsze dni.\nWskazówka: jeśli masz blokadę autorów lub nie masz przygotowanych przykładowych tekstów usługi, możesz użyć opcji Swobodny prompt, aby model tekstowy wygenerował dla Ciebie odpowiedni tekst.\nAby zaimportować przykłady z pliku:\nW prawym górnym rogu tabeli przykłady kliknij Działania > Importuj przykłady.\nW oknie dialogowym wybierz plik CSV lub Arkusze Google na Dysku Google albo prześlij go z komputera.\nW oknie z przykładami importu wybierz kolumny, które chcesz zaimportować, a które pominąć. Okno pozwala też określić, która kolumna danych ma być importowana do której kolumny tabeli w uporządkowanym promptie.\nGdy uzyskasz przykłady, które pokazują odpowiedni model, sprawdź prompt z użyciem nowych danych wejściowych w tabeli Przetestuj prompt u dołu. Podobnie jak w przypadku typu promptu tekstowego, możesz dostosowywać parametry modelu, aby sprawdzić, czy pomagają uzyskać lepsze wyniki w Twoim przypadku.\nSprawdzanie sposobu przesyłania przykładów do modelu\nNajpierw Google AI Studio tworzy prompt, łącząc instrukcje z przesłanymi przez Ciebie przykładami. W miarę dodawania kolejnych przykładów będą one dodawane do tekstu wysyłanego do modelu. W zależności od tego, jak długie są przykłady, możesz zacząć zbliżać się do limitu tokenów modelu. Wszystkie modele generatywnej AI mają limit tokenów, czyli maksymalną długość tekstu, które mogą zaakceptować jako dane wejściowe.\nAby zobaczyć pełną treść promptu:\nU dołu aplikacji internetowej Google AI Studio wybierz Podgląd tekstu.\nUwaga: limit tokenów modelu jest wyświetlany u dołu okienka podglądu.\nGdy prompt będzie gotowy, możesz go zapisać lub wyeksportować do kodu, klikając przycisk Pobierz kod.\nMożesz też wyeksportować poszczególne przykłady kilku zdjęć do pliku CSV lub Arkuszy Google. Aby wyeksportować przykłady, w menu Działanie wybierz opcję Eksportuj przykłady.\nJeśli korzystasz z czatbota ogólnego przeznaczenia, takiego jak Gemini, przekonasz się na własne oczy, jak wydajne mogą być modele generatywnej AI w przypadku otwartego dialogu. Czatboty te są przydatne, ale często muszą być dostosowane do konkretnych przypadków użycia. Możesz np. utworzyć czatbota do obsługi klienta, który będzie obsługiwać tylko rozmowy o produkcie firmy. Dobrym pomysłem może być stworzenie czatbota, który będzie mówił o konkretnym tonie lub stylu – np. niszczy mnóstwo żartów, rymuje się jak poeta albo używa wielu emotikonów w odpowiedziach.\nTen przykład pokazuje, jak za pomocą Google AI Studio zbudować przyjazny czatbot, który komunikuje się tak, jakby to kosmita żyjący na jednym z księżyców Jowisza – Europy.\nW ostatniej sekcji zaprojektowaliśmy uporządkowany prompt, używając kombinacji przykładów danych wejściowych i wyjściowych. Podobnie, aby utworzyć czatbota, musisz podać przykłady interakcji między użytkownikiem a czatbotem, aby pokierować modelem do odpowiedzi, których szukasz.\nAby utworzyć prompt na czacie:\nW lewym górnym rogu aplikacji internetowej Google AI Studio kliknij Utwórz nowy > Wiadomość od Google Chat.\nPrzykłady interakcji możesz zacząć podawać w kolumnie Wpisz przykłady promptów w interfejsie. W pierwszym przykładzie możesz też podać dodatkowy kontekst, na przykład:\nUżytkownik: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nW polach Użytkownik i Model widać, jak mogą wyglądać interakcje między użytkownikiem a czatbotem:\nUżytkownik: none Hi!\nGdy podasz już przykład, zacznij testować swoją aplikację, rozmawiając z modelem w prawym panelu interfejsu promptu na czacie.\nAby przetestować działanie czatbota:\nU dołu panelu Testowanie promptu wybierz pole do wprowadzania danych.\nWpisz pytanie lub obserwację użytkownika, na przykład:\nUżytkownik: none What's the weather like?\nKliknij przycisk rombu po prawej stronie pola do wprowadzania danych, aby uzyskać odpowiedź od czatbota, na przykład taką:\nUdało Ci się stworzyć prostego czatbota obcych Europa, korzystając z jednego przykładu z odpowiedzią. Jednak pojedynczy przykład zwykle nie wystarcza do zapewnienia spójności i jakości odpowiedzi modelu. Bez dodatkowych danych odpowiedź modelu na pytanie o pogodę jest zwykle bardzo długa i wydaje się, że pochodzi z podręcznika, a nie od przyjaznego kosmity.\nDostosuj ton swojego czatbota, korzystając z odpowiedzi modelu i edytuj ją tak, aby pasowała do danego tonu i stylu czatbota obcych.\nAby dodać i edytować przykłady definicji czatbota:\nW panelu Testowanie promptu najedź kursorem na lewą stronę nagłówka Użytkownik i kliknij przycisk Dodaj do przykładów.\nW kolumnie Wpisz przykłady promptów edytuj skopiowane dane wejściowe i odpowiedzi, aby pasowały do stylu i tonu czatbota.\nW ten sposób możesz dodać więcej przykładów. Zadawaj więcej pytań, edytuj odpowiedzi i poprawiaj jakość czatbota. Dodawaj przykłady i sprawdzaj, jak wpływają one na zachowanie Twojego czatbota. Im więcej przykładów, tym lepsza jest jakość odpowiedzi czatbota.\nW tle Google AI Studio tworzy prompt, łącząc:\nPrzykłady okien dialogowych\nHistoria rozmowy\nw jeden blok tekstu wysyłany do modelu. Jeśli chcesz zobaczyć, jak wygląda pełny komunikat, kliknij Podgląd u dołu ekranu, by otworzyć okienko podglądu.\nPonieważ prompt zawiera każdą wiadomość między modelem a użytkownikiem (jest to „historia rozmowy”), komunikaty konwersacyjne mogą trwać dość długo. W końcu możesz osiągnąć limit tokenów modelu, czyli maksymalną długość tekstu akceptowanego przez model. Pełną liczbę wątków i tokenów możesz zobaczyć na karcie Podgląd.\nMożesz też spróbować dostosować parametry modelu, aby sprawdzić, czy dają one lepsze wyniki w Twoim przypadku.\nPodobnie jak w przypadku innych typów promptów, gdy już otrzymasz satysfakcjonujący prototyp, możesz użyć przycisku Pobierz kod, aby zacząć kodować, lub zapisać prompt, aby później nad nim pracować i udostępnić go innym.\nJeśli chcesz już przejść do kodu, zapoznaj się z krótkimi wprowadzeniami do interfejsu API.\nAby dowiedzieć się, jak tworzyć lepsze prompty, zapoznaj się ze wskazówkami dotyczącymi projektowania promptów.\nOstatnia aktualizacja: 2024-04-22 UTC.",
            "filtered_word_count": 1877
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br": {
            "status": "Looks good",
            "content": "Produtos\nExemplos\nFazer login\nDocs\nReferência da API\nVisão geral\nComeçar\nObter uma chave de API\nGuia de início rápido da API Gemini\nGuia de início rápido do Google AI Studio\nTutoriais com os primeiros passos\nModelos\nSobre modelos generativos\nGemini\nGemini API\nVisão geral da API\nReferência da API\nVersões da API\nNotas da versão\nRecursos\nAjuste do modelo\nChamadas de funções\nEmbeddings\nSegurança\nGuias\nSolicitações de prompt\nInstruções do sistema\nRecuperação semântica\nAutenticação OAuth\nExtensões do Firebase\nMigrar para o Cloud\nTutoriais\nChamadas de funções\nEmbeddings\nAplicativos\nSolução de problemas\nGuia de solução de problemas\nAcessar o AI Studio usando o Workspace\nComo solucionar problemas no AI Studio\nSolicitar mais cotas\nComunidade\nFórum do Discourse\nAPI PaLM (legada)\nMigrar para o Gêmeos\nDocumentos do PaLM\nJurídico\nTermos de Serviço\n(Prévia) Termos de Serviço\nRegiões disponíveis\nNesta página\nComandos e ajuste de modelos\nExemplo de comando de formato livre: saiba mais sobre um edifício\nEtapa 1: criar um comando com texto e imagens\nEtapa 2: adicionar uma variável substituível ao comando\nEtapa 3: testar parâmetros do modelo\nEtapa 4: próximas etapas\nExemplo de comando estruturado: criar um gerador de textos para o produto\nEtapa 1: criar um comando estruturado\nEtapa 2: adicionar exemplos\nEtapa 3: testar o comando\nEtapa 4: próximas etapas\nExemplo de comando de chat: criar um aplicativo de chat personalizado\nEtapa 1: criar um comando de chat\nEtapa 2: ensinar seu bot a conversar melhor\nEtapa 3: testar parâmetros do modelo\nEtapa 4: próximas etapas\nLeia mais\nConfira o Cookbook da nova API Gemini e nosso fórum da comunidade.\n Esta página foi traduzida pela API Cloud Translation.\nGoogle AI for Developers\nProdutos\nIsso foi útil?\nEnvie comentários\nGuia de início rápido do Google AI Studio \nbookmark_border\n\nO Google AI Studio é um ambiente de desenvolvimento integrado baseado em navegador para prototipagem com modelos generativos. Com o Google AI Studio, é possível testar modelos rapidamente e com diferentes comandos. Quando estiver contente com sua criação, você poderá exportar esse conteúdo para um código na sua linguagem de programação preferida, com a tecnologia da API Genmini.\n\nComandos e ajuste de modelos\n\nO Google AI Studio oferece várias interfaces para comandos projetados para diferentes casos de uso:\n\nComandos de formato livre: oferecem uma experiência aberta para gerar conteúdo e respostas a instruções. É possível usar dados tanto de imagens quanto de texto para seus comandos. Saiba mais\n\nComandos estruturados: esta técnica permite orientar a saída do modelo fornecendo um conjunto de exemplos de solicitações e respostas. Use essa abordagem quando precisar de mais controle sobre a estrutura de saída do modelo. Saiba mais\n\nSolicitações de chat: use comandos de chat para criar experiências de conversa. Essa técnica de comandos permite que várias rodadas de entrada e resposta gerem saídas. Saiba mais\n\nO Google AI Studio também permite alterar o comportamento de um modelo usando uma técnica chamada ajuste:\n\nModelo ajustado: use essa técnica avançada para melhorar as respostas de um modelo para uma tarefa específica ao fornecer mais exemplos. Saiba mais\nExemplo de comando de formato livre: saiba mais sobre um edifício\n\nAs habilidades multimodais do Gemini permitem solicitar o modelo com uma combinação de imagens e texto. Por exemplo, você pode usar esse recurso para saber mais sobre uma construção mostrada em uma imagem.\n\nEtapa 1: criar um comando com texto e imagens\n\nPara criar um comando multimodal:\n\nAcesse o Google AI Studio.\nNo painel esquerdo, selecione Criar novo > Comando de formato livre.\nNo campo Modelo da coluna à direita, selecione um modelo que aceite imagens, como o modelo Gemini Pro Vision.\n\nNa área de texto do prompt, digite o seguinte:\n\nlook at the following picture and tell me who is the architect\n\n\nNa barra Inserir acima da área do prompt, selecione Imagem e escolha uma das imagens de exemplo de um edifício.\n\nNa parte de baixo da janela do app, selecione Run para gerar uma resposta a essa solicitação.\n\nEtapa 2: adicionar uma variável substituível ao comando\n\nNa etapa 1, você solicitou ao modelo uma string fixa de texto e uma imagem. Mas, às vezes, você quer mudar dinamicamente partes de um comando. Por exemplo, se você estiver criando um aplicativo interativo, poderá modificar o comando com diferentes entradas do usuário. Para isso, parametrize os comandos usando variáveis.\n\nPara adicionar variáveis aos comandos:\n\nSelecione a palavra ou frase que você quer substituir no comando. Nesse caso, selecione o texto: who is the architect.\nNo cabeçalho Inserir: acima do prompt, selecione &lcub;&lcub; &rcub;&rcub; Testar entrada.\nNa tabela Testar seu comando abaixo dele, adicione outro valor a ele. Para isso, selecione Adicionar exemplo de teste e insira um valor extra. Fique à vontade para adicionar vários valores de entrada novos.\nNa parte de baixo da janela do app, selecione Run para gerar uma resposta para cada uma das solicitações variáveis.\nEtapa 3: testar parâmetros do modelo\n\nDurante a prototipagem do comando, você também pode testar as configurações de execução do modelo no lado direito do aplicativo. Estas são as principais configurações:\n\nModelo: selecione qual modelo você quer responder aos comandos. Para mais informações sobre os modelos e recursos disponíveis, consulte Modelos.\nTemperatura: controla quanta aleatoriedade é permitida nas respostas do modelo. Aumentar esse valor permite que o modelo produza respostas mais inesperadas e criativas.\nMáximo de saídas: aumenta o número de respostas que o modelo retorna para cada solicitação. Essa opção pode ser útil para testar comandos rapidamente, gerando várias respostas para um único comando.\nConfigurações de segurança: ajuste as configurações de segurança para gerenciar as respostas do modelo. Para ver mais detalhes sobre esses controles, consulte as Configurações de segurança.\nEtapa 4: próximas etapas\n\nAgora que o protótipo de um aplicativo de IA generativa foi criado, salve seu trabalho ou gere código para usar esse comando no seu próprio ambiente de desenvolvimento.\n\nPara salvar o comando que você criou:\n\nNo canto superior direito do app Google AI Studio, selecione Salvar.\nConecte o aplicativo à sua conta do Google Drive, caso ainda não tenha feito isso.\nNa caixa de diálogo Salvar prompt, insira um Nome do prompt e uma Descrição opcional e selecione Salvar.\n\nPara exportar o comando que você criou como código:\n\nNo canto superior direito do app Google AI Studio, selecione Receber código.\nSelecione uma guia de linguagem de programação.\nSelecione Copiar para copiar o código para a área de transferência.\nObservação:você precisa de uma chave de API para executar o código de comando fora do Google AI Studio, então não se esqueça de criar e incluir uma chave no código de solicitação.\nAtenção:trate sua chave de API como uma senha e proteja-a adequadamente. Não incorpore sua chave em um código publicado publicamente.\nExemplo de comando estruturado: criar um gerador de textos para o produto\n\nAté agora, você aprendeu como solicitar o modelo com uma instrução (look at the following picture and tell me who is the architect). No entanto, às vezes, é possível conseguir resultados melhores ao solicitar o modelo com uma combinação de instruções e exemplos. Os comandos estruturados no Google AI Studio ajudam você a fazer exatamente isso: combinar instruções com exemplos para mostrar ao modelo o tipo de saída que você quer, em vez de apenas informar o que fazer. Esse tipo de comando, chamado comando few-shot, é útil quando você quer que o modelo mantenha um formato de saída consistente (ou seja, JSON estruturado) ou quando é difícil descrever o modelo em palavras específicas. Nesta seção, você vai aprender a criar comandos estruturados no Google AI Studio.\n\nObservação :é possível testar esse exemplo diretamente no Google AI Studio pela galeria de exemplos.\nEtapa 1: criar um comando estruturado\n\nNeste exemplo, você criará um comando estruturado que gera o texto publicitário dos produtos. Para começar, defina a estrutura do comando criando duas colunas: uma coluna de entrada Product e uma coluna de saída Product copy.\n\nPara criar o comando estruturado, faça o seguinte:\n\nNo canto superior esquerdo do app da Web Google AI Studio, selecione Criar novo > Comando estruturado.\n\nAbaixo do cabeçalho Insert:, adicione as instruções para o comando estruturado:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nAdicione um cabeçalho descritivo para INPUT substituindo a descrição de texto padrão input: por Product:.\n\nAdicione um cabeçalho descritivo para OUTPUT substituindo a descrição de texto output: padrão por Product copy:.\n\nDica :adicione dois pontos ao final dos nomes das colunas para facilitar a análise da estrutura pelo modelo.\nEtapa 2: adicionar exemplos\n\nAgora que você nomeou suas colunas, forneça algumas linhas de exemplo. As linhas precisam conter exemplos de entrada (nomes de produtos deste exemplo) e saídas de exemplo (descrições de produtos correspondentes). Ao fornecer ao modelo algumas descrições de produtos de exemplo, é possível orientá-lo a replicar um estilo semelhante ao gerar as próprias saídas. Insira exemplos manualmente ou importe de um arquivo usando o menu de importação de dados.\n\nPara inserir exemplos manualmente:\n\nNa tabela de dados na parte superior de examples, selecione o campo abaixo do cabeçalho Product: e digite uma descrição do produto.\n\nSelecione o campo abaixo do cabeçalho Cópia do produto: e digite o texto de marketing do produto.\n\nConfira um exemplo de valores de entrada e saída para o comando:\n\nProduto:\tCópia do produto:\nTênis antigo\tVamos amarrar! Esses chutes criam um visual icônico e uma paleta de cores exclusiva, além de apoiar você no estilo e na funcionalidade como nenhum outro calçado antes.\nMoletom supermacio\tFique confortável e com estilo no nosso novo moletom unissex! Feito com 100% de algodão, este moletom com capuz é macio e confortável para usar o dia todo. O interior semiescovado mantém você aquecido até mesmo nos dias mais frios.\n\nDica :se os roteiristas estiverem bloqueando o código ou não tiver exemplos de texto do produto em mãos, use o comando de formato livre para que o modelo de texto gere alguns para você.\n\nPara importar exemplos de um arquivo:\n\nNo canto superior direito da tabela examples, selecione Actions > Import examples.\n\nNa caixa de diálogo, selecione um arquivo CSV ou do Planilhas Google no Google Drive ou faça o upload pelo computador.\n\nNa caixa de diálogo de exemplos de importação, escolha quais colunas importar e quais deixar de fora. A caixa de diálogo também permite especificar qual coluna de dados é importada para qual coluna da tabela no comando estruturado.\n\nEtapa 3: testar o comando\n\nQuando você tiver os exemplos que mostram o modelo que você quer, teste seu comando com uma nova entrada na tabela Testar seu comando na parte de baixo da tela. Assim como no tipo de prompt de texto, é possível ajustar os parâmetros do modelo para testar se eles ajudam a produzir melhores resultados para seu caso de uso.\n\nAnalisar como os exemplos são enviados ao modelo\n\nEm segundo plano, o Google AI Studio cria um comando combinando as instruções com os exemplos fornecidos. À medida que você adiciona mais exemplos, eles são adicionados ao texto enviado ao modelo. Dependendo do tamanho dos exemplos, é possível atingir o limite de tokens do modelo. Todos os modelos de IA generativa têm um limite de tokens, que é o tamanho máximo do texto que eles podem aceitar como entrada.\n\nPara conferir o conteúdo completo do comando, siga estas etapas:\n\nSelecione Visualização do texto na parte inferior do app da Web Google AI Studio.\nObservação: o limite de tokens do modelo aparece na parte de baixo do painel de visualização.\nEtapa 4: próximas etapas\n\nQuando estiver contente com o comando, salve-o ou exporte-o para o código clicando no botão Ver código.\n\nTambém é possível exportar os exemplos few-shot individuais para um arquivo CSV ou uma planilha Google. Escolha a opção Exportar exemplos no menu Ação para exportar seus exemplos.\n\nExemplo de comando de chat: criar um aplicativo de chat personalizado\n\nSe você já usou um bot de bate-papo de uso geral, como o Gemini, já percebeu, em primeira mão, como os modelos de IA generativa podem ser poderosos para caixas de diálogo abertas. Embora esses chatbots de uso geral sejam úteis, muitas vezes eles precisam ser adaptados para casos de uso específicos. Por exemplo, talvez você queira criar um chatbot de atendimento ao cliente que aceite apenas conversas que falam sobre o produto de uma empresa. Talvez você queira criar um chatbot que se comunica com um tom ou estilo específico: um bot que conta várias piadas, rime como um poeta ou use muitos emojis nas respostas.\n\nNeste exemplo, mostramos como usar o Google AI Studio para criar um chatbot amigável que se comunica como se fosse um alienígena vivendo em uma das luas de Júpiter, Europa.\n\nEtapa 1: criar um comando de chat\n\nNa última seção, você criou um comando estruturado usando uma combinação de exemplos de entrada e saída. Da mesma forma, para criar um bot de bate-papo, é preciso fornecer exemplos de interações entre um usuário e ele para orientar o modelo a fornecer as respostas que você procura.\n\nPara criar um comando de chat:\n\nNo canto superior esquerdo do app da Web Google AI Studio, selecione Criar novo > Comando de chat.\n\nNa coluna Escreva seus exemplos de comandos da interface de comandos, é possível começar a fornecer exemplos de interações. Você também pode fornecer mais contexto no primeiro exemplo, como:\n\nUsuário: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModelo: none Ok\n\nNos campos Usuário e Modelo, há um exemplo de como as interações entre um usuário e o bot de bate-papo podem ser:\n\nUsuário: none Hi!\n\nModelo: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nDepois de preencher um exemplo, comece a testar seu aplicativo batendo papo com o modelo no painel direito da interface de comando de chat.\n\nPara testar o comportamento do bot de bate-papo:\n\nNo painel Teste seu comando, selecione o campo de entrada na parte inferior.\n\nDigite uma pergunta ou observação que um usuário pode fazer, por exemplo:\n\nUsuário: none What's the weather like?\n\nClique no botão de diamante à direita do campo de entrada para receber uma resposta do bot de bate-papo, que pode ser semelhante a esta:\n\nModelo: none The weather on Europa is very cold and icy. ...\n\nEtapa 2: ensinar seu bot a conversar melhor\n\nCom uma única instrução e um exemplo de resposta, você conseguiu criar um bot de bate-papo básico de alienígenas da Europa. No entanto, um único exemplo normalmente não é suficiente para garantir a consistência e a qualidade das respostas do modelo. Sem mais informações, a resposta do modelo a uma pergunta sobre o clima tende a ser muito longa e parece ter saído de um livro didático em vez de um alienígena simpático.\n\nPersonalize o tom do bot de bate-papo usando a resposta do modelo e editando-o para que ele corresponda ao tom e ao estilo do bot de bate-papo alienígena.\n\nPara adicionar e editar exemplos para a definição do bot de bate-papo:\n\nNo painel Teste sua solicitação, mantenha o cursor à esquerda do título Usuário e selecione o botão Adicionar aos exemplos.\n\nNa coluna Escreva seus exemplos de comandos, edite a entrada e a resposta copiadas para corresponder ao estilo e tom do bot de bate-papo.\n\nUse essa abordagem para adicionar outros exemplos. Faça mais perguntas, edite as respostas e melhore a qualidade do bot de bate-papo. Continue adicionando exemplos e teste como eles modificam o comportamento do bot de bate-papo. Normalmente, mais exemplos correspondem a respostas de maior qualidade do bot de bate-papo.\n\nEm segundo plano, o Google AI Studio constrói um comando combinando:\n\nExemplos de caixas de diálogo\nHistórico da conversa\n\nem um único bloco de texto enviado ao modelo. Para conferir a aparência do comando completo, clique em Preview na parte de baixo da tela para abrir o painel de visualização.\n\nObserve que, como todas as mensagens entre o modelo e o usuário são incluídas no comando (esse é o \"histórico conversacional\"), os comandos de conversa podem crescer ao longo do tempo. Eventualmente, você pode atingir o limite de token do modelo, o tamanho máximo do texto que o modelo pode aceitar. É possível conferir a conversa completa e a contagem de tokens na guia Visualização.\n\nEtapa 3: testar parâmetros do modelo\n\nTambém é possível tentar ajustar os parâmetros do modelo para ver se eles produzem resultados mais apropriados para seu caso de uso.\n\nEtapa 4: próximas etapas\n\nAssim como nos outros tipos de comandos, depois de prototipar o comando de maneira satisfatória, você poderá usar o botão Receber código para começar a programar ou salvar o comando para trabalhar mais tarde e compartilhar com outras pessoas.\n\nLeia mais\nSe você estiver com tudo pronto para passar ao código, consulte os guias de início rápido da API.\nPara saber como criar comandos melhores, confira as Diretrizes de design de comandos.\nIsso foi útil?\nEnvie comentários\n\nExceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.\n\nÚltima atualização 2024-04-22 UTC.\n\nTermos de Serviço\nPrivacidade",
            "word_count": 2886,
            "filtered_content": "Guia de início rápido do Google AI Studio \nO Google AI Studio é um ambiente de desenvolvimento integrado baseado em navegador para prototipagem com modelos generativos. Com o Google AI Studio, é possível testar modelos rapidamente e com diferentes comandos. Quando estiver contente com sua criação, você poderá exportar esse conteúdo para um código na sua linguagem de programação preferida, com a tecnologia da API Genmini.\nO Google AI Studio oferece várias interfaces para comandos projetados para diferentes casos de uso:\nComandos de formato livre: oferecem uma experiência aberta para gerar conteúdo e respostas a instruções. É possível usar dados tanto de imagens quanto de texto para seus comandos. Saiba mais\nComandos estruturados: esta técnica permite orientar a saída do modelo fornecendo um conjunto de exemplos de solicitações e respostas. Use essa abordagem quando precisar de mais controle sobre a estrutura de saída do modelo. Saiba mais\nSolicitações de chat: use comandos de chat para criar experiências de conversa. Essa técnica de comandos permite que várias rodadas de entrada e resposta gerem saídas. Saiba mais\nO Google AI Studio também permite alterar o comportamento de um modelo usando uma técnica chamada ajuste:\nModelo ajustado: use essa técnica avançada para melhorar as respostas de um modelo para uma tarefa específica ao fornecer mais exemplos. Saiba mais\nAs habilidades multimodais do Gemini permitem solicitar o modelo com uma combinação de imagens e texto. Por exemplo, você pode usar esse recurso para saber mais sobre uma construção mostrada em uma imagem.\nPara criar um comando multimodal:\nAcesse o Google AI Studio.\nNo painel esquerdo, selecione Criar novo > Comando de formato livre.\nNo campo Modelo da coluna à direita, selecione um modelo que aceite imagens, como o modelo Gemini Pro Vision.\nNa área de texto do prompt, digite o seguinte:\nNa barra Inserir acima da área do prompt, selecione Imagem e escolha uma das imagens de exemplo de um edifício.\nNa parte de baixo da janela do app, selecione Run para gerar uma resposta a essa solicitação.\nNa etapa 1, você solicitou ao modelo uma string fixa de texto e uma imagem. Mas, às vezes, você quer mudar dinamicamente partes de um comando. Por exemplo, se você estiver criando um aplicativo interativo, poderá modificar o comando com diferentes entradas do usuário. Para isso, parametrize os comandos usando variáveis.\nPara adicionar variáveis aos comandos:\nSelecione a palavra ou frase que você quer substituir no comando. Nesse caso, selecione o texto: who is the architect.\nNo cabeçalho Inserir: acima do prompt, selecione &lcub;&lcub; &rcub;&rcub; Testar entrada.\nNa tabela Testar seu comando abaixo dele, adicione outro valor a ele. Para isso, selecione Adicionar exemplo de teste e insira um valor extra. Fique à vontade para adicionar vários valores de entrada novos.\nNa parte de baixo da janela do app, selecione Run para gerar uma resposta para cada uma das solicitações variáveis.\nDurante a prototipagem do comando, você também pode testar as configurações de execução do modelo no lado direito do aplicativo. Estas são as principais configurações:\nModelo: selecione qual modelo você quer responder aos comandos. Para mais informações sobre os modelos e recursos disponíveis, consulte Modelos.\nTemperatura: controla quanta aleatoriedade é permitida nas respostas do modelo. Aumentar esse valor permite que o modelo produza respostas mais inesperadas e criativas.\nMáximo de saídas: aumenta o número de respostas que o modelo retorna para cada solicitação. Essa opção pode ser útil para testar comandos rapidamente, gerando várias respostas para um único comando.\nConfigurações de segurança: ajuste as configurações de segurança para gerenciar as respostas do modelo. Para ver mais detalhes sobre esses controles, consulte as Configurações de segurança.\nAgora que o protótipo de um aplicativo de IA generativa foi criado, salve seu trabalho ou gere código para usar esse comando no seu próprio ambiente de desenvolvimento.\nPara salvar o comando que você criou:\nNo canto superior direito do app Google AI Studio, selecione Salvar.\nConecte o aplicativo à sua conta do Google Drive, caso ainda não tenha feito isso.\nNa caixa de diálogo Salvar prompt, insira um Nome do prompt e uma Descrição opcional e selecione Salvar.\nPara exportar o comando que você criou como código:\nNo canto superior direito do app Google AI Studio, selecione Receber código.\nSelecione uma guia de linguagem de programação.\nSelecione Copiar para copiar o código para a área de transferência.\nObservação:você precisa de uma chave de API para executar o código de comando fora do Google AI Studio, então não se esqueça de criar e incluir uma chave no código de solicitação.\nAtenção:trate sua chave de API como uma senha e proteja-a adequadamente. Não incorpore sua chave em um código publicado publicamente.\nAté agora, você aprendeu como solicitar o modelo com uma instrução (look at the following picture and tell me who is the architect). No entanto, às vezes, é possível conseguir resultados melhores ao solicitar o modelo com uma combinação de instruções e exemplos. Os comandos estruturados no Google AI Studio ajudam você a fazer exatamente isso: combinar instruções com exemplos para mostrar ao modelo o tipo de saída que você quer, em vez de apenas informar o que fazer. Esse tipo de comando, chamado comando few-shot, é útil quando você quer que o modelo mantenha um formato de saída consistente (ou seja, JSON estruturado) ou quando é difícil descrever o modelo em palavras específicas. Nesta seção, você vai aprender a criar comandos estruturados no Google AI Studio.\nObservação :é possível testar esse exemplo diretamente no Google AI Studio pela galeria de exemplos.\nNeste exemplo, você criará um comando estruturado que gera o texto publicitário dos produtos. Para começar, defina a estrutura do comando criando duas colunas: uma coluna de entrada Product e uma coluna de saída Product copy.\nPara criar o comando estruturado, faça o seguinte:\nNo canto superior esquerdo do app da Web Google AI Studio, selecione Criar novo > Comando estruturado.\nAbaixo do cabeçalho Insert:, adicione as instruções para o comando estruturado:\nAdicione um cabeçalho descritivo para INPUT substituindo a descrição de texto padrão input: por Product:.\nAdicione um cabeçalho descritivo para OUTPUT substituindo a descrição de texto output: padrão por Product copy:.\nDica :adicione dois pontos ao final dos nomes das colunas para facilitar a análise da estrutura pelo modelo.\nAgora que você nomeou suas colunas, forneça algumas linhas de exemplo. As linhas precisam conter exemplos de entrada (nomes de produtos deste exemplo) e saídas de exemplo (descrições de produtos correspondentes). Ao fornecer ao modelo algumas descrições de produtos de exemplo, é possível orientá-lo a replicar um estilo semelhante ao gerar as próprias saídas. Insira exemplos manualmente ou importe de um arquivo usando o menu de importação de dados.\nPara inserir exemplos manualmente:\nNa tabela de dados na parte superior de examples, selecione o campo abaixo do cabeçalho Product: e digite uma descrição do produto.\nSelecione o campo abaixo do cabeçalho Cópia do produto: e digite o texto de marketing do produto.\nConfira um exemplo de valores de entrada e saída para o comando:\nProduto:\tCópia do produto:\nTênis antigo\tVamos amarrar! Esses chutes criam um visual icônico e uma paleta de cores exclusiva, além de apoiar você no estilo e na funcionalidade como nenhum outro calçado antes.\nMoletom supermacio\tFique confortável e com estilo no nosso novo moletom unissex! Feito com 100% de algodão, este moletom com capuz é macio e confortável para usar o dia todo. O interior semiescovado mantém você aquecido até mesmo nos dias mais frios.\nDica :se os roteiristas estiverem bloqueando o código ou não tiver exemplos de texto do produto em mãos, use o comando de formato livre para que o modelo de texto gere alguns para você.\nPara importar exemplos de um arquivo:\nNo canto superior direito da tabela examples, selecione Actions > Import examples.\nNa caixa de diálogo, selecione um arquivo CSV ou do Planilhas Google no Google Drive ou faça o upload pelo computador.\nNa caixa de diálogo de exemplos de importação, escolha quais colunas importar e quais deixar de fora. A caixa de diálogo também permite especificar qual coluna de dados é importada para qual coluna da tabela no comando estruturado.\nQuando você tiver os exemplos que mostram o modelo que você quer, teste seu comando com uma nova entrada na tabela Testar seu comando na parte de baixo da tela. Assim como no tipo de prompt de texto, é possível ajustar os parâmetros do modelo para testar se eles ajudam a produzir melhores resultados para seu caso de uso.\nAnalisar como os exemplos são enviados ao modelo\nEm segundo plano, o Google AI Studio cria um comando combinando as instruções com os exemplos fornecidos. À medida que você adiciona mais exemplos, eles são adicionados ao texto enviado ao modelo. Dependendo do tamanho dos exemplos, é possível atingir o limite de tokens do modelo. Todos os modelos de IA generativa têm um limite de tokens, que é o tamanho máximo do texto que eles podem aceitar como entrada.\nPara conferir o conteúdo completo do comando, siga estas etapas:\nSelecione Visualização do texto na parte inferior do app da Web Google AI Studio.\nObservação: o limite de tokens do modelo aparece na parte de baixo do painel de visualização.\nQuando estiver contente com o comando, salve-o ou exporte-o para o código clicando no botão Ver código.\nTambém é possível exportar os exemplos few-shot individuais para um arquivo CSV ou uma planilha Google. Escolha a opção Exportar exemplos no menu Ação para exportar seus exemplos.\nSe você já usou um bot de bate-papo de uso geral, como o Gemini, já percebeu, em primeira mão, como os modelos de IA generativa podem ser poderosos para caixas de diálogo abertas. Embora esses chatbots de uso geral sejam úteis, muitas vezes eles precisam ser adaptados para casos de uso específicos. Por exemplo, talvez você queira criar um chatbot de atendimento ao cliente que aceite apenas conversas que falam sobre o produto de uma empresa. Talvez você queira criar um chatbot que se comunica com um tom ou estilo específico: um bot que conta várias piadas, rime como um poeta ou use muitos emojis nas respostas.\nNeste exemplo, mostramos como usar o Google AI Studio para criar um chatbot amigável que se comunica como se fosse um alienígena vivendo em uma das luas de Júpiter, Europa.\nNa última seção, você criou um comando estruturado usando uma combinação de exemplos de entrada e saída. Da mesma forma, para criar um bot de bate-papo, é preciso fornecer exemplos de interações entre um usuário e ele para orientar o modelo a fornecer as respostas que você procura.\nPara criar um comando de chat:\nNo canto superior esquerdo do app da Web Google AI Studio, selecione Criar novo > Comando de chat.\nNa coluna Escreva seus exemplos de comandos da interface de comandos, é possível começar a fornecer exemplos de interações. Você também pode fornecer mais contexto no primeiro exemplo, como:\nUsuário: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nNos campos Usuário e Modelo, há um exemplo de como as interações entre um usuário e o bot de bate-papo podem ser:\nUsuário: none Hi!\nDepois de preencher um exemplo, comece a testar seu aplicativo batendo papo com o modelo no painel direito da interface de comando de chat.\nPara testar o comportamento do bot de bate-papo:\nNo painel Teste seu comando, selecione o campo de entrada na parte inferior.\nDigite uma pergunta ou observação que um usuário pode fazer, por exemplo:\nUsuário: none What's the weather like?\nClique no botão de diamante à direita do campo de entrada para receber uma resposta do bot de bate-papo, que pode ser semelhante a esta:\nCom uma única instrução e um exemplo de resposta, você conseguiu criar um bot de bate-papo básico de alienígenas da Europa. No entanto, um único exemplo normalmente não é suficiente para garantir a consistência e a qualidade das respostas do modelo. Sem mais informações, a resposta do modelo a uma pergunta sobre o clima tende a ser muito longa e parece ter saído de um livro didático em vez de um alienígena simpático.\nPersonalize o tom do bot de bate-papo usando a resposta do modelo e editando-o para que ele corresponda ao tom e ao estilo do bot de bate-papo alienígena.\nPara adicionar e editar exemplos para a definição do bot de bate-papo:\nNo painel Teste sua solicitação, mantenha o cursor à esquerda do título Usuário e selecione o botão Adicionar aos exemplos.\nNa coluna Escreva seus exemplos de comandos, edite a entrada e a resposta copiadas para corresponder ao estilo e tom do bot de bate-papo.\nUse essa abordagem para adicionar outros exemplos. Faça mais perguntas, edite as respostas e melhore a qualidade do bot de bate-papo. Continue adicionando exemplos e teste como eles modificam o comportamento do bot de bate-papo. Normalmente, mais exemplos correspondem a respostas de maior qualidade do bot de bate-papo.\nEm segundo plano, o Google AI Studio constrói um comando combinando:\nExemplos de caixas de diálogo\nHistórico da conversa\nem um único bloco de texto enviado ao modelo. Para conferir a aparência do comando completo, clique em Preview na parte de baixo da tela para abrir o painel de visualização.\nObserve que, como todas as mensagens entre o modelo e o usuário são incluídas no comando (esse é o \"histórico conversacional\"), os comandos de conversa podem crescer ao longo do tempo. Eventualmente, você pode atingir o limite de token do modelo, o tamanho máximo do texto que o modelo pode aceitar. É possível conferir a conversa completa e a contagem de tokens na guia Visualização.\nTambém é possível tentar ajustar os parâmetros do modelo para ver se eles produzem resultados mais apropriados para seu caso de uso.\nAssim como nos outros tipos de comandos, depois de prototipar o comando de maneira satisfatória, você poderá usar o botão Receber código para começar a programar ou salvar o comando para trabalhar mais tarde e compartilhar com outras pessoas.\nSe você estiver com tudo pronto para passar ao código, consulte os guias de início rápido da API.\nPara saber como criar comandos melhores, confira as Diretrizes de design de comandos.\nÚltima atualização 2024-04-22 UTC.",
            "filtered_word_count": 2349
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi": {
            "status": "Looks good",
            "content": "Sản phẩm\nVí dụ\nĐăng nhập\nTài liệu\nTài liệu tham khảo API\nTổng quan\nBắt đầu\nNhận khoá API\nBắt đầu nhanh API Gemini\nHướng dẫn nhanh về Google AI Studio\nHướng dẫn bắt đầu sử dụng\nMô hình\nGiới thiệu về các mô hình tạo sinh\nGemini\nGemini API\nTổng quan về API\nTài liệu tham khảo API\nPhiên bản API\nGhi chú phát hành\nChức năng\nĐiều chỉnh mô hình\nGọi hàm\nNhúng\nAn toàn\nHướng dẫn\nNhắc nhở\nHướng dẫn hệ thống\nTruy xuất ngữ nghĩa\nXác thực OAuth\nTiện ích Firebase\nDi chuyển sang nền tảng đám mây\nHướng dẫn\nGọi hàm\nNhúng\nỨng dụng\nKhắc phục sự cố\nHướng dẫn khắc phục sự cố\nTruy cập vào AI Studio bằng Workspace\nKhắc phục sự cố với AI Studio\nYêu cầu tăng hạn mức\nCộng đồng\nDiễn đàn Discourse\nAPI PaLM (cũ)\nDi chuyển sang Gemini\nTài liệu PaLM\nPháp lý\nĐiều khoản dịch vụ\n(Bản xem trước) Điều khoản dịch vụ\nKhu vực khả dụng\nTrên trang này\nLời nhắc và điều chỉnh mô hình\nVí dụ về câu lệnh dạng tự do: Tìm hiểu thêm về một toà nhà\nBước 1 – Tạo câu lệnh có văn bản và hình ảnh\nBước 2 – Thêm một biến có thể thay thế vào câu lệnh\nBước 3 – Thử nghiệm các thông số mô hình\nBước 4 – Các bước tiếp theo\nVí dụ về câu lệnh có cấu trúc: Xây dựng trình tạo nội dung sản phẩm\nBước 1 – Tạo một câu lệnh có cấu trúc\nBước 2 – Thêm ví dụ\nBước 3 – Kiểm tra lời nhắc của bạn\nBước 4 – Các bước tiếp theo\nVí dụ về lời nhắc trò chuyện: Tạo một ứng dụng trò chuyện tuỳ chỉnh\nBước 1 – Tạo lời nhắc trò chuyện\nBước 2 – Đào tạo bot trò chuyện hiệu quả hơn\nBước 3 – Thử nghiệm các thông số mô hình\nBước 4 – Các bước tiếp theo\nTài liệu đọc thêm\nHãy khám phá Cookbook API mới và diễn đàn cộng đồng của chúng tôi.\n Trang này được dịch bởi Cloud Translation API.\nGoogle AI for Developers\nSản phẩm\nThông tin này có hữu ích không cho bạn không?\nGửi ý kiến phản hồi\nHướng dẫn nhanh về Google AI Studio \nbookmark_border\n\nGoogle AI Studio là một IDE dựa trên trình duyệt để tạo nguyên mẫu bằng các mô hình tạo sinh. Google AI Studio giúp bạn nhanh chóng dùng thử các mô hình và thử nghiệm với nhiều câu lệnh. Khi xây dựng được một ứng dụng mà bạn hài lòng, bạn có thể xuất nội dung đó sang ngôn ngữ lập trình mà mình muốn, với sự hỗ trợ của API Gemini.\n\nLời nhắc và điều chỉnh mô hình\n\nGoogle AI Studio cung cấp một số giao diện cho lời nhắc được thiết kế cho nhiều trường hợp sử dụng:\n\nLời nhắc dạng biểu mẫu tuỳ ý – Các câu lệnh này mang đến trải nghiệm nhắc mở để tạo nội dung và phản hồi cho hướng dẫn. Bạn có thể sử dụng cả dữ liệu văn bản và hình ảnh cho các câu lệnh của mình. Tìm hiểu thêm\n\nLời nhắc có cấu trúc – Kỹ thuật nhắc này cho phép bạn định hướng đầu ra theo mô hình bằng cách cung cấp một tập hợp các yêu cầu và câu trả lời mẫu. Hãy sử dụng phương pháp này khi bạn cần kiểm soát nhiều hơn đối với cấu trúc của đầu ra của mô hình. Tìm hiểu thêm\n\nLời nhắc trò chuyện – Sử dụng câu lệnh trò chuyện để xây dựng trải nghiệm trò chuyện. Kỹ thuật nhắc này cho phép nhiều lượt nhập và phản hồi để tạo đầu ra. Tìm hiểu thêm\n\nGoogle AI Studio cũng cho phép bạn thay đổi hành vi của một mô hình bằng cách sử dụng một kỹ thuật có tên là điều chỉnh:\n\nMô hình điều chỉnh – Hãy sử dụng kỹ thuật nâng cao này để cải thiện phản hồi của mô hình cho một tác vụ cụ thể bằng cách cung cấp thêm ví dụ. Tìm hiểu thêm\nVí dụ về câu lệnh dạng tự do: Tìm hiểu thêm về một toà nhà\n\nKhả năng đa phương thức của Gemini cho phép bạn đưa ra câu lệnh cho mô hình bằng cách kết hợp hình ảnh và văn bản. Ví dụ: bạn có thể sử dụng tính năng này để tìm hiểu thêm về một toà nhà hiển thị trong hình ảnh.\n\nBước 1 – Tạo câu lệnh có văn bản và hình ảnh\n\nCách tạo lời nhắc đa phương thức:\n\nChuyển đến Google AI Studio.\nTrong bảng điều khiển bên trái, hãy chọn Tạo mới > Câu lệnh dạng tự do.\nTrong trường Model (Mô hình) bên phải, hãy chọn một mô hình hỗ trợ hình ảnh, chẳng hạn như mô hình Gemini Pro Vision.\n\nTrong vùng văn bản câu lệnh, hãy nhập văn bản sau:\n\nlook at the following picture and tell me who is the architect\n\n\nTừ thanh Insert (Chèn) ở phía trên vùng lời nhắc, hãy chọn Image (Hình ảnh) rồi chọn một trong các hình ảnh mẫu của toà nhà.\n\nỞ cuối cửa sổ ứng dụng, hãy chọn Run (Chạy) để tạo câu trả lời cho yêu cầu này.\n\nBước 2 – Thêm một biến có thể thay thế vào câu lệnh\n\nỞ bước 1, bạn đã nhắc mô hình bằng một chuỗi văn bản cố định và một hình ảnh. Nhưng đôi khi, bạn muốn thay đổi linh động các phần của lời nhắc. Ví dụ: nếu đang tạo một ứng dụng tương tác, bạn nên sửa đổi lời nhắc bằng nhiều hoạt động đầu vào của người dùng. Để làm được điều này, bạn có thể tham số hoá lời nhắc bằng cách sử dụng biến.\n\nCách thêm biến vào câu lệnh của bạn:\n\nChọn từ hoặc cụm từ bạn muốn thay thế trong câu lệnh của mình. Trong trường hợp này, hãy chọn văn bản: who is the architect.\nTrong tiêu đề Chèn: phía trên lời nhắc, hãy chọn &lcub;&lcub; &rcub;&rcub; Kiểm thử đầu vào.\nTrong bảng Kiểm thử lời nhắc bên dưới lời nhắc, hãy thêm giá trị bổ sung cho lời nhắc của bạn bằng cách chọn Add test example (Thêm ví dụ kiểm thử) rồi nhập một giá trị lời nhắc bổ sung. Bạn có thể thêm một vài giá trị nhập mới.\nỞ cuối cửa sổ ứng dụng, hãy chọn Run (Chạy) để tạo câu trả lời cho từng yêu cầu khác nhau.\nBước 3 – Thử nghiệm các thông số mô hình\n\nKhi tạo nguyên mẫu lời nhắc, bạn cũng có thể thử nghiệm các chế độ cài đặt chạy mô hình ở bên phải của ứng dụng. Dưới đây là các chế độ cài đặt quan trọng mà bạn cần biết:\n\nMô hình – Chọn mô hình bạn muốn phản hồi lời nhắc của bạn. Để biết thêm thông tin về các mô hình và tính năng hiện có, hãy xem phần Mô hình.\nNhiệt độ – Kiểm soát mức độ ngẫu nhiên được cho phép trong các phản hồi của mô hình. Việc tăng giá trị này cho phép mô hình tạo ra nhiều phản hồi sáng tạo và bất ngờ hơn.\nĐầu ra tối đa – Tăng số lượng phản hồi mà mô hình trả về cho mỗi yêu cầu. Tuỳ chọn này có thể giúp bạn kiểm thử nhanh các câu lệnh bằng cách tạo nhiều phản hồi cho một câu lệnh.\nCài đặt an toàn – Điều chỉnh chế độ cài đặt an toàn để quản lý các phản hồi của mô hình. Để biết thêm thông tin chi tiết về các chế độ kiểm soát này, hãy xem phần Cài đặt an toàn.\nBước 4 – Các bước tiếp theo\n\nGiờ đây, khi đã tạo nguyên mẫu cho một ứng dụng AI tạo sinh, bạn có thể lưu công việc của mình hoặc tạo mã để sử dụng câu lệnh này trong môi trường phát triển của riêng mình.\n\nCách lưu lời nhắc bạn đã tạo:\n\nỞ góc trên cùng bên phải của ứng dụng Google AI Studio, hãy chọn Lưu.\nKết nối ứng dụng với tài khoản Google Drive nếu bạn chưa thực hiện việc này.\nTrong hộp thoại Save Prompt (Lưu lời nhắc), hãy nhập Prompt name (Tên lời nhắc), một Description (Mô tả) không bắt buộc rồi chọn Save (Lưu).\n\nCách xuất câu lệnh bạn đã tạo dưới dạng mã:\n\nỞ góc trên cùng bên phải của ứng dụng Google AI Studio, hãy chọn Nhận mã.\nChọn một thẻ ngôn ngữ lập trình.\nChọn Sao chép để sao chép mã vào bảng nhớ tạm.\nLưu ý: Bạn cần có khoá API để chạy mã nhắc bên ngoài Google AI Studio. Vì vậy, hãy nhớ tạo khoá và kèm theo khoá đó cùng với mã nhắc.\nThận trọng: Hãy coi khoá API của bạn như mật khẩu và bảo vệ khoá đó một cách thích hợp. Đừng nhúng khoá của bạn vào mã được xuất bản công khai.\nVí dụ về câu lệnh có cấu trúc: Xây dựng trình tạo nội dung sản phẩm\n\nCho đến nay, bạn đã biết cách có thể đưa ra câu lệnh (look at the following picture and tell me who is the architect) cho mô hình của mình. Tuy nhiên, đôi khi bạn có thể nhận được kết quả tốt hơn bằng cách nhắc mô hình cùng với hướng dẫn và ví dụ kết hợp. Các câu lệnh có cấu trúc trong Google AI Studio giúp bạn làm điều đó bằng cách kết hợp hướng dẫn với ví dụ để cho thấy cho mô hình loại kết quả mà bạn muốn, thay vì chỉ cho mô hình biết việc cần làm. Loại câu lệnh này, được gọi là nhắc nhở nhiều lần chụp, rất hữu ích khi bạn muốn mô hình duy trì một định dạng đầu ra nhất quán (tức là json có cấu trúc) hoặc khi khó mô tả bằng lời nói theo cách viết theo ý muốn của mô hình. Trong phần này, bạn sẽ tìm hiểu cách tạo câu lệnh có cấu trúc trong Google AI Studio.\n\nLưu ý: Bạn có thể thử ví dụ này ngay trong Google AI Studio từ thư viện mẫu.\nBước 1 – Tạo một câu lệnh có cấu trúc\n\nTrong ví dụ này, bạn sẽ tạo một lời nhắc có cấu trúc để tạo nội dung quảng cáo cho sản phẩm. Để bắt đầu, bạn sẽ xác định cấu trúc cho lời nhắc bằng cách tạo 2 cột: cột dữ liệu đầu vào Product và cột đầu ra Product copy.\n\nCách tạo câu lệnh có cấu trúc:\n\nỞ trên cùng bên trái của ứng dụng web Google AI Studio, hãy chọn Tạo mới > Lời nhắc có cấu trúc.\n\nBên dưới tiêu đề Insert: (Chèn:), hãy thêm hướng dẫn cho lời nhắc có cấu trúc:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nThêm tiêu đề mô tả cho INPUT bằng cách thay thế nội dung mô tả văn bản input: mặc định bằng Product:.\n\nThêm tiêu đề mô tả cho OUTPUT bằng cách thay thế nội dung mô tả văn bản mặc định của output: bằng Product copy:.\n\nMẹo: Hãy thêm dấu hai chấm vào cuối tên cột để giúp mô hình phân tích cú pháp cấu trúc dễ dàng hơn.\nBước 2 – Thêm ví dụ\n\nGiờ bạn đã đặt tên cho các cột, hãy cung cấp một số hàng ví dụ. Các hàng này phải chứa dữ liệu đầu vào mẫu (tên sản phẩm cho ví dụ này) và đầu ra mẫu (nội dung mô tả sản phẩm tương ứng). Bằng cách cung cấp cho mô hình này một số nội dung mô tả sản phẩm mẫu, bạn có thể hướng dẫn mô hình này tái tạo một kiểu tương tự khi tạo kết quả đầu ra riêng. Bạn có thể nhập ví dụ theo cách thủ công hoặc nhập từ một tệp bằng cách sử dụng trình đơn nhập dữ liệu.\n\nCách nhập ví dụ theo cách thủ công:\n\nTrong bảng dữ liệu ví dụ ở trên cùng, hãy chọn trường bên dưới tiêu đề Sản phẩm: rồi nhập nội dung mô tả sản phẩm.\n\nChọn trường bên dưới tiêu đề Product copy: (Nội dung tiếp thị loại sản phẩm): rồi chọn nội dung tiếp thị loại cho sản phẩm này.\n\nDưới đây là ví dụ về các giá trị đầu vào và đầu ra cho câu lệnh này:\n\nSản phẩm:\tNội dung sản phẩm:\nGiày sneaker cổ điển\tHãy cuộn dây nào! Những kiểu giày này mang đến một diện mạo mang tính biểu tượng và là một bảng màu độc đáo, đồng thời hỗ trợ bạn về kiểu dáng và chức năng độc đáo so với những đôi giày trước đây.\nÁo hoodie siêu mềm\tGiữ ấm cúng và phong cách với chiếc áo hoodie trung tính mới của chúng tôi! Được làm từ 100% cotton, chiếc áo hoodie này mềm mại và thoải mái để mặc cả ngày. Bên trong được phủ quét một nửa sẽ giúp bạn giữ ấm ngay cả những ngày lạnh nhất.\n\nMẹo: Nếu bạn đang yêu cầu người viết chặn hoặc không có sẵn ví dụ về nội dung sản phẩm, bạn có thể sử dụng câu lệnh dạng tự do để yêu cầu mô hình văn bản tạo một số mẫu cho bạn.\n\nCách nhập ví dụ từ tệp:\n\nỞ góc trên cùng bên phải của bảng ví dụ, hãy chọn Thao tác > Nhập ví dụ.\n\nTrong hộp thoại, hãy chọn một tệp CSV hoặc Google Trang tính trong Google Drive hoặc tải lên từ máy tính.\n\nTrong hộp thoại ví dụ nhập, hãy chọn những cột cần nhập và những cột cần loại bỏ. Hộp thoại này cũng cho phép bạn chỉ định cột dữ liệu nào sẽ nhập vào cột nào của bảng trong lời nhắc có cấu trúc.\n\nBước 3 – Kiểm tra lời nhắc của bạn\n\nSau khi có các ví dụ cho thấy mô hình mà bạn muốn, hãy kiểm thử lời nhắc bằng dữ liệu đầu vào mới trong bảng Kiểm thử lời nhắc ở dưới cùng. Tương tự như với loại lời nhắc bằng văn bản, bạn có thể điều chỉnh các tham số mô hình để kiểm thử xem các tham số đó có giúp tạo ra kết quả tốt hơn cho trường hợp sử dụng của bạn hay không.\n\nXem cách các ví dụ được gửi đến mô hình\n\nTrong trường hợp này, Google AI Studio sẽ tạo lời nhắc bằng cách kết hợp hướng dẫn với các ví dụ mà bạn cung cấp. Khi bạn thêm nhiều ví dụ hơn, các ví dụ này sẽ được thêm vào văn bản được gửi đến mô hình. Tuỳ thuộc vào thời lượng của ví dụ, bạn có thể bắt đầu đạt đến giới hạn mã thông báo của mô hình. Tất cả các mô hình AI tạo sinh đều có giới hạn về mã thông báo. Giới hạn này là độ dài tối đa của văn bản mà chúng có thể chấp nhận làm dữ liệu đầu vào.\n\nCách xem toàn bộ nội dung của câu lệnh:\n\nChọn Xem trước văn bản ở cuối ứng dụng web Google AI Studio.\nLưu ý: Giới hạn mã thông báo của mô hình hiển thị ở cuối ngăn xem trước.\nBước 4 – Các bước tiếp theo\n\nKhi đã hài lòng với lời nhắc, bạn có thể Lưu hoặc xuất lời nhắc sang mã bằng cách nhấp vào nút Lấy mã.\n\nBạn cũng có thể xuất từng ví dụ về một vài ảnh sang tệp CSV hoặc Google Trang tính. Chọn tuỳ chọn Xuất ví dụ trong trình đơn Thao tác để xuất ví dụ.\n\nVí dụ về lời nhắc trò chuyện: Tạo một ứng dụng trò chuyện tuỳ chỉnh\n\nNếu đã từng sử dụng bot trò chuyện đa năng như Gemini, thì bạn đã trực tiếp trải nghiệm sức mạnh của các mô hình AI tạo sinh đối với hộp thoại mở. Mặc dù những bot trò chuyện đa năng này rất hữu ích, nhưng thường thì chúng cần được điều chỉnh cho phù hợp với các trường hợp sử dụng cụ thể. Ví dụ: có thể bạn muốn xây dựng một bot trò chuyện dịch vụ khách hàng chỉ hỗ trợ các cuộc trò chuyện nói về sản phẩm của một công ty. Bạn có thể muốn xây dựng một bot trò chuyện nói chuyện với một giọng điệu hoặc phong cách cụ thể: một bot biết cách đùa vui, vần điệu như một nhà thơ hoặc sử dụng rất nhiều biểu tượng cảm xúc trong câu trả lời.\n\nVí dụ này cho bạn thấy cách sử dụng Google AI Studio để xây dựng một bot trò chuyện thân thiện giao tiếp như thể nó là một người ngoài hành tinh sống trên một trong các mặt trăng của Sao Mộc, Europa.\n\nBước 1 – Tạo lời nhắc trò chuyện\n\nTrong phần cuối, bạn đã thiết kế một lời nhắc có cấu trúc bằng cách sử dụng kết hợp các ví dụ về dữ liệu đầu vào và đầu ra. Tương tự, để tạo một bot trò chuyện, bạn cần đưa ra ví dụ về hoạt động tương tác giữa người dùng và bot trò chuyện đó để định hướng mô hình đưa ra câu trả lời mà bạn đang tìm kiếm.\n\nCách tạo lời nhắc trò chuyện:\n\nỞ trên cùng bên trái của ứng dụng web Google AI Studio, hãy chọn Tạo mới > Lời nhắc trò chuyện.\n\nTrong cột Viết ví dụ về lời nhắc của giao diện lời nhắc, bạn có thể bắt đầu cung cấp ví dụ về các hoạt động tương tác. Bạn cũng có thể cung cấp thêm ngữ cảnh trong ví dụ đầu tiên như:\n\nNgười dùng: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nMô hình: none Ok\n\nTrong các trường Người dùng và Mô hình, bạn có thể xem một ví dụ về hoạt động tương tác giữa người dùng và bot trò chuyện:\n\nNgười dùng: none Hi!\n\nMô hình: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nSau khi bạn điền vào ví dụ, hãy bắt đầu kiểm thử ứng dụng bằng cách trò chuyện với mô hình ở ngăn bên phải của giao diện lời nhắc trò chuyện.\n\nCách kiểm thử hành vi của bot trò chuyện:\n\nTrong bảng Kiểm tra lời nhắc của bạn, hãy chọn trường nhập dữ liệu ở dưới cùng.\n\nNhập câu hỏi hoặc quan sát mà người dùng có thể thực hiện, ví dụ:\n\nNgười dùng: none What's the weather like?\n\nChọn nút hình thoi ở bên phải trường nhập dữ liệu để nhận phản hồi từ bot trò chuyện, có thể có dạng như sau:\n\nMô hình: none The weather on Europa is very cold and icy. ...\n\nBước 2 – Đào tạo bot trò chuyện hiệu quả hơn\n\nBằng cách đưa ra một câu lệnh và ví dụ phản hồi duy nhất, bạn đã có thể xây dựng một bot trò chuyện cơ bản cho người ngoài hành tinh Europa. Tuy nhiên, một ví dụ duy nhất thường là chưa đủ để đảm bảo tính nhất quán và chất lượng trong các phản hồi của mô hình. Nếu không có thêm thông tin thì câu trả lời của mô hình cho một câu hỏi về thời tiết thường sẽ rất dài và trông giống như được trích ra từ một cuốn sách giáo khoa chứ không phải là của một người ngoài hành tinh thân thiện.\n\nTuỳ chỉnh giọng điệu của bot trò chuyện bằng cách sử dụng phản hồi của mô hình và chỉnh sửa cho phù hợp với tông điệu và phong cách mong muốn của bot trò chuyện từ người ngoài hành tinh.\n\nCách thêm và chỉnh sửa ví dụ cho định nghĩa bot trò chuyện:\n\nTrong bảng điều khiển Kiểm thử lời nhắc của bạn, hãy giữ con trỏ ở phía bên trái của tiêu đề Người dùng rồi chọn nút Thêm vào ví dụ.\n\nTrong cột Viết ví dụ về câu lệnh của bạn, hãy chỉnh sửa dữ liệu đầu vào và câu trả lời được sao chép cho phù hợp với phong cách và giọng điệu dự kiến của bot trò chuyện.\n\nBạn có thể sử dụng phương pháp này để bổ sung thêm ví dụ. Đặt thêm câu hỏi, chỉnh sửa câu trả lời và cải thiện chất lượng bot trò chuyện. Tiếp tục thêm ví dụ và thử nghiệm cách các ví dụ sửa đổi hành vi của bot trò chuyện. Thông thường, sẽ có nhiều ví dụ tương ứng với phản hồi chất lượng cao hơn của bot trò chuyện.\n\nTrong trường hợp này, Google AI Studio tạo câu lệnh bằng cách kết hợp:\n\nVí dụ về hộp thoại\nLịch sử cuộc trò chuyện\n\nvào một khối văn bản duy nhất được gửi đến mô hình. Để xem lời nhắc hoàn chỉnh, hãy nhấp vào Preview (Xem trước) ở cuối màn hình để hiển thị ngăn xem trước.\n\nLưu ý rằng, vì mọi tin nhắn giữa mô hình và người dùng đều được đưa vào lời nhắc (đây là \"nhật ký trò chuyện\"), các câu lệnh trò chuyện có thể kéo dài khá lâu sau một cuộc trò chuyện tiếp tục. Cuối cùng, bạn có thể đạt đến giới hạn mã thông báo của mô hình, độ dài tối đa của văn bản mà mô hình có thể chấp nhận. Bạn có thể xem toàn bộ cuộc trò chuyện và số lượng mã thông báo trong thẻ Xem trước.\n\nBước 3 – Thử nghiệm các thông số mô hình\n\nBạn cũng có thể thử điều chỉnh các tham số của mô hình để xem các tham số đó có tạo ra kết quả phù hợp hơn cho trường hợp sử dụng của mình hay không.\n\nBước 4 – Các bước tiếp theo\n\nTương tự như các loại câu lệnh khác, sau khi tạo câu lệnh để đảm bảo sự hài lòng, bạn có thể sử dụng nút Get Code (Lấy mã) để bắt đầu lập trình hoặc lưu lời nhắc để thực hiện sau và chia sẻ với người khác.\n\nTài liệu đọc thêm\nNếu bạn đã sẵn sàng chuyển sang viết mã, hãy xem phần bắt đầu nhanh API.\nĐể tìm hiểu cách tạo câu lệnh hiệu quả hơn, hãy xem Nguyên tắc thiết kế câu lệnh.\nThông tin này có hữu ích không cho bạn không?\nGửi ý kiến phản hồi\n\nTrừ khi có lưu ý khác, nội dung của trang này được cấp phép theo Giấy phép ghi nhận tác giả 4.0 của Creative Commons và các mẫu mã lập trình được cấp phép theo Giấy phép Apache 2.0. Để biết thông tin chi tiết, vui lòng tham khảo Chính sách trang web của Google Developers. Java là nhãn hiệu đã đăng ký của Oracle và/hoặc các đơn vị liên kết với Oracle.\n\nCập nhật lần gần đây nhất: 2024-04-22 UTC.\n\nĐiều khoản\nQuyền riêng tư",
            "word_count": 3930,
            "filtered_content": "Hướng dẫn nhanh về Google AI Studio \nGoogle AI Studio là một IDE dựa trên trình duyệt để tạo nguyên mẫu bằng các mô hình tạo sinh. Google AI Studio giúp bạn nhanh chóng dùng thử các mô hình và thử nghiệm với nhiều câu lệnh. Khi xây dựng được một ứng dụng mà bạn hài lòng, bạn có thể xuất nội dung đó sang ngôn ngữ lập trình mà mình muốn, với sự hỗ trợ của API Gemini.\nGoogle AI Studio cung cấp một số giao diện cho lời nhắc được thiết kế cho nhiều trường hợp sử dụng:\nLời nhắc dạng biểu mẫu tuỳ ý – Các câu lệnh này mang đến trải nghiệm nhắc mở để tạo nội dung và phản hồi cho hướng dẫn. Bạn có thể sử dụng cả dữ liệu văn bản và hình ảnh cho các câu lệnh của mình. Tìm hiểu thêm\nLời nhắc có cấu trúc – Kỹ thuật nhắc này cho phép bạn định hướng đầu ra theo mô hình bằng cách cung cấp một tập hợp các yêu cầu và câu trả lời mẫu. Hãy sử dụng phương pháp này khi bạn cần kiểm soát nhiều hơn đối với cấu trúc của đầu ra của mô hình. Tìm hiểu thêm\nLời nhắc trò chuyện – Sử dụng câu lệnh trò chuyện để xây dựng trải nghiệm trò chuyện. Kỹ thuật nhắc này cho phép nhiều lượt nhập và phản hồi để tạo đầu ra. Tìm hiểu thêm\nGoogle AI Studio cũng cho phép bạn thay đổi hành vi của một mô hình bằng cách sử dụng một kỹ thuật có tên là điều chỉnh:\nMô hình điều chỉnh – Hãy sử dụng kỹ thuật nâng cao này để cải thiện phản hồi của mô hình cho một tác vụ cụ thể bằng cách cung cấp thêm ví dụ. Tìm hiểu thêm\nKhả năng đa phương thức của Gemini cho phép bạn đưa ra câu lệnh cho mô hình bằng cách kết hợp hình ảnh và văn bản. Ví dụ: bạn có thể sử dụng tính năng này để tìm hiểu thêm về một toà nhà hiển thị trong hình ảnh.\nCách tạo lời nhắc đa phương thức:\nChuyển đến Google AI Studio.\nTrong bảng điều khiển bên trái, hãy chọn Tạo mới > Câu lệnh dạng tự do.\nTrong trường Model (Mô hình) bên phải, hãy chọn một mô hình hỗ trợ hình ảnh, chẳng hạn như mô hình Gemini Pro Vision.\nTrong vùng văn bản câu lệnh, hãy nhập văn bản sau:\nTừ thanh Insert (Chèn) ở phía trên vùng lời nhắc, hãy chọn Image (Hình ảnh) rồi chọn một trong các hình ảnh mẫu của toà nhà.\nỞ cuối cửa sổ ứng dụng, hãy chọn Run (Chạy) để tạo câu trả lời cho yêu cầu này.\nỞ bước 1, bạn đã nhắc mô hình bằng một chuỗi văn bản cố định và một hình ảnh. Nhưng đôi khi, bạn muốn thay đổi linh động các phần của lời nhắc. Ví dụ: nếu đang tạo một ứng dụng tương tác, bạn nên sửa đổi lời nhắc bằng nhiều hoạt động đầu vào của người dùng. Để làm được điều này, bạn có thể tham số hoá lời nhắc bằng cách sử dụng biến.\nCách thêm biến vào câu lệnh của bạn:\nChọn từ hoặc cụm từ bạn muốn thay thế trong câu lệnh của mình. Trong trường hợp này, hãy chọn văn bản: who is the architect.\nTrong tiêu đề Chèn: phía trên lời nhắc, hãy chọn &lcub;&lcub; &rcub;&rcub; Kiểm thử đầu vào.\nTrong bảng Kiểm thử lời nhắc bên dưới lời nhắc, hãy thêm giá trị bổ sung cho lời nhắc của bạn bằng cách chọn Add test example (Thêm ví dụ kiểm thử) rồi nhập một giá trị lời nhắc bổ sung. Bạn có thể thêm một vài giá trị nhập mới.\nỞ cuối cửa sổ ứng dụng, hãy chọn Run (Chạy) để tạo câu trả lời cho từng yêu cầu khác nhau.\nKhi tạo nguyên mẫu lời nhắc, bạn cũng có thể thử nghiệm các chế độ cài đặt chạy mô hình ở bên phải của ứng dụng. Dưới đây là các chế độ cài đặt quan trọng mà bạn cần biết:\nMô hình – Chọn mô hình bạn muốn phản hồi lời nhắc của bạn. Để biết thêm thông tin về các mô hình và tính năng hiện có, hãy xem phần Mô hình.\nNhiệt độ – Kiểm soát mức độ ngẫu nhiên được cho phép trong các phản hồi của mô hình. Việc tăng giá trị này cho phép mô hình tạo ra nhiều phản hồi sáng tạo và bất ngờ hơn.\nĐầu ra tối đa – Tăng số lượng phản hồi mà mô hình trả về cho mỗi yêu cầu. Tuỳ chọn này có thể giúp bạn kiểm thử nhanh các câu lệnh bằng cách tạo nhiều phản hồi cho một câu lệnh.\nCài đặt an toàn – Điều chỉnh chế độ cài đặt an toàn để quản lý các phản hồi của mô hình. Để biết thêm thông tin chi tiết về các chế độ kiểm soát này, hãy xem phần Cài đặt an toàn.\nGiờ đây, khi đã tạo nguyên mẫu cho một ứng dụng AI tạo sinh, bạn có thể lưu công việc của mình hoặc tạo mã để sử dụng câu lệnh này trong môi trường phát triển của riêng mình.\nCách lưu lời nhắc bạn đã tạo:\nỞ góc trên cùng bên phải của ứng dụng Google AI Studio, hãy chọn Lưu.\nKết nối ứng dụng với tài khoản Google Drive nếu bạn chưa thực hiện việc này.\nTrong hộp thoại Save Prompt (Lưu lời nhắc), hãy nhập Prompt name (Tên lời nhắc), một Description (Mô tả) không bắt buộc rồi chọn Save (Lưu).\nCách xuất câu lệnh bạn đã tạo dưới dạng mã:\nỞ góc trên cùng bên phải của ứng dụng Google AI Studio, hãy chọn Nhận mã.\nChọn một thẻ ngôn ngữ lập trình.\nChọn Sao chép để sao chép mã vào bảng nhớ tạm.\nLưu ý: Bạn cần có khoá API để chạy mã nhắc bên ngoài Google AI Studio. Vì vậy, hãy nhớ tạo khoá và kèm theo khoá đó cùng với mã nhắc.\nThận trọng: Hãy coi khoá API của bạn như mật khẩu và bảo vệ khoá đó một cách thích hợp. Đừng nhúng khoá của bạn vào mã được xuất bản công khai.\nCho đến nay, bạn đã biết cách có thể đưa ra câu lệnh (look at the following picture and tell me who is the architect) cho mô hình của mình. Tuy nhiên, đôi khi bạn có thể nhận được kết quả tốt hơn bằng cách nhắc mô hình cùng với hướng dẫn và ví dụ kết hợp. Các câu lệnh có cấu trúc trong Google AI Studio giúp bạn làm điều đó bằng cách kết hợp hướng dẫn với ví dụ để cho thấy cho mô hình loại kết quả mà bạn muốn, thay vì chỉ cho mô hình biết việc cần làm. Loại câu lệnh này, được gọi là nhắc nhở nhiều lần chụp, rất hữu ích khi bạn muốn mô hình duy trì một định dạng đầu ra nhất quán (tức là json có cấu trúc) hoặc khi khó mô tả bằng lời nói theo cách viết theo ý muốn của mô hình. Trong phần này, bạn sẽ tìm hiểu cách tạo câu lệnh có cấu trúc trong Google AI Studio.\nLưu ý: Bạn có thể thử ví dụ này ngay trong Google AI Studio từ thư viện mẫu.\nTrong ví dụ này, bạn sẽ tạo một lời nhắc có cấu trúc để tạo nội dung quảng cáo cho sản phẩm. Để bắt đầu, bạn sẽ xác định cấu trúc cho lời nhắc bằng cách tạo 2 cột: cột dữ liệu đầu vào Product và cột đầu ra Product copy.\nCách tạo câu lệnh có cấu trúc:\nỞ trên cùng bên trái của ứng dụng web Google AI Studio, hãy chọn Tạo mới > Lời nhắc có cấu trúc.\nBên dưới tiêu đề Insert: (Chèn:), hãy thêm hướng dẫn cho lời nhắc có cấu trúc:\nThêm tiêu đề mô tả cho INPUT bằng cách thay thế nội dung mô tả văn bản input: mặc định bằng Product:.\nThêm tiêu đề mô tả cho OUTPUT bằng cách thay thế nội dung mô tả văn bản mặc định của output: bằng Product copy:.\nMẹo: Hãy thêm dấu hai chấm vào cuối tên cột để giúp mô hình phân tích cú pháp cấu trúc dễ dàng hơn.\nGiờ bạn đã đặt tên cho các cột, hãy cung cấp một số hàng ví dụ. Các hàng này phải chứa dữ liệu đầu vào mẫu (tên sản phẩm cho ví dụ này) và đầu ra mẫu (nội dung mô tả sản phẩm tương ứng). Bằng cách cung cấp cho mô hình này một số nội dung mô tả sản phẩm mẫu, bạn có thể hướng dẫn mô hình này tái tạo một kiểu tương tự khi tạo kết quả đầu ra riêng. Bạn có thể nhập ví dụ theo cách thủ công hoặc nhập từ một tệp bằng cách sử dụng trình đơn nhập dữ liệu.\nCách nhập ví dụ theo cách thủ công:\nTrong bảng dữ liệu ví dụ ở trên cùng, hãy chọn trường bên dưới tiêu đề Sản phẩm: rồi nhập nội dung mô tả sản phẩm.\nChọn trường bên dưới tiêu đề Product copy: (Nội dung tiếp thị loại sản phẩm): rồi chọn nội dung tiếp thị loại cho sản phẩm này.\nDưới đây là ví dụ về các giá trị đầu vào và đầu ra cho câu lệnh này:\nSản phẩm:\tNội dung sản phẩm:\nGiày sneaker cổ điển\tHãy cuộn dây nào! Những kiểu giày này mang đến một diện mạo mang tính biểu tượng và là một bảng màu độc đáo, đồng thời hỗ trợ bạn về kiểu dáng và chức năng độc đáo so với những đôi giày trước đây.\nÁo hoodie siêu mềm\tGiữ ấm cúng và phong cách với chiếc áo hoodie trung tính mới của chúng tôi! Được làm từ 100% cotton, chiếc áo hoodie này mềm mại và thoải mái để mặc cả ngày. Bên trong được phủ quét một nửa sẽ giúp bạn giữ ấm ngay cả những ngày lạnh nhất.\nMẹo: Nếu bạn đang yêu cầu người viết chặn hoặc không có sẵn ví dụ về nội dung sản phẩm, bạn có thể sử dụng câu lệnh dạng tự do để yêu cầu mô hình văn bản tạo một số mẫu cho bạn.\nCách nhập ví dụ từ tệp:\nỞ góc trên cùng bên phải của bảng ví dụ, hãy chọn Thao tác > Nhập ví dụ.\nTrong hộp thoại, hãy chọn một tệp CSV hoặc Google Trang tính trong Google Drive hoặc tải lên từ máy tính.\nTrong hộp thoại ví dụ nhập, hãy chọn những cột cần nhập và những cột cần loại bỏ. Hộp thoại này cũng cho phép bạn chỉ định cột dữ liệu nào sẽ nhập vào cột nào của bảng trong lời nhắc có cấu trúc.\nSau khi có các ví dụ cho thấy mô hình mà bạn muốn, hãy kiểm thử lời nhắc bằng dữ liệu đầu vào mới trong bảng Kiểm thử lời nhắc ở dưới cùng. Tương tự như với loại lời nhắc bằng văn bản, bạn có thể điều chỉnh các tham số mô hình để kiểm thử xem các tham số đó có giúp tạo ra kết quả tốt hơn cho trường hợp sử dụng của bạn hay không.\nXem cách các ví dụ được gửi đến mô hình\nTrong trường hợp này, Google AI Studio sẽ tạo lời nhắc bằng cách kết hợp hướng dẫn với các ví dụ mà bạn cung cấp. Khi bạn thêm nhiều ví dụ hơn, các ví dụ này sẽ được thêm vào văn bản được gửi đến mô hình. Tuỳ thuộc vào thời lượng của ví dụ, bạn có thể bắt đầu đạt đến giới hạn mã thông báo của mô hình. Tất cả các mô hình AI tạo sinh đều có giới hạn về mã thông báo. Giới hạn này là độ dài tối đa của văn bản mà chúng có thể chấp nhận làm dữ liệu đầu vào.\nCách xem toàn bộ nội dung của câu lệnh:\nChọn Xem trước văn bản ở cuối ứng dụng web Google AI Studio.\nLưu ý: Giới hạn mã thông báo của mô hình hiển thị ở cuối ngăn xem trước.\nKhi đã hài lòng với lời nhắc, bạn có thể Lưu hoặc xuất lời nhắc sang mã bằng cách nhấp vào nút Lấy mã.\nBạn cũng có thể xuất từng ví dụ về một vài ảnh sang tệp CSV hoặc Google Trang tính. Chọn tuỳ chọn Xuất ví dụ trong trình đơn Thao tác để xuất ví dụ.\nNếu đã từng sử dụng bot trò chuyện đa năng như Gemini, thì bạn đã trực tiếp trải nghiệm sức mạnh của các mô hình AI tạo sinh đối với hộp thoại mở. Mặc dù những bot trò chuyện đa năng này rất hữu ích, nhưng thường thì chúng cần được điều chỉnh cho phù hợp với các trường hợp sử dụng cụ thể. Ví dụ: có thể bạn muốn xây dựng một bot trò chuyện dịch vụ khách hàng chỉ hỗ trợ các cuộc trò chuyện nói về sản phẩm của một công ty. Bạn có thể muốn xây dựng một bot trò chuyện nói chuyện với một giọng điệu hoặc phong cách cụ thể: một bot biết cách đùa vui, vần điệu như một nhà thơ hoặc sử dụng rất nhiều biểu tượng cảm xúc trong câu trả lời.\nVí dụ này cho bạn thấy cách sử dụng Google AI Studio để xây dựng một bot trò chuyện thân thiện giao tiếp như thể nó là một người ngoài hành tinh sống trên một trong các mặt trăng của Sao Mộc, Europa.\nTrong phần cuối, bạn đã thiết kế một lời nhắc có cấu trúc bằng cách sử dụng kết hợp các ví dụ về dữ liệu đầu vào và đầu ra. Tương tự, để tạo một bot trò chuyện, bạn cần đưa ra ví dụ về hoạt động tương tác giữa người dùng và bot trò chuyện đó để định hướng mô hình đưa ra câu trả lời mà bạn đang tìm kiếm.\nCách tạo lời nhắc trò chuyện:\nỞ trên cùng bên trái của ứng dụng web Google AI Studio, hãy chọn Tạo mới > Lời nhắc trò chuyện.\nTrong cột Viết ví dụ về lời nhắc của giao diện lời nhắc, bạn có thể bắt đầu cung cấp ví dụ về các hoạt động tương tác. Bạn cũng có thể cung cấp thêm ngữ cảnh trong ví dụ đầu tiên như:\nNgười dùng: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nMô hình: none Ok\nTrong các trường Người dùng và Mô hình, bạn có thể xem một ví dụ về hoạt động tương tác giữa người dùng và bot trò chuyện:\nNgười dùng: none Hi!\nMô hình: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\nSau khi bạn điền vào ví dụ, hãy bắt đầu kiểm thử ứng dụng bằng cách trò chuyện với mô hình ở ngăn bên phải của giao diện lời nhắc trò chuyện.\nCách kiểm thử hành vi của bot trò chuyện:\nTrong bảng Kiểm tra lời nhắc của bạn, hãy chọn trường nhập dữ liệu ở dưới cùng.\nNhập câu hỏi hoặc quan sát mà người dùng có thể thực hiện, ví dụ:\nNgười dùng: none What's the weather like?\nChọn nút hình thoi ở bên phải trường nhập dữ liệu để nhận phản hồi từ bot trò chuyện, có thể có dạng như sau:\nMô hình: none The weather on Europa is very cold and icy. ...\nBằng cách đưa ra một câu lệnh và ví dụ phản hồi duy nhất, bạn đã có thể xây dựng một bot trò chuyện cơ bản cho người ngoài hành tinh Europa. Tuy nhiên, một ví dụ duy nhất thường là chưa đủ để đảm bảo tính nhất quán và chất lượng trong các phản hồi của mô hình. Nếu không có thêm thông tin thì câu trả lời của mô hình cho một câu hỏi về thời tiết thường sẽ rất dài và trông giống như được trích ra từ một cuốn sách giáo khoa chứ không phải là của một người ngoài hành tinh thân thiện.\nTuỳ chỉnh giọng điệu của bot trò chuyện bằng cách sử dụng phản hồi của mô hình và chỉnh sửa cho phù hợp với tông điệu và phong cách mong muốn của bot trò chuyện từ người ngoài hành tinh.\nCách thêm và chỉnh sửa ví dụ cho định nghĩa bot trò chuyện:\nTrong bảng điều khiển Kiểm thử lời nhắc của bạn, hãy giữ con trỏ ở phía bên trái của tiêu đề Người dùng rồi chọn nút Thêm vào ví dụ.\nTrong cột Viết ví dụ về câu lệnh của bạn, hãy chỉnh sửa dữ liệu đầu vào và câu trả lời được sao chép cho phù hợp với phong cách và giọng điệu dự kiến của bot trò chuyện.\nBạn có thể sử dụng phương pháp này để bổ sung thêm ví dụ. Đặt thêm câu hỏi, chỉnh sửa câu trả lời và cải thiện chất lượng bot trò chuyện. Tiếp tục thêm ví dụ và thử nghiệm cách các ví dụ sửa đổi hành vi của bot trò chuyện. Thông thường, sẽ có nhiều ví dụ tương ứng với phản hồi chất lượng cao hơn của bot trò chuyện.\nTrong trường hợp này, Google AI Studio tạo câu lệnh bằng cách kết hợp:\nVí dụ về hộp thoại\nLịch sử cuộc trò chuyện\nvào một khối văn bản duy nhất được gửi đến mô hình. Để xem lời nhắc hoàn chỉnh, hãy nhấp vào Preview (Xem trước) ở cuối màn hình để hiển thị ngăn xem trước.\nLưu ý rằng, vì mọi tin nhắn giữa mô hình và người dùng đều được đưa vào lời nhắc (đây là \"nhật ký trò chuyện\"), các câu lệnh trò chuyện có thể kéo dài khá lâu sau một cuộc trò chuyện tiếp tục. Cuối cùng, bạn có thể đạt đến giới hạn mã thông báo của mô hình, độ dài tối đa của văn bản mà mô hình có thể chấp nhận. Bạn có thể xem toàn bộ cuộc trò chuyện và số lượng mã thông báo trong thẻ Xem trước.\nBạn cũng có thể thử điều chỉnh các tham số của mô hình để xem các tham số đó có tạo ra kết quả phù hợp hơn cho trường hợp sử dụng của mình hay không.\nTương tự như các loại câu lệnh khác, sau khi tạo câu lệnh để đảm bảo sự hài lòng, bạn có thể sử dụng nút Get Code (Lấy mã) để bắt đầu lập trình hoặc lưu lời nhắc để thực hiện sau và chia sẻ với người khác.\nNếu bạn đã sẵn sàng chuyển sang viết mã, hãy xem phần bắt đầu nhanh API.\nĐể tìm hiểu cách tạo câu lệnh hiệu quả hơn, hãy xem Nguyên tắc thiết kế câu lệnh.\nCập nhật lần gần đây nhất: 2024-04-22 UTC.",
            "filtered_word_count": 3244
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr": {
            "status": "Looks good",
            "content": "Ürünler\nÖrnekler\nOturum aç\nDokümanlar\nAPI Referansı\nGenel bakış\nBaşlama\nAPI anahtarı alma\nGemini API hızlı başlangıç kılavuzu\nGoogle AI Studio hızlı başlangıç kılavuzu\nBaşlangıç eğiticileri\nModeller\nÜretken modeller hakkında\nGemini\nGemini API\nAPI'ye genel bakış\nAPI referansı\nAPI sürümleri\nSürüm notları\nÖzellikler\nModel ince ayarı\nİşlev çağrısı\nYerleştirmeler\nGüvenlik\nRehberler\nİstemde bulunma\nSistem talimatları\nAnlamsal alma\nOAuth kimlik doğrulaması\nFirebase uzantıları\nCloud'a taşı\nEğitimler\nİşlev çağrısı\nYerleştirmeler\nUygulamalar\nSorun giderme\nSorun giderme kılavuzu\nWorkspace'i kullanarak AI Studio'ya erişme\nAI Studio ile ilgili sorunları giderme\nDaha fazla kota isteme\nTopluluk\nTartışma forumu\nPaLM API (eski)\nGemini'a taşıyın\nPaLM belgeleri\nHukuk\nHizmet şartları\n(Önizleme) Hizmet şartları\nKullanılabildiği bölgeler\nBu sayfada\nİstemler ve model ayarlama\nSerbest biçimli istem örneği: Yapı hakkında daha fazla bilgi\n1. Adım - Metin ve resimlerle bir istem oluşturun\n2. Adım - İsteme değiştirilebilir bir değişken ekleyin\n3. Adım - Model parametreleriyle deneme yapma\n4. adım - Sonraki adımlar\nYapılandırılmış istem örneği: Ürün kopyası oluşturma aracı derleme\n1. Adım - Yapılandırılmış bir istem oluşturun\n2. Adım - Örnek ekleme\n3. Adım - İsteminizi test edin\n4. adım - Sonraki adımlar\nSohbet istemi örneği: Özel bir sohbet uygulaması oluşturma\n1. Adım - Sohbet istemi oluşturun\n2. Adım - Bot'unuza daha iyi sohbet etmeyi öğretin\n3. Adım - Model parametreleriyle deneme yapma\n4. adım - Sonraki adımlar\nDaha fazla bilgi\nYeni Gemini API Cookbook'una ve topluluk forumumuza göz atın.\n Bu sayfa, Cloud Translation API ile çevrilmiştir.\nGoogle AI for Developers\nÜrünler\nBu size yardımcı oldu mu?\nGeri bildirim gönderin\nGoogle AI Studio hızlı başlangıç kılavuzu \nbookmark_border\n\nGoogle AI Studio, üretken modellerle prototip oluşturmaya yönelik tarayıcı tabanlı bir IDE'dir. Google AI Studio, modelleri hızlı bir şekilde denemenizi ve farklı istemlerle deneme yapmanızı sağlar. Memnun kaldığınız bir şey oluşturduğunuzda, Gemini API'nin desteğiyle tercih ettiğiniz programlama dilinde koda aktarabilirsiniz.\n\nİstemler ve model ayarlama\n\nGoogle AI Studio, farklı kullanım alanları için tasarlanmış istemler için çeşitli arayüzler sunar:\n\nSerbest biçimli istemler - Bu istemler, içerik ve talimatlara yanıt oluşturmak için açık uçlu bir istem deneyimi sunar. İstemleriniz için hem resim hem de metin verileri kullanabilirsiniz. Daha fazla bilgi\n\nYapılandırılmış istemler: Bu istem tekniği, bir dizi örnek istek ve yanıt sağlayarak model çıkışını yönlendirmenize olanak tanır. Model çıktısının yapısı üzerinde daha fazla kontrole ihtiyacınız olduğunda bu yaklaşımı kullanın. Daha fazla bilgi\n\nSohbet istemleri: Sohbet deneyimleri oluşturmak için sohbet istemlerini kullanın. Bu isteme tekniği, çıktı oluşturmak için birden fazla girdi ve yanıt dönüşü sağlar. Daha fazla bilgi\n\nGoogle AI Studio, ayarlama adı verilen bir teknik kullanarak modelin davranışını değiştirmenize de olanak tanır:\n\nUyarlanmış model: Daha fazla örnek sağlayarak bir modelin belirli bir göreve verdiği yanıtları iyileştirmek için bu gelişmiş tekniği kullanın. Daha fazla bilgi\nSerbest biçimli istem örneği: Yapı hakkında daha fazla bilgi\n\nGemini'ın çok modlu özellikleri, görüntüler ve metinlerin bir kombinasyonuyla modele yön vermenize olanak tanır. Örneğin, bir resimde gösterilen yapı hakkında daha fazla bilgi edinmek için bu özelliği kullanabilirsiniz.\n\n1. Adım - Metin ve resimlerle bir istem oluşturun\n\nÇok modlu bir istem oluşturmak için:\n\nGoogle AI Studio'ya gidin.\nSol panelde, Yeni oluştur > Serbest biçimli istem'i seçin.\nSağ sütundaki Model alanında, Gemini Pro Vision modeli gibi görüntüleri destekleyen bir model seçin.\n\nİstem metin alanına aşağıdaki metni girin:\n\nlook at the following picture and tell me who is the architect\n\n\nİstem alanının üstündeki Ekle çubuğundan Resim'i seçin ve bir binanın örnek resimlerinden birini seçin.\n\nUygulama penceresinin alt kısmında, bu isteğe yanıt oluşturmak için Çalıştır'ı seçin.\n\n2. Adım - İsteme değiştirilebilir bir değişken ekleyin\n\n1. adımda, modelden sabit bir metin dizesi ve bir resim oluşturmasını istemiştiniz. Ancak bazen bir istemin bölümlerini dinamik olarak değiştirebilmek istersiniz. Örneğin, etkileşimli bir uygulama oluşturuyorsanız isteminizi farklı kullanıcı girişleriyle değiştirmek isteyebilirsiniz. Bunun için değişkenleri kullanarak istemlerinizi parametre haline getirebilirsiniz.\n\nİstemlerinize değişken eklemek için:\n\nİsteminizde değiştirmek istediğiniz kelimeyi veya kelime öbeğini seçin. Bu durumda, şu metni seçin: who is the architect.\nİstemin üzerindeki Ekle: başlığından &lcub;&lcub;&rcub;&rcub; Test girişi'ni seçin.\nİstemin altındaki İsteminizi test edin tablosunda Test örneği ekle'yi seçip ek bir istem değeri girerek isteminiz için ek bir değer ekleyin. Birkaç yeni giriş değeri ekleyebilirsiniz.\nUygulama penceresinin alt kısmında, Çalıştır'ı seçerek değişen isteklerin her biri için bir yanıt oluşturun.\n3. Adım - Model parametreleriyle deneme yapma\n\nİsteminizin prototipini oluştururken uygulamanın sağ tarafında model çalıştırma ayarlarıyla da değişiklikler yapabilirsiniz. Bunlar, bilmeniz gereken önemli ayarlardır:\n\nModel - İstemlerinize yanıt vermek istediğiniz modeli seçin. Kullanılabilir modeller ve özellikler hakkında daha fazla bilgi için Modeller bölümüne bakın.\nSıcaklık: Modelin yanıtlarında ne kadar rastgeleliğe izin verildiğini kontrol edin. Bu değeri artırmak, modelin daha beklenmedik ve yaratıcı yanıtlar üretmesine olanak tanır.\nMaksimum çıkış sayısı: Modelin her istek için döndürdüğü yanıt sayısını artırın. Bu seçenek, tek bir istem için birden fazla yanıt oluşturarak istemleri hızlıca test etmeye yardımcı olabilir.\nGüvenlik ayarları - Model yanıtlarını yönetmek için güvenlik ayarlarını düzenleyin. Bu denetimlerle ilgili daha ayrıntılı bilgi için Güvenlik ayarları bölümüne göz atın.\n4. adım - Sonraki adımlar\n\nArtık üretken yapay zeka uygulamasının prototipini oluşturduğunuza göre çalışmanızı kaydedebilir veya bu istemi kendi geliştirme ortamınızda kullanmak için kod oluşturabilirsiniz.\n\nOluşturduğunuz istemi kaydetmek için:\n\nGoogle AI Studio uygulamasının sağ üst köşesinde Kaydet'i seçin.\nDaha önce yapmadıysanız uygulamayı Google Drive hesabınıza bağlayın.\nİstemi Kaydet iletişim kutusunda bir İstem adı ve isteğe bağlı bir Açıklama girip Kaydet'i seçin.\n\nOluşturduğunuz istemi kod olarak dışa aktarmak için:\n\nGoogle AI Studio uygulamasının sağ üst köşesinde Kodu al'ı seçin.\nBir programlama dili sekmesi seçin.\nKodu panonuza kopyalamak için Kopyala'yı seçin.\nNot: İstem kodunu Google AI Studio dışında çalıştırmak için API anahtarına ihtiyacınız vardır. Bu nedenle, bir anahtar oluşturup istem kodunuza eklediğinizden emin olun.\nDikkat: API anahtarınızı şifre gibi kullanıp uygun şekilde koruyun. Anahtarınızı herkese açık olarak yayınlanan bir koda yerleştirmeyin.\nYapılandırılmış istem örneği: Ürün kopyası oluşturma aracı derleme\n\nŞu ana kadar modelinize bir talimat (look at the following picture and tell me who is the architect) ile nasıl istem gösterebileceğinizi gördünüz. Bununla birlikte, bazen modele talimat ve örneklerin bir kombinasyonuyla istekte bulunarak daha iyi sonuçlar elde edebilirsiniz. Google AI Studio'daki yapılandırılmış istemler tam da bunu yapmanıza yardımcı olur. Modele sadece ne yapması gerektiğini söylemek yerine, istediğiniz çıkış türünü göstermek için talimatları örneklerle birleştirin. Bu tür istemler, modelin tutarlı bir çıkış biçimine bağlı kalmasını (ör. yapılandırılmış json) ya da bir modeli açıklamak istediğiniz durumlarda faydalıdır. Bu bölümde, Google AI Studio'da yapılandırılmış istemlerin nasıl oluşturulacağını öğreneceksiniz.\n\nNot: Bu örneği doğrudan Google AI Studio'da örnekler galerisinden deneyebilirsiniz.\n1. Adım - Yapılandırılmış bir istem oluşturun\n\nBu örnekte, ürünler için reklam metni oluşturan yapılandırılmış bir istem oluşturacaksınız. Başlamak için Product giriş sütunu ve Product copy çıkış sütunu olmak üzere iki sütun oluşturarak istemin yapısını tanımlarsınız.\n\nYapılandırılmış istemi oluşturmak için:\n\nGoogle AI Studio web uygulamasının sol üst tarafında, Yeni oluştur > Yapılandırılmış istem'i seçin.\n\nEkle: başlığının altına, yapılandırılmış isteme ilişkin talimatları ekleyin:\n\nYou are a product marketer targeting a Gen Z audience. Create exciting and\nfresh advertising copy for products and their simple description. Keep copy\nunder a few sentences long.\n\n\nVarsayılan input: metin açıklamasını Product: ile değiştirerek INPUT için açıklayıcı bir üstbilgi ekleyin.\n\nVarsayılan output: metin açıklamasını Product copy: ile değiştirerek ÇIKIŞ için açıklayıcı bir başlık ekleyin.\n\nİpucu: Modelin yapıyı ayrıştırmasını kolaylaştırmak için sütun adlarının sonuna iki nokta üst üste ekleyin.\n2. Adım - Örnek ekleme\n\nArtık sütunlarınızı adlandırdığınıza göre bazı örnek satırlar sağlayabilirsiniz. Bu satırlar, örnek girişler (bu örnek için ürün adları) ve örnek çıkışlar (karşılık gelen ürün açıklamaları) içermelidir. Modele birkaç örnek ürün açıklaması sağlayarak kendi çıktılarını oluştururken benzer bir stili taklit edebilir. Örnekleri manuel olarak girebilir veya verileri içe aktarma menüsünü kullanarak bir dosyadan içe aktarabilirsiniz.\n\nÖrnekleri manuel olarak girmek için:\n\nEn iyi örnekler veri tablosunda Product: başlığının altındaki alanı seçin ve bir ürün açıklaması yazın.\n\nÜrün metni: başlığının altındaki alanı seçin ve bu ürün için pazarlama metni yazın.\n\nAşağıda, bu istemdeki giriş ve çıkış değerlerinin bir örneğini bulabilirsiniz:\n\nÜrün:\tÜrün kopyası:\nNostaljik spor ayakkabı\tBağlayalım! Bu ayakkabılar, benzersiz bir görünüm ve benzersiz renk paletiyle size yardımcı olurken daha önce eşi benzeri olmayan ayakkabının tarzını ve işlevini de sağlıyor.\nSupersoft kapüşonlu sweatshirt\tYeni üniseks kapüşonlu sweatshirt ile rahatlığınızı ve tarzınızı koruyun. %100 pamuktan üretilmiş bu kapüşonlu sweatshirt yumuşaktır ve gün boyu rahatça takılabilir. Yarı fırçalı malzemesi en soğuk günlerde bile sizi sıcak tutar.\n\nİpucu: Yazar engeliniz varsa veya örnek ürün metni örnekleriniz yoksa metin modelinin sizin için bir şeyler oluşturmasını sağlamak amacıyla Serbest biçim istemi'ni kullanabilirsiniz.\n\nBir dosyadan örnekleri içe aktarmak için:\n\nÖrnekler tablosunun sağ üst köşesinde İşlemler > Örnekleri içe aktar'ı seçin.\n\nİletişim kutusunda, Google Drive'ınızdan bir CSV veya Google E-Tablolar dosyası seçin ya da dosyayı bilgisayarınızdan yükleyin.\n\nİçe aktarma örnekleri iletişim kutusunda, hangi sütunların içe aktarılacağını ve hangilerinin dışarıda bırakılacağını seçin. İletişim kutusu, yapılandırılmış isteminizdeki hangi veri sütununun hangi tablo sütununa içe aktarılacağını da belirtmenizi sağlar.\n\n3. Adım - İsteminizi test edin\n\nModele istediğiniz şeyi gösteren örnekleri bulduktan sonra alt kısımdaki İsteminizi test edin tablosunda yeni girişle isteminizi test edin. Metin istemi türünde olduğu gibi, kullanım alanınız için daha iyi sonuçlar üretmeye yardımcı olup olmadıklarını test etmek üzere model parametrelerini ayarlayabilirsiniz.\n\nÖrneklerin modele nasıl gönderildiğini inceleme\n\nTemelde, Google AI Studio sağladığınız örneklerle talimatları birleştirerek bir istem oluşturur. Siz daha fazla örnek ekledikçe, bunlar modele gönderilen metne eklenir. Örneklerinizin uzunluğuna bağlı olarak, modelin jeton sınırına ulaşmaya başlayabilirsiniz. Tüm üretken yapay zeka modellerinin bir jeton sınırı vardır. Bu sınır, giriş olarak kabul edebilecekleri metnin maksimum uzunluğudur.\n\nİsteminizin tüm içeriğini görmek için:\n\nGoogle AI Studio web uygulamasının en altındaki Metin önizleme'yi seçin.\nNot: Model jeton sınırı, önizleme bölmesinin en altında gösterilir.\n4. adım - Sonraki adımlar\n\nİsteminizden memnun olduğunuzda, Kaydet'i tıklayarak veya Kodu Al düğmesini tıklayarak koda aktarabilirsiniz.\n\nBirkaç çekim örneğini tek tek bir CSV dosyasına veya Google E-Tablosuna da aktarabilirsiniz. Örneklerinizi dışa aktarmak için İşlem menüsü altındaki Örnekleri dışa aktar seçeneğini belirleyin.\n\nSohbet istemi örneği: Özel bir sohbet uygulaması oluşturma\n\nGemini gibi genel amaçlı bir chatbot kullandıysanız üretken yapay zeka modellerinin açık uçlu diyaloglar için ne kadar güçlü olabileceğini bizzat tecrübe etmişsinizdir. Bu genel amaçlı chatbot'lar kullanışlı olsa da çoğu zaman belirli kullanım alanları için özelleştirilmesi gerekir. Örneğin, yalnızca bir şirketin ürünüyle ilgili konuşmaları destekleyen bir müşteri hizmetleri chatbot'u oluşturmak isteyebilirsiniz. Belirli bir üslup veya tarzda konuşan bir chatbot (çok fazla şaka yapan, bir şair gibi kafiyeli veya yanıtlarında çok sayıda emoji kullanan bir bot) geliştirmek isteyebilirsiniz.\n\nBu örnekte, Google AI Studio'yu kullanarak Jüpiter'in uydularından biri olan Europa'da yaşayan bir uzaylıymış gibi iletişim kuran, samimi bir chatbot geliştirmek için nasıl kullanılacağı gösterilmektedir.\n\n1. Adım - Sohbet istemi oluşturun\n\nSon bölümde, giriş ve çıkış örneklerinin bir kombinasyonunu kullanarak yapılandırılmış bir istem tasarladınız. Benzer şekilde, bir chatbot oluşturmak amacıyla, aradığınız yanıtları sağlaması için modeli yönlendirmek amacıyla kullanıcı ile chatbot arasındaki etkileşim örnekleri sağlamanız gerekir.\n\nSohbet istemi oluşturmak için:\n\nGoogle AI Studio web uygulamasının sol üst tarafında, Yeni oluştur > Sohbet istemi'ni seçin.\n\nİstem arayüzünün İstem örneklerinizi yazın sütununda, etkileşim örnekleri sağlamaya başlayabilirsiniz. İlk örnekte aşağıdakiler gibi ek bağlam da sağlayabilirsiniz:\n\nKullanıcı: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\n\nModel: none Ok\n\nKullanıcı ve Model alanlarında, bir kullanıcı ile chatbot'unuz arasındaki etkileşimlerin nasıl görünebileceğine dair bir örnek sağlanır:\n\nKullanıcı: none Hi!\n\nModel: none Hi! My name is Tim and I live on Europa, one of Jupiter's moons. Brr! It's cold down here!\n\nBir örneği doldurduktan sonra sohbet istemi arayüzünün sağ bölmesindeki modelle sohbet ederek uygulamanızı test etmeye başlayın.\n\nChatbot davranışını test etmek için:\n\nİsteminizi test edin panelinde, alttaki giriş alanını seçin.\n\nKullanıcının sorabileceği bir soru veya gözlem girin. Örneğin:\n\nKullanıcı: none What's the weather like?\n\nChatbot'tan aşağıdakine benzer bir yanıt almak için giriş alanının sağındaki elmas düğmeyi seçin:\n\nModel: none The weather on Europa is very cold and icy. ...\n\n2. Adım - Bot'unuza daha iyi sohbet etmeyi öğretin\n\nTek bir ifade ve yanıt örneği vererek temel bir Europa uzaylı chatbot'u oluşturmayı başardınız. Ancak modelin yanıtlarında tutarlılığı ve kaliteyi sağlamak için genellikle tek bir örnek yeterli olmaz. Modelin hava durumuyla ilgili bir soruya verdiği yanıt daha fazla giriş olmadan çok uzun oluyor ve sanki cana yakın bir uzaylıdan ziyade bir ders kitabından geliyormuş gibi geliyor.\n\nModel yanıtını kullanarak chatbot'unuzun tonunu özelleştirin ve bunu, uzaylı chatbot'unuzun tonu ve stiline uyacak şekilde düzenleyin.\n\nChatbot tanımına örnekler eklemek ve düzenlemek için:\n\nİsteminizi test edin panelinde, imleci Kullanıcı başlığının sol tarafında tutun ve Örneklere ekle düğmesini seçin.\n\nİstem örneklerinizi yazın sütununda, kopyalanan girişi ve yanıtı chatbot'unuzun istenen stiline ve üslubuna uyacak şekilde düzenleyin.\n\nBaşka örnekler eklemek için bu yaklaşımı kullanabilirsiniz. Daha fazla soru sorun, yanıtları düzenleyin ve chatbot'unuzun kalitesini artırın. Örnekler eklemeye ve chatbot'unuzun davranışını nasıl değiştirdiğini test etmeye devam edin. Genellikle daha fazla örnek, daha yüksek kaliteli chatbot yanıtlarına karşılık gelir.\n\nGoogle AI Studio, aşağıdaki özellikleri birleştirerek bir istem oluşturur:\n\nİletişim kutusu örnekleri\nGörüşme geçmişi\n\nmodele gönderilen tek bir metin bloğuna dönüşür. İstemin tamamının nasıl göründüğünü görmek için önizleme bölmesini açmak üzere ekranın alt kısmındaki Önizleme'yi tıklayın.\n\nModel ile kullanıcı arasındaki her mesaj isteme dahil edildiğinden (bu, \"sohbet geçmişi\"dir) görüşme devam ettiği sürece sohbet istemlerinin büyüyebileceğini unutmayın. Sonunda modelin kabul edebileceği metnin maksimum uzunluğu olan jeton sınırına ulaşabilirsiniz. Görüşmenin ve jeton sayısının tamamını Önizleme sekmesinde görebilirsiniz.\n\n3. Adım - Model parametreleriyle deneme yapma\n\nKullanım alanınız için daha uygun sonuçlar üretip üretmediklerini görmek için model parametrelerini ayarlamayı da deneyebilirsiniz.\n\n4. adım - Sonraki adımlar\n\nDiğer istem türlerine benzer şekilde, isteminiz istediğiniz gibi prototipini oluşturduktan sonra kodlamaya başlamak veya isteminizi daha sonra üzerinde çalışmak ve başkalarıyla paylaşmak üzere kaydetmek için Kodu Al düğmesini kullanabilirsiniz.\n\nDaha fazla bilgi\nKodlamaya devam etmeye hazırsanız API hızlı başlangıç kılavuzlarını inceleyin.\nNasıl daha iyi istemler oluşturacağınızı öğrenmek için İstem tasarım yönergelerine göz atın.\nBu size yardımcı oldu mu?\nGeri bildirim gönderin\n\nAksi belirtilmediği sürece bu sayfanın içeriği Creative Commons Atıf 4.0 Lisansı altında ve kod örnekleri Apache 2.0 Lisansı altında lisanslanmıştır. Ayrıntılı bilgi için Google Developers Site Politikaları'na göz atın. Java, Oracle ve/veya satış ortaklarının tescilli ticari markasıdır.\n\nSon güncelleme tarihi: 2024-04-22 UTC.\n\nŞartlar\nGizlilik",
            "word_count": 2258,
            "filtered_content": "Google AI Studio hızlı başlangıç kılavuzu \nGoogle AI Studio, üretken modellerle prototip oluşturmaya yönelik tarayıcı tabanlı bir IDE'dir. Google AI Studio, modelleri hızlı bir şekilde denemenizi ve farklı istemlerle deneme yapmanızı sağlar. Memnun kaldığınız bir şey oluşturduğunuzda, Gemini API'nin desteğiyle tercih ettiğiniz programlama dilinde koda aktarabilirsiniz.\nGoogle AI Studio, farklı kullanım alanları için tasarlanmış istemler için çeşitli arayüzler sunar:\nSerbest biçimli istemler - Bu istemler, içerik ve talimatlara yanıt oluşturmak için açık uçlu bir istem deneyimi sunar. İstemleriniz için hem resim hem de metin verileri kullanabilirsiniz. Daha fazla bilgi\nYapılandırılmış istemler: Bu istem tekniği, bir dizi örnek istek ve yanıt sağlayarak model çıkışını yönlendirmenize olanak tanır. Model çıktısının yapısı üzerinde daha fazla kontrole ihtiyacınız olduğunda bu yaklaşımı kullanın. Daha fazla bilgi\nSohbet istemleri: Sohbet deneyimleri oluşturmak için sohbet istemlerini kullanın. Bu isteme tekniği, çıktı oluşturmak için birden fazla girdi ve yanıt dönüşü sağlar. Daha fazla bilgi\nGoogle AI Studio, ayarlama adı verilen bir teknik kullanarak modelin davranışını değiştirmenize de olanak tanır:\nUyarlanmış model: Daha fazla örnek sağlayarak bir modelin belirli bir göreve verdiği yanıtları iyileştirmek için bu gelişmiş tekniği kullanın. Daha fazla bilgi\nGemini'ın çok modlu özellikleri, görüntüler ve metinlerin bir kombinasyonuyla modele yön vermenize olanak tanır. Örneğin, bir resimde gösterilen yapı hakkında daha fazla bilgi edinmek için bu özelliği kullanabilirsiniz.\nÇok modlu bir istem oluşturmak için:\nGoogle AI Studio'ya gidin.\nSol panelde, Yeni oluştur > Serbest biçimli istem'i seçin.\nSağ sütundaki Model alanında, Gemini Pro Vision modeli gibi görüntüleri destekleyen bir model seçin.\nİstem metin alanına aşağıdaki metni girin:\nİstem alanının üstündeki Ekle çubuğundan Resim'i seçin ve bir binanın örnek resimlerinden birini seçin.\nUygulama penceresinin alt kısmında, bu isteğe yanıt oluşturmak için Çalıştır'ı seçin.\n1. adımda, modelden sabit bir metin dizesi ve bir resim oluşturmasını istemiştiniz. Ancak bazen bir istemin bölümlerini dinamik olarak değiştirebilmek istersiniz. Örneğin, etkileşimli bir uygulama oluşturuyorsanız isteminizi farklı kullanıcı girişleriyle değiştirmek isteyebilirsiniz. Bunun için değişkenleri kullanarak istemlerinizi parametre haline getirebilirsiniz.\nİstemlerinize değişken eklemek için:\nİsteminizde değiştirmek istediğiniz kelimeyi veya kelime öbeğini seçin. Bu durumda, şu metni seçin: who is the architect.\nİstemin üzerindeki Ekle: başlığından &lcub;&lcub;&rcub;&rcub; Test girişi'ni seçin.\nİstemin altındaki İsteminizi test edin tablosunda Test örneği ekle'yi seçip ek bir istem değeri girerek isteminiz için ek bir değer ekleyin. Birkaç yeni giriş değeri ekleyebilirsiniz.\nUygulama penceresinin alt kısmında, Çalıştır'ı seçerek değişen isteklerin her biri için bir yanıt oluşturun.\nİsteminizin prototipini oluştururken uygulamanın sağ tarafında model çalıştırma ayarlarıyla da değişiklikler yapabilirsiniz. Bunlar, bilmeniz gereken önemli ayarlardır:\nModel - İstemlerinize yanıt vermek istediğiniz modeli seçin. Kullanılabilir modeller ve özellikler hakkında daha fazla bilgi için Modeller bölümüne bakın.\nSıcaklık: Modelin yanıtlarında ne kadar rastgeleliğe izin verildiğini kontrol edin. Bu değeri artırmak, modelin daha beklenmedik ve yaratıcı yanıtlar üretmesine olanak tanır.\nMaksimum çıkış sayısı: Modelin her istek için döndürdüğü yanıt sayısını artırın. Bu seçenek, tek bir istem için birden fazla yanıt oluşturarak istemleri hızlıca test etmeye yardımcı olabilir.\nGüvenlik ayarları - Model yanıtlarını yönetmek için güvenlik ayarlarını düzenleyin. Bu denetimlerle ilgili daha ayrıntılı bilgi için Güvenlik ayarları bölümüne göz atın.\nArtık üretken yapay zeka uygulamasının prototipini oluşturduğunuza göre çalışmanızı kaydedebilir veya bu istemi kendi geliştirme ortamınızda kullanmak için kod oluşturabilirsiniz.\nOluşturduğunuz istemi kaydetmek için:\nGoogle AI Studio uygulamasının sağ üst köşesinde Kaydet'i seçin.\nDaha önce yapmadıysanız uygulamayı Google Drive hesabınıza bağlayın.\nİstemi Kaydet iletişim kutusunda bir İstem adı ve isteğe bağlı bir Açıklama girip Kaydet'i seçin.\nOluşturduğunuz istemi kod olarak dışa aktarmak için:\nGoogle AI Studio uygulamasının sağ üst köşesinde Kodu al'ı seçin.\nBir programlama dili sekmesi seçin.\nKodu panonuza kopyalamak için Kopyala'yı seçin.\nNot: İstem kodunu Google AI Studio dışında çalıştırmak için API anahtarına ihtiyacınız vardır. Bu nedenle, bir anahtar oluşturup istem kodunuza eklediğinizden emin olun.\nDikkat: API anahtarınızı şifre gibi kullanıp uygun şekilde koruyun. Anahtarınızı herkese açık olarak yayınlanan bir koda yerleştirmeyin.\nŞu ana kadar modelinize bir talimat (look at the following picture and tell me who is the architect) ile nasıl istem gösterebileceğinizi gördünüz. Bununla birlikte, bazen modele talimat ve örneklerin bir kombinasyonuyla istekte bulunarak daha iyi sonuçlar elde edebilirsiniz. Google AI Studio'daki yapılandırılmış istemler tam da bunu yapmanıza yardımcı olur. Modele sadece ne yapması gerektiğini söylemek yerine, istediğiniz çıkış türünü göstermek için talimatları örneklerle birleştirin. Bu tür istemler, modelin tutarlı bir çıkış biçimine bağlı kalmasını (ör. yapılandırılmış json) ya da bir modeli açıklamak istediğiniz durumlarda faydalıdır. Bu bölümde, Google AI Studio'da yapılandırılmış istemlerin nasıl oluşturulacağını öğreneceksiniz.\nNot: Bu örneği doğrudan Google AI Studio'da örnekler galerisinden deneyebilirsiniz.\nBu örnekte, ürünler için reklam metni oluşturan yapılandırılmış bir istem oluşturacaksınız. Başlamak için Product giriş sütunu ve Product copy çıkış sütunu olmak üzere iki sütun oluşturarak istemin yapısını tanımlarsınız.\nYapılandırılmış istemi oluşturmak için:\nGoogle AI Studio web uygulamasının sol üst tarafında, Yeni oluştur > Yapılandırılmış istem'i seçin.\nEkle: başlığının altına, yapılandırılmış isteme ilişkin talimatları ekleyin:\nVarsayılan input: metin açıklamasını Product: ile değiştirerek INPUT için açıklayıcı bir üstbilgi ekleyin.\nVarsayılan output: metin açıklamasını Product copy: ile değiştirerek ÇIKIŞ için açıklayıcı bir başlık ekleyin.\nİpucu: Modelin yapıyı ayrıştırmasını kolaylaştırmak için sütun adlarının sonuna iki nokta üst üste ekleyin.\nArtık sütunlarınızı adlandırdığınıza göre bazı örnek satırlar sağlayabilirsiniz. Bu satırlar, örnek girişler (bu örnek için ürün adları) ve örnek çıkışlar (karşılık gelen ürün açıklamaları) içermelidir. Modele birkaç örnek ürün açıklaması sağlayarak kendi çıktılarını oluştururken benzer bir stili taklit edebilir. Örnekleri manuel olarak girebilir veya verileri içe aktarma menüsünü kullanarak bir dosyadan içe aktarabilirsiniz.\nÖrnekleri manuel olarak girmek için:\nEn iyi örnekler veri tablosunda Product: başlığının altındaki alanı seçin ve bir ürün açıklaması yazın.\nÜrün metni: başlığının altındaki alanı seçin ve bu ürün için pazarlama metni yazın.\nAşağıda, bu istemdeki giriş ve çıkış değerlerinin bir örneğini bulabilirsiniz:\nÜrün:\tÜrün kopyası:\nNostaljik spor ayakkabı\tBağlayalım! Bu ayakkabılar, benzersiz bir görünüm ve benzersiz renk paletiyle size yardımcı olurken daha önce eşi benzeri olmayan ayakkabının tarzını ve işlevini de sağlıyor.\nSupersoft kapüşonlu sweatshirt\tYeni üniseks kapüşonlu sweatshirt ile rahatlığınızı ve tarzınızı koruyun. %100 pamuktan üretilmiş bu kapüşonlu sweatshirt yumuşaktır ve gün boyu rahatça takılabilir. Yarı fırçalı malzemesi en soğuk günlerde bile sizi sıcak tutar.\nİpucu: Yazar engeliniz varsa veya örnek ürün metni örnekleriniz yoksa metin modelinin sizin için bir şeyler oluşturmasını sağlamak amacıyla Serbest biçim istemi'ni kullanabilirsiniz.\nBir dosyadan örnekleri içe aktarmak için:\nÖrnekler tablosunun sağ üst köşesinde İşlemler > Örnekleri içe aktar'ı seçin.\nİletişim kutusunda, Google Drive'ınızdan bir CSV veya Google E-Tablolar dosyası seçin ya da dosyayı bilgisayarınızdan yükleyin.\nİçe aktarma örnekleri iletişim kutusunda, hangi sütunların içe aktarılacağını ve hangilerinin dışarıda bırakılacağını seçin. İletişim kutusu, yapılandırılmış isteminizdeki hangi veri sütununun hangi tablo sütununa içe aktarılacağını da belirtmenizi sağlar.\nModele istediğiniz şeyi gösteren örnekleri bulduktan sonra alt kısımdaki İsteminizi test edin tablosunda yeni girişle isteminizi test edin. Metin istemi türünde olduğu gibi, kullanım alanınız için daha iyi sonuçlar üretmeye yardımcı olup olmadıklarını test etmek üzere model parametrelerini ayarlayabilirsiniz.\nÖrneklerin modele nasıl gönderildiğini inceleme\nTemelde, Google AI Studio sağladığınız örneklerle talimatları birleştirerek bir istem oluşturur. Siz daha fazla örnek ekledikçe, bunlar modele gönderilen metne eklenir. Örneklerinizin uzunluğuna bağlı olarak, modelin jeton sınırına ulaşmaya başlayabilirsiniz. Tüm üretken yapay zeka modellerinin bir jeton sınırı vardır. Bu sınır, giriş olarak kabul edebilecekleri metnin maksimum uzunluğudur.\nİsteminizin tüm içeriğini görmek için:\nGoogle AI Studio web uygulamasının en altındaki Metin önizleme'yi seçin.\nNot: Model jeton sınırı, önizleme bölmesinin en altında gösterilir.\nİsteminizden memnun olduğunuzda, Kaydet'i tıklayarak veya Kodu Al düğmesini tıklayarak koda aktarabilirsiniz.\nBirkaç çekim örneğini tek tek bir CSV dosyasına veya Google E-Tablosuna da aktarabilirsiniz. Örneklerinizi dışa aktarmak için İşlem menüsü altındaki Örnekleri dışa aktar seçeneğini belirleyin.\nGemini gibi genel amaçlı bir chatbot kullandıysanız üretken yapay zeka modellerinin açık uçlu diyaloglar için ne kadar güçlü olabileceğini bizzat tecrübe etmişsinizdir. Bu genel amaçlı chatbot'lar kullanışlı olsa da çoğu zaman belirli kullanım alanları için özelleştirilmesi gerekir. Örneğin, yalnızca bir şirketin ürünüyle ilgili konuşmaları destekleyen bir müşteri hizmetleri chatbot'u oluşturmak isteyebilirsiniz. Belirli bir üslup veya tarzda konuşan bir chatbot (çok fazla şaka yapan, bir şair gibi kafiyeli veya yanıtlarında çok sayıda emoji kullanan bir bot) geliştirmek isteyebilirsiniz.\nBu örnekte, Google AI Studio'yu kullanarak Jüpiter'in uydularından biri olan Europa'da yaşayan bir uzaylıymış gibi iletişim kuran, samimi bir chatbot geliştirmek için nasıl kullanılacağı gösterilmektedir.\nSon bölümde, giriş ve çıkış örneklerinin bir kombinasyonunu kullanarak yapılandırılmış bir istem tasarladınız. Benzer şekilde, bir chatbot oluşturmak amacıyla, aradığınız yanıtları sağlaması için modeli yönlendirmek amacıyla kullanıcı ile chatbot arasındaki etkileşim örnekleri sağlamanız gerekir.\nSohbet istemi oluşturmak için:\nGoogle AI Studio web uygulamasının sol üst tarafında, Yeni oluştur > Sohbet istemi'ni seçin.\nİstem arayüzünün İstem örneklerinizi yazın sütununda, etkileşim örnekleri sağlamaya başlayabilirsiniz. İlk örnekte aşağıdakiler gibi ek bağlam da sağlayabilirsiniz:\nKullanıcı: none You are Tim, a friendly alien that lives on Europa, one of Jupiter's moons.\nKullanıcı ve Model alanlarında, bir kullanıcı ile chatbot'unuz arasındaki etkileşimlerin nasıl görünebileceğine dair bir örnek sağlanır:\nKullanıcı: none Hi!\nBir örneği doldurduktan sonra sohbet istemi arayüzünün sağ bölmesindeki modelle sohbet ederek uygulamanızı test etmeye başlayın.\nChatbot davranışını test etmek için:\nİsteminizi test edin panelinde, alttaki giriş alanını seçin.\nKullanıcının sorabileceği bir soru veya gözlem girin. Örneğin:\nKullanıcı: none What's the weather like?\nChatbot'tan aşağıdakine benzer bir yanıt almak için giriş alanının sağındaki elmas düğmeyi seçin:\nTek bir ifade ve yanıt örneği vererek temel bir Europa uzaylı chatbot'u oluşturmayı başardınız. Ancak modelin yanıtlarında tutarlılığı ve kaliteyi sağlamak için genellikle tek bir örnek yeterli olmaz. Modelin hava durumuyla ilgili bir soruya verdiği yanıt daha fazla giriş olmadan çok uzun oluyor ve sanki cana yakın bir uzaylıdan ziyade bir ders kitabından geliyormuş gibi geliyor.\nModel yanıtını kullanarak chatbot'unuzun tonunu özelleştirin ve bunu, uzaylı chatbot'unuzun tonu ve stiline uyacak şekilde düzenleyin.\nChatbot tanımına örnekler eklemek ve düzenlemek için:\nİsteminizi test edin panelinde, imleci Kullanıcı başlığının sol tarafında tutun ve Örneklere ekle düğmesini seçin.\nİstem örneklerinizi yazın sütununda, kopyalanan girişi ve yanıtı chatbot'unuzun istenen stiline ve üslubuna uyacak şekilde düzenleyin.\nBaşka örnekler eklemek için bu yaklaşımı kullanabilirsiniz. Daha fazla soru sorun, yanıtları düzenleyin ve chatbot'unuzun kalitesini artırın. Örnekler eklemeye ve chatbot'unuzun davranışını nasıl değiştirdiğini test etmeye devam edin. Genellikle daha fazla örnek, daha yüksek kaliteli chatbot yanıtlarına karşılık gelir.\nGoogle AI Studio, aşağıdaki özellikleri birleştirerek bir istem oluşturur:\nİletişim kutusu örnekleri\nGörüşme geçmişi\nmodele gönderilen tek bir metin bloğuna dönüşür. İstemin tamamının nasıl göründüğünü görmek için önizleme bölmesini açmak üzere ekranın alt kısmındaki Önizleme'yi tıklayın.\nModel ile kullanıcı arasındaki her mesaj isteme dahil edildiğinden (bu, \"sohbet geçmişi\"dir) görüşme devam ettiği sürece sohbet istemlerinin büyüyebileceğini unutmayın. Sonunda modelin kabul edebileceği metnin maksimum uzunluğu olan jeton sınırına ulaşabilirsiniz. Görüşmenin ve jeton sayısının tamamını Önizleme sekmesinde görebilirsiniz.\nKullanım alanınız için daha uygun sonuçlar üretip üretmediklerini görmek için model parametrelerini ayarlamayı da deneyebilirsiniz.\nDiğer istem türlerine benzer şekilde, isteminiz istediğiniz gibi prototipini oluşturduktan sonra kodlamaya başlamak veya isteminizi daha sonra üzerinde çalışmak ve başkalarıyla paylaşmak üzere kaydetmek için Kodu Al düğmesini kullanabilirsiniz.\nKodlamaya devam etmeye hazırsanız API hızlı başlangıç kılavuzlarını inceleyin.\nNasıl daha iyi istemler oluşturacağınızı öğrenmek için İstem tasarım yönergelerine göz atın.\nSon güncelleme tarihi: 2024-04-22 UTC.",
            "filtered_word_count": 1773
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#setup": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#install_the_python_sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#import_packages": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#setup_your_api_key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#list_models": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#generate_text_from_text_inputs": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#generate_text_from_image_and_text_inputs": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#chat_conversations": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#count_tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#use_embeddings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#advanced_use_cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#safety_settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#encode_messages": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#multi-turn_conversations": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#generation_configuration": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/python#whats_next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#set-up-project": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#add-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#initialize-model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#implement-common-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#generate-text-from-text-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#generate-text-from-text-and-image-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#multi-turn-conversations-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#streaming": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#implement-advanced-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#embeddings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#count-tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#control-content-generation": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#model-parameters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#use-safety-settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/go#whats-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#set-up-project": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#add-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#initialize-model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#implement-common-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#generate-text-from-text-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#generate-text-from-text-and-image-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#multi-turn-conversations-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#streaming": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#implement-advanced-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#embeddings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#count-tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#control-content-generation": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#model-parameters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#use-safety-settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/node#whats-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#set-up-project": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#initialize-model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#implement-common-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#generate-text-from-text-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#generate-text-from-text-and-image-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#multi-turn-conversations-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#streaming": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#implement-advanced-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#count-tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#control-content-generation": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#model-parameters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#use-safety-settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/web#whats-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#set-up-project": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#add-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#initialize-model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#implement-common-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#generate-text-from-text-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#generate-text-from-text-and-image-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#multi-turn-conversations-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#streaming": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#implement-advanced-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#embeddings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#count-tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#control-content-generation": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#model-parameters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#use-safety-settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#whats-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#dart": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/dart#flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#set-up-project": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#add-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#initialize-model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#implement-common-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#generate-text-from-text-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#generate-text-from-text-and-image-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#multi-turn-conversations-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#streaming": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#implement-advanced-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#count-tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#control-content-generation": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#model-parameters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#use-safety-settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/swift#whats-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#set-up-project": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#add-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#initialize-model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#implement-common-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#generate-text-from-text-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#generate-text-from-text-and-image-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#multi-turn-conversations-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#streaming": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#implement-advanced-use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#count-tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#control-content-generation": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#model-parameters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#use-safety-settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#whats-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#kotlin": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android#java": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore#benefits-on-device": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore#how-it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/android_aicore#whats-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#set_up_your_api_key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#gemini_and_content_based_apis": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#text-only_input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#text-and-image_input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#multi-turn_conversations_chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#configuration": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#stream_generate_content": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#count_tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#embedding": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#model_info": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#get_model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/get-started/rest#list_models": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/downloads?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#example-applications": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#generate-poem": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#generate-list": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#prompt101": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#prompting-versus": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#prompt-types": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#zero-shot-prompts": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#one-shot-prompts": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#few-shot-prompts": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#under-the-hood": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/generative-models#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#safety": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#model-sizes": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#model-versions": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#model-variations": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#model-metadata": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#model-attributes": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#embedding": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#aqa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/models/gemini#rate-limits": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#models": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#prompt_data_design": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#prompt_design": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#generate_content": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#text_image_input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#text_input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#stream": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#json": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#embedding": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-overview#curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-versions?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/changelog#december-13": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#how-model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#supported-models": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#model-tuning-workflow": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#prepare-dataset": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#format": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#size-recommendation": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#upload-tuning": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#advanced-settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#recommended-configurations": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#check-tuning-status": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#troubleshoot-errors": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#authentication": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#canceled-models": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio#dataset": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio#create-tuned": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/ai-studio#using-tuned": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#setup": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#authenticate": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#install_the_client_library": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#import_libraries": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#create_tuned_model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#check_tuning_progress": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#evaluate_your_model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#update_the_description": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/python#delete_the_model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#setup": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#authenticate": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#calling_the_rest_api_with_curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#set_variables": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#list_tuned_models": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#create_tuned_model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#get_tuned_model_state": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#run_inference": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#call_the_rest_api_with_python_requests": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#set_variables_2": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#list_tuned_models_2": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#create_tuned_model_2": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#get_tuned_model_state_2": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#run_inference_2": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#conclusion": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/model-tuning/rest#next_steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#how_it_works": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#supported-models": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#function_calling_mode": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#function-calling-curl-samples": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#function-calling-single-turn-curl-sample": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#single-turn-any-mode": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#single-turn-using-mode-and-allowed-functions": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#function-calling-one-and-a-half-turn-curl-sample": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#best-practices": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#key-parameters-best-practices": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#prompt-best-practices": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#sampling-parameters-best-practices": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#invoke-api-best-practices": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#multi-turn-example-1": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling#multi-turn-example-2": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python#setup": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python#install_the_python_sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python#import_packages": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python#set_up_your_api_key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python#function_basics": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python#optional_low_level_access": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/function-calling/python#summary": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings#what-are-embeddings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings#use-cases": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings#elastic-embedding": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/embeddings#whats-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#safety-filters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#probability-vs": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#safety-settings": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#safety-feedback": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#safety-settings-ai-studio": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#code-examples": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#request-example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#response-example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-settings#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance#understand_the_safety_risks_of_your_application": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance#consider_adjustments_to_mitigate_safety_risks": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance#perform_safety_testing_appropriate_to_your_use_case": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance#monitor_for_problems": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/safety-guidance#next_steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro#what-is-a-prompt": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro#prompt-content-types": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro#input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro#context": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-intro#examples": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#setup": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#install_the_python_sdk_and_import_packages": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#setup_your_api_key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#upload_a_file_to_the_file_api": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#get_file": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#generate_content": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#delete_files": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#supported_file_formats": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#image_formats": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#audio_formats": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#video_formats": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#appendix_uploading_files_to_colab": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting_with_media#uploading_files_to_colab": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#give-clear-and-specific-instructions": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#define-the-task-to-perform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#specify-any-constraints": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#define-the-format-of-the-response": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#include-few-shot-examples": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#zero-shot-vs-few-shot-prompts": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#find-the-optimal-number-of-examples": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#use-examples-to-show-patterns-instead-of-antipatterns": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#use-consistent-formatting-across-examples": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#add-contextual-information": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#add-prefixes": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#let-the-model-complete-partial-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#break-down-prompts-into-simple-components": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#break-down-instructions": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#chain-prompts": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#aggregate-responses": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#experiment-with-different-parameter-values": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#max-output-tokens": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#temperature": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#top-k": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#top-p": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#prompt-iteration-strategies": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#use-different-phrasing": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#switch-to-an-analogous-task": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#change-the-order-of-prompt-content": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#fallback-responses": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#things-to-avoid": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/prompting-strategies#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#using_media_files_with_prompts": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#strategies": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#prompt-design-fundamentals": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#troubleshooting-your-multimodal-prompt": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#fundamentals": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#be-specific-in-your-instructions": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#add-a-few-examples": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#break-it-down-step-by-step": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#try-specifying-the-output-format": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#put-your-image-first-for-single-image-prompts": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#troubleshooting": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#if-the-model-is-not-drawing-information-from-the-relevant-part-of-the-image": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#if-the-model-output-is-too-generic-and-not-tailored-enough-to-the-image-input": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#troubleshooting-which-part-of-the-prompt-failed": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#tuning-the-sampling-parameters": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/file-prompting-strategies#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions#examples": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions#code-generation": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions#formatted-data": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/system-instructions#music-chatbot": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#overview": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#setup": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#import_the_generative_language_api": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#authenticate": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#service-oauth": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#create-corpus": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#get_the_created_corpus": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#create_a_document": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#get_the_created_document": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#ingest_chunk_a_document": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#ingest_html_and_chunk_via_htmlchunker": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#batch_create_chunks": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#list_chunks_and_get_state": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#ingest_another_document": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#query_the_corpus": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#attributed_question-answering": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#answerable_probability_and_the_%E2%80%9Ci_don%E2%80%99t_know%E2%80%9D_problem": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#aqa_helpful_tips": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#more_options_aqa_using_inline_passages": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#share_the_corpus": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#delete_the_corpus": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#summary_and_further_reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#user-oauth": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#service_oauth": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#user_oauth": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/semantic_retrieval#create_corpus": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#objectives": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#set-cloud": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#enable-api": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#configure-oauth": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#authorize-credentials": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#set-application-default": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#manage-credentials": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#install-libs": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#write-credentials": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#write-program": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/oauth#run-program": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions#chatbot": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/firebase-extensions#multimodal": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud#migrate-gemini": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud#python-migrate": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud#delete-unused-keys": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/migrate-to-cloud#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#error-codes": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#check-api": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#check-if": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#safety-issues": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#improve-model": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#understand-token": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#known-issues": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshooting#file-bug": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace#turn-on-early-access": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/workspace#troubleshooting": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio#understand-403-errors": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio#resolve-no-content": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio#check-token-usage": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quota?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=de": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=es-419": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=fr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=id": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=it": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=pl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=pt-br": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=vi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=tr": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=ru": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=he": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=ar": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=fa": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=hi": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=bn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=th": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=zh-cn": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=zh-tw": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=ja": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions?hl=ko": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions#available_languages": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/available-regions#available_regions": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=de#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=de#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=de#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=de#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=es-419#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=es-419#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=es-419#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=es-419#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fr#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fr#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fr#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fr#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=id#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=id#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=id#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=id#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=it#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=it#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=it#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=it#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pl#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pl#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pl#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pl#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pt-br#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pt-br#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pt-br#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=pt-br#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=vi#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=vi#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=vi#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=vi#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=tr#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=tr#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=tr#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=tr#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ru#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ru#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ru#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ru#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=he#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=he#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=he#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=he#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ar#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ar#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ar#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ar#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fa#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fa#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fa#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=fa#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=hi#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=hi#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=hi#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=hi#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=bn#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=bn#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=bn#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=bn#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=th#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=th#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=th#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=th#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-cn#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-cn#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-cn#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-cn#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-tw#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-tw#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-tw#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=zh-tw#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ja#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ja#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ja#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ja#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ko#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ko#verify-key-with-curl": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ko#security": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/api-key?hl=ko#next-steps": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#ok": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=de#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=es-419#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fr#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=id#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=it#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#rzutki-zrzuty": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pl#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=pt-br#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#phi-ti%C3%AAu-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=vi#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=tr#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#%D0%BF%D0%B8%D1%82%D0%BE%D0%BD": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#%D0%B8%D0%B4%D1%82%D0%B8": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%BD%D0%B5%D1%82": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#%D0%B4%D0%B0%D1%80%D1%82-%D1%84%D0%BB%D0%B0%D1%82%D1%82%D0%B5%D1%80": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#%D0%B1%D1%8B%D1%81%D1%82%D1%80%D1%8B%D0%B9": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ru#%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B8%D0%B4": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#%D7%90%D7%AA%D7%A8%D7%99%D7%9D": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#%D7%A7%D7%9C%D7%99%D7%A2%D7%94-%D7%9C%D7%9E%D7%98%D7%A8%D7%94-%D7%A4%D7%9C%D7%95%D7%98%D7%A8": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=he#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#%D8%A7%D9%84%D8%A8%D8%AF%D8%A1": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#%D8%A7%D9%84%D9%88%D9%8A%D8%A8": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ar#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#%D8%A8%D8%B1%D9%88": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#%D9%88%D8%A8": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#%D8%AF%D8%A7%D8%B1%D8%AA-%D9%81%D9%84%D8%A7%D8%AA%D8%B1": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#%D8%B3%D8%B1%DB%8C%D8%B9": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=fa#%D8%A7%D9%86%D8%AF%D8%B1%D9%88%DB%8C%D8%AF": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#%E0%A4%B6%E0%A5%81%E0%A4%B0%E0%A5%82-%E0%A4%95%E0%A4%B0%E0%A5%87%E0%A4%82": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#%E0%A4%B5%E0%A5%87%E0%A4%AC": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#%E0%A4%A1%E0%A4%BE%E0%A4%B0%E0%A5%8D%E0%A4%9F-%E0%A4%AB%E0%A4%BC%E0%A5%8D%E0%A4%B2%E0%A4%9F%E0%A4%B0": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=hi#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#%E0%A6%AF%E0%A6%BE%E0%A6%93%E0%A6%AF%E0%A6%BC%E0%A6%BE": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#%E0%A6%93%E0%A6%AF%E0%A6%BC%E0%A7%87%E0%A6%AC": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#%E0%A6%A1%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%9F-%E0%A6%AB%E0%A7%8D%E0%A6%B2%E0%A6%9F%E0%A6%BE%E0%A6%B0": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#%E0%A6%B8%E0%A7%81%E0%A6%87%E0%A6%AB%E0%A6%9F": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=bn#%E0%A6%85%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A8%E0%A7%8D%E0%A6%A1%E0%A7%8D%E0%A6%B0%E0%A6%AF%E0%A6%BC%E0%A7%87%E0%A6%A1": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#%E0%B9%80%E0%B8%A7%E0%B9%87%E0%B8%9A%E0%B9%84%E0%B8%8B%E0%B8%95%E0%B9%8C": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#%E0%B8%A5%E0%B8%B9%E0%B8%81%E0%B8%94%E0%B8%AD%E0%B8%81-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=th#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#%E7%BD%91%E7%AB%99": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-cn#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#%E6%9F%A5%E7%9C%8B": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#web": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#%E9%A3%9B%E9%8F%A2-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=zh-tw#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#%E3%82%A6%E3%82%A7%E3%83%96": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#dart%EF%BC%88flutter%EF%BC%89": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ja#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#prerequisites": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#set-up-api-key": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#install-sdk": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#initialize-generative": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#generate-text": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#what's-next": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#python": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#go": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#node.js": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#%EC%9B%B9": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#dart-flutter": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#swift": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/quickstart?hl=ko#android": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=de#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=es-419#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=fr#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=id#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=it#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pl#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=pt-br#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=vi#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#prompts-and": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#freeform_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-1-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-2-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-3-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-4-freeform": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#structured_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step_1_sp": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-2-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-3-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-4-structured": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#chat_example": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-1-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-2-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-3-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#step-4-chat": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        },
        "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart?hl=tr#further-reading": {
            "status": "not_indexed",
            "word_count": 0,
            "filtered_word_count": 0,
            "filtered_content": ""
        }
    }
}