{
    "total_words": 96748,
    "total_links": 25,
    "links": {
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nDocuments / Nodes\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nConcept\nUsage Pattern\nDocuments\nNodes\nDocument/Node Usage\nDocuments / Nodes#\nConcept#\n\nDocument and Node objects are core abstractions within LlamaIndex.\n\nA Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below.\n\nmetadata - a dictionary of annotations that can be appended to the text.\nrelationships - a dictionary containing relationships to other Documents/Nodes.\n\nNote: We have beta support for allowing Documents to store images, and are actively working on improving its multimodal capabilities.\n\nA Node represents a \"chunk\" of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a \"file_name\" filed in the Document is propagated to every Node).\n\nUsage Pattern#\n\nHere are some simple snippets to get started with Documents and Nodes.\n\nDocuments#\nfrom llama_index.core import Document, VectorStoreIndex\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n# build index\nindex = VectorStoreIndex.from_documents(documents)\n\nNodes#\nfrom llama_index.core.node_parser import SentenceSplitter\n\n# load documents\n...\n\n# parse nodes\nparser = SentenceSplitter()\nnodes = parser.get_nodes_from_documents(documents)\n\n# build index\nindex = VectorStoreIndex(nodes)\n\nDocument/Node Usage#\n\nTake a look at our in-depth guides for more details on how to use Documents/Nodes.\n\nUsing Documents\nUsing Nodes\nIngestion Pipeline\n Back to top\nPrevious\nLoading Data\nNext\nUsing Documents\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3608
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_metadata_extractor/": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nMetadata Extraction\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nResources\nMetadata Extraction Usage Pattern#\n\nYou can use LLMs to automate metadata extraction with our Metadata Extractor modules.\n\nOur metadata extractor modules include the following \"feature extractors\":\n\nSummaryExtractor - automatically extracts a summary over a set of Nodes\nQuestionsAnsweredExtractor - extracts a set of questions that each Node can answer\nTitleExtractor - extracts a title over the context of each Node\nEntityExtractor - extracts entities (i.e. names of places, people, things) mentioned in the content of each Node\n\nThen you can chain the Metadata Extractors with our node parser:\n\nfrom llama_index.core.extractors import (\n    TitleExtractor,\n    QuestionsAnsweredExtractor,\n)\nfrom llama_index.core.node_parser import TokenTextSplitter\n\ntext_splitter = TokenTextSplitter(\n    separator=\" \", chunk_size=512, chunk_overlap=128\n)\ntitle_extractor = TitleExtractor(nodes=5)\nqa_extractor = QuestionsAnsweredExtractor(questions=3)\n\n# assume documents are defined -> extract nodes\nfrom llama_index.core.ingestion import IngestionPipeline\n\npipeline = IngestionPipeline(\n    transformations=[text_splitter, title_extractor, qa_extractor]\n)\n\nnodes = pipeline.run(\n    documents=documents,\n    in_place=True,\n    show_progress=True,\n)\n\n\nor insert into an index:\n\nfrom llama_index.core import VectorStoreIndex\n\nindex = VectorStoreIndex.from_documents(\n    documents, transformations=[text_splitter, title_extractor, qa_extractor]\n)\n\nResources#\nSEC Documents Metadata Extraction\nLLM Survey Extraction\nEntity Extraction\nMarvin Metadata Extraction\nPydantic Metadata Extraction\n Back to top\nPrevious\nUsing Nodes\nNext\nSimpleDirectoryReader\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3488
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/#documents-nodes": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nDocuments / Nodes\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nConcept\nUsage Pattern\nDocuments\nNodes\nDocument/Node Usage\nDocuments / Nodes#\nConcept#\n\nDocument and Node objects are core abstractions within LlamaIndex.\n\nA Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below.\n\nmetadata - a dictionary of annotations that can be appended to the text.\nrelationships - a dictionary containing relationships to other Documents/Nodes.\n\nNote: We have beta support for allowing Documents to store images, and are actively working on improving its multimodal capabilities.\n\nA Node represents a \"chunk\" of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a \"file_name\" filed in the Document is propagated to every Node).\n\nUsage Pattern#\n\nHere are some simple snippets to get started with Documents and Nodes.\n\nDocuments#\nfrom llama_index.core import Document, VectorStoreIndex\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n# build index\nindex = VectorStoreIndex.from_documents(documents)\n\nNodes#\nfrom llama_index.core.node_parser import SentenceSplitter\n\n# load documents\n...\n\n# parse nodes\nparser = SentenceSplitter()\nnodes = parser.get_nodes_from_documents(documents)\n\n# build index\nindex = VectorStoreIndex(nodes)\n\nDocument/Node Usage#\n\nTake a look at our in-depth guides for more details on how to use Documents/Nodes.\n\nUsing Documents\nUsing Nodes\nIngestion Pipeline\n Back to top\nPrevious\nLoading Data\nNext\nUsing Documents\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3608
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/#nodes": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nDocuments / Nodes\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nConcept\nUsage Pattern\nDocuments\nNodes\nDocument/Node Usage\nDocuments / Nodes#\nConcept#\n\nDocument and Node objects are core abstractions within LlamaIndex.\n\nA Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below.\n\nmetadata - a dictionary of annotations that can be appended to the text.\nrelationships - a dictionary containing relationships to other Documents/Nodes.\n\nNote: We have beta support for allowing Documents to store images, and are actively working on improving its multimodal capabilities.\n\nA Node represents a \"chunk\" of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a \"file_name\" filed in the Document is propagated to every Node).\n\nUsage Pattern#\n\nHere are some simple snippets to get started with Documents and Nodes.\n\nDocuments#\nfrom llama_index.core import Document, VectorStoreIndex\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n# build index\nindex = VectorStoreIndex.from_documents(documents)\n\nNodes#\nfrom llama_index.core.node_parser import SentenceSplitter\n\n# load documents\n...\n\n# parse nodes\nparser = SentenceSplitter()\nnodes = parser.get_nodes_from_documents(documents)\n\n# build index\nindex = VectorStoreIndex(nodes)\n\nDocument/Node Usage#\n\nTake a look at our in-depth guides for more details on how to use Documents/Nodes.\n\nUsing Documents\nUsing Nodes\nIngestion Pipeline\n Back to top\nPrevious\nLoading Data\nNext\nUsing Documents\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3610
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/#documentnode-usage": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nDocuments / Nodes\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nConcept\nUsage Pattern\nDocuments\nNodes\nDocument/Node Usage\nDocuments / Nodes#\nConcept#\n\nDocument and Node objects are core abstractions within LlamaIndex.\n\nA Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below.\n\nmetadata - a dictionary of annotations that can be appended to the text.\nrelationships - a dictionary containing relationships to other Documents/Nodes.\n\nNote: We have beta support for allowing Documents to store images, and are actively working on improving its multimodal capabilities.\n\nA Node represents a \"chunk\" of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a \"file_name\" filed in the Document is propagated to every Node).\n\nUsage Pattern#\n\nHere are some simple snippets to get started with Documents and Nodes.\n\nDocuments#\nfrom llama_index.core import Document, VectorStoreIndex\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n# build index\nindex = VectorStoreIndex.from_documents(documents)\n\nNodes#\nfrom llama_index.core.node_parser import SentenceSplitter\n\n# load documents\n...\n\n# parse nodes\nparser = SentenceSplitter()\nnodes = parser.get_nodes_from_documents(documents)\n\n# build index\nindex = VectorStoreIndex(nodes)\n\nDocument/Node Usage#\n\nTake a look at our in-depth guides for more details on how to use Documents/Nodes.\n\nUsing Documents\nUsing Nodes\nIngestion Pipeline\n Back to top\nPrevious\nLoading Data\nNext\nUsing Documents\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3610
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/#documents": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nDocuments / Nodes\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nConcept\nUsage Pattern\nDocuments\nNodes\nDocument/Node Usage\nDocuments / Nodes#\nConcept#\n\nDocument and Node objects are core abstractions within LlamaIndex.\n\nA Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below.\n\nmetadata - a dictionary of annotations that can be appended to the text.\nrelationships - a dictionary containing relationships to other Documents/Nodes.\n\nNote: We have beta support for allowing Documents to store images, and are actively working on improving its multimodal capabilities.\n\nA Node represents a \"chunk\" of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a \"file_name\" filed in the Document is propagated to every Node).\n\nUsage Pattern#\n\nHere are some simple snippets to get started with Documents and Nodes.\n\nDocuments#\nfrom llama_index.core import Document, VectorStoreIndex\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n# build index\nindex = VectorStoreIndex.from_documents(documents)\n\nNodes#\nfrom llama_index.core.node_parser import SentenceSplitter\n\n# load documents\n...\n\n# parse nodes\nparser = SentenceSplitter()\nnodes = parser.get_nodes_from_documents(documents)\n\n# build index\nindex = VectorStoreIndex(nodes)\n\nDocument/Node Usage#\n\nTake a look at our in-depth guides for more details on how to use Documents/Nodes.\n\nUsing Documents\nUsing Nodes\nIngestion Pipeline\n Back to top\nPrevious\nLoading Data\nNext\nUsing Documents\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3610
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/#concept": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nDocuments / Nodes\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nConcept\nUsage Pattern\nDocuments\nNodes\nDocument/Node Usage\nDocuments / Nodes#\nConcept#\n\nDocument and Node objects are core abstractions within LlamaIndex.\n\nA Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below.\n\nmetadata - a dictionary of annotations that can be appended to the text.\nrelationships - a dictionary containing relationships to other Documents/Nodes.\n\nNote: We have beta support for allowing Documents to store images, and are actively working on improving its multimodal capabilities.\n\nA Node represents a \"chunk\" of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a \"file_name\" filed in the Document is propagated to every Node).\n\nUsage Pattern#\n\nHere are some simple snippets to get started with Documents and Nodes.\n\nDocuments#\nfrom llama_index.core import Document, VectorStoreIndex\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n# build index\nindex = VectorStoreIndex.from_documents(documents)\n\nNodes#\nfrom llama_index.core.node_parser import SentenceSplitter\n\n# load documents\n...\n\n# parse nodes\nparser = SentenceSplitter()\nnodes = parser.get_nodes_from_documents(documents)\n\n# build index\nindex = VectorStoreIndex(nodes)\n\nDocument/Node Usage#\n\nTake a look at our in-depth guides for more details on how to use Documents/Nodes.\n\nUsing Documents\nUsing Nodes\nIngestion Pipeline\n Back to top\nPrevious\nLoading Data\nNext\nUsing Documents\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3610
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4201
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_nodes/": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Nodes\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nCustomizing the ID\nDefining and Customizing Nodes#\n\nNodes represent \"chunks\" of source Documents, whether that is a text chunk, an image, or more. They also contain metadata and relationship information with other nodes and index structures.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes.\n\nFor instance, you can do\n\nfrom llama_index.core.node_parser import SentenceSplitter\n\nparser = SentenceSplitter()\n\nnodes = parser.get_nodes_from_documents(documents)\n\n\nYou can also choose to construct Node objects manually and skip the first section. For instance,\n\nfrom llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n\nnode1 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\nnode2 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\n# set relationships\nnode1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n    node_id=node2.node_id\n)\nnode2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n    node_id=node1.node_id\n)\nnodes = [node1, node2]\n\n\nThe RelatedNodeInfo class can also store additional metadata if needed:\n\nnode2.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n    node_id=node1.node_id, metadata={\"key\": \"val\"}\n)\n\nCustomizing the ID#\n\nEach node has an node_id property that is automatically generated if not manually specified. This ID can be used for a variety of purposes; this includes being able to update nodes in storage, being able to define relationships between nodes (through IndexNode), and more.\n\nYou can also get and set the node_id of any TextNode directly.\n\nprint(node.node_id)\nnode.node_id = \"My new node_id!\"\n\n Back to top\nPrevious\nUsing Documents\nNext\nMetadata Extraction\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3528
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/#usage-pattern": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nDocuments / Nodes\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nConcept\nUsage Pattern\nDocuments\nNodes\nDocument/Node Usage\nDocuments / Nodes#\nConcept#\n\nDocument and Node objects are core abstractions within LlamaIndex.\n\nA Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below.\n\nmetadata - a dictionary of annotations that can be appended to the text.\nrelationships - a dictionary containing relationships to other Documents/Nodes.\n\nNote: We have beta support for allowing Documents to store images, and are actively working on improving its multimodal capabilities.\n\nA Node represents a \"chunk\" of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a \"file_name\" filed in the Document is propagated to every Node).\n\nUsage Pattern#\n\nHere are some simple snippets to get started with Documents and Nodes.\n\nDocuments#\nfrom llama_index.core import Document, VectorStoreIndex\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n# build index\nindex = VectorStoreIndex.from_documents(documents)\n\nNodes#\nfrom llama_index.core.node_parser import SentenceSplitter\n\n# load documents\n...\n\n# parse nodes\nparser = SentenceSplitter()\nnodes = parser.get_nodes_from_documents(documents)\n\n# build index\nindex = VectorStoreIndex(nodes)\n\nDocument/Node Usage#\n\nTake a look at our in-depth guides for more details on how to use Documents/Nodes.\n\nUsing Documents\nUsing Nodes\nIngestion Pipeline\n Back to top\nPrevious\nLoading Data\nNext\nUsing Documents\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3608
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_metadata_extractor/#metadata-extraction-usage-pattern": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nMetadata Extraction\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nResources\nMetadata Extraction Usage Pattern#\n\nYou can use LLMs to automate metadata extraction with our Metadata Extractor modules.\n\nOur metadata extractor modules include the following \"feature extractors\":\n\nSummaryExtractor - automatically extracts a summary over a set of Nodes\nQuestionsAnsweredExtractor - extracts a set of questions that each Node can answer\nTitleExtractor - extracts a title over the context of each Node\nEntityExtractor - extracts entities (i.e. names of places, people, things) mentioned in the content of each Node\n\nThen you can chain the Metadata Extractors with our node parser:\n\nfrom llama_index.core.extractors import (\n    TitleExtractor,\n    QuestionsAnsweredExtractor,\n)\nfrom llama_index.core.node_parser import TokenTextSplitter\n\ntext_splitter = TokenTextSplitter(\n    separator=\" \", chunk_size=512, chunk_overlap=128\n)\ntitle_extractor = TitleExtractor(nodes=5)\nqa_extractor = QuestionsAnsweredExtractor(questions=3)\n\n# assume documents are defined -> extract nodes\nfrom llama_index.core.ingestion import IngestionPipeline\n\npipeline = IngestionPipeline(\n    transformations=[text_splitter, title_extractor, qa_extractor]\n)\n\nnodes = pipeline.run(\n    documents=documents,\n    in_place=True,\n    show_progress=True,\n)\n\n\nor insert into an index:\n\nfrom llama_index.core import VectorStoreIndex\n\nindex = VectorStoreIndex.from_documents(\n    documents, transformations=[text_splitter, title_extractor, qa_extractor]\n)\n\nResources#\nSEC Documents Metadata Extraction\nLLM Survey Extraction\nEntity Extraction\nMarvin Metadata Extraction\nPydantic Metadata Extraction\n Back to top\nPrevious\nUsing Nodes\nNext\nSimpleDirectoryReader\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3488
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_metadata_extractor/#resources": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nMetadata Extraction\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nResources\nMetadata Extraction Usage Pattern#\n\nYou can use LLMs to automate metadata extraction with our Metadata Extractor modules.\n\nOur metadata extractor modules include the following \"feature extractors\":\n\nSummaryExtractor - automatically extracts a summary over a set of Nodes\nQuestionsAnsweredExtractor - extracts a set of questions that each Node can answer\nTitleExtractor - extracts a title over the context of each Node\nEntityExtractor - extracts entities (i.e. names of places, people, things) mentioned in the content of each Node\n\nThen you can chain the Metadata Extractors with our node parser:\n\nfrom llama_index.core.extractors import (\n    TitleExtractor,\n    QuestionsAnsweredExtractor,\n)\nfrom llama_index.core.node_parser import TokenTextSplitter\n\ntext_splitter = TokenTextSplitter(\n    separator=\" \", chunk_size=512, chunk_overlap=128\n)\ntitle_extractor = TitleExtractor(nodes=5)\nqa_extractor = QuestionsAnsweredExtractor(questions=3)\n\n# assume documents are defined -> extract nodes\nfrom llama_index.core.ingestion import IngestionPipeline\n\npipeline = IngestionPipeline(\n    transformations=[text_splitter, title_extractor, qa_extractor]\n)\n\nnodes = pipeline.run(\n    documents=documents,\n    in_place=True,\n    show_progress=True,\n)\n\n\nor insert into an index:\n\nfrom llama_index.core import VectorStoreIndex\n\nindex = VectorStoreIndex.from_documents(\n    documents, transformations=[text_splitter, title_extractor, qa_extractor]\n)\n\nResources#\nSEC Documents Metadata Extraction\nLLM Survey Extraction\nEntity Extraction\nMarvin Metadata Extraction\nPydantic Metadata Extraction\n Back to top\nPrevious\nUsing Nodes\nNext\nSimpleDirectoryReader\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3490
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#metadata": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4201
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#customizing-llm-metadata-text": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#defining-documents": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#customizing-metadata-format": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#customizing-the-id": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#customizing-documents": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#defining-and-customizing-documents": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#summary": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#advanced-automatic-metadata-extraction": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#advanced-metadata-customization": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents/#customizing-embedding-metadata-text": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Documents\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nDefining Documents\nCustomizing Documents\nMetadata\nCustomizing the id\nAdvanced - Metadata Customization\nCustomizing LLM Metadata Text\nCustomizing Embedding Metadata Text\nCustomizing Metadata Format\nSummary\nAdvanced - Automatic Metadata Extraction\nDefining and Customizing Documents#\nDefining Documents#\n\nDocuments can either be created automatically via data loaders, or constructed manually.\n\nBy default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n\nYou can also choose to construct documents manually. LlamaIndex exposes the Document struct.\n\nfrom llama_index.core import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(text=t) for t in text_list]\n\n\nTo speed up prototyping and development, you can also quickly create a document using some default text:\n\ndocument = Document.example()\n\nCustomizing Documents#\n\nThis section covers various ways to customize Document objects. Since the Document object is a subclass of our TextNode object, all these settings and details apply to the TextNode object class as well.\n\nMetadata#\n\nDocuments also offer the chance to include useful metadata. Using the metadata dictionary on each document, additional information can be included to help inform responses and track down sources for query responses. This information can be anything, such as filenames or categories. If you are integrating with a vector database, keep in mind that some vector databases require that the keys must be strings, and the values must be flat (either str, float, or int).\n\nAny information set in the metadata dictionary of each document will show up in the metadata of each source node created from the document. Additionally, this information is included in the nodes, enabling the index to utilize it on queries and responses. By default, the metadata is injected into the text for both embedding and LLM model calls.\n\nThere are a few ways to set up this dictionary:\n\nIn the document constructor:\ndocument = Document(\n    text=\"text\",\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n)\n\nAfter the document is created:\ndocument.metadata = {\"filename\": \"<doc_file_name>\"}\n\nSet the filename automatically using the SimpleDirectoryReader and file_metadata hook. This will automatically run the hook on each document to set the metadata field:\nfrom llama_index.core import SimpleDirectoryReader\n\nfilename_fn = lambda filename: {\"file_name\": filename}\n\n# automatically sets the metadata of each document according to filename_fn\ndocuments = SimpleDirectoryReader(\n    \"./data\", file_metadata=filename_fn\n).load_data()\n\nCustomizing the id#\n\nAs detailed in the section Document Management, the doc_id is used to enable efficient refreshing of documents in the index. When using the SimpleDirectoryReader, you can automatically set the doc doc_id to be the full path to each document:\n\nfrom llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()\nprint([x.doc_id for x in documents])\n\n\nYou can also set the doc_id of any Document directly!\n\ndocument.doc_id = \"My new document id!\"\n\n\nNote: the ID can also be set through the node_id or id_ property on a Document object, similar to a TextNode object.\n\nAdvanced - Metadata Customization#\n\nA key detail mentioned above is that by default, any metadata you set is included in the embeddings generation and LLM.\n\nCustomizing LLM Metadata Text#\n\nTypically, a document might have many metadata keys, but you might not want all of them visible to the LLM during response synthesis. In the above examples, we may not want the LLM to read the file_name of our document. However, the file_name might include information that will help generate better embeddings. A key advantage of doing this is to bias the embeddings for retrieval without changing what the LLM ends up reading.\n\nWe can exclude it like so:\n\ndocument.excluded_llm_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the LLM will actually end up reading using the get_content() function and specifying MetadataMode.LLM:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.LLM))\n\nCustomizing Embedding Metadata Text#\n\nSimilar to customing the metadata visible to the LLM, we can also customize the metadata visible to embeddings. In this case, you can specifically exclude metadata visible to the embedding model, in case you DON'T want particular text to bias the embeddings.\n\ndocument.excluded_embed_metadata_keys = [\"file_name\"]\n\n\nThen, we can test what the embedding model will actually end up reading using the get_content() function and specifying MetadataMode.EMBED:\n\nfrom llama_index.core.schema import MetadataMode\n\nprint(document.get_content(metadata_mode=MetadataMode.EMBED))\n\nCustomizing Metadata Format#\n\nAs you know by now, metadata is injected into the actual text of each document/node when sent to the LLM or embedding model. By default, the format of this metadata is controlled by three attributes:\n\nDocument.metadata_seperator -> default = \"\\n\"\n\nWhen concatenating all key/value fields of your metadata, this field controls the separator between each key/value pair.\n\nDocument.metadata_template -> default = \"{key}: {value}\"\n\nThis attribute controls how each key/value pair in your metadata is formatted. The two variables key and value string keys are required.\n\nDocument.text_template -> default = {metadata_str}\\n\\n{content}\n\nOnce your metadata is converted into a string using metadata_seperator and metadata_template, this templates controls what that metadata looks like when joined with the text content of your document/node. The metadata and content string keys are required.\n\nSummary#\n\nKnowing all this, let's create a short example using all this power:\n\nfrom llama_index.core import Document\nfrom llama_index.core.schema import MetadataMode\n\ndocument = Document(\n    text=\"This is a super-customized document\",\n    metadata={\n        \"file_name\": \"super_secret_document.txt\",\n        \"category\": \"finance\",\n        \"author\": \"LlamaIndex\",\n    },\n    excluded_llm_metadata_keys=[\"file_name\"],\n    metadata_seperator=\"::\",\n    metadata_template=\"{key}=>{value}\",\n    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n)\n\nprint(\n    \"The LLM sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.LLM),\n)\nprint(\n    \"The Embedding model sees this: \\n\",\n    document.get_content(metadata_mode=MetadataMode.EMBED),\n)\n\nAdvanced - Automatic Metadata Extraction#\n\nWe have initial examples of using LLMs themselves to perform metadata extraction.\n\n Back to top\nPrevious\nDocuments / Nodes\nNext\nUsing Nodes\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 4203
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_nodes/#customizing-the-id": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Nodes\nInitializing search\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nCustomizing the ID\nDefining and Customizing Nodes#\n\nNodes represent \"chunks\" of source Documents, whether that is a text chunk, an image, or more. They also contain metadata and relationship information with other nodes and index structures.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes.\n\nFor instance, you can do\n\nfrom llama_index.core.node_parser import SentenceSplitter\n\nparser = SentenceSplitter()\n\nnodes = parser.get_nodes_from_documents(documents)\n\n\nYou can also choose to construct Node objects manually and skip the first section. For instance,\n\nfrom llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n\nnode1 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\nnode2 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\n# set relationships\nnode1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n    node_id=node2.node_id\n)\nnode2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n    node_id=node1.node_id\n)\nnodes = [node1, node2]\n\n\nThe RelatedNodeInfo class can also store additional metadata if needed:\n\nnode2.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n    node_id=node1.node_id, metadata={\"key\": \"val\"}\n)\n\nCustomizing the ID#\n\nEach node has an node_id property that is automatically generated if not manually specified. This ID can be used for a variety of purposes; this includes being able to update nodes in storage, being able to define relationships between nodes (through IndexNode), and more.\n\nYou can also get and set the node_id of any TextNode directly.\n\nprint(node.node_id)\nnode.node_id = \"My new node_id!\"\n\n Back to top\nPrevious\nUsing Documents\nNext\nMetadata Extraction\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3528
        },
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_nodes/#defining-and-customizing-nodes": {
            "status": "Looks good",
            "content": "Skip to content\nLlamaIndex\nUsing Nodes\nType to start searching\nLlamaIndex\nHome\nHome\nHigh-Level Concepts (RAG)\nInstallation and Setup\nHow to read these docs\nStarter Examples\nStarter Examples\nStarter Tutorial (OpenAI)\nStarter Tutorial (Local Models)\nDiscover LlamaIndex Video Series\nFrequently Asked Questions (FAQ)\nStarter Tools\nStarter Tools\nRAG CLI\nLearn\nLearn\nUsing LLMs\nLoading & Ingestion\nLoading & Ingestion\nLoading Data (Ingestion)\nLlamaHub\nIndexing & Embedding\nStoring\nQuerying\nTracing and Debugging\nEvaluating\nEvaluating\nEvaluating\nCost Analysis\nCost Analysis\nUsage Pattern\nPutting it all Together\nPutting it all Together\nAgents\nFull-Stack Web Application\nKnowledge Graphs\nQ&A patterns\nStructured Data\napps\napps\nA Guide to Building a Full-Stack Web App with LLamaIndex\nA Guide to Building a Full-Stack LlamaIndex Web App with Delphic\nchatbots\nchatbots\nHow to Build a Chatbot\nq_and_a\nq_and_a\nA Guide to Extracting Terms and Definitions\nUse Cases\nUse Cases\nPrompting\nQuestion-Answering (RAG)\nChatbots\nStructured Data Extraction\nAgents\nMulti-Modal Applications\nFine-Tuning\nExamples\nExamples\nAgents\nAgents\nðŸ’¬ðŸ¤– How to Build a Chatbot\nBuild your own OpenAI Agent\nOpenAI agent: specifying a forced function call\nBuilding a Custom Agent\nOpenAI Assistant Advanced Retrieval Cookbook\nBuilding an Agent around a Query Pipeline\nStep-wise, Controllable Agents\nControllable Agents for RAG\nControllable Agents for RAG\nRetrieval-Augmented OpenAI Agent\nReAct Agent with Query Engine (RAG) Tools\nOpenAI Assistant Agent\nMulti-Document Agents (V1)\nSingle-Turn Multi-Function Calling OpenAI Agents\nReAct Agent - A Simple Intro with Calculator Tools\nGPT Builder Demo\nContext-Augmented OpenAI Agent\nMulti-Document Agents\nOpenAI Agent with Query Engine Tools\nOpenAI Agent + Query Engine Experimental Cookbook\nOpenAI Agent Query Planning\nBenchmarking OpenAI Retrieval API (through Assistant Agent)\nBuilding a Multi-PDF Agent using Query Pipelines and HyDE\nFunction Calling Mistral Agent\nOpenAI Agent with Tool Call Parser\nControlling Agent Reasoning Loop with Return Direct Tools\nFunction Calling Anthropic Agent\nChain-of-Abstraction LlamaPack\nLanguage Agent Tree Search\nLLM Compiler Agent Cookbook\nCallbacks\nCallbacks\nHoneyHive LlamaIndex Tracer\nPromptLayer Handler\nToken Counting Handler\nLlama Debug Handler\nObservability with OpenLLMetry\nUpTrain Callback Handler\nWandb Callback Handler\nAim Callback\nOpenInference Callback Handler + Arize Phoenix\nLangfuse Callback Handler\nChat Engines\nChat Engines\nChat Engine with a Personality âœ¨\nChat Engine - OpenAI Agent Mode\nChat Engine - Context Mode\nChat Engine - Best Mode\nChat Engine - ReAct Agent Mode\nChat Engine - Simple Mode REPL\nChat Engine - Condense Plus Context Mode\nChat Engine - Condense Question Mode\nCookbooks\nCookbooks\nCohere init8 and binary Embeddings Retrieval Evaluation\nmixedbread Rerank Cookbook\nMistralAI Cookbook\nAnthropic Haiku Cookbook\nLlama3 Cookbook\nCustomization\nCustomization\nStreaming for Chat Engine - Condense Question Mode\nStreaming\nCompletion Prompts Customization\nChat Prompts Customization\nChatGPT\nHuggingFace LLM - StableLM\nHuggingFace LLM - Camel-5b\nAzure OpenAI\nData Connectors\nData Connectors\nParallel Processing SimpleDirectoryReader\nDeepLake Reader\nPsychic Reader\nQdrant Reader\nHTML Tag Reader\nDiscord Reader\nMongoDB Reader\nChroma Reader\nMyScale Reader\nFaiss Reader\nObsidian Reader\nSlack Reader\nWeb Page Reader\nPinecone Reader\nMbox Reader\nMilvusReader\nNotion Reader\nDashVector Reader\nPathway Reader\nDeplot Reader Demo\nGithub Repo Reader\nSimple Directory Reader\nGoogle Docs Reader\nDatabase Reader\nTwitter Reader\nWeaviate Reader\nMake Reader\nGoogle Sheets Reader\nSimple Directory Reader over a Remote FileSystem\nGoogle Drive Reader\nDiscover LlamaIndex\nDiscover LlamaIndex\nDiscord Thread Management\nDocstores\nDocstores\nDynamo DB Docstore Demo\nRedis Docstore+Index Store Demo\nMongoDB Demo\nFirestore Demo\nDocstore Demo\nEmbeddings\nEmbeddings\nQdrant FastEmbed Embeddings\nText Embedding Inference\nEmbeddings with Clarifai\nBedrock Embeddings\nVoyage Embeddings\nOllama Embeddings\nGradient Embeddings\nCustom Embeddings\nGoogle Gemini Embeddings\nLocal Embeddings with HuggingFace\nAnyscale Embeddings\nOptimized Embedding Model using Optimum-Intel\nJina Embeddings\nFireworks Embeddings\nNomic Embedding\nMistralAI Embeddings\nDashscope embeddings\nJina 8K Context Window Embeddings\nLLMRails Embeddings\nGoogle PaLM Embeddings\nInteracting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex\nLangChain Embeddings\nElasticsearch Embeddings\nOpenAI Embeddings\nCohereAI Embeddings\nTogether AI Embeddings\nLlamafile Embeddings\nPremAI Embeddings\nAleph Alpha Embeddings\nOptimized BGE Embedding Model using IntelÂ® Extension for Transformers\nCloudflare Workers AI Embeddings\nLocal Embeddings with OpenVINO\nLocal Embeddings with IPEX-LLM\nOctoAI Embeddings\nEvaluation\nEvaluation\nTonic Validate Evaluators\nEmbedding Similarity Evaluator\nBatchEvalRunner - Running Multiple Evaluations\nBenchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset\nBenchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset\nAnswer Relevancy and Context Relevancy Evaluations\nEvaluation using Prometheus model\nFaithfulness Evaluator\nHotpotQADistractor Demo\nSelf Correcting Query Engines - Evaluation & Retry\nCorrectness Evaluator\nHow to use UpTrain with LlamaIndex\nQuestionGeneration\nRetrieval Evaluation\nEvaluating Multi-Modal RAG\nBEIR Out of Domain Benchmark\nRelevancy Evaluator\nðŸš€ RAG/LLM Evaluators - DeepEval\nGuideline Evaluator\nPairwise Evaluator\nFinetuning\nFinetuning\nFine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex\nFine Tuning Nous-Hermes-2 With Gradient and LlamaIndex\nFine Tuning for Text-to-SQL With Gradient and LlamaIndex\nFinetune Embeddings\nFinetuning an Adapter on Top of any Black-Box Embedding Model\nFine Tuning with Function Calling\nCustom Cohere Reranker\nFine Tuning GPT-3.5-Turbo\nHow to Finetune a cross-encoder using LLamaIndex\nFine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\nKnowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\nRouter Fine-tuning\nIngestion\nIngestion\nAsync Ingestion Pipeline + Metadata Extraction\nParallelizing Ingestion Pipeline\nIngestion Pipeline + Document Management\nBuilding a Live RAG Pipeline over Google Drive Files\nAdvanced Ingestion Pipeline\nRedis Ingestion Pipeline\nLlama Datasets\nLlama Datasets\nContributing a LlamaDataset To LlamaHub\nBenchmarking RAG Pipelines With A LabelledRagDatatset\nDownloading a LlamaDataset from LlamaHub\nLlamaDataset Submission Template Notebook\nLlama Hub\nLlama Hub\nOllama Llama Pack Example\nLlama Packs Example\nLlamaHub Demostration\nLlama Pack - Resume Screener ðŸ“„\nLLMs\nLLMs\nRunGPT\nWatsonX\nOpenLLM\nOpenAI JSON Mode vs. Function Calling for Data Extraction\nMyMagic AI LLM\nPortkey\nEverlyAI\nPaLM\nCohere\nVertex AI\nPredibase\nLlama API\nClarifai LLM\nBedrock\nReplicate - Llama 2 13B\nGradient Model Adapter\nMaritalk\nNvidia TensorRT-LLM\nXorbits Inference\nAzure OpenAI\nGemini\nHugging Face LLMs\nAnyscale\nReplicate - Vicuna 13B\nOpenRouter\nFireworks\nðŸ¦™ x ðŸ¦™ Rap Battle\nvLLM\nDashScope LLMS\nLocalAI\nLLM Predictor\nMistralAI\nMonster API <> LLamaIndex\nAI21\nLlamaCPP\nNvidia Triton\nPerplexity\nLiteLLM\nOllama - Llama 2 7B\nNeutrino AI\nGroq\nLangchain\nInteracting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex\nOpenAI\nAnthropic\nGradient Base Model\nOllama - Gemma\nKonko\nTogether AI LLM\nFireworks Function Calling Cookbook\nFriendli\nModelScope LLMS\nllamafile\nPremAI LlamaIndex\nSolar LLM\nAleph Alpha\nIPEX-LLM\nDataBricks\nOpenVINO LLMs\nOctoAI\nLow Level\nLow Level\nBuilding RAG from Scratch (Open-source only!)\nBuilding an Advanced Fusion Retriever from Scratch\nBuilding a Router from Scratch\nBuilding Retrieval from Scratch\nBuilding Evaluation from Scratch\nBuilding Response Synthesis from Scratch\nBuilding a (Very Simple) Vector Store from Scratch\nBuilding Data Ingestion from Scratch\nManaged Indexes\nManaged Indexes\nVectara Managed Index\nSemantic Retriever Benchmark\nGoogle Generative Language Semantic Retriever\nManaged Index with Zilliz Cloud Pipelines\nMetadata Extractors\nMetadata Extractors\nMetadata Extraction and Augmentation w/ Marvin\nAutomated Metadata Extraction for Better Retrieval + Synthesis\nPydantic Extractor\nEntity Metadata Extraction\nExtracting Metadata for Better Document Indexing and Understanding\nMulti-Modal\nMulti-Modal\nLlaVa Demo with LlamaIndex\nRetrieval-Augmented Image Captioning\nMulti-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\nSemi-structured Image Retrieval\nGPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\nMulti-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\nMulti-Modal LLM using DashScope qwen-vl model for image reasoning\nMulti-Modal LLM using OpenAI GPT-4V model for image reasoning\n[Beta] Multi-modal ReAct Agent\nMulti-Modal LLM using Azure OpenAI GPT-4V model for image reasoning\nMulti-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\nMultimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore\nMultimodal Ollama Cookbook\nChroma Multi-Modal Demo with LlamaIndex\nMulti-Modal GPT4V Pydantic Program\nAdvanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\nImage to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\nMulti-Modal LLM using Anthropic model for image reasoning\nMulti-Tenancy\nMulti-Tenancy\nMulti-Tenancy RAG with LlamaIndex\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nSemantic Chunker\nNode Postprocessors\nNode Postprocessors\nFile Based Node Parsers\nMetadata Replacement + Node Sentence Window\nPII Masking\nForward/Backward Augmentation\nRankGPT Reranker Demonstration (Van Gogh Wiki)\nLLM Reranker Demonstration (Great Gatsby)\nSentenceTransformerRerank\nLLM Reranker Demonstration (2021 Lyft 10-k)\nLongContextReorder\nCohere Rerank\nRecency Filtering\nColbert Rerank\nFlagEmbeddingReranker\nSentence Embedding Optimizer\nTime-Weighted Rerank\nJina Rerank\nRankLLM Reranker Demonstration (Van Gogh Wiki)\nOpenVINO Rerank\nObject Stores\nObject Stores\nThe ObjectIndex Class\nOutput Parsers\nOutput Parsers\nLLM Pydantic Program\nFunction Calling Program for Structured Extraction\nOpenAI Pydantic Program\nDataFrame Structured Data Extraction\nEvaporate Demo\nOpenAI function calling for Sub-Question Query Engine\nGuidance Pydantic Program\nGuardrails Output Parsing\nLangchain Output Parsing\nLM Format Enforcer Pydantic Program\nLM Format Enforcer Regular Expression Generation\nGuidance for Sub-Question Query Engine\nParam Optimizer\nParam Optimizer\n[WIP] Hyperparameter Optimization for RAG\nQuery Pipeline\nQuery Pipeline\nAn Introduction to LlamaIndex Query Pipelines\nQuery Pipeline over Pandas DataFrames\nQuery Pipeline for Advanced Text-to-SQL\nQuery Pipeline with Async/Parallel Execution\nQuery Pipeline with Routing\nQuery Pipeline Chat Engine\nPrompts\nPrompts\nAdvanced Prompt Techniques (Variable Mappings, Functions)\nEmotionPrompt in RAG\nPrompt Engineering for RAG\nAccessing/Customizing Prompts within Higher-Level Modules\n\"Optimization by Prompting\" for RAG\nQuery Engines\nQuery Engines\nKnowledge Graph RAG Query Engine\nJSONalyze Query Engine\nRetriever Router Query Engine\n[Beta] Text-to-SQL with PGVector\nSQL Join Query Engine\nCitationQueryEngine\nPandas Query Engine\nEnsemble Query Engine Guide\nJSON Query Engine\nRouter Query Engine\nQuery Engine with Pydantic Outputs\nCogniswitch query engine\nRecursive Retriever + Query Engine Demo\nSQL Router Query Engine\nJoint Tabular/Semantic QA over Tesla 10K\nRecursive Retriever + Document Agents\nJoint QA Summary Query Engine\nStructured Hierarchical Retrieval\nFLARE Query Engine\nKnowledge Graph Query Engine\nSub Question Query Engine\nSQL Auto Vector Query Engine\nDefining a Custom Query Engine\nRetriever Query Engine with Custom Retrievers - Simple Hybrid Search\nQuery Transformations\nQuery Transformations\nQuery Transform Cookbook\nHyDE Query Transform\nMulti-Step Query Engine\nResponse Synthesizers\nResponse Synthesizers\nPydantic Tree Summarize\nRefine\nRefine with Structured Answer Filtering\nPydantic Tree Summarize\nStress-Testing Long Context LLMs with a Recall Task\nTree Summarize\nRetrievers\nRetrievers\nBM25 Retriever\nComposable Objects\nRouter Retriever\nRecursive Retriever + Node References\nChunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)\nAuto-Retrieval from a Vectara Index\nPathway Retriever\nComparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\nEnsemble Retrieval Guide\nSimple Fusion Retriever\nAuto Merging Retriever\nRecursive Retriever + Node References + Braintrust\nActiveloop Deep Memory\nYou.com Retriever\nReciprocal Rerank Fusion Retriever\nRelative Score Fusion and Distribution-Based Score Fusion\nVideoDB Retriever\nBedrock (Knowledge Bases)\nTools\nTools\nOnDemandLoaderTool Tutorial\nEvaluation Query Engine Tool\nTransforms\nTransforms\nTransforms Evaluation\nUse Cases\nUse Cases\n10Q Analysis\n10K Analysis\nGithub Issue Analysis\nEmail Data Extraction\nVector Stores\nVector Stores\nTypesense Vector Store\nBagel Vector Store\nRockset Vector Store\nTencent Cloud VectorDB\nQdrant Vector Store\nTimescale Vector Store (PostgreSQL)\nMongoDBAtlasVectorSearch\nDocArray InMemory Vector Store\nAuto-Retrieval from a Vector Database\nZep Vector Store\nFaiss Vector Store\nGuide: Using Vector Store Index with Existing Pinecone Vector Store\nGuide: Using Vector Store Index with Existing Weaviate Vector Store\nSimple Vector Store\nQdrant Hybrid Search\nDeep Lake Vector Store Quickstart\nPinecone Vector Store - Metadata Filter\nQdrant Vector Store - Default Qdrant Filters\nAuto-Retrieval from a Vector Database\nClickHouse Vector Store\nS3/R2 Storage\ntxtai Vector Store\nCassandra Vector Store\nElasticsearch\nAwadb Vector Store\nPostgres Vector Store\nChroma Vector Store\nAzure CosmosDB MongoDB Vector Store\nUpstash Vector Store\nNeo4j vector store\nElasticsearch Vector Store\nLocal Llama2 + VectorStoreIndex\nMyScale Vector Store\nMetal Vector Store\nSimple Vector Store - Async Index Creation\nTair Vector Store\nPinecone Vector Store\nMongoDBAtlasVectorSearchRAGOpenAI\nRedis Vector Store\nJaguar Vector Store\nLlama2 + VectorStoreIndex\nWeaviate Vector Store\nSupabase Vector Store\npgvecto.rs\nWeaviate Vector Store Metadata Filter\nWeaviate Vector Store - Hybrid Search\nDocArray Hnsw Vector Store\nDashVector Vector Store\nOpensearch Vector Store\nPinecone Vector Store - Hybrid Search\nQdrant Vector Store - Metadata Filter\nSimple Vector Stores - Maximum Marginal Relevance Retrieval\nA Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)\nChroma\nLanceDB Vector Store\nBagel Network\nEpsilla Vector Store\nMilvus Vector Store\nAzure AI Search\nLantern Vector Store\nAstra DB\nLantern Vector Store (auto-retriever)\nAuto-Retrieval from a Weaviate Vector Database\nDatabricks Vector Search\nChroma + Fireworks + Nomic with Matryoshka embedding\nDuckDB\nBaidu VectorDB\nnow make sure you create the search index with the right name here\nAdvanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\nAnalyticDB\nTiDB Vector Store\nAmazon Neptune - Neptune Analytics vector store\nCouchbaseVectorStoreDemo\nVearchDemo\nNeo4j Vector Store - Metadata Filter\nAWSDocDBDemo\nComponent Guides\nComponent Guides\nModels\nModels\nLLMs\nLLMs\nUsing LLMs\nStandalone Usage\nCustomizing LLMs\nAvailable LLM Integrations\nEmbeddings\nMulti Modal\nPrompts\nPrompts\nUsage pattern\nLoading\nLoading\nDocuments and Nodes\nDocuments and Nodes\nUsing Documents\nUsing Nodes\nMetadata Extraction\nSimpleDirectoryReader\nData Connectors\nData Connectors\nUsage Pattern\nLlamaParse\nModule Guides\nNode Parsers / Text Splitters\nNode Parsers / Text Splitters\nNode Parser Modules\nIngestion Pipeline\nIngestion Pipeline\nTransformations\nIndexing\nIndexing\nIndex Guide\nVector Store Index\nDocument Management\nLlamaCloud\nMetadata Extraction\nModules\nStoring\nStoring\nVector Stores\nDocument Stores\nIndex Stores\nChat Stores\nKey-Value Stores\nPersisting & Loading Data\nCustomizing Storage\nQuerying\nQuerying\nQuery Engines\nQuery Engines\nUsage Pattern\nResponse Modes\nStreaming\nModule Guides\nSupporting Modules\nChat Engines\nChat Engines\nUsage Pattern\nModule Guides\nRetrieval\nRetrieval\nRetriever Modules\nRetriever Modes\nNode Postprocessors\nNode Postprocessors\nNode Postprocessor Modules\nResponse Synthesis\nResponse Synthesis\nResponse Synthesis Modules\nRouting\nQuery Pipelines\nQuery Pipelines\nUsage Pattern\nModule Guides\nModule Usage\nStructured Outputs\nStructured Outputs\nOutput Parsing Modules\nQuery Engines + Pydantic Outputs\nPydantic Program\nAgents\nAgents\nUsage Pattern\nLower-Level Agent API\nModule Guides\nTools\nEvaluation\nEvaluation\nUsage Pattern (Response Evaluation)\nUsage Pattern (Retrieval)\nModules\nLlamaDatasets\nLlamaDatasets\nContributing A LabelledRagDataset\nEvaluating With LabelledRagDataset's\nEvaluating Evaluators with LabelledEvaluatorDataset's\nObservability\nObservability\nInstrumentation\nSettings\nAdvanced Topics\nAdvanced Topics\nBuilding Performant RAG Applications for Production\nBasic Strategies\nAgentic strategies\nRetrieval\nRetrieval\nAdvanced Retrieval Strategies\nQuery Transformations\nEvaluation\nEvaluation\nComponent Wise Evaluation\nEnd-to-End Evaluation\nEvaluation\nFine-Tuning\nWriting Custom Modules\nBuilding RAG from Scratch (Lower-Level)\nAPI Reference\nAPI Reference\nAgents\nAgents\nCoa\nLats\nLlm compiler\nOpenai\nOpenai legacy\nReact\nCallbacks\nCallbacks\nAim\nArgilla\nArize phoenix\nDeepeval\nHoneyhive\nLangfuse\nLlama debug\nOpeninference\nPromptlayer\nToken counter\nUptrain\nWandb\nChat Engines\nChat Engines\nCondense plus context\nCondense question\nContext\nSimple\nEmbeddings\nEmbeddings\nAdapter\nAlephalpha\nAnyscale\nAzure openai\nBedrock\nClarifai\nClip\nCloudflare workersai\nCohere\nDashscope\nElasticsearch\nFastembed\nFireworks\nGemini\nGoogle\nGradient\nHuggingface\nHuggingface itrex\nHuggingface optimum\nHuggingface optimum intel\nInstructor\nIpex llm\nJinaai\nLangchain\nLlamafile\nLlm rails\nMistralai\nNomic\nOctoai\nOllama\nOpenai\nOpenvino\nPremai\nSagemaker endpoint\nText embeddings inference\nTogether\nVertex\nVoyageai\nEvaluation\nEvaluation\nAnswer relevancy\nContext relevancy\nCorrectness\nDataset generation\nFaithfullness\nGuideline\nMetrics\nMulti modal\nPairwise comparison\nQuery response\nResponse\nRetrieval\nSemantic similarity\nTonic validate\nIndexes\nIndexes\nColbert\nDocument summary\nGoogle\nKeyword\nKnowledge graph\nLlama cloud\nSummary\nTree\nVectara\nVector\nZilliz\nIngestion\nIngestion\nInstrumentation\nInstrumentation\nEvent handlers\nEvent types\nSpan handlers\nSpan types\nLLMs\nLLMs\nAi21\nAlephalpha\nAnthropic\nAnyscale\nAzure openai\nBedrock\nClarifai\nCohere\nCustom llm\nDashscope\nDatabricks\nEverlyai\nFireworks\nFriendli\nGemini\nGradient\nGroq\nHuggingface\nIpex llm\nKonko\nLangchain\nLitellm\nLlama api\nLlama cpp\nLlamafile\nLocalai\nMaritalk\nMistralai\nModelscope\nMonsterapi\nMymagic\nNeutrino\nNvidia tensorrt\nNvidia triton\nOctoai\nOllama\nOpenai\nOpenai like\nOpenllm\nOpenrouter\nOpenvino\nPalm\nPerplexity\nPortkey\nPredibase\nPremai\nReplicate\nRungpt\nSagemaker endpoint\nSolar\nTogether\nVertex\nVllm\nWatsonx\nXinference\nLlama Datasets\nLlama Datasets\nLlama Packs\nLlama Packs\nAgent search retriever\nAgents coa\nAgents lats\nAgents llm compiler\nAmazon product extraction\nArize phoenix query engine\nAuto merging retriever\nChroma autoretrieval\nCode hierarchy\nCogniswitch agent\nCohere citation chat\nCorrective rag\nDeeplake deepmemory retriever\nDeeplake multimodal retrieval\nDense x retrieval\nDiff private simple dataset\nDocugami kg rag\nEvaluator benchmarker\nFinchat\nFusion retriever\nFuzzy citation\nGmail openai agent\nGradio agent chat\nGradio react agent chatbot\nInfer retrieve rerank\nKoda retriever\nLlama dataset metadata\nLlama guard moderator\nLlava completion\nMulti document agents\nMulti tenancy rag\nMultidoc autoretrieval\nNebulagraph query engine\nNeo4j query engine\nNode parser semantic chunking\nOllama query engine\nPanel chatbot\nQuery understanding agent\nRaft dataset\nRag cli local\nRag evaluator\nRag fusion query pipeline\nRagatouille retriever\nRaptor\nRecursive retriever\nRedis ingestion pipeline\nResume screener\nRetry engine weaviate\nSearchain\nSelf discover\nSelf rag\nSentence window retriever\nSnowflake query engine\nStock market data query engine\nStreamlit chatbot\nSub question weaviate\nSubdoc summary\nTables\nTimescale vector autoretrieval\nTrulens eval packs\nVanna\nVectara rag\nVoyage query engine\nZephyr query engine\nMemory\nMemory\nChat memory buffer\nMetadata Extractors\nMetadata Extractors\nEntity\nKeyword\nMarvin\nPydantic\nQuestion\nSummary\nTitle\nMulti-Modal LLMs\nMulti-Modal LLMs\nAnthropic\nAzure openai\nDashscope\nGemini\nOllama\nOpenai\nReplicate\nNode Parsers & Text Splitters\nNode Parsers & Text Splitters\nCode\nHierarchical\nHtml\nJson\nLangchain\nMarkdown\nMarkdown element\nSemantic splitter\nSentence splitter\nSentence window\nToken text splitter\nUnstructured element\nNode Postprocessors\nNode Postprocessors\nNER PII\nPII\nAuto prev next\nCohere rerank\nColbert rerank\nEmbedding recency\nFixed recency\nFlag embedding reranker\nJinaai rerank\nKeyword\nLlm rerank\nLong context reorder\nLongllmlingua\nMetadata replacement\nOpenvino rerank\nPresidio\nPrev next\nRankgpt rerank\nRankllm rerank\nSbert rerank\nSentence optimizer\nSimilarity\nTime weighted\nVoyageai rerank\nObject Stores\nObject Stores\nOutput Parsers\nOutput Parsers\nGuardrails\nLangchain\nPydantic\nSelection\nPrograms\nPrograms\nEvaporate\nGuidance\nLlm text completion\nLmformatenforcer\nMulti modal\nOpenai\nPrompts\nPrompts\nQuery Engines\nQuery Engines\nFLARE\nJSONalayze\nNL SQL table\nPGVector SQL\nSQL join\nSQL table retriever\nCitation\nCogniswitch\nCustom\nKnowledge graph\nMulti step\nPandas\nRetriever\nRetriever router\nRetry\nRouter\nSimple multi modal\nSub question\nTool retriever router\nTransform\nQuery Pipeline\nQuery Pipeline\nAgent\nArg pack\nCustom\nFunction\nInput\nLlm\nMulti modal\nObject\nOutput parser\nPostprocessor\nPrompt\nQuery engine\nQuery transform\nRetriever\nRouter\nSynthesizer\nTool runner\nQuestion Generators\nQuestion Generators\nGuidance\nLlm question gen\nOpenai\nReaders\nReaders\nAgent search\nAirbyte cdk\nAirbyte gong\nAirbyte hubspot\nAirbyte salesforce\nAirbyte shopify\nAirbyte stripe\nAirbyte typeform\nAirbyte zendesk support\nAirtable\nApify\nArango db\nArxiv\nAsana\nAssemblyai\nAstra db\nAthena\nAwadb\nAzcognitive search\nAzstorage blob\nBagel\nBilibili\nBitbucket\nBoarddocs\nChatgpt plugin\nChroma\nClickhouse\nConfluence\nCouchbase\nCouchdb\nDad jokes\nDashvector\nDatabase\nDeeplake\nDiscord\nDocstring walker\nDocugami\nEarnings call transcript\nElasticsearch\nFaiss\nFeedly rss\nFeishu docs\nFeishu wiki\nFile\nFirebase realtimedb\nFirestore\nGcs\nGenius\nGithub\nGoogle\nGpt repo\nGraphdb cypher\nGraphql\nGuru\nHatena blog\nHive\nHubspot\nHuggingface fs\nHwp\nImdb review\nIntercom\nJaguar\nJira\nJoplin\nJson\nKaltura esearch\nKibela\nLilac\nLinear\nLlama parse\nMacrometa gdn\nMake com\nMangadex\nMangoapps guides\nMaps\nMbox\nMemos\nMetal\nMicrosoft onedrive\nMicrosoft outlook\nMicrosoft sharepoint\nMilvus\nMinio\nMondaydotcom\nMongodb\nMyscale\nNotion\nNougat ocr\nObsidian\nOpenalex\nOpenapi\nOpendal\nOpensearch\nPandas ai\nPapers\nPatentsview\nPathway\nPdb\nPdf table\nPinecone\nPreprocess\nPsychic\nQdrant\nRayyan\nReadme\nReadwise\nReddit\nRemote\nRemote depth\nS3\nSec filings\nSemanticscholar\nSimple directory reader\nSinglestore\nSlack\nSmart pdf loader\nSnowflake\nSnscrape twitter\nSpotify\nStackoverflow\nSteamship\nString iterable\nStripe docs\nTelegram\nTrello\nTwitter\nTxtai\nWeather\nWeaviate\nWeb\nWhatsapp\nWikipedia\nWordlift\nWordpress\nYoutube transcript\nZendesk\nZep\nZulip\nResponse Synthesizers\nResponse Synthesizers\nAccumulate\nCompact accumulate\nCompact and refine\nGeneration\nGoogle\nRefine\nSimple summarize\nTree summarize\nRetrievers\nRetrievers\nAuto merging\nBedrock\nBm25\nKeyword\nKnowledge graph\nMongodb atlas bm25 retriever\nPathway\nQuery fusion\nRecursive\nRouter\nSql\nSummary\nTransform\nTree\nVector\nVideodb\nYou\nSchema\nSchema\nStorage\nStorage\nChat Store\nChat Store\nRedis\nSimple\nDocstore\nDocstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nGraph Stores\nGraph Stores\nFalkordb\nKuzu\nNebula\nNeo4j\nNeptune\nSimple\nIndex Store\nIndex Store\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nSimple\nKvstore\nKvstore\nDynamodb\nElasticsearch\nFirestore\nMongodb\nPostgres\nRedis\nS3\nSimple\nStorage\nStorage\nStorage context\nVector Store\nVector Store\nAnalyticdb\nAstra db\nAwadb\nAwsdocdb\nAzureaisearch\nAzurecosmosmongo\nBagel\nBaiduvectordb\nCassandra\nChatgpt plugin\nChroma\nClickhouse\nCouchbase\nDashvector\nDatabricks\nDeeplake\nDocarray\nDuckdb\nDynamodb\nElasticsearch\nEpsilla\nFaiss\nGoogle\nJaguar\nKdbai\nLancedb\nLantern\nMetal\nMilvus\nMongodb\nMyscale\nNeo4jvector\nNeptune\nOpensearch\nPgvecto rs\nPinecone\nPostgres\nQdrant\nRedis\nRocksetdb\nSimple\nSinglestoredb\nSupabase\nTair\nTencentvectordb\nTidbvector\nTimescalevector\nTxtai\nTypesense\nUpstash\nVearch\nWeaviate\nZep\nTools\nTools\nArxiv\nAzure cv\nAzure speech\nAzure translate\nBing search\nBrave search\nChatgpt plugin\nCode interpreter\nCogniswitch\nDatabase\nDuckduckgo\nExa\nFinance\nFunction\nGoogle\nGraphql\nIonic shopping\nLoad and search\nMetaphor\nMultion\nNeo4j\nNotion\nOndemand loader\nOpenai\nOpenapi\nPassio nutrition ai\nPlaygrounds\nPython file\nQuery engine\nQuery plan\nRequests\nRetriever\nSalesforce\nShopify\nSlack\nTavily research\nText to image\nTool spec\nVector db\nWaii\nWeather\nWikipedia\nWolfram alpha\nYahoo finance\nYelp\nZapier\nOpen-Source Community\nOpen-Source Community\nIntegrations\nFull Stack Projects\nCommunity FAQ\nCommunity FAQ\nChat Engines\nDocuments and Nodes\nEmbeddings\nLarge Language Models\nQuery Engines\nVector Database\nContributing\nContributing\nCode\nDocs\nChangelog\nPresentations\nUpgrading to v0.10.x\nDeprecated Terms\nLlamaCloud\nLlamaCloud\nLlamaParse\nTable of contents\nCustomizing the ID\nDefining and Customizing Nodes#\n\nNodes represent \"chunks\" of source Documents, whether that is a text chunk, an image, or more. They also contain metadata and relationship information with other nodes and index structures.\n\nNodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes.\n\nFor instance, you can do\n\nfrom llama_index.core.node_parser import SentenceSplitter\n\nparser = SentenceSplitter()\n\nnodes = parser.get_nodes_from_documents(documents)\n\n\nYou can also choose to construct Node objects manually and skip the first section. For instance,\n\nfrom llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n\nnode1 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\nnode2 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\n# set relationships\nnode1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n    node_id=node2.node_id\n)\nnode2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n    node_id=node1.node_id\n)\nnodes = [node1, node2]\n\n\nThe RelatedNodeInfo class can also store additional metadata if needed:\n\nnode2.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n    node_id=node1.node_id, metadata={\"key\": \"val\"}\n)\n\nCustomizing the ID#\n\nEach node has an node_id property that is automatically generated if not manually specified. This ID can be used for a variety of purposes; this includes being able to update nodes in storage, being able to define relationships between nodes (through IndexNode), and more.\n\nYou can also get and set the node_id of any TextNode directly.\n\nprint(node.node_id)\nnode.node_id = \"My new node_id!\"\n\n Back to top\nPrevious\nUsing Documents\nNext\nMetadata Extraction\n\nðŸ¦™\n\nâŒ˜ + K",
            "word_count": 3530
        }
    }
}